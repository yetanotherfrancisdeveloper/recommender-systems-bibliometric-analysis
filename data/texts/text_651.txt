Sciences,Beijing,China & School of Cyber Security, Institute of Information Engineering, Chinese Academy ofInstitute of Information Engineering, Chinese Academy of Sciences,Beijing,China & School of Cyber Security, The core objective of modelling recommender systems from implicit feedback is to maximize the positive sample scoreğ‘ and minimize the negative sample scoreğ‘ , which can usually be summarized into two paradigms: the pointwise and the pairwise. The pointwise approaches î€›t each sample with its label individually, which is î€exible in weighting and sampling on instance-level but ignores the inherent ranking property. By qualitatively minimizing the relative scoreğ‘ âˆ’ğ‘ , the pairwise approaches capture the ranking of samples naturally but suî€er from training eî€œciency. Additionally, both approaches are hard to explicitly provide a personalized decision boundary to determine if users are interested in items unseen. To address those issues, we innovatively introduce an auxiliary score ğ‘for each user to represent the User Interest Boundary(UIB) and individually penalize samples that cross the boundary with pairwise paradigms, i.e., the positive samples whose score is lower thanğ‘ and the negative samples whose score is higher thanğ‘. In this way, our approach successfully achieves a hybrid loss of the pointwise and the pairwise to combine the advantages of both. Analytically, we show that our approach can provide a personalized decision boundary and signiî€›cantly improve the training eî€œciency without any special sampling strategy. Extensive results show that our approach achieves signiî€›cant improvements on not only the classical pointwise or pairwise models but also state-of-the-art models with complex loss function and complicated feature encoding. â€¢ Computing methodologies â†’ Ranking;â€¢ Information systems â†’ Learning to rank. Gaoling School of Artiî€›cial Intelligence, Renmin University of China, Beijing Key Laboratory of Big Data ACM Reference Format: Jianhuan Zhuo, Qiannan Zhu, Yinliang Yue, and Yuhong Zhao. 2018. Learning Explicit User Interest Boundary for Recommendation. In Woodstock â€™18: ACM Symposium on Neural Gaze Detection, June 03â€“05, 2018, Woodstock, NY . ACM, New York, NY, USA, 12 pages. https://doi.org/10.1145/1122445.1122456 scorescorescore With the problem of information overload, recommendation system plays an important role to provide useful information for users eî€œciently. As the widely used technique of the recommendation system, collaborative î€›ltering (CF) based methods usually leverage the user interaction behaviours to model usersâ€™ potential preferences and recommend items to users based on their preferences [14]. Generally, given the user-item interaction data, a typical CF approach generally consists of two steps: (i) deî€›ning a scoring function to calculate the relevance scores between the user and candidate items, (ii) deî€›ning a loss function to optimize the total relevance scores of all observed user-item interaction. From the view of the loss deî€›nition, the CF methods are usually optimized by a loss function that assigns higher scoresğ‘ to observed interactions (i.e., positive instances) and lower scoresğ‘ to unobserved interactions (i.e., negative instances). In the previous work, there are two types of loss functions designed for recommendation systems, namely, pointwise and pairwise. As shown in î€›gure 1(a), pointwise based approaches typically formulate the ranking task as a regression or classiî€›cation task, where the loss functionğœ“ (ğ‘¥,ğ‘™)directly optimizes the normalized relevance scoreğ‘ of the sampleğ‘¥into its labelğ‘™ âˆˆ {0, 1}. The sampleğ‘¥ = (ğ‘¢, ğ‘–)is the observed or unobserved pair of the userğ‘¢ and the itemğ‘–. Usually, the pointwise-based loss function uses a î€›xed hardline like 0.5 as the indictor to distinguish the sample as positive or negative, i.e., for all users in the ranking stage, samples whose scores more than 0.5 are regarded as positive, where the user ğ‘¢would be interested in the itemğ‘–. Correspondingly, the pairwise based approaches shown in î€›gure 1(b), take the pairs(ğ‘¥, ğ‘¥)of the positive and negative samples as input, and try to minimize the relative scoreğ‘ âˆ’ğ‘ by the loss functionğœ™ (ğ‘¥, ğ‘¥). The pairwise loss focuses on making the scoreğ‘ of positive samples greater than thatğ‘ of negative samples, which can get the plausibility of the sample ğ‘¥ = (ğ‘¢, ğ‘–) for being used in the ranking stage. Recently, such two paradigms of loss function are widely used in various recommendation methods, and helpful to achieve a promising recommendation performance. However, they still have disadvantages. They are hard to learn theexplicit userâ€™s personalized interest boundary, which can directly infer whether the user likes a given unseen item [5,16]. Factually, the users have their own interest boundary learned from their interactions for determining whether the sample is the positive sample in ranking stage. As mentioned above, the pointwise loss function is non-personalized and prone to determine the global interest boundary as a î€›xed hardline for all users, which may make the incorrect classiî€›cation for the users whose real interest boundary is lower than the î€›xed hardline. For example, in î€›gure 1(a), although the scoreğ‘†of the sampleğ‘¥is more than the usersâ€™ real interest boundary, the positive sample ğ‘¥ is still classiî€›ed into the negative group as its scoreğ‘†is lower than the î€›x hardline. While the pairwise approach is unable to provide an explicit personalized boundary for unseen candidate sampleğ‘¥ in î€›gure 1(b), because its scoreğ‘†learned by the relative scores can only reî€ect the plausibility of the sampleğ‘¥, not the explicit user-speciî€›c indicator of whether the sample is a positive sample in ranking stage. In addition, we are also interested in another issue, thelower training eî€œciencyproblem that prevents the pairwise models from obtaining optimal performance. For the pairwise, with the convergence of the model in the later stage of training, most of negative samples have been classiî€›ed correctly. In this case, the loss of most randomly generated training samples is zero, i.e., those samples are too â€œeasyâ€ to be classiî€›ed correctly and are unable to produce an eî€ective gradient to update models, which is also called the gradient vanishing problem. To alleviate this problem, previous work adopt the hard negative sample mining strategy to improve the probability of sampled eî€ective instances [6,7,24,32,35]. Although these methods are successful, they ignore the basic mechanism leading to the vanishing problem. Intuitively, hard samples are typically those near the boundary, and it is hard for the model to distinguish these samples well. Instead of improving the sampling strategy to mine a hard sample, why donâ€™t we directly use the boundary to represent the hard sample score? To address the issue mentioned above, we innovatively introduce an auxiliary scoreğ‘for each user and individually penalize samples that cross the boundary with the pairwise paradigm, i.e., the positive samples whose score is lower thanğ‘and the negative samples whose score is higher thanğ‘. The boundaryğ‘is meaningfully used to indicate user interest boundary(UIB), which can be used to explicitly determine whether an unseen item is worth recommending to users. As we can see from the î€›gure 1(c), the candidate sampleğ‘ can be easily predicted as positive by the UIB ğ‘of userğ‘¢. In this way, our approach successfully achieves a hybrid loss of the pointwise and the pairwise to combine the advantages of both. Speciî€›cally, it follows the pointwise in the whole loss expression while the pairwise inside each example. In the ideal state, the positive and negative samples should be separated by the boundaryğ‘, i.e., scores of positive samples are higher thanğ‘and those of negative are lower as î€›gure 1. The learned boundary can provide a personalized interest boundary for each user to predict unseen items. Additionally, diî€erent from previous works trying to mine hard samples, the boundaryğ‘can be directly interpreted as score of the hard samples, which signiî€›cantly improves the training eî€œciency without any special sampling strategy. Extensive results show that our approach achieves signiî€›cant improvements on not only classical models of the pointwise or pairwise approaches, but also state-of-the-art models with complex loss function and complicated feature encoding. The main contributions of this paper can be summarized as: â€¢We propose a novel hybrid loss to combine and complement the pointwise and pairwise approaches. As far as we know, it is the î€›rst attempt to introduce an auxiliary score for fusing pointwise and pairwise. â€¢We provide a eî€œcient and eî€ective boundary to match usersâ€™ interest scope. As the result, a personalized interest boundary of each user is learned, which can be used in the pre-ranking stage to î€›lter out abundant obviously worthless items. â€¢We analyze qualitatively the reason why the pairwise trains ineî€œciently, and further alleviate the gradient vanishing problem from the source by introducing an auxiliary score to represent as the hard sample. â€¢We conduct extensive experiments on four publicly available datasets to demonstrate the eî€ectiveness of UIB, where multiple baseline models achieve signiî€›cant performance improvements with UIB. For the implicit CF methods, the user-item interactions are the important resource in boosting the development of recommender systems. For convenience, we use the following consistent notations throughout this paper: the user set isUand the item set isX. Their possible interaction set is donoted asT = U Ã— X, in which the observed part is regarded as usersâ€™ real interaction historiesI âŠ‚ T. Formally, the labeling functionğ‘™ : T â†’ {0, 1}is used to indicate if a sample is observed, where a value of 1 denotes the interaction is positive (i.e. (ğ‘¢, ğ‘) âˆˆ I) and a value of 0 denotes the interaction is negative (i.e. (ğ‘¢, ğ‘›) âˆ‰ I). In implicit collaborative î€›ltering, the goal of models is to learn a score functionğ‘  : T â†’ Rto reî€ect the relevance between items î€exible samplingâˆšÃ—âˆšâˆšâˆš î€exible weightingÃ—âˆš Table 1: Features comparison among loss paradigms. and users. The loss function is used to indicate how well the score function î€›ts, which can usually be summarized into two paradigms: the pointwise and the pairwise. The pointwise approach formulates the task as a classiî€›cation task of single sample, whose loss functionğœ“directly optimizes the normalized relevance scoreğ‘  (ğ‘¢, ğ‘¥)between userğ‘¢and itemğ‘¥into its label ğ‘™ (ğ‘¢, ğ‘¥):îƒ• whereğœ“can be CrossEntropy [14] or Mean-Sum-Error [4] and so on. Since the pointwise approach optimizes each sample individually, it is î€exible on sampling and weighting on instance-level. However, as these scores depend on the observation context, î€›tting the sample into the î€›xed score is hard to reî€ect the inherent ranking property [22]. Instead of î€›tting samples with î€›xed scores, the pairwise approach tries to assign the positive samples with higher scores than that of the negative [2]. The loss function of the pairwise approach can be rewritten as:îƒ•îƒ• whereğœ™can be MarginLoss [15,18] or LnSigmoid [12,14] and so on. Although the pairwise approach can improve generalization performance by learning the qualitative scores between the positive and negative samples, it is hard to provide eî€ective ranking information in the inference stage and suî€ers from the gradient vanishing problem. The pointwise and the pairwise approaches have their two sides as shown in table 1. Intuitively, a better loss function can be obtained by fully combining the advantages of the two to further improve the recommendation performance. Hence, we seek a hybrid loss to combine and complement each other. We propose a new loss paradigm to combine the advantages of two mainstream methods and match the userâ€™s interest adaptively. Our approach is eî€ective and eî€œcient. As shown in equation 4, we innovatively introduce an auxiliary scoreğ‘âˆˆ Rfor each userğ‘¢ to represent the User Interest Boundary(UIB): wherePâˆˆ Ris the embedding vector of userğ‘¢,ğ‘Š âˆˆ Ris a learnable vector. Our loss comes from the weighted sum of two parts: the positive sample loss partğ¿and the negative sample loss partğ¿. Within theğ¿andğ¿, the pairwise loss is used to penalize samples that cross the decision boundaryğ‘, i.e. the positive samples whoseğ‘  (ğ‘¢, ğ‘)is lower thanğ‘and the negative samples whoseğ‘  (ğ‘¢, ğ‘›)is higher thanğ‘. Formally, the loss function of our approach can be rewritten as: L =ğœ™ (ğ‘âˆ’ğ‘ (ğ‘¢, ğ‘))+ğ›¼ğœ™ (ğ‘ (ğ‘¢, ğ‘›) âˆ’ğ‘)(4) whereğ›¼is a hyperparameter to balance the contribution weights of positive and negative samples. Our approach can be regarded asthe hybrid loss of the pointwise and the pairwise, which is signiî€›cantly diî€erent from previous works. On one hand, the pointwise loss usually optimizes each sample to match its label, which is î€exible but not suitable for rank-related tasks. On another hand, the pairwise loss takes a pair of the positive and negative samples, then optimizes the model to make their scores orderly, which is a great success but suî€ers from the gradient vanishing problem. Our approach successfully combines and complements each other by introducing an auxiliary scoreğ‘. Speciî€›cally, in the whole loss expression, it follows the pointwise loss because the positive samples and negative samples are calculated separately inğ¿andğ¿. Inside theğ¿andğ¿, each sample is applied the pairwise loss, e.g. the margin loss, with the auxiliary scoreğ‘. In other words, the pairwise loss is applied on (ğ‘âˆ’ğ‘  (ğ‘¢, ğ‘))and(ğ‘  (ğ‘¢, ğ‘›) âˆ’ğ‘)respectively rather than traditional (ğ‘  (ğ‘¢, ğ‘›) âˆ’ğ‘  (ğ‘¢, ğ‘)). In this way, our approach can provide a î€exible and eî€œcient loss function. The learnedğ‘can provide a personalized decision boundary to determine whether the user likes the item in the inference stage. The explicit boundary is useful for many applications, e.g. î€›lter out abundant obviously worthless items in the pre-ranking stage. Why it is personalized? From the view of gradient direction, the ideal boundary of userğ‘¢is adaptively matched under the balance between positive and negative samples, which provides a personalized decision boundary for diî€erent users. Concretely, to optimize the loss function equation 4 we proposed, the optimizer has to penalize two-part simultaneously: the positive partğ¿and the negative partğ¿. During the process, theğ¿upward forces the scores of positive samples and downward forces the boundaryğ‘like the green arrow in î€›gure 2, while theğ¿upward forces the boundary ğ‘and downward forces the negative like the blue arrow. If the boundary is straying from its reasonable range, the unbalance gradient will push it back until it well-matched between positive and negative. Take the boundaryğ‘in î€›gure 2 for example. The boundary is mistakenly initialized to a very low score so that all negative samples are incorrectly classiî€›ed as positive. Consequently, the boundary is pushed upward to balance the lowğ¿and largeğ¿. As the result of the balance between positive and negative samples, the boundary can adaptively match the userâ€™s interest scope. Additionally, we also conduct experiments to verify this statement, detailed in section 4.6. As our approach explicitly learns the user interest boundary in the training stage, the boundary learned can be directly used to determine whether the user likes the item in the inference stage. It is easily used, such as regarding candidates with a higher score than boundary as the positive, otherwise the negative as shown in î€›gure 1(c). Our approach can signiî€›cantly improve the training eî€œciency without any special sampling strategy. The traditional pairwise loss function suî€ers from the gradient vanishing problem, especially in the later stage of training. Since the pairwise loss is to minimize the relative scoreÎ” = (ğ‘ âˆ’ğ‘ ), it is reasonable to useÎ”as an indicator to explain the training eî€œciency. For example, as shown in î€›gure 3, 9 pair training instances are generated by combining the scores of positive examples {ğ‘ ,ğ‘ ,ğ‘ } and the scores of negative examples {ğ‘ ,ğ‘ ,ğ‘ }, but only the pair (ğ‘ ,ğ‘ ) can provide eî€ective gradient information to update the model, i.e. is not classiî€›ed correctly or â€œcorruptedâ€ [13] asÎ” = (ğ‘ âˆ’ ğ‘ )greater than zero. That is1/9 probability. By introducing the boundary setting, our approach signiî€›cantly improves the training eî€œciency only with the simple uniform sampling strategy. From the view of negative sampling, the boundaryğ‘can be naturally interpreted as the hard negative sample for positive samples and the hard positive for negative ones. Concretely, both positive and negative samples are paired with the boundaryğ‘and result in 6 pair training instances, two of which are eî€ective, i.e.,(ğ‘ âˆ’ğ‘)and(ğ‘âˆ’ğ‘ ). That is1/3probability. Formally, let a dataset containsğ‘positive samples,ğ‘negative samples, andğ‘€eî€ective pairs of all possible combination results. Each time a training instance(ğ‘ , ğ‘ )is generated by randomly sampling, onlyğ‘€/ğ‘probability of the pairwise loss can provides eî€ective gradient information. While in our approach,ğ‘€/ğ‘probability can be achieved. Hence, compared with the traditional pairwise loss, our approach is more eî€œcient and signiî€›cantly alleviate the gradient vanishing problem. Furthermore, the advantage of our approach is proved experimentally in section 4.8. Our approach can provide a î€exible way to balance the negative and positive samples. In general, the positive samples are observed instances collected from usersâ€™ interaction history, while negative samples are instances that are not in the interaction history. As the method is diî€erent to obtain the positive and negative samples, it is unreasonable to treat both with the same weight and sampling strategy. As our approach optimizesğ¿andğ¿individually on the whole expression, we can assign a properğ›¼and develop diî€erent sampling strategy to balance classes. For sampling strategy, since the negative sample space is much larger than the positive, we use negative samples ofğ‘€times the positive to balance the class for each batch sampling. Signiî€›cantly, here we still use the simplest uniform sampling strategy instead of other advanced methods [6, 7,24,32,35]. For weighting, the introduction of the auxiliary score mechanism makes another way possible: adjustingğ›¼to enlarge or reduce the scoring space of positive and negative samples. Here, we denote the positive scoring spaceSas the range between boundary and the maximum score of positive samples, while the negative scoring spaceSas the range between boundary and the minimum score of negative samples as shown in î€›gure 4. Intuitively, the scoring space corresponds to the score range of a candidate sample determined as the positive sample or negative. Amplifying Lby increasingğ›¼will push the boundary upward and compress the positive scoring spaceSas shown on the right side of î€›gure 4. With the boundaryğ‘driven up, all positive samples obtain a larger upward gradient by largerLand gather into a more compact space. In this way, the expected score of positive and negative samples are limited in a proper range. our approach can adjustğ›¼to balance the negative and positive samples. Conversely, the same is true for reducingğ›¼. This phenomenon is also observed in the experiments with diî€erent ğ›¼ settings in section 4.7. In this section, we î€›rst introduce the baselines (including the boosted version via our approach), datasets, evaluation protocols, Figure 4: Boundary rebalance with larger ğ›¼ setting. and detailed experimental settings. Further, we show the experimental results and some analysis of them. In particular, our experiments mainly answer the following research questions: â€¢ RQ1How well can the proposed UIB boost the existing models? â€¢ RQ2How well does the boundary match the usersâ€™ interest scope? â€¢ RQ3How does theğ›¼aî€ect the behaviour of the boundary? â€¢ RQ4How does the proposed UIB improve the training eî€œciency? To verify the generality and eî€ectiveness of our approach, targeted experiments are conducted. Concretely, we reproduce the following four types of S.O.T.A. models as the baselines and implement the boosted version by our UIB loss. To compare the diî€erence among those architectures, table 2 list all score function and loss function used in the baselines and our boosted models. â€¢ Pairwise model, i.e. the BPR [28], which applies an inner product on the latent features of users and items and uses a pairwise loss, the LnSigmoid(also known as the soft hinge loss) to optimize the model as follows: In boosted version, the loss function is reformed into UIB style as: â€¢ Pointwise model, i.e. the NCF [14], which is a classical neural collaborative î€›ltering model. The NCF uses the crossentropy loss (pointwise approach) to optimize the model as equation 7. Here, we only use the MLP version of NCF as our baseline and replace the cross-entropy loss with UIB loss to build our boosted model. Speciî€›cally, we directly replace the loss function with equation 6 in the boosted version of NCF. L = âˆ’ğ‘™ (ğ‘¢, ğ‘¥)ln(ğ‘  (ğ‘¢, ğ‘)) + (1 âˆ’ğ‘™ (ğ‘¢, ğ‘¥))ln(1 âˆ’ğ‘  (ğ‘¢, ğ‘›)) (7) â€¢ Model with complicated loss function, i.e. the SML [18], which is a S.O.T.A. metric learning model. The loss function of SML not only makes sure the score of positive items is higher than that of negative, i.e.L, but also keeps positive items away from negative items, i.e.L. Furthermore, it extends the traditional margin loss with the dynamically adaptive margins to mitigate the impact of bias. The loss of SML can be characterized as: whereğ‘šandğ‘›are learnable margin parameters,ğœ†andğ›¾ are hyperparameters and theLis the regularization on dynamical margins. Since the loss of SML contains multiple pairwise terms, various adaptations on SML with UIB can be selected, which also shows the î€exibility of our approach to boost models with a complex loss function. Here, we boost the SML only by replacing the main part Lto: L= |ğ‘  (ğ‘¢, ğ‘›) âˆ’ğ‘+ğ‘š|+ğ›¼ |ğ‘âˆ’ğ‘ (ğ‘¢, ğ‘) +ğ‘š|(11) â€¢ Model with complicated feature encoding, i.e. the Light- GCN [12], is used to make sure our approach can work on advanced models. The LightGCN [12] is a state-of-the-art graph convolution network for the recommendation task. Here, we only focus on the loss part and employ the simpliî€›edG(Â·)to represent the complicated feature encoding process with the graph convolution network. LightGCN uses the same loss function as BPR [28] in equation 5. To boost the LightGCN, we remain the score functionğ‘  (ğ‘¢ , ğ‘¥ ) = G(ğ‘¢)G(ğ‘¥)and only replace the loss function with equation 6. In order to evaluate the performance of each model comprehensively, we select four publicly available datasets including diî€erent types and sizes. The detailed statistics of the datasets are shown in table 3. â€¢Amazon Instant Video (AIV) is a video subset of Amazon Dataset benchmark, which contains product reviews and metadata from Amazon [11]. We follow the 5-core, which promises that each user and item have 5 reviews at least. â€¢LastFM dataset [3] contains music artist listening information from Last.fm online music system. â€¢Movielens-1M (ML1M)dataset [10] contains 1M anonymous movie ratings to describe usersâ€™ preferences on movies. â€¢Movielens-10M (ML10M) dataset is the large version of ML1M, which contains 10 million ratings of 10,677 movies by 72,000 lnğœ(ğ‘  (ğ‘¢, ğ‘) âˆ’ğ‘Ã lnğœ(ğ‘  (ğ‘¢, ğ‘) âˆ’ğ‘Ã lnğœ(ğ‘  (ğ‘¢, ğ‘) âˆ’ğ‘ users. We use this dataset to check whether our approach works well on the large dataset. We use Hit Ratio(Hit@K), Normalized Discounted Cumulative Gain(NDCG@K) and Mean Reciprocal Rank(MRR@K) to evaluate the models, where K is selected from classical settings {1, 10}. The higher value of all measures means the better performance. As Hit@1, NDCG@1 and MRR@1 are equivalent mathematically, we only report the Hit@1, Hit@10, NDCG@10 and MRR@10. All datasets are split by the popular One-Leave-Out strategy [14, 28] as table 3. In the testing phase, models learned are asked to rank a given item list for each user. As the space of negative sampling is extremely huge or unknown in the real world, for each positive sample in the test set, we î€›x the number of its relevant negative items as 100 negative samples [18]. Each experiment is independently repeated 5 times on the same candidates and the average performance is reported. We use the PyTorch [25] to implement all models and use Adagrad [8] optimizer to learn all models. To make the comparison fair, the dimensionğ‘‘and batch size of all experiments are assigned as 32and1024, respectively. For all boosted version,ğ‘€ = 32is used to balance classes as discussed in section 3.4. Grid search with early stop strategy on NDCG@10 of the validation dataset is adopted to determine the best hyperparameter conî€›guration. Each experiment runs 500 epochs for all datasets except ML10M, which is limited to 100 epochs due to its big size. The detailed hyperparameter conî€›guration table is reported in the appendix. Ãlnğœ(ğ‘  (ğ‘¢ , ğ‘) âˆ’ğ‘  (ğ‘¢, ğ‘›)) From the results shown in î€›gure 4, we make three observations: (1) Comparing our boosted versions and the baselines on all datasets, our approach works well for all data sets to improves the model, even if in the large ML10M dataset. It conî€›rms that our model successfully uses the UIB to improve the prediction performance on the recommendation task. Speciî€›cally, compared with the baselines, our models achieve a consistent average improvement of 6.669% on HIT@1, 1.579% on HIT@10, 3.193% on NDCG@10, 4.078% on MRR@10 for the AIV dataset, 4.153%, 1.013%, 2.345%, 2.909% for the LastFM dataset, 5.075%, 0.782%, 2.001%, 2.608% for the ML1M dataset and 4.987%, 0.2946%, 2.341%, 3.277% for the ML10M dataset. Among them, the improvement on HIT@1 is the most impressive, reaching 5.22% average on all datasets. (2) Comparing the pointwise and pairwise models, our approach achieves a higher performance, concretely, 9.18%, 0.68%, 3.83%, 5.34% average improvements for pointwise approach and 5.81%, 1.36%, 3.10%, 3.94% for pairwise approach. It conî€›rms that the UIB loss can be used to boost pointwise or pairwise based models dominated in the recommendation system. It is because our approach can help for learning inherent ranking property to boost the pointwise and improves training eî€œciency to boost the pairwise. (3) Compared to the state-of-theart model LightGCN [12] with complicated feature encoding, our boosted model LightGCN+UIB makes an average gain of 4.73% on HIT@1, 0.93% on HIT@10, 2.30% on NDCG@10 and 2.97% on MRR@10, which suggests our approach also works on the deep learning models. To determine how well the boundary matches the userâ€™s interest scope, we essentially need to answer two sub-questions: (1) Does the model match diî€erent boundaries for diî€erent users? (2) Does the matched boundary is the best value? To answer the î€›rst question, learned boundary distributions of NCF+UIB on four datasets are visualized in î€›gure 5. It conî€›rms that our model matches diî€erent boundaries for diî€erent users in the form of diî€erent normal distributions. To answer the second question, we add extra oî€sets {-5,-4. . .4,5} on theğ‘and make predictions on all items for users. Then the precision, recall, and F1 measures are reported to determine if the boundary learned is the best. As the results shows in Figure 5: Boundary distribution on diî€erent datasets. î€›gure 6, (1) The boundary learned makes a competitive performance. Speciî€›cally, the F1 measure of 54% in AIV, 48% in LastFM, 58% in ML1M, and 51% in ML10M are achieved, which suggests the boundary is competent to match the userâ€™s interest scope. (2) From all datasets, reducing oî€set consistently increases recall and reduces accuracy, and vice versa. When the oî€set is zero, F1 that considers both precision and recall performs best which shows that our method can learn the best boundary matching the userâ€™s interest scope. As discussed in section 3.2, the boundary is the best result of game between positive and negative samples, which can save computing by î€›ltering out abundant obviously worthless items Figure 6: Measures with diî€erent oî€set on boundary. in the pre-ranking stage, like 1674 of 1685 items (99.37%) for AIV, 17562 of 17617(99.69%) fro LastFM, 3529 of 3706(95.24%) for ML1M, 10576 of 10677 (99.06%) for ML10M. In our approach, only one hyperparameterğ›¼is introduced to balance the contributions of positive and negative samples. To investigate how does theğ›¼aî€ect the behaviour of our approach, experiments with variousğ›¼ âˆˆ{0.1,0.2,1,2,4,8,16} settings are conducted based on the optimal experiment of NCF+UIB in LastFM datasets. We also provides the results on other datasets in the appendix. Besides the performance and boundary distribution comparison, we also analyze the score distribution changes of positive and negative samples. The experimental results in î€›gure 7 show that: (1) From the î€›rst cell of î€›gure 7, it is conî€›rmed that theğ›¼does aî€ect the performance and here exists an optimalğ›¼to achieve the best performance. (2) Along with the growth ofğ›¼, boundaryğ‘consistently increases, which suggests that theğ›¼is strongly relative with boundary distribution. This phenomenon conî€›rms that increasing ğ›¼to emphasize the negative loss part actually forces upward the boundary and aî€ects both positive and negative sides at the same time. (3) From the change of positive sample score distribution at the bottom-left, it is conî€›rmed that the positive sample score space is compressed caused by the growth ofğ›¼. (4) We also observe that the negative sample score distribution becomes compact at the bottom-right cell. It is because the largerğ›¼also enlarges the loss of â€œmarginâ€, such asğ›¾in the MarginLossmax(0, Î” +ğ›¾), which pushes negative samples farther from the boundary and becomes compact. Figure 7: Mo del comparison with diî€erent ğ›¼ settings. To show the ability of our approach to improve training eî€œciency and alleviate the gradient vanishing problem that plague the traditional pairwise approach, experiments on BPR(the pairwise approach) and BPR+UIB(ours) are conducted to compare the rate of corrupted samples through epochs, i.e. the proportion of training samples that model classify incorrectly. Usually, a high corrupted rate means that a higher proportion of training samples can provide gradient information to optmize model. As shown in î€›gure 8, the x-axis is the epoch through training, while the y-axis is the corrupted rate. The red is computed by our approach, while the blue is by the traditional pairwise approach. From î€›gure 8, we can observe that the corrupted rate in our model is higher than that in BPR loss on all datasets. Consistent with previous literature, the training eî€œciency of the traditional pairwise model decreases obviously with the convergence, that is, the gradient vanishing. This leads to low training eî€œciency. Especially in ML10M and ML1M datasets, the proportion of training samples that can provide eî€ective gradient is low after 10 epochs. Our approach maintains a certain eî€ective gradient in training for all datasets, especially in the AIV dataset. As discussed in section 3.3, this is because the boundary itself is a good hard sample to guide the training. This paper tries to combine and complement the two mainstream loss paradigms for the recommendation task. As the pointwise and the pairwise approaches have their advantages and limitations [22], several methods have been proposed to improve the loss function [9,33]. Bellogin et al. [1]improved the recommendations based on the formation of user neighbourhoods. Liu et al. [19]proposed Wasserstein automatic coding framework to improve data sparsity and optimize uncertainty. The pairwise approach is good at modeling the inferent ranking property but suî€ers the inî€exible optimization [31]. Lo and Ishigaki[20]proposed a personalized pairwise weighting framework for BPR loss function, which makes the model overcome the limitations of BPR on cold start of items. Sidana et al. [29]proposed a model that can jointly learn the new representation of users and items in the embedded space, as well as the userâ€™s preference for item pairs. Mao et al. [21]considers loss function and negative sampling ratio equivalently and propose a uniî€›ed CF model to incorporate both. Zhou et al. [36]introduces a limitations to ensure the fact that the scoring of correct instances must be low enough to fulî€›ll the translation. Inspired by metric learning [31], several researchers try to employ the metric learning to optimize the recommendation model [15,17,18,23,30]. In addition, the problem of low training eî€œciency of paired method has also attracted much attention. Uniform Sampling approaches are widely used in training collaborative î€›ltering because of their simplicity and extensibility [14]. Advanced methods try to mine the hard negative samples to improve the training eî€œciency, including attribute-based [26,27], GAN-based [6,24,32], Cache-based [7,35] and Random-walk-based methods [34]. Chen et al. [4]provides another way by directly using all samples in the negative sample space. In this work, we innovatively introduce an auxiliary scoreğ‘for each user to represent the User Interest Boundary(UIB) and individually penalize samples that cross the boundary with pairwise paradigms. In this way, our approach successfully achieves a hybrid loss of the pointwise and the pairwise to combine the advantages of both. Speciî€›cally, it follows the pointwise in the whole loss expression while the pairwise inside each example. Analytically, we show that our approach can provide a personalized decision boundary and signiî€›cantly improve the training eî€œciency without any special sampling strategy. Extensive results show that our approach achieves signiî€›cant improvements on not only classical models of the pointwise or pairwise approaches, but also state-ofthe-art models with complex loss function and complicated feature encoding.
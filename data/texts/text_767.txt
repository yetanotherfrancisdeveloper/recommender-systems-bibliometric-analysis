Figure 1: Conversational critiquing workî€ow. The system scores candidate items and generates a justiî€›cation for the top item. If the user rejects the suggestion and critiques an aspect, the system uses the critique to update the latent user representation. Conversational recommender systems oî€er the promise of interactive, engaging ways for users to î€›nd items they enjoy. We seek to improve conversational recommendation via three dimensions: 1) We aim to mimic a common mode of human interaction for recommendation: experts justify their suggestions, a seeker explains why they donâ€™t like the item, and both parties iterate through the dialog to î€›nd a suitable item. 2) We leverage ideas from conversational critiquing to allow users to î€exibly interact with natural language justiî€›cations by critiquing subjective aspects. 3) We adapt conversational recommendation to a wider range of domains where crowdsourced ground truth dialogs are not available. We develop a new two-part framework for training conversational recommender systems. First, we train a recommender system to jointly suggest items and justify its reasoning with subjective aspects. We then î€›ne-tune this model to incorporate iterative user feedback via self-supervised bot-play. Experiments on three real-world datasets demonstrate that our system can be applied to diî€erent recommendation models across diverse domains to achieve superior performance in conversational recommendation compared to state-of-the-art methods. We also evaluate our model on human users, showing that systems trained under our framework provide more useful, helpful, and knowledgeable recommendations in warm- and cold-start settings.. conversational recommendation, recommender systems, critiquing ACM Reference Format: Shuyang Li, Bodhisattwa Prasad Majumder, and Julian McAuley. 2021. SelfSupervised Bot Play for Conversational Recommendation with Justiî€›cations. In arXiv. , 11 pages. Traditional recommender systems often return static recommendations, with no way for users to meaningfully express their preferences and feedback. However, interactivity and explainability can greatly aî€ect a userâ€™s trust of and willingness to use a recommender system [29,35]. This is reî€ected in human conversations: experts justify their recommendations, customers critique suggestions, and both parties iterate through the conversation to arrive at a satisfactory item. Early work on interactive recommender systems focused on iteratively presenting suggestions to the user based on simple â€œlike" and â€œdislike" feedback on individual items [3,11,15]. Gradually, systems began to accommodate more î€›ne-grained user feedbackâ€”critiquing î€›xed attributes of an item (e.g. its color or brand) [6]. Recent models for conversational critiquing incorporate user feedback on subjective aspects (e.g. taste and perception) [22,23,40]. However, such methods are trained using a next-item recommendation objective, and perform poorly when engaging with users over multiple turns. Another approach lies in training dialog agents to interact with the user over multiple turns [39]. While such models are able to generate convincing dialog in a vacuum, they require large corpora of transcripts from crowd-sourced recommendation games [12,20]. To create high-quality training dialogs, crowd-workers must be knowledgable about many items in the target domainâ€”this expertise requirement limits data collection to a few common domains like movies. Additionally, these dialog policies limit a userâ€™s freedom to interact with the system by asking yes/no questions about speciî€›c item attributes. We thus desire a conversational recommender system that mimics characteristics of human interactions not yet captured by existing systems: (1) It can justify suggestions made to the user; (2)It updates suggestions based on user feedback about subjective aspects; and (3)It can be trained using review data that is easily harvestable from arbitrary new domains. Table 1: Conversational critiquing systems (î€›rst section) are transcript-free but not equipped for multi-turn interactions. Dialog-based agents (second section) learn multi-turn interactions using large corpora of domain-speciî€›c dialog transcripts. Our framework allows us to train multi-turn interactive recommender systems without costly transcript data. To accomplish these goals, we present a two-part framework to train conversational recommender systems. Ours is the î€›rst framework, to our knowledge, that allows training of conversational recommender systems for multi-turn settings without the need for supervised dialog examples. First, using a next-item recommendation task we learn to encode historical user preferences and generate justiî€›cations for our suggestions via sets of subjective aspects. We then î€›ne-tune our trained model via multiple turns of bot-play in a recommendation game based on user reviews and simulated critiques. We apply our framework to two base recommender systems (PLRec [32] and BPR [30]), and evaluate the resultingPLRec-Bot andBPR-Botmodels on three large real-world recommendation datasets containing user reviews. Our method reaches the target item with a higher success rate than state-of-the-art methods, and takes fewer turns to do so, on average. We also conduct a study with real users, showing that it can eî€ectively help users î€›nd desired items in real time, even in a cold-start setting. We summarize our main contributions as follows: 1) We present a framework for training conversational recommender systems using bot-play on historical user reviews, without the need for large collections of human dialogs; 2) We apply our framework to two popular recommendation models (BPR-BotandPLRec-Bot), with each showing superior or competitive performance in comparison to state-of-the-art recommendation and critiquing methods; 3) We demonstrate that our framework can be eî€ectively combined with query reî€›nement techniques to quickly suggest desired items. Users prefer recommendations that they perceive to be transparent or justiî€›ed [33,35]. Some early recommender systems presented the objective attributes of suggested items to users [34,37], but did not attempt to personalize the justiî€›cations. Another line of work considered the problem of generating natural language explanations of recommendations. McAuley et al. [24]extract key aspects from the text of user reviews using topic extraction. Such justiî€›cations have been expanded into full sentences based on aspects of interestâ€”constructed via template-î€›lling [42] or recurrent language Kâˆˆ RUser aspect frequency; kis how oftenuser ğ‘¢ mentioned aspect ğ‘ in their reviews. KâˆˆBinary matrix; kis 1 if and only if aspect ğ‘was used in any review of item ğ‘– ğ›¾,ğ›¾âˆˆ RLearned â„-dimension user/item embeddings. Ë†ğ‘˜âˆˆPredicted justiî€›cation (binary for all aspects). ğ‘âˆˆ RCumulative critique vector representing theuserâ€™s evolving opinion about each aspect. ğ‘šâˆˆThe user critique vector at turn ğ‘¡. ğ‘šis 1 ifand only if the user critiqued ğ‘ at turn ğ‘¡. models [26]. Due to the unstructured nature of these justiî€›cations, however, sentence-level justiî€›cations have not been used for iteratively reî€›ning recommendations. In this work, justiî€›cations take the form of speciî€›c aspects that a user is interested in (e.g. that a song is poetic) [2,24,40]. In Section 4.2 we describe how we extract such aspects from user reviews in large recommendation datasets. Users often seek to make informed decisions around consumption, and controllability of a recommendation system is linked to improved user satisfaction [27]. We thus turn to conversational recommendation as a way to iteratively engage with a user to learn their preferences with the goal of recommending a suitable item [5]. We view recommenders as domain experts engaging with human customers, able to elicit user preferences and requirements and suggest appropriate items in the course of the conversation. In early interactive recommender systems, users were only able to give binary â€œlike" and â€œdislike" feedback without further explanation [15]. One line of research used such feedback to reî€›ne the search space for retrieving desired images from the web [11]. Biswas et al. [3]extended this approach to interactive product search. More recently, multi-armed bandit approaches to conversational recommendation [43,45] leverage exploration-exploitation algorithms to maximize the information learned from feedback at each turn. Another line of work treats conversational recommendation as a form of task-oriented dialog where users express opinions about speciî€›c aspects of an item. At each turn, the user is either a) asked if they prefer a speciî€›ed aspect; or b) recommended an item [7]. Self-supervised bot-play has been explored as a way to train such conversational dialog agents [12,20], but such approaches require Wizard-of-Oz style data [8] with humans playing the role of expert and seeker. The quality of such dialog data depends heavily on the domain knowledge and competence of crowd-workers, which makes it unsuitable for complex domains. Zhang et al. [41]uses templated dialog forms and trains a model to ask about aspects that are most informative of the userâ€™s preferences. However, this forces the user to answer yes/no questions and restricts their î€exibility when giving feedback. Instead, we explore conversational critiquing, where a user is presented with items and justiî€›cations, and is able to give feedback regarding any aspect in the justiî€›cation. Figure 2: In (latent) conversational critiquing, user feedback about aspects (ğ‘, ğ‘) modiî€›es our prior latent user preference vector ğ›¾to bring it closer to the target item embedding. Critiquing systems aim to help users incrementally construct their preferences in a way that mimics how humans reî€›ne their preferences and constraints depending on conversation context [36]. Early critiquing methods relied on constraint-based programming to iteratively shrink the search space of items as users provided more critiques [4]. More recently, Wu et al. [40]introduced a critiquing model with justiî€›cations via a list of natural language aspects mined from user reviews. In this setting, users are able to interact with any aspect present in the generated justiî€›cation. Antognini et al. [2]generate a single sentence of explanation alongside the set of aspects, but still require users to interact with the aspect set. Luo et al. [23]use a variational auto-encoder (VAE) [14] in place of the collaborative î€›ltering model, learning a bi-directional mapping function between user latent representations and aspects they have expressed in reviews. Such models can generate high precision justiî€›cations but have shown poor multi-turn recommendation performance. Latent Linear Critiquing (LLC) methods do not generate justiî€›cations and instead allow users to critique any aspect from the vocabulary [18,22]. After training a matrix factorization model to predict ratings, these models then learn a linear regressor to recover user embeddings from their historical aspect usage frequency. A linear programming problem is then solved to weight a userâ€™s critiques during each turn of the conversation, which we observe to take an order of magnitude longer than VAE-based methods and our own. Furthermore, while LLC assumes that user preferences are fully explained by their review texts, recent studies have shown that this assumption may be unfounded [31]. In Table 1 we compare our approach in context of recent frameworks for training dialog agents for conversational recommendation and conversational critiquing agents. Our model consists of three sections, as seen in Figure 3: (1)A matrix factorization recommender modelğ‘€that learns to embed users and items in an â„-dimensional latent space; (2)A justiî€›cation headğ‘€that predicts the aspects of an item toward which the user holds preferences; Figure 3: The proposed model architecture. Given a user, items, and critique vector, our model encodes the critique ğ‘€(ğ‘) and fuses it with the user embeddingğ›¾. The fused user representation ğ›¾and item representation ğ›¾are then used to predict the justiî€›cation and score items. (3)A critiquing functionğ‘“that modiî€›es a userâ€™s preference embedding based on user feedback about speciî€›c aspects. Our model supports multi-turn critiquing as shown in Figure 2. At each turn of a conversation, a user may provide explicit feedback about aspects they dislike about the current set of recommendations in the form of a critique (ğ‘). The critiquing functionğ‘“then uses this critique to modify our latent user representationğ›¾in order to bring it closer to the userâ€™s target item. Our method can be applied to any recommender systemğ‘€that learns user and item representations. We demonstrate its eî€ectiveness using two popular methods based on matrix factorization and linear recommendation. Bayesian Personalized Ranking (BPR) [30] is a matrix factorization recommender system that seeks to decompose the interaction matrixR âˆˆ Rinto user and item representations [16]. BPR optimizes a ranked list of items given implicit feedback (a set of items with which a user has recorded a binary interaction). We learnâ„-dimensional user and item embeddings (ğ›¾,ğ›¾), computing the score via the inner product:Ë†ğ‘¥= âŸ¨ğ›¾,ğ›¾âŸ©. At training time, the model is given a userğ‘¢, observed itemğ‘– âˆˆ ğ¼, and unobserved itemğ‘— âˆˆ ğ¼. We maximize the likelihood that the user prefers the observed item ğ‘– to the unobserved item ğ‘—: where ğœ represents the sigmoid function. Projected Linear Recommendation (PLRec) is an SVD-based method to learn low-rank representations for users and items via linear regression [32]. The PLRec objective minimizes the following:îƒ• whereğ‘‰is a î€›xed matrix obtained by taking a low-rank SVD approximation ofRsuch thatR = ğ‘ˆ Î£ğ‘‰, andğ‘Šis a learned embedding matrix. We thus obtain anâ„-dimensional user embedding ğ›¾= ğ‘Ÿğ‘‰ and â„-dimensional item embedding ğ›¾= ğ‘Š. Our justiî€›cation modelğ‘€consists of an aspect prediction head: a fully connected network with twoâ„-dimensional hidden layers Algorithm 1:Bot play framework for î€›ne-tuning conversational recommenders. Recommendation and Justiî€›cation models ğ‘€, ğ‘€; Critique fusion function ğ‘“; Seeker model ğ‘€; for each user ğ‘¢ do for goal item ğ‘” âˆˆ ğ¼(Evaluation set) do end end that predicts a scoreğ‘ for each aspectğ‘. This model takes as input the sum of the learned user and item embeddings (ğ›¾,ğ›¾). At training time, we incorporate an aspect prediction lossL by computing the binary cross entropy (BCE) for each aspect: L= âˆ’1|ğ´|kÂ· log ğ‘+ (1 âˆ’ k) Â· log(1 âˆ’ ğ‘) (3) whereğ‘= ğœ (ğ‘ )represents the likelihood of userğ‘¢caring about aspectğ‘in context of itemğ‘–. At inference time, we again compute the likelihood for each aspect (ğ‘= ğœ (ğ‘ )) and sample from the Bernoulli distribution withğ‘to determine which aspects ğ‘ appear in the justiî€›cation. We posit that the userâ€™s latent representation can be partially explained by their written reviews. Thus, we jointly learn an aspect encoderğ‘€alongside our recommendation model. This takes the form of a linear projection from the aspect space to the user preference space:ğ‘€(ğ‘) = ğ‘Šğ‘+ ğ‘, whereğ‘âˆˆ Zis the critique vector representing the strength of a userâ€™s preference for each aspect. We then fuse this aspect encoding with the latent user embedding fromğ‘€to form the î€›nal user preference vectorğ›¾: For the BPR-based model, we useğ‘“ (ğ‘, ğ‘) = ğ‘ + ğ‘as a fusion function, and for the PLRec-based model, we useğ‘“ (ğ‘, ğ‘) =. During training, the aspect encoder takes in the userâ€™s aspect history: ğ‘= k. To train our BPR-based model, we jointly optimize each component. Each training example consists of a userğ‘¢, an observed itemğ‘– âˆˆ ğ¼ that the user has interacted with, and an unobserved itemğ‘— âˆˆ ğ¼ that the user has not rated. We predict scores for items ğ‘– and ğ‘—: We î€›rst compute the BPR loss (see Section 3.1) with predicted scores Ë†ğ‘¥andË†ğ‘¥. We add the aspect prediction loss, scaled by a constant ğœ†to the ranking loss for our training objective:L = ğœ†Lâˆ’ L. We î€›nd empirically that ğœ†âˆˆ {0.5, 1.0} works well. To train our PLRec-based model, we follow Luo et al. [22]and separately optimizeğ‘€,ğ‘€, andğ‘€. The user and item embeddings are learned via eq. (2). We solve the following linear regression problem to optimize ğ‘€: Finally, we optimize the aspect prediction (justiî€›cation) lossLto train the justiî€›cation head. To perform conversational critiquing with a model trained using our framework, we adapt the latent critiquing formulation from Luo et al. [22], as shown in Figure 1. Each conversation with a userğ‘¢consists of multiple turns. At each turnğ‘¡, the system assigns scoresË†ğ‘¥for all candidate itemsğ‘–, and presents the user with the highest scoring itemË†ğ‘–. The system also justiî€›es its prediction with a set of predicted aspectsË†ğ‘˜. The user may either accept the recommended item (ending the conversation) or critique an aspect from the justiî€›cation: ğ‘ âˆˆ {ğ‘|Ë†ğ‘˜= 1}. Given a user critique, the system modiî€›es the predicted scores for each item and presents the user with a new item and justiî€›cation: Eî€ectively, a user critique modiî€›es our prior for the userâ€™s preferences; we then re-rank the items presented to the user. At inference time,ğ‘is the cumulative critique vector, initialized with the userâ€™s aspect history: whereâŠ™is element-wise multiplication. We usemax(k,1)as the critique should match the strength of the userâ€™s previous opinion on the aspectâ€”otherwise the encoding may have a small magnitude. Even if a user has not mentioned an aspect in their previous reviews, the max ensures a non-zero eî€ect from each critique. We propose a framework for critiquing via bot play that simulates conversations when provided just a known set of user reviews. We î€›rst pre-train our expert model (recommender model, justiî€›cation model, and aspect encoder). A seeker modelğ‘€is pre-trained via a simple user prior: when provided with a known target item Table 3: Descriptive statistics of datasets, including average unique aspects expressed in reviews per item and user. and justiî€›cation, it selects the most popular aspect present in the justiî€›cationË†ğ‘˜but not the targetâ€™s historical aspectskto critique. For each training example (userğ‘¢and a goal item they have reviewedğ‘”), we allow the expert and seeker models to converse with the goal of recommending the goal item. We î€›ne-tune the expert by maximizing its reward (minimizing its loss) in the botplay game (Algorithm 1). We end the dialog after the goal item is recommended or a maximum session length ofğ‘‡ =10 turns is reached. We deî€›ne the expertâ€™s loss as the cross entropy loss of recommendation scores per turn: whereğ›¿is a discount factorto encourage successfully recommending the goal item at earlier turns.L(ğ‘”,Ë†ğ‘¥)is the cross entropy loss between predicted scores and the goal item: L(ğ‘”,Ë†ğ‘¥) = âˆ’ğ‘ƒ (ğ‘–) logğ‘„ (ğ‘–); ğ‘„ (ğ‘–) =ğ‘’Ã(11) whereğ‘ƒ (ğ‘–)is 1 ifğ‘” = ğ‘–and 0 otherwise. As the cross-entropy loss is continuous, we optimize the reward for each conversation (ğ‘¢,ğ‘–). To train our initial model, we select hyperparameters via AUC on the validation set. We select hyperparameters for bot-play î€›netuning by evaluating the success rate at 1 (SR@1) on the validation set. We train each model once, with three evaluation runs per experimental setting. For baseline models, we re-used the authorsâ€™ code. We include additional training details in the supplementary materials.We will make our code available upon publication. We evaluate the quantitative performance of our model using three real-world, publicly available recommendation datasets: Goodreads Fantasy (Books) [38], BeerAdvocate (Beer) [24], and Amazon CDs & Vinyl (Music) [10,25]â€”each with over 100K reviews and ratings. We keep only reviews with positive ratings, setting thresholds of ğ‘¡ >4.0 for Beer and Music andğ‘¡ >3.5 for Books. We partition each dataset into 50% training, 20% validation, and 30% test splits. Dataset statistics are shown in Table 3. Our datasets do not contain pre-existing aspects, so we follow the pipeline of [40] to extract subjective aspects from user reviews: Recommendation and Justiî€›cation models ğ‘€, ğ‘€; Critique fusion function ğ‘“; for each user ğ‘¢ do for goal item ğ‘” âˆˆ ğ¼(Evaluation set) do end end return average success rate & length (1)Extract lists of high-frequency unigrams and bigrams (nouns and adjective phrases only) from all user reviews; (2)Prune the bigram keyphrase list using a Pointwise Mutual Information (PMI) threshold, ensuring aspects are statistically unlikely to have randomly co-occurred; (3)Represent reviews as sparse binary vectors indicating whether each aspect was expressed in the review. Aspects describe a wide range of qualities; for beers, users commonly describe the malt (e.g. roasted) and taste (e.g. citrus). For music, aspects range from perceived genres (e.g. techno) to emotions (e.g. soulful). Users describe books by reacting to character descriptions (e.g. strong female) and settings (e.g. realistic).. Following prior work on conversational critiquing [18,22], we simulate multi-step recommendation dialogs to assess model performance. We randomly sample 500 user-item interactions from the test set to conduct user simulations following Algorithm 2 for each userğ‘¢and goal itemğ‘”. At each turn, we recommend an itemË†ğ‘–to the user alongside a set of aspectsË†ğ‘˜. If the goal item is not recommended, the user will critique an aspectğ‘from the justiî€›cation that is inconsistent with the goal item aspects: ğ‘ âˆˆ {ğ‘ |Ë†ğ‘˜=1 &k=0}We set a maximum session limit of ğ‘‡ = 10 turns. To evaluate how our models behave with diî€erent user behaviors, we simulate each observation with three diî€erent critique selection strategies [18]: â€¢ Random: We assume the user randomly chooses an aspect. This assumes no prior knowledge on the part of the user. â€¢ Pop: We assume the user selects the most popular aspect used across all training reviews. â€¢ Diî€: We assume the user selects the aspect that deviates most from the goal item reviews. In simulations, we select Figure 4: Success Rate @ N (% dialogs where target item rank â‰¤ N) across datasets and user models. BPR-Bot (brown triangle) and PLRec-Bot (pink circle) out-perform baselines (dashed) in all settings. the aspect with the largest frequency diî€erential between the goal item and current item: arg max(kâˆ’ k) In all critiquing settings, a user may not critique the same aspect multiple times in a session, and any recommended items are removed from consideration in the following turns. As our method can be applied to any base recommender system ğ‘€, we apply our framework to train models based on BPR and PLRec (see Section 3.1)â€”BPR-Bot and PLRec-Bot, respectively. We assess Latent Linear Critiquing (LLC) baselines, which embed critique vectorsğ‘in the sameâ„-dimensional space as the latent user representationğ›¾.ğ‘“is deî€›ned as a weighted sum of the embedding for each critiqued aspect, alongside the original user preference vector.UAC[22] averages the initial user embedding and all critiqued aspect embeddings.BAC[22] î€›rst averages critiqued aspects, and then averages the result with the initial user embedding.LLC-Score[22] learns the weights via a linear program maximizing the posterior rating diî€erences between items containing critiqued aspects and those without. Instead of directly optimizing the scoring margin,LLC-Rank[18] minimizes the number of ranking violations. These models cannot generate justiî€›cations; we binarize the historical aspect frequency vector for the item (k) as a justiî€›cation at each turn. We compare against these models to evaluate whether generating personalized justiî€›cations can improve critiquing. Figure 5: Avg. number of turns before the target item reaches rank N, across datasets and user models. BPR-Bot (brown triangle) and PLRec-Bot (pink circle) promote target items faster than baselines (dashed), especially for low N. We also compare against a state-of-the-art variational conversational recommender,CE-VAE[23]â€”an improvement on the Wu et al. [40]justiî€›ed critiquing modelâ€”which jointly learns to recommend and justify. CE-VAE learns a VAE with a bidirectional mapping between critique vectors and the user latent preference space. We compare our models to CE-VAE to assess how justiî€›cation quality impacts multi-turn critiquing performance. RQ1: Can our framework enable multi-step critiquing?To measure multi-step critiquing performance, we assess the average success rate and session length following Luo et al. [22]. Success rate measures the percentage of sessions in which the target item reaches rank N, and session length measures the average length of sessions with a limit of 10 iterations. Success rates and session lengths for each dataset and user behavior model are shown in Figure 4 and Figure 5, respectively. Our models are î€›ne-tuned via bot-play with a seeker model that assumes one particular user behavior: popularity-based critique selection. As such, we expect it to perform better in the Pop user setting. However, BPR-Bot and PLRec-Bot succeeds at a higher rate in fewer turns than baselines under all user settingsâ€”including random aspect critiquing, which assumes no prior on user behavior. Variational Baseline. Despite its strong î€›rst-turn recommendation performance and high-î€›delity justiî€›cations, CE-VAE is outperformed by our models in all nine settings across all metrics. This supports our observation that the training method to learn Figure 6: Success Rate @ N (% dialogs where target item rank â‰¤ N), comparing bot-play methods (orange) against non-botplay ablations (blue). Bot-play î€›ne-tuning improves target item ranking across datasets compared to the ablation, for both BPR-Bot (crosses) and PLRec-Bot (circles). a bi-directional mapping between latent user preferences and a justiî€›cation causes a trade-oî€ between justiî€›cation quality and critiquing ability. Linear Baselines. We further observe that linear critiquing models (UAC, BAC, LLC-Score, and LLC-Rank) perform poorly on multistep critiquing, especially when trying to î€›nd the goal item outright (ğ‘ =1). This conî€›rms our observation that the method of co-embedding aspect critiques with learned user latent preferences ignores the existence of user preferences not explained by review text. This additionally suggests that generating personalized justiî€›cations helps users more eî€ectively choose aspects to critique. In general, the large item space makes it diî€œcult for critiquing models to reach the goal item within the turn limit, with the best model reaching the goal item in only 6-15% of sessions. This suggests that practical conversational critiquing systems may beneî€›t from constraint-based î€›ltering as well as starting the session from an initial set of user requirementsâ€”while users rarely enter a conversation knowing their full preference set [28], they often start with a limited set of broad requirements (e.g. when buying a car, they want an SUV or a coupe). We demonstrate in RQ3 that our model can be combined with constraint-based query reî€›nement to quickly reach signiî€›cantly higher success rates. RQ2: Can our bot-play framework improve multi-step critiquing performance?We next compare BPR-Bot (left) and PLRec-Bot (right) in Figure 6 against ablated versions that were trained using the î€›rst step of our framework but not î€›ne-tuned via bot-play. For clarity, we display only results using the Pop user behavioral model, as we observe the same trends with the Random and Diî€ user models. In domains with relatively high aspect occurrence across reviews (Books, Beer), we observe that bot-play confers a 3-6% improvement in success rate for various N. This Figure 7: Hit rate by turn for query reî€›nement models on each dataset with multi-step critiquing up to 10 turns. demonstrates that we can eî€ectively train conversational recommender systems using our bot-play framework using domains with rich user reviews in lieu of crowd-sourced dialog transcripts. In domains with more sparse coverage of subjective aspects (i.e. Music), we observe lower improvement when using bot-play. Here, our model may not encounter suî€œcient examples of rare aspects being critiqued. In future work, we will explore methods to add noise to our user model to ensure that the bot-play process encounters more rare aspects. We will also investigate additional losses for bot-play, including ranking losses instead of cross entropy. We conî€›rm that our method is model-agnostic, as it improves conversational recommendation success rates for both the matrix factorization-based (BPR) and linear (PLRec) recommender systems. We also observe that models with a higher latent dimensionality (â„ âˆˆ [50,400]for PLRec-Bot vs.â„ =10 for BPR-Bot) beneî€›t more from bot-play, suggesting that our method eî€ectively learns to navigate complex user preference spaces. RQ3: Can our models be eî€ectively combined with query reî€›nement?So far, we have assumed that users provide soft feedback via critiques: even if a user has critiqued aspectğ‘during a session, future suggested items may still contain aspectğ‘. This assumption holds for some aspects: for example, even if previous users mentioned that a song was dispassionate, a user may î€›nd it emotional and enjoyable. However, in a real-world setting that user may reject the suggestion after reading the reviews. Thus, we experiment with treating critiques as hard feedback: if a user critiques some aspectğ‘, we prune all candidate items whose reviews mentionğ‘. We compare three models in this setting, with the turn-0 ranked list of candidate items initialized from BPR-Bot. TheQuerybaseline model suggests one item per turn and asks the user whether they like aspectğ‘. If the user answers yes, we prune all candidate items whose reviews have not expressedğ‘: ğ¼â† {ğ‘– âˆ€ ğ‘– âˆˆ ğ¼|k=1}. Otherwise, we prune all candidates whose reviews have expressed the aspect:ğ¼â† {ğ‘– âˆ€ ğ‘– âˆˆ ğ¼|k= 0}. At each turn, we pick the aspect that most evenly divides the remaining candidate items:arg min||ğ¼| âˆ’ |ğ¼||Eî€ectively, we perform binary search over our candidate space, and expect to î€›nd the target item within log |ğ¼ | turns. In theFiltermodel, we suggest an item alongside a generated justiî€›cation per turn. When a user critiques aspectğ‘, we prune candidate items whose reviews have expressedğ‘:ğ¼â† {ğ‘– âˆ€ ğ‘– âˆˆ ğ¼|k=0}. We extend this model via our learned critiquing functionğ‘“to further modify the user preference vector and Table 4: Conversation-level human evaluation via ACUTEEVAL. Win (W) and Loss (L) percentages are reported while ties are not. All results statistically signiî€›cant with ğ‘ <0.05. PLRec-Bot Useful Informative Knowledgeable Adaptive re-compute scores for the remaining items. This hybridFilter+Rerankmodel then re-ranks the remaining candidate items for the next turn. We conduct user simulations with the Pop user model following Algorithm 2, and plot the success rate by turnâ€”rate of achieving the goal item ğ‘” at or before turn ğ‘¡â€”in Figure 7. Binary queries are guaranteed to eventually î€›nd the answer, but the queried aspect may not be related to suggested items. By allowing the user to provide negative critiques, we can rapidly reduce the search space at early turns. Across domains the success rate rises much faster in the î€›rst 6-10 turns for Filter and Filter+Re-rank compared to binary querying. Re-ranking after î€›ltering improves performance across domains, suggesting that we have learned how user critiques relate to their latent preferences for other aspects. For the Beer and Books domains, the î€›ltering approach reaches higher success rates compared to binary querying same high success rate within the session turn limit (70.7% vs. 69.7% and 57.0% vs. 55.2%, respectively). We see less of a beneî€›t in the Music domain. Relative aspect sparsity may play a role: per Table 3, only 25% of possible aspects are expressed for the average item. There also exists a longer tail of aspects expressed only for a small set of items in Music compared to the other datasets. As such, user critiques prune fewer candidate items on average in Music. Our bot-play framework can be easily adapted to train models incorporating hard critiquing constraints by pruning candidate items. One possible extension involves masking the cross entropy (î€›netuning) loss to only adjust the scores of non-pruned items, setting pruned item scores to a large negative value:Ë†ğ‘¥= âˆ’1ğ‘’15âˆ€ ğ‘– âˆˆ ğ¼. We also wish to explore î€›ne-tuning with a ranking loss during botplay, to encourage the model to rank items containing a critiqued aspect ğ‘– âˆˆ ğ¼below those without. Human EvaluationTo assess the quality of the simulated conversations during bot-play, we conduct human evaluations with 100 samples. Following ACUTE-EVAL [19], we conduct a comparative evaluation of each sample conversation on four criteria: which agent seems more useful, informative, knowledgeable and adaptive. We compare each bot-play model (BPR-BotandPLRec-Bot) against an ablative version (with no bot-play î€›ne-tuning) and the best baseline model (CE-VAE). Table 5: Turn- and conversation-level feedback from coldstart user study. Statistically signiî€›cant results are bolded. Each sample is evaluated by three annotators. We observe substantial [17] inter-annotator agreement, with Fleiss Kappa [9] of 0.67, 0.79, 0.73, and 0.60 for the usefulness, informativeness, knowledgeable, and adaptiveness criteria, respectively. BPR-Bot and PLRec-Bot are judged to be signiî€›cantly more informative and knowledgeable compared to ablative models and CE-VAE, showing that our justiî€›cation module accurately predicts aspects of a recommended item. We design the usefulness and adaptiveness criteria to capture how our framework aids the user in achieving their conversational goal (i.e. recommending the most relevant item within a minimum number of turns). Compared to the alternatives, models trained under our bot-play framework are judged to be more useful and adapt their recommendations in a manner more consistent with critiques. Our framework allows us to train conversational agents that are useful and engaging for human users: evaluators overwhelmingly judged the models trained via bot-play to be more useful, informative, knowledgeable, and adaptive compared to CE-VAE and ablated variants. Cold-Start User StudyWe conduct a user study using items and reviews from the Books dataset to evaluate our modelâ€™s ability to provide useful conversational recommendations in real-time. We recruited 32 real human users to interact with ourBPR-Bot recommender and another 32 to interact with the ablation model (no conversational î€›ne-tuning). As evaluators do not correspond to users in our training data, we initialize each conversation with the average of all learned latent user representations. At each turn, the user is presented with the three top-ranked items and their justiî€›cations (list of aspects), and is allowed to critique multiple aspects. On average, users critiqued two aspects per turnâ€”this suggests that when training conversational models we should assume multiple critiques at each turn. We evaluate our systems following Li et al. [19]: at each turn, we ask our users if the generated justiî€›cations are informative, useful in helping to make a decision, and whether our system adapted its suggestions in response to the userâ€™s feedback. We provide four options for each question: yes, weak-yes, weak-no, and no, mapping these values to a score between 0 and 1 [13]. We display the normalized aggregated score for each question in Table 5. We î€›nd that BPR-Botsigniî€›cantly out-scores the ablation model in all three metrics (ğ‘ <0.01), showing that î€›ne-tuning our model on a botplay framework instills a stronger ability to respond to techniques and provide meaningful justiî€›cationsâ€”even for unseen users. At the end of a conversation, we additionally ask the user how frequently (if at all) they would choose to engage with our conversational agent in their daily life. 69% of users indicated they would â€œoften" or â€œalways" use BPR-Bot to î€›nd books, compared to 41% of users for the ablation model. We thus î€›nd that î€›ne-tuning our model via bot-play also makes it signiî€›cantly (ğ‘ < 0 .05) more useful for new users. In this work, we aim to develop conversational agents for recommendation that engage with users following common modes of human dialog: justifying why suggestions were made and incorporating feedback about certain aspects of an item to provide better recommendations at the next turn. We present a framework for training conversational recommenders in this modality via selfsupervised bot-play. Our framework is model-agnostic and allows conversational recommenders to be trained on any domain with review data. We use two popular underlying recommender systems to train theBPR-BotandPLRec-Botconversational agents using our framework, demonstrating quantitatively on three datasets that our models 1) oî€er superior multi-turn recommendation performance compared to current state-of-the-art methods; 2) can be eî€ectively combined with query reî€›nement techniques to quickly converge on suitable items; and 3) can iteratively reî€›ne suggestions in real-time, as shown in user studies. In future work, we aim to adapt our framework to natural language critiques (i.e. complete utterances), allowing users to freely express their feedback in a less restrictive way.
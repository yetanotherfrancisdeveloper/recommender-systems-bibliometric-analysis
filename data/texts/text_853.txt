Conversational recommendation system (CRS) is able to obtain ï¬negrained and dynamic user preferences based on interactive dialogue. Previous CRS assumes that the user has a clear target item, which often deviates from the real scenario, that is for many users who resort to CRS, they might not have a clear idea about what they really like. Speciï¬cally, the user may have a clear single preference for some attribute types (e.g. color) of items, while for other attribute types (e.g. brand), the user may have multiple preferences or even no clear preferences, which leads to multiple acceptable attribute instances (e.g. black and red) of one attribute type. Therefore, the users could show their preferences over items under multiple combinations of attribute instances rather than a single item with unique combination of all attribute instances. As a result, we ï¬rst propose a more realistic conversational recommendation learning setting, namely Multi-Interest Multi-round Conversational Recommendation (MIMCR), where users may have multiple interests in attribute instance combinations and accept multiple items with partially overlapped combinations of attribute instances. To effectively cope with the new CRS learning setting, in this paper, we propose a novel learning framework namely, Multi-Choice questions based Multi-Interest Policy Learning (MCMIPL). In order to obtain user preferences more efï¬ciently, the agent generates multi-choice questions rather than binary yes/no ones on speciï¬c attribute instance. Furthermore, we propose a union set strategy to select candidate items instead of Simon Fraser University existing intersection set strategy in order to overcome over-ï¬ltering items during the conversation. Finally, we design a Multi-Interest Policy Learning (MIPL) module, which utilizes captured multiple interests of the user to decide next action, either asking attribute instances or recommending items. Extensive experimental results on four datasets demonstrate the superiority of our method for the proposed MIMCR setting. â€¢ Information systems â†’ Users and interactive retrieval;Recommender systems. Conversational Recommendation, Reinforcement Learning, Graph Representation Learning ACM Reference Format: Yiming Zhang, Lingfei Wu, Qi Shen, Yitong Pang, Zhihua Wei, Fangli Xu, Bo Long, and Jian Pei. 2018. Multi-Choice Questions based Multi-Interest Policy Learning for Conversational Recommendation. In Woodstock â€™18: ACM Symposium on Neural Gaze Detection, June 03â€“05, 2018, Woodstock, NY. ACM, New York, NY, USA, 10 pages. https://doi.org/10.1145/1122445. 1122456 Conversational recommendation system (CRS) aims to obtain ï¬negrained and dynamic user preferences and make successful recommendations through conversations with users [13,39]. In each conversation turn, CRS can select different actions [12] based on user feedback, either asking attributes or recommending items. Since it is able to explicitly obtain user preferences and has the advantage of conducting explainable recommendation, CRS has become one of the hot topics in current research. Various methods [7,11,18,26,46] have been proposed to improve the performance of CRS based on different problem settings. In this work, we focus on the multi-round conversational recommendation (MCR) setting [8,13,15], which is the most realistic CRS setting so far. The system focuses on whether asking attributes or recommending items in each turn, and adjusts actions ï¬‚exibly via user feedback to make successful recommendations with fewer turns. Despite the success of MCR in recent years, the assumption of the existing MCR [13], that the user preserves clear preferences towards all the attributes and items, may often deviate from the real scenario. For the user who resorts to CRS, he/she might not have a clear idea about what he/she really likes. Speciï¬cally, the user may have a clear single preference for someattribute types(e.g., color) of items, while for other attribute types (e.g., brand), the user might have multiple preferences or even no clear preferences. With the guidance of CRS, he/she may accept multipleattribute instances (e.g., red and black) of one attribute type. In addition, different combinations of these attribute instances are generally associated with different items. Therefore, the user could show his preferences over items under multiple combinations of attribute instances rather than a single item with unique combination of all attribute instances. To this end, we extend the MCR to a more realistic scenario, namely Multi-Interest Multi-round Conversational Recommendation (MIMCR), in which users may have multiple interests in attribute instance combinations and accept multiple items with partially overlapped combinations of attribute instances. As shown in Figure 1, the user wants a black T-shirt. For the attribute types such as "style" or "brand", he/she can accept one or more instances. He/She shows interest in the combinations of "Nike-brand" and "sports", as well as "solid" and "polo" respectively. The user could accept a "black solid polo" T-shirt or a "black Nike-brand sports" T-shirt. The task will be completed as CRS successfully recommends one of them. Existing works may encounter three signiï¬cant limitations under the MIMCR scenario. First, current CRS frameworks often employ binary questions [13], which is concise but unable to elicit user interests effectively. As shown in the conversation (a) in Figure 1, although the user accepts all of the attribute instances asked by CRS, the combination of them does not point to any target items the user prefers. Moreover, since the CRS agent has asked attribute instance "sports", it will hardly ask "polo" (the user favors). This is the result of the mutual exclusion of attribute instances with the same attribute type in the current CRS system design. On the other hand, enumerating all choices (associated with each attribute instances) [13,23,44] are not practical since there may be too many attribute instances to be shown and answered by the user. Second, as shown in the conversation (b) in Figure 1, CRS can efï¬ciently obtain user preferences by using multi-choice questions. However, the existing methods utilize the intersection set strategy to select items that are associated with all accepted attribute instances, which could easily lead to the over-ï¬lter of user preferred candidate items as the conversation progresses. Finally, the existing methods simply model userâ€™s intentions in a uniform manner, while neglecting the diversity of user interests, which will often fail to identify the userâ€™s multiple interests through the combinations of attribute instances. To effectively address the aforementioned challenges, we propose a novel framework named Multi-Choice questions based MultiInterest Policy Learning (MCMIPL) for MIMCR. In order to obtain user preferences more efï¬ciently, our method generates attribute type-based multiple choice questions. As the conversation (b) in Figure 1, the user can ï¬‚exibly select the attribute instances he/she likes or the option "Others" if he/she likes none. To avoid over-ï¬ltering items, we propose a union set strategy to select candidate items. In particular, we select the items satisfying at least one of the accepted attribute instances as the candidate items. Moreover, we develop a Multi-Interest Policy Learning (MIPL) module to decide the next action, either asking or recommending items. In details, we construct a current graph based on the conversation state, and a global graph based on the historical user-item interactions and the global itemattribute instance correlations. Based on the representation learned by graph neural network (GNN), we iteratively capture multiple interests of the user. Finally, the next action will be decided based on the policy learning with the multi-interest representations. The contributions of this work are summarized as follows: â€¢We extend existing CRS to a more realistic scenario setting named MIMCR, which comprehensively takes into account the incompleteness and diversity of userâ€™s interests. â€¢For the MIMCR scenario, we propose the MCMIPL framework with more appropriate strategies to generate questions and select candidate items. Furthermore, our method iteratively extracts the userâ€™s multiple interests based on the current state and historical global information, to decide the next action via policy learning. â€¢We adapt four datasets for MIMCR, and extensive experimental results on these datasets show the superiority of our method. Compared to existing sequential or social recommendation systems [21,27,40], Conversational Recommendation System (CRS) is an effective solution for dynamic user preference modeling and explainable recommendation, originated from task-oriented dialogue systems [14]. This emerging task helps the user to ï¬nd his dynamic demand with human-like dialogues. Through the conversations with users, CRS collects the userâ€™s preference and then generates recommendations directly. In recent years, various approaches [4,11,16,22,37,39,42,46] based on deep learning and reinforcement learning (RL) have been proposed for CRS. For instance, Multi-Armed Bandits based methods [7,18,39] and meta-learning based methods [11,46] solve the user cold-start problem and balance the exploration and exploitation trade-offs for CRS. Besides, some methods [7,26,41,45] focus on asking questions about items for collecting more information of usersâ€™ preference. In addition, the approaches focusing on the dialogue ability [4,17,42], are more likely to understand userâ€™s preferences and intentions with the input of raw natural language, and automatically generate ï¬‚uent responses. The most realistic conversational recommendation setting proposed so far is multi-round conversational recommendation (MCR) [8,13,15,38]. In MCR task, the system focuses on whether to ask attributes or make recommendations based on policy learning at each turn, and adjusts action ï¬‚exibly via usersâ€™ feedback, which aims to hit the target item for fewer interaction turns to improve the user experience. In this work, we focus on the MCR problem. For multi-round conversational recommendation, a conversation strategy is essential in the interaction process. The key of the conversation strategy is to dynamically decide when to ask questions, and when to make recommendations. At current stage of research, several reinforcement learning (RL) based frameworks have been adopted into MCR to model the complex conversational interaction environment. For instance, EAR [13] utilizes latent vectors based on available information to capture the current state of MCR, and learns the proper timing to ask questions about attributes or to recommend. Furthermore, SCPR [15] models the MCR task as an interactive path reasoning problem on the knowledge graph (KG). It chooses attributes and items strictly following the paths, and reasons on KG to ï¬nd the candidate attributes or items via userâ€™s feedback. KBQG [23] generates the clarifying questions to collect the userâ€™s preference of attribute types based on knowledge graph. UNICORN [8] proposes a uniï¬ed reinforcement learning framework based on dynamic weighted graph for MCR, which uniï¬es three decision-making processes. Moreover, some sophisticated conversational strategies try to lead dialogues [35], which can introduce diverse topics and tasks in MCR [16, 19, 29, 32, 34, 36, 43]. However, these works all ignore a more realistic scenario in which users may accept multiple items with partially overlapped attributes. Therefore, we propose a new scenario named MIMCR to ï¬ll this gap. Furthermore, we develop a novel framework namely MCMIPL to tackle the existing challenges. Although the multi-round conversational recommendation (MCR) scenario [8,13,15] is the most realistic CRS setting proposed so far, the assumption proposed by MCR [13], that the user preserves clear preferences towards all the attributes and items, still deviates from real scenario. In this work, we assume the userâ€™s preference for items is incomplete when resorting to CRS. Speciï¬cally, the user has clear single preferences for some attribute types, while for other attribute types, his preference might be various or vague. With the guidance of CRS, he/she may accept multiple attribute instances with the same type, which results in that the user may show interests in over items under different attribute instance combinations. Therefore, we propose a new scenario namedMulti-InterestMultiround Conversational Recommendation (MIMCR). In this scenario, we deï¬ne the sets of users and items asUand V, respectively. And we also separately deï¬ne the sets of attribute types and instances asCandP. Eachğ‘£ âˆˆ Vis associated with a set of attribute instancesP. Eachğ‘ âˆˆ Phas its corresponding attribute typeğ‘âˆˆ C. In each episode, there is a setVof items that are acceptable to the user ğ‘¢ âˆˆ U. The set is represented as follows: whereğ‘is the number of acceptable items,Pâˆ© Pâˆ© Â· Â· Â· âˆ© P= Pâ‰  âˆ…andPâ‰  P. A conversation session is initialized by user ğ‘¢specifying an attribute instanceğ‘âˆˆ Phe/she clearly prefers. Then, the agent selects to ask questions about attribute instances or to recommend items based on policy learning. The CRS will update the conversational state based on the user feedback. The process will repeat until at least one acceptable item is successfully recommended to the user or the system reaches the maximum number of turn ğ‘‡ . We propose Multi-Choice questions based Multi-Interest Policy Learning (MCMIPL), a novel framework for MIMCR. The goal of our framework is to learn the policy networkğœ‹ (ğ‘ |ğ‘)to maximizeî€‚Ãî€ƒ the expected cumulative rewards as:ğœ‹= argmaxEğ‘Ÿ, whereğ‘ denotes the current state,ğ‘denotes the action taken by the agent and theğ‘Ÿis intermediate reward. On the whole, the process of our framework in one turn can be decomposed into three steps: user modeling, consultation and transition. We ï¬rstly encode the stateğ‘ , which contains all the conversational information of the priorğ‘¡ âˆ’1turns. The current state includes six components:ğ‘ = {ğ‘¢, P, P, V, P, V}. Previous methods [8,13,15] for MCR only extract the userâ€™s interest from the current state, ignoring the complements of historical interactions to the current userâ€™s preference. To this end, we construct a current graph and a global graph to jointly learn user representations. Moreover, we develop an iterative multi-interest extractor to obtain multiple interests of the user, which will be discussed in subsection 5.1. Once the system ï¬nishes the user modeling step, it will move to the consultation step, with the purpose to decide whether to ask attribute instances or to recommend items. To make the next action more proï¬table and recommend successfully with the fewer turns, we employ a reinforcement learning (RL) method based on the extracted multiple interests of the user to learn the policy. The action space includes all candidate items and candidate attribute instances. However, in the real world, the number of items and attribute instances is very large, which severely limits the efï¬ciency of CRS. To improve the efï¬ciency, we sampleğ¾items andğ¾attribute instances as action spaceA. We develop a novel dueling Q-network [33] to calculate the Q-value of each action inA. If CRS decides to ask a question, our method will selectğ¾attribute instances inAwith the same attribute type to generate attribute type-based multi-choice questions. The user can choose zero (the option "Others" as shown in conversation (b) of Figure 1), one, or more attribute instances with the given attribute type. If CRS decides to recommend items, the system will selectğ¾items inAto recommend. We will discuss the details of sampling strategies and policy learning in subsection 5.2. When the user responds to the action of agent, the transition step will be triggered. This step will transition the current state to the next stateğ‘ . If the user responses the question, attribute instance sets that the user accepts and rejects in this turn can be deï¬ned as PandPrespectively. Some components are updated andP= Pâˆª P. When the user is recommended items, if the setVof recommended items are all rejected, the next state can be updated byV= Vâˆª V. Otherwise, this conversation session ends. Finally, we need to update the candidate item setVbased on the userâ€™s feedback. Previous works [8,15] update candidate items based the intersection set strategy, that is, only the items satisfying all the accepted attribute instances inP remain, which obviously deviates from the scenario. In fact, the user might not prefer the combination of all attribute instances, but rather part of them. To this end, we propose the attribute instance-based union set strategy to update Vas follows: V= {ğ‘£ |ğ‘£ âˆˆ Vâˆ’ Vand Pâˆ© Pâ‰  âˆ… whereVis the item set in which all items are associated to attribute instanceğ‘which initializes the conversation session. In this way, we can get the next state, which will be updated asğ‘ = {ğ‘¢, P, P, V, P, V}. In this work, ï¬ve kinds of rewards are deï¬ned following [8,15], namely, (1)ğ‘Ÿ, a strongly positive reward when the recommendation succeeds, (2)ğ‘Ÿ, a strongly negative reward when the recommendation fails, (3)ğ‘Ÿ, a slightly positive reward when the user accepts an asked attribute instance, (4)ğ‘Ÿ, a negative reward when the user rejects an asked attribute instance, (5)ğ‘Ÿ, a strongly negative reward if the session reaches the maximum number of turns. In addition, since our method asks multi-choice questions, we design the reward from the userâ€™s feedback on a question in theÃÃ form of sum as ğ‘Ÿ=ğ‘Ÿ+ğ‘Ÿ. In this section, we detail the design of Multi-Interest Policy Learning (MIPL) module. As shown in Figure 2, to obtain more comprehensive user representations, we establish a current graph to capture user current preferences, and a global graph to capture long-term preferences. Based on the learned node representations of the two graphs, we propose an iterative multi-interest extractor to model userâ€™s preferences for different combinations of attribute instances. Moreover, we design a new dueling Q-network [33] to decide the next action based on the extracted multiple interests. 5.1.1 GNN-based Representation Fusion. The existing methods [8,13,15] capture user preferences based on the current conversation state, which might cause user preferences to be incomplete due to the limited number of turns. In addition, only the current conversation information is not enough to capture the correlation of attribute instances. Therefore, we construct a current graph based on the conversation state, and a historical global graph based on the historical user-item interactions and the global item-attribute instance correlations. We employ GNNs to learn the node representations of two graphs separately and utilize gating mechanism for fusion. Current Graph Representation. Following [8], we construct a weighted graph based on theğ‘¡-th turn state of a episode asG= (N, E), whereN= {ğ‘¢} âˆª Pâˆª Pâˆª V. For the edge weightE, we consider three cases: (1) The weight of edge between the user and each accepted attribute instance is1; (2) The weight of edge between each attribute instance and the associated item is 1; (3) The weight of edge between the user and each item is ğ‘¤, which indicates the coarse matching score of the itemğ‘£to the current state as follows:îƒ•îƒ• whereğœ (Â·)is the sigmoid function,e,eandeâˆˆ Rare the initial embedding of user, item and attribute instance. We employ ağ¿-layer GCN [10] to capture the connectivity between nodes ofGand obtain higher-quality node representations in the current state. We deï¬ne the initial embeddingeof nodeğ‘› ase, andeas the output node embedding ofğ‘™-th layer. The calculation method of ğ‘™ + 1-th layer is as follows: whereNdenotes the set of neighbor nodes of nodeğ‘›in the turnğ‘¡, Wâˆˆ Ris trainable parameters. We deï¬ne the output of the last layer eas the ï¬nal embedding eof the node. Global Graph Representation. We use the historical interactions between users and items as well as the correlation between items and attribute instances to establish a heterogeneous global graphG= (N, E), whereN = U âˆª V âˆª PandE = Eâˆª E. The edge(ğ‘¢, ğ‘£, ğ‘Ÿ) âˆˆ Edenotes the userğ‘¢has interacted the itemğ‘£. And the edge(ğ‘, ğ‘£, ğ‘Ÿ) âˆˆ Edenotes that the itemğ‘£is associated with the attribute instance ğ‘. Inspired by [5,6,25], we employ ağ¿-layer Global Graph Neural Network (GGNN) to extract long-term historical interests of users, and global correlations of items and attribute instances. The initial input embeddings of the ï¬rst layer ares= e,s= eand s= e. Lets,sandsdenote the output representations of nodes after the propagation ofğ‘™-th layer. For theğ‘™ + 1-th layer of GGNN, we model different edge types separately. For the edge in E, we adopt the calculation method as follow: whereN(ğ‘›)denotes the neighbor nodes of nodeğ‘›with the edge typeğ‘Ÿ,Wandbare trainable parameters. For the edge in E, we adopt the same method as Equation 5 to get s(ğ‘›). For the userğ‘¢and attribute instanceğ‘, we utilize ReLU function to activate semantic messages to obtain output node embeddings: s= ReLU(s(ğ‘¢)),s= ReLU(s(ğ‘)). Since itemğ‘£ is connected by both two kinds of edges, we accumulate different messages propagated by different types of edges and update the item node representation as follows: whereaccum(Â·)denotes an accumulation operation, such assum(Â·) ormean(Â·). Similarly, we deï¬ne the output of the last layersas the ï¬nal embedding sof the node. We apply the gating mechanism to fuse the embeddings of nodes which belong to both graphs Gand Gas follows: whereâˆ¥is the concatenate operation,Wâˆˆ Ris trainable parameter and ğœ(Â·) is the sigmoid function. 5.1.2 Iterative multi-interest Extractor. In CRS scenario, since the userâ€™s interest is diversity, we use multi-attention mechanism to model the userğ‘¢and attribute instances accepted byğ‘¢. The multiinterest embeddings of user can be obtained through the combination of attribute instances with different weights. Inspired by [3,24,31], we adopt the iterative update rule to adjust the weights of attribute instances with ğ‘€ iterations more precisely. Previous works rarely consider items or attribute instances rejected by users, which can complement the current preferences of the user effectively. Therefore, we ï¬rst fuse the global embeddings of the rejected items and attribute instances with the userâ€™s embedding: whereN= Vâˆª P, andWâˆˆ Ris trainable parameters. Then, we deï¬neğ¾attention networks forğ¾interests. Based on accepted attribute instance embeddings[v, v, ..., v]and user embeddingË†v, the initial iteration calculation method of each attention network to obtain the interest embedding qis as follows: wherehandWare trainable parameters. Then, theğ‘š-th iteration precisely adjusts the weightsğ›¼based on theğ‘š âˆ’ 1-th iteration results as follows: wherehandWare parameters shared with the previous iterations. We deï¬ne the output{q, q, ..., q}ofğ‘€-th iteration as the ï¬nal multi-interest embeddings {q, q, ...q}. A large action search space will bring a great negative impact on the efï¬ciency of the system. Following [8], we selectğ¾items andğ¾ attribute instances as candidate action spaceA. For candidate items to be recommended, we consider how well they match the current state. Therefore, we select top-ğ¾items into the action space based onğ‘¤. For candidate attribute instances, we also select top-ğ¾ attribute instances based on ğ‘¤, which is calculated: Inspired by [8], we design an improved dueling Q-network [33] to determine the next action. Following the standard assumption that delayed rewards are discounted by a factor ofğ›¾per timestep, we deï¬ne the Q-valueğ‘„ (ğ‘ , ğ‘)as the expected reward based on the stateğ‘ and the actionğ‘. Based on the obtainedğ¾interest representations according to the current stateğ‘ , we calculate each score between actionğ‘and each interest, and take the maximum value as Q-value: ğ‘„ (ğ‘ , ğ‘) = max(ğ‘“(q) + ğ‘“(q, ğ‘)), ğ‘˜ âˆˆ {1, ...ğ¾}(15) whereğ‘“(Â·)andğ‘“(Â·)are two separate multi-layer perceptions (MLP). The optimal Q-functionğ‘„(ğ‘ , ğ‘)can achieve the maximum expected reward by the optimal policyğœ‹, following the Bellman [1] equation:î€”î€• The CRS ï¬rstly selects the action with the max Q-value. If the selected action points to an item, the system will recommend top-ğ¾ items with the highest Q-value to the user. If the selected action points to an attribute instanceğ‘, the system will generate attribute type-based multi-choice questions to ask user. To be speciï¬c, the system will decide a attribute typeğ‘, and select top-ğ¾attribute instances whose corresponding attribute type isğ‘with the highest Q-value. Then the user can choose which of the attribute instances he/she likes or dislikes. We propose two strategies to decide the attribute typeğ‘: (1) Top-based strategy. We select the attribute type corresponding to the attribute instance with the highest Q-value. (2) Sum-based strategy. For each attribute type, we sum the Q-values of its corresponding attribute instances to obtain the attribute type level score, and select the attribute type with the highest score. During the experiment, we mainly use Top-based strategy, and the other strategy will be compared in the ablation study. For each turn, the agent will receive the rewardğ‘Ÿbased on the userâ€™s feedback. According to user feedback, we can update the state ğ‘ and action spaceA. We deï¬ne a replay bufferDfollowing [8], which stores the experience(ğ‘ , ğ‘, ğ‘Ÿ, ğ‘ , A). To train our model, we sample mini-batch experiences from the replay bufferD and deï¬ne a loss function as follows:î€‚î€ƒ L = E(ğ‘¦âˆ’ ğ‘„ (ğ‘ , ğ‘; ğœƒ, ğœƒ))(17) whereğœƒis the set of parameters to capture multi-interest embeddings,ğœƒ= {ğœƒ, ğœƒ}, andğ‘¦is the target value, which is based on the optimal Q-function as follows: We update model parameters by minimizing the loss function. To fully demonstrate the superiority of our method, we conduct experiments to verify the following four research questions (RQ): â€¢ (RQ1): Compared with the state-of-the-art methods, does our framework achieve better performance? â€¢ (RQ2): What are the impacts of key components on framework performance? â€¢ (RQ3): How do the settings of hyper-parameters (such as the number of interests ğ¾) affect our framework? â€¢ (RQ4): How can our framework effectively extract multiple interests in different attribute instance combinations? To evaluate the proposed method, we adapt two existing MCR benchmark datasets, named Yelp and LastFM. To evaluate our method more comprehensively, we also process two additional datasets. The statistics of these datasets are presented in Table 1. #Triplets2,533,827 â€¢ YelpandLastFM[13]: For the Yelp, Lei et al. build a 2-layer taxonomy. We deï¬ne the 29 ï¬rst-layer categories as attribute types, and 590 second-layer categories as attribute instances. For the LastFM, we adopt original attributes as attribute instances. We utilize clustering to select 34 categories as attribute types. â€¢ Amazon-Book[30]: We select entities and relations in knowledge graph (KG) as attribute instances and types, separately. To ensure data quality, we select entities associated with at least 10 items. â€¢ MovieLens: MovieLens-20Mis a widely used recommendation benchmark dataset. We retain the user-item interactions with the rating> 3. Similarly, we select entities in KG as attribute instances and relations as attribute types. For each conversation episode, we sampleğ‘items with partially overlapped attribute instances as the acceptable items for the user. 6.2.1 User Simulator. Since MCR is a system based on interaction with users, we design a user simulator to train and evaluate it. Based on the scenario MIMCR, we adjust the user simulator adopted in [13]. We simulate a conversation session for each observed useritem set interaction pair(ğ‘¢, V). We regard each itemğ‘£âˆˆ Vas the ground-truth target item. The session is initialized by the simulated user specifying an attribute instanceğ‘âˆˆ P. Given a conversation, the simulated userâ€™s feedback of each turn follows the rules: (1) when the system asks a question, he/she will accept the attribute instances which are associated with any item inVand reject others; (2) when the system recommends a list of items, he/she will accept it if the list contains at least one item inV; (3) We consider that userâ€™s patience will run out when the maximum number of turnğ‘‡is reached. The simulated user will exit the system until he/she accepts the recommended item list or his patience runs out. 6.2.2 Baselines. To evaluate model performance, we compare our model with following six representative baselines: â€¢ Max Entropy: selects an attribute with the maximum entropy to ask, or recommends the top ranked items based on a certain probability [13] for each turn. â€¢ Abs Greedy[7]: only recommends items in each turn and treats rejected items as negative examples to update the model. â€¢ CRM[28]: is originally designed for single-round CRS, which utilizes reinforcement learning to select next action. Following [13], we adapt CRM to MCR scenario. â€¢ EAR[13]: adopts a three stage solution called Estimationâ€“Actionâ€“ Reï¬‚ection for MCR, and employs RL strategy to decide actions. â€¢ SCPR[15]: proposes a generic framework that models MCR as an interactive path reasoning problem on a graph, and employs the DQN [20] framework to select actions. â€¢ UNICORN[8]: proposes a uniï¬ed policy learning framework, which develops a dynamic graph based RL to select action for each turn. It is the state-of-the-art (SOTA) method. Since the above methods all use binary questions and intersection set strategy, for a more comprehensive and fair performance comparison, we adapt SCPR and UNICORN as follows: (1) The system employs multi-choice questions to ask the user. When the system decides to ask the user, the agent will generate attribute type-based multichoice questions as described in subsection 5.2. (2) The system selects candidate item set by the attribute instance-based union set strategy described in subsection 4.3. We name the two adapted methods SCPRand UNICORNrespectively. 6.2.3 Parameters Setting. We randomly split each dataset for training, validation and test with the ratio of7 : 1.5 : 1.5. We implement our model based on Pytorch and DGL. The embedding dimension is set as 64, while the batch size as128. We recommend topğ¾ = 10items or askğ‘˜= 2attribute instances in each turn. The maximum turnğ‘‡of conversation is set as15. We employ the Adam optimizer with the learning rate1ğ‘’ âˆ’ 4. Discount factorğ›¾is set to be 0.999. Following [8], we adopt TransE [2] via OpenKE [9] to pretrain the node embeddings in the constructed KG with the training set. We construct the global graph based on the training set. The numbers of current GNN layersğ¿and global GNN layersğ¿are set to be2 and1, respectively. We extract userâ€™s multiple interests withğ‘€ = 2 iterations. For the action space, we selectğ¾= 10attribute instances andğ¾= 10items. To maintain a fair comparison, we adopt the same reward settings:ğ‘Ÿ= 1, ğ‘Ÿ= âˆ’0.1, ğ‘Ÿ= 0.01, ğ‘Ÿ= 0.1, ğ‘Ÿ= âˆ’0.3. We conduct the online training for10, 000episodes for all methods. We set the maximum number ğ‘of acceptable items as 2 during the experiment. Other settings are explored in the hyper-parameter analysis. 6.2.4 Evaluation Metrics. Following previous studies on MCR [8,13,15], we utilize success rate (SR@ğ‘‡) [28] to measure the cumulative ratio of successful recommendation with the maximum turnğ‘‡, and average turn (AT) to evaluate the average number of Figure 3: Comparisons at Different Conversation Turns. turns. Besides, we adopt hDCG@(ğ‘‡,ğ¾) [8] to additionally evaluate the ranking performance of recommendations. For SR@ğ‘¡and hDCG@(ğ‘‡,ğ¾), the higher value indicates better performance. While the lower AT means the overall higher efï¬ciency. The comparison experimental results of the baseline models and our models are shown in Table 2. We also intuitively present the performance comparison of success rate at each turn in Figure 3. Relative success rate denotes the difference between each methods and the most competitive baselineUNICORN, where the blue line ofUNICORNis set toğ‘¦ = 0in the ï¬gures. For clear observation, we only report the result of four competitive baselines and our model. Based on the comparison in the table and ï¬gures, we can summarize our observations as follows: â€¢ Our framework outperforms all the comparison methods on four datasets. Compared with baselines, our method extends the form of questions to attribute type-based multi-choice formula, eliciting userâ€™s feedback of multi-acceptable items efï¬ciently. Besides, the union set strategy can effectively avoid over-ï¬ltering items. Moreover, we extract multiple interests of the user from the accepted attribute instances by combining current preferences with historical interactions, instead of utilizing a mixed single state representation to decide the next action. -w/o multi-interest0.435 12.41 0.145 0.522 10.96 0.204 -w/o global graph0.463 12.31 0.150 0.516 11.03 0.198 -binary questions0.448 12.96 0.151 0.513 11.12 0.192 -intersection set strategy0.414 12.29 0.145 0.438 11.81 0.159 -Sum-based strategy0.467 11.94 0.152 0.529 11.01 0.217 Figure 4: Performance comparisons w.r.t. ğ¾with ğ‘= 2. Figure 5: Performance comparisons w.r.t. ğ¾with ğ‘= 3. â€¢Compared to the original version of SCPR and UNICORN, adaptedSCPRandUNICORNachieve better performance, which indicates the effectiveness of above designs (multi-choice questions and union set strategy) for MIMCR. Nevertheless, our method still outperforms the adapted methods. We infer that the single user preference extracted by these baselines limits the ability to capture ï¬ne-grained user interests. â€¢Interestingly, we can ï¬nd that original SCPR and UNICORN outperform adapted versions at the ï¬rst few turns, but they fall quickly as the turn increases. Since original frameworks narrow the candidate item set following the intersection set strategy, and the acceptable items might not be ï¬ltered out when the number of accepted attribute instances is small, a smaller candidate item set can increase the probability of successful recommendation. As the number of conversations turn grows, the over-speciï¬c candidate item set over-ï¬lters out the acceptable items, which limits the subsequent improvement of these methods. On the contrary, our method achieves an outstanding performance in the latter stage of the conversation, where there are still comparatively generalized candidate items set and attributes space to avoid over-ï¬ltering. In order to verify the effectiveness of some key designs, we conduct a series of ablation experiments on the Yelp and Amazon-Book datasets. The results are shown in Table 3. 6.4.1 Impact of different modules. Firstly, we evaluate the effectiveness of different modules, including Iterative Multi-interest Extractor and Global Graph Representation. Speciï¬cally, we remove Figure 6: Performance comparisons w.r.t. ğ¾. these critical modules of MCMIPL to observe performance changes. As can be seen in Table 3, the model performance decreases signiï¬cantly without the Iterative Multi-interest Extractor, which suggests that multi-interest representation is more appropriate for MIMCR, compared to the mixed single-interest representation. Moreover, we can see that the removal of Global Graph Representation module also leads to poor performance, which indicates that the historical user representation is important for revealing latent user preferences and guiding the extraction of current multiple interests. 6.4.2 Impact of different strategies. We conduct some experiments to study the effectiveness of strategies. Speciï¬cally, we retain the binary question type ("-binary questions"), traditional candidate item ï¬ltering strategy ("-intersection set strategy"), separately. Meanwhile, we utilize the Sum-based strategy to decide the attribute type involved in questions. The binary question type version of our model performs worse than default setting, which demonstrates the efï¬ciency of multi-choice question types for the conversational interaction. Besides, the intersection set strategy achieves inferior performance. It can be inferred that limitation of item selection strategy based on all accepted attribute instances will over-ï¬lter some user-acceptable items. While for the adjustment of sum-based strategy, the model still keeps competitive performance in all metrics for MIMCR, which indicates that this strategy can select suitable attribute types based on user interests. 6.5.1 Impact of Interests Number. Since interest numberğ¾ is closely related to maximum numberğ‘of acceptable items. We explore the hyper-parameterğ¾in the case of the maximum number ğ‘of acceptable items is 2 and 3 respectively. As we can see from Figure 4 and Figure 5, with the increase of interest numberğ¾, the performance of our methods improves. In addition, when the interest numberğ¾exceeds the maximum number of acceptable items, the performance will hardly improve, which indicates that some interests may exist redundancy and point to the same user preferences. 6.5.2 Impact of Asked Attribute Instances Number. When asking users questions, the attribute instances numberğ¾included in a question affects model performance. As can be seen in Figure 6, the performance improves as the value ofğ¾increases, which indicates that the larger number of asked attribute instances in a turn, the more information the CRS obtains. However, if the value ofğ¾is too large, performance improvement is limited. That also indicates the most of extra attribute instances are invalid. Figure 7: A conversation generated by our framework. ğ¼and ğ¼denote two interests of the user, respectively. To show the process of extracting the userâ€™s multiple interests, we present a conversation case generated by our framework from MovieLens dataset in Figure 7. We only show the attribute types and instances that are relevant to the questions. For each interest, we present attribute instances with high contribution rate, where the sum of their attention scoresâ‰¥ 0.8. As can be seen, based on userâ€™s feedback of each turn as well as historical global information, our model extracts multiple interests in different attribute instances combinations. Finally, our method makes a successful recommendation based on one of the interest representations that perfectly matches userâ€™s preference. In this work, we deï¬ne a more realistic CRS scenario named MIMCR, in which the user may accepts one of multiple potential items instead of single target item in a conversation. Based on the scenario, we propose a novel framework MCMIPL, which generates multi-choice questions to collect user preferences, and utilizes union set strategy to select candidate items. In addition, we propose a MIPL module to exact multi-interest of the user to decide the next action. Extensive experimental results on four datasets demonstrate the superiority of our method in the proposed scenario.
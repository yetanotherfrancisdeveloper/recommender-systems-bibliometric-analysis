With the hardware development of mobile devices, it is possible to build the recommendation models on the mobile side to utilize the î€›ne-grained features and based modeling, we propose a mutual beneî€›t. Specially, in our MC component they will communicate the prior/privileged knowledge to each other to help better capture the user interests about the candidates, resembling the role of System I and System II in the human cognition. We conduct the extensive experiments on three benchmark datasets and demonstrate the proposed MC ACM Reference Format: Zeyuan Chen, Jiangchao Yao, Feng Wang, Kunyang Jia, Bo Han, Wei Zhang, and Hongxia Yang. 2021. MC for Mobile-Cloud Collaborative Recommendation. In Woodstock â€™18: ACM Symposium on Neural Gaze Detection, June 03â€“05, 2018, Woodsto ck, NY . ACM, New York, NY, USA, 13 pages. https://doi.org/10.1145/1122445.1122456 The information explosion on the websites greatly drives the development of recommender systems, which automatically search the content e.g., movies, songs and news, for the users based on their interests. In the past years, recommender systems are usually deployed in the cloud server, owing to the large amounts of the user behavior data and the high demand of the computing power. Recently, the rapid development of mobile devices reshapes the architecture of industrial recommender systems, and building a recommendation phase on the mobile devices to utilize the î€›ne-grained features and the real-time feedbacks is becoming a trend [4, 23, 31]. Previous recommendation tends to build the model on the cloud or device side independently as illustrated in Figure 1(a) and (b). For the slow component deployed in the cloud, it enjoys the large computing power and the rich but delayed user behaviors, which drive the development of a range of deep-learning-based models like SASRec [ DIN [35] and other complex models [ lightweight to meet the hardware constraint. They usually beneî€›t from the real-time feedbacks, î€›ne-grained features or and thefast component, according to their interaction frequency in real-world scenarios. During training and serving, Fig. 1. The recommendation prototypes. Subfigure (a) and subfigure (b) represent the independent modeling without relying on other sides, subfigure (c) and subfigure (d) respectively represent the slow-centralized modeling and the fast-centralized modeling and subfigure (e) is our framework. frequent responses [4,23] compared to the cloud-based models. However, the models of two sides have no collaboration in the training. Recent advances in recommendation start to consider the advantages of the counterpart side. For example, one representative methodology is Federated recommender systems [30], which leverage the local devices to compute the gradients of the model and simultaneously keep the data privacy. They actually utilize the computing power of the fast component to serve the slow component, but have not considered the modeling of the fast component. We use Figure 1 (c) to indicate this type of biased collaboration and term it as theslow-centralizedmodeling. Note that, the dashed arrow means the pseudo collaboration for the other side. Another representative methodology is Model-Personalized recommender systems [31], which leverage the cloud server and data to re-calibrate the backbone model. We can appropriately consider it as the reverse counterpart of Federated recommender systems and illustrate it in Figure 1 (d). In comparison, we term it as the fast-centralized modeling. Diî€erent from the above works, we focus on the bidirectional collaboration to beneî€›t both the slow component and the fast component as shown in Figure 1 (e). Speciî€›cally, we propose MC-SF, a Slow-Fast Learning mechanism for Mobile-Cloud Collaborative recommendation. In MC-SF, the slow component helps the fast component make predictions by delivering the auxiliary latent representations; and conversely, the fast component transfers the feedbacks from the real-time exposed items to the slow component, which helps better capture the user interests. The intuition behind MC-SF resembles the role of System I and System II in the human recognition [9], where System II makes the slow changes but conducts the comprehensive reasoning along with the circumstances, and System I perceives fast to make the accurate recognition [15]. The interaction between System I and System II allows the prior/privileged information exchanged in time to collaboratively meet the requirements of the environment. We summarize the contributions of this paper as follows: â€¢To our best knowledge, we are the î€›rst to study the bidirectional collaboration between the cloud-based model and the mobile-based model with the hardware advances. â€¢We introduce a slow-fast learning mechanism, MC model respectively as a slow component and a fast component, between which the prior and the privileged knowledge are interacted during the training and serving. â€¢Extensive experiments on three benchmark datasets have demonstrated that the proposed method signiî€›cantly outperforms the state-of-the-art recommendation baselines and shown the promise of the bidirectional collaboration. 2 RELATED WORK 2.1 Independent Modeling in Recommendation In this section, we review the independent modeling on the cloud side and on the mobile side respectively. Regarding the cloud-based recommendation models, the early exploration falls in the collaborative î€›ltering [ Model (LFM) [ to acquire the high-level semantics [ for recommendation and deep learning for feature learning, yielding a promising improvement in performance. To model the user dynamics in the sequences, the recurrent neural networks (RNNs) are applied to obtain the representations of whole user behavior sessions for sequential recommendation [ the hierarchical version of recurrent neural networks. Moreover, Caser [ in sequential behaviors by means of the convolution î€›lters. Some recent studies explore to utilize the attention mechanisms to learn behavior sequence representations [ scenarios [2, 14, 32]. With the hardware development of mobile devices, the mobile-based modeling has drawn much more attention in the industrial scenarios [ student network from the teacher network, which adapts the on-device inference [ that jointly leverages weight quantization and distillation for eî€œciently executing deep models in resource-constrained environments like mobile or embedded devices, is also proposed. CpRec [ technique to reduce responding time and memory footprint. Other work [ on the device side and addresses the serving concern based on a split deployment strategy. 2.2 Biased Collaboration in Recommendation This line of works could be split into two parts, the slow-centralized modeling and the fast-centralized modeling. One exemplar of the slow-centralized modeling is Federated recommender systems [ model with the aid of distributed local devices. The gradients of the local copy from the centralized deep model are î€›rst executed on plenty of devices, and then are collected to the server to update the model parameters by federated averaging (FedAvg) or its variants [ to train an accurate news recommendation model and meanwhile keep the privacy of the sensitive data. To reduce the communication costs of federated learning, the structured update and the sketched update to compress networks on the device side are introduced [ treated as the reverse counterpart of Federated Learning. DCCL leverages the cloud server and data to re-calibrate the backbone model, but actually for the on-device personalization. The slow-centralized modeling and the fast-centralized modeling do not actually achieve the bidirectional mobile-cloud collaboration, which is meaningful under the real-world pipeline of the industrial recommender systems. 33]. With the development of deep learning, deep neural networks are involved into the recommendation Fig. 2. Architecture of the model MC-SF. Input denotes the sequence of item embedding. The interacted items generated in fast component would be updated instantly (fast update) and uploaded to slow component at regular intervals (slow update) in industrial practice, whose input update is slower than fast component. Owing to large computing power, slow component has more parameters and computational complexity compared to fast component. The collaboration of both sides is achieved by prior/privileged knowledge delivery. 3 PRELIMINARY In this section, we will formulate the problem of Mobile-Cloud collaborative recommendation. LetU = {ğ‘¢, ...,ğ‘¢} denote the user set andI = {ğ‘–, ..., ğ‘–}denote the item set, whereğ‘andğ‘€are the user number and the item number respectively. For each userğ‘¢, we deî€›ne the interactive item sequenceS= {ğ‘–, ..., ğ‘–}. In the perspective of collaborative recommendation,Son the cloud side is instantiated asS= {ğ‘–, ğ‘–, ..., ğ‘–}and on the mobile side is instantiated asS= {ğ‘–, ğ‘–, ..., ğ‘–}respectively. The reason that the sequences on two sides are diî€erent, is that the feature on the mobile side are more real-time and î€›ne-grained, and we might not leverage too long sequences i.e.,ğ‘™< ğ‘™, given the limited computational resource of mobile devices. We will refer more details about them in the subsequent sections. Without loss of generality, we deî€›ne the problem of mobile-cloud collaborative recommendation as follows. Problem (Mobile-Cloud Collaborative Recommendation). As aforementioned before, we term the cloud-based model as the slow component and the mobile-based model as the fast component. Given a target userğ‘¢and a candidate item ğ‘–, the goal of both slow and fast components is to learn a function that accurately predicts the user interaction, respectively deî€›ning asË†ğ‘¦= ğ‘“(ğ‘¢, ğ‘– |S, R;Î˜)andË†ğ‘¦= ğ‘“(ğ‘¢, ğ‘– |S, R;Î˜).Î˜andÎ˜denotes the trainable parameters of the slow component and the fast component, andRandRmean the interactive features between them. Compared to the traditional recommendation without mobile-cloud collaboration or only with the biased collaboration, they will not have Rand R. The Figure 1 summarizes the diî€erence from the previous works. 4 METHODOLOGY Following the convention of recent deep learning-based recommendation methods, we map each item ID to a dense vector and tune it in the training stage. Taking item function: whereğ‘¬ the cloud and only part of it is distributed to the mobile when requested. ğ’ 4.1 Independent Slow Component For the cloud-based modeling, i.e., the slow component, we use the click sequence Hand the candidate item ğ’† whereğ’†denotes the embedding of the candidate item. We then combine following click-through rate prediction Finally, the cross-entropy loss is applied for the training of the parameters in the slow component as follows, By far, we present a typical cloud-based model without any real-time knowledge intervention from the mobile side. 4.2 Independent Fast Component For the mobile-based model, i.e., the fast component, we use either clicked or real-time exposed items they are also informative as pointed in [ parts and the exposed parts of mechanism. Formally, the procedure is formulated by the following equations, whereğ’“can be seen as the user real-time interests, and component, we combine ğ’“ and ğ’† Similarly, the cross-entropy loss is applied to train the parameters of the fast component as follows, Now, we have an independent recommendation model on the mobile side, which exploits more real-time clicked items and feedbacks from the exposed items to capture user interests. âˆˆ Ris a trainable item embedding matrix andğ‘‘is the embedding dimension. Noting that,ğ‘¬is saved in S. Deep Interest Network [35], abbreviated asDIN, is used to model the user representation from 4.3 Interactive Slow Component As proved by [5], the real-time exposures reî€ecting the user negative impression would bring the gains to the model. Based on Eq.(3)in the basic fast component, we can obtain the negative memoryË†ğ’“which memorizes the previous exposed items, and send it to the slow component. With this, the slow component can continue to feedğ’†intoGRUto generate the presumed response, and re-weight it to form the î€›nal feature about the exposure feedback, Note that, during the training phase, the oî€Ÿine optimization of the slow component could aî€ect the update operation of GRU. After Eq. (5), we can concatenate ğ’“, ğ’“in Eq. (1) and ğ’†to compute the exposure-aware prediction The optimization objective is the same as Eq. (2). 4.4 Interactive Fast Comp onent The fast component is usually a smaller model than the slow component, since the cloud side has the suî€œcient computing and storage resource to enlarge the model. This yields that the prior knowledge from the slow component is a useful hint to the fast component. Considering this, we sendğ’“andğ’“from the cloud to the mobile to help the prediction of the fast component. Specially, we transform them into the space of the hidden state in GRU, and use the transformed representations to initialize the state of GRUand GRUin Eq. (3). The procedure is formulated as follows, Following Eq.(3), we could transformğ’“andËœğ’“to the î€›nal representationğ’“. To enhance the eî€ect of the prior knowledge from the slow component, we also combineğ‘Ÿwithğ’“andğ’†to compute the prediction score like Eq.(6)as follows Similarly, the optimization objective Eq. (4) is applied. 4.5 Slow-Fast Learning The complete procedure of MC-SF is summarized in Algorithm 1. Speciî€›cally, the slow component î€›rstly receives negative memoryË†ğ’“and proceeds model optimization based onË†ğ’“and relevant input. With the completion of the training, the slow could generate representationğ’“andğ’“so as to send them to the fast component to help prediction, which corresponds to â€œInterest Embeddingâ€ transfer operation as shown in Figure 2. Based onğ’“andğ’“, the fast component continues to optimize. As the model is deployed in the mobile, it could update corresponding real-time exposed items to generate new negative memoryË†ğ’“. The upload of â€œNegative Interestâ€ in Figure 2 represents new negative memoryË†ğ’“is uploaded to improve the slow component. As such, the collaboration framework could be iterate continuously. Slow: Training: Inference: Fast: Training: 5 EXPERIMENTS This section î€›rst clariî€›es the experimental setups and then provides comprehensive experimental results, striving to answer the pivotal questions below: Q1. What is the performance of MC Q2. How does the bidirectional collaboration used in MC Q3. How do the hyper-parameters of MC 5.1 Experimental Setups This section explains the used datasets, the adopted evaluation protocols, the baselines to be compared, and the model implementations. 5.1.1 Datasets. To evaluate the model performance, we choose two datasets, ML-1M available and one industrial dataset Alipay. We preprocess the datasets to guarantee that users and items have been interacted at least 20 times in above datasets. The basic statistics of the three datasets are summarized in Table 1. Generally, each dataset is divided into three disjoint parts according to the log timestamps, including slow training phase, fast training phase, and testing phase. Speciî€›cally, for a sequence containing 1.Generate representations ğ’“and ğ’“based on ğ‘“. 2.Send representations to the fast component ğ‘“. 1.Receive representations ğ’“and ğ’“ 2.Optimize the fast component ğ‘“ 1.Accumulate exposed items and update negative memoryË†ğ’“ 2.If time > threshold: uploadË†ğ’“ 3.Else: return step 1 last 5 items, fast training phase uses the interaction history from the(ğ‘™ âˆ’9)th to the(ğ‘™ âˆ’5)th item and slow training phase contains the rest of items. Each component is trained in the corresponding phase with the aid of the other side. 5.1.2 Evaluation Protocols. Three widely used metrics is adopted: (1) HR@k (Hit Ratio@k) is the proportion of recommendation lists that have at least one positive item within top-k positions. (2) NDCG@k (Normalized Discounted Cumulative Gain@k) is a position-aware ranking metric that assigns larger weights to the top positions. As the positive items rank higher, the metric value becomes larger. (3) MRR (Mean Reciprocal Rank) measures the relative position of the top-ranked positive item and takes value 1 if the positive item is ranked at the î€›rst position. HR@k and MRR mainly focus on the î€›rst positive item, while NDCG@k considers a wider range of positive items. They are mathematically deî€›ned as follows. where ğ‘ƒis the ranking position of interaction between user ğ‘¢ and item ğ‘–, and I is the indicator function. In the experiments, we list the results w.r.t. HR@1, HR@5, HR@10, NDCG@5, NDCG@10 and MRR. Regarding negative sampling, we follow the way which is commonly observed in recommendation studies considering implicit feedback [7,10]. It is notable that there is a diî€erence between our settings and traditional recommendation when testing. For each sequence, traditional recommendation uses the most recent interaction of each user for testing. However, in our settings, we have diî€erent strategies to evaluate the slow component and fast component. The slow component cannot immediately use the sequence on the test set so that it predicts every item in testing phase based on the sequence in the slow training phase. But for the fast component deployed on the mobile side, it could instantaneously access the sequence of testing phase. Therefore, the fast component leverages all the items before the target item to perform the prediction. 5.1.3 Baselines. Some representative sequential recommendation models are considered as the slow component in the experiments: o Caser [24]. Caser is a method that combines CNNs and a latent factor model to learn usersâ€™ sequential and general representations. o SASRec[10]. SASRec is a well-performed model that heavily relies on self-attention mechanisms to identify important items from a userâ€™s behavior history. These important items aî€ect user representations and î€›nally determine the next-item prediction. o DIN[35]. DIN is a popular attention model that captures relative interests to target item and obtain adaptive interest representations. We also take the following three well-known lightweight recommendation models as the fast component: o FM[19]. This is a benchmark factorization model considering the second-order feature interactions between inputs. Here we treat the IDs of a user and an item as input features. Table 2. The results w.r.t. HR@1, HR@5, HR@10, NDCG@5, NDCG@10, and MRR for recommendation on three datasets. The best results in each measure are highlighted in â€œboldâ€. Improv. denotes the relative improvement over the second-best results. Method o NeuMF mendation. o GRU4Rec for recommendation. To validate the eî€ectiveness of the slow component as the prior of the fast component, we distribute ranking list of candidate items from the slow component to the fast component. As such, the fast component produces more accurate recommendation results based on ranking features from the slow component. Owing to the best performance validated in Table 2 and 3, we choose DIN as the slow component. Thus, the ad-hoc combination with the fast component can be termed as DIN+FM, DIN+NeuMF and DIN+GRU4Rec. 5.1.4 Model Implementations. We implement our model by Tensorî€ow and deploy it on a Linux server with GPUs of Nvidia Tesla V100 (16G memory). The model is learned in a mini-batch fashion with a size of 256. Without speciî€›cation, all methods optimized by Adam keep the default conî€›guration with optimizer, we set the learning rate to 5e-4 and keep the other hyper-parameters by default. We add L2 regularization to [7]. This is a pioneering model that combines deep learning with collaborative î€›ltering for general recom- [8]. This is a pioneering model that successfully applies recurrent neural networks to model user sequence the loss function by setting the regularization weight to 1e-4. The embedding size of all the relevant models is î€›xed to 32 for ensuring fairness. The number of layers used in MLP is set to 3. For reducing the impact of noise, all results in our experiments are averaged over 3 runs. 5.2 Experimental Results This section elaborates on the comprehensive experimental results to answer the aforementioned three research questions. Fig. 3. The case study to compare the independent or interactive slow and fast components for one user. The leî€œ side presents five items that user clicked recently and the right side gives the top-5 recommendation from four methods. (â€œFastâ€ and â€œSlowâ€ denote independent components, â€œS2Fâ€ and â€œF2Sâ€ denote interactive components.) 5.2.1 Comparison (Q1). Table 2 presents the overall performance of our model and all the adopted baselines on the mobile side, from which we have the following observations: â€¢FM and NeuMF are comparable on each dataset. These two models both focus on feature interaction and user-item collaborative information. Such distinction might be attributed to the characteristics of corresponding datasets. â€¢Compared with other baseline models of the fast component, GRU4Rec achieves the best results on the three datasets. This conforms to the expectation since only using the representations from the user and item is insuî€œcient, which ignores sequential temporal patterns. Standard RNNs are good at modeling sequential dependencies, and thus user preference information hidden in behavior sequences could be eî€ectively captured. â€¢Compared to basic fast components that do not consider the guidance of the slow components, all fast components with the privileged information from DIN achieve better performance than the independent counterparts. Table 2 and 3 presents the overall performance of our model and all the adopetd baselines on the cloud side. â€¢ From the table, Caser achieves poor results on the three datasets. The reason might be that the convolution î€›lter is not good at capturing sequential patterns. â€¢SASRec is a transformer-like recommendation model. Due to the strong power of attention computation used in transformer, they perform signiî€›cantly better than the aforementioned models. However, DIN that models the interaction between the target item and the behavior sequence achieves the best results. As shown in Table 2 and 3, MC-SF achieves consistently better performance than all the baselines. In particular, MC-SF improves the second-best performed models w.r.t. NDCG@5 by 5.70%, 1.60%, and 2.30% on ML-1M, Alipay, and Steam, respectively. This is because: (1) MC-SF can distill collaborative knowledge from the slow component to the fast component through generalized interest representations. (2) The introduction of the negative memory can signiî€›cantly improve the collaborative recommendation task, which is validated in Figure 4. 5.2.2 Ablation Study ( in MC-SF. Speciî€›cally, (1) â€œDINâ€ represents using DIN to produce prediction results from perspectives of the slow component. (2) â€œw/ F2Sâ€ means uploading negative memory from the fast component to the slow component, so that the slow component could combine these features to reî€›ne the predictions. (3) â€œw/ S2Fâ€ denotes that the slow component distributes privileged features to the fast component on the basis of â€œw/ F2Sâ€ and proceeding the collaborative recommendation. Throughout the result analysis of the ablation study shown in Figure 4, we observe that: â€¢â€œw/ F2Sâ€ achieves better performance improvement. It validates the crucial role of negative memory of the fast component. This is because learning from negative features could lead to more informative user representations which contain positive and negative information. â€¢â€œw/ S2Fâ€ also shows the signiî€›cant improvements, which reveals that distributing privileged features and proceeding collaborative recommendation is indispensable. The reason might be that the privileged features could introduce the long-term user interests that the fast component does not have. Meanwhile, collaborative learning for both components is easy to reach equilibrium of the two sides. 0.74 0.72 0.70 0.68HR@5 0.66 0.64 HR@50.70NDCG@50.74HR@50.70NDCG@5 Fig. 5. The performance of MC-SF on ML-1M dataset w.r.t diî€›erent hyper-parameters. 5.2.3 Parameter Sensitivity (Q3). We here study the performance variation for MC-SF w.r.t. hyper-parameters, and comparative results are shown in Figure 5. Impact of Embedding Size.We set the embedding size in{4,8,16,32,64}. According to the results, the small embedding size might limit the capacity of the model, and too large embedding size is also hard to learn. Only the proper dimension achieves the best performance. Impact of Regularization.We vary the regularization coeî€œcientğœ†among{1ğ‘’,1ğ‘’,1ğ‘’,1ğ‘’,1ğ‘’}, and the best performance is achieved when it is set to 1ğ‘’. The regularization coeî€œcientğœ†is critical to avoid over-î€›tting. Too small ğœ† cannot constrain the model eî€ectively and too large ğœ† may lead to the under-î€›tting situation. 5.2.4 Case Study. To visualize how the collaborative recommendation works, we present the recommendation results of four methods, and illustrate in Figure 3. According to Figure 3, (1) â€œFastâ€ prefers to the prediction relevant to recent click sequence. â€œSlowâ€ recommends based on the sequence in the cloud server, thus the category of movies is somewhat diî€erent compared to the î€›ve items that user clicked recently. (2) â€œS2Fâ€ mixes the results from â€œFastâ€ and â€œSlowâ€ to some extent, which considers both the long-term interests and the short-term interests. Besides, the category of childrenâ€™s does not exist in the recommendation results of â€œF2Sâ€, which is more relevant to the sequence in the cloud server. 6 CONCLUSION This paper studies mutual beneî€›ts of the slow component and the fast component by a Slow-Fast Collaborative Learning framework. The proposed MC-SF explores to transfer the prior/privileged knowledge from one side to the other side, and introduces a bidirectional collaborative learning framework to beneî€›t each other. Especially, this work î€›rstly introduces slow-fast ideology to recommendation, resembling the role of System I and System II in the human cognition. The comprehensive experiments conducted on two public datasets and one industrial datasets show the promise of MC-SF and the eî€ectiveness of its main components.
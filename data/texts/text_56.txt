In the information explosion era, recommender systems (RSs) are widely studied and applied to discover user-preferred information. A RS performs poorly when suî€ering from the cold-start issue, which can be alleviated if incorporating Knowledge Graphs (KGs) as side information. However, most existing works neglect the facts that node degrees in KGs are skewed and massive amount of interactions in KGs are recommendation-irrelevant. To address these problems, in this paper, we proposeDiî€erentiableSampling onKnowledge Graph forRecommendation with RelationalGNN (DSKReG) that learns the relevance distribution of connected items from KGs and samples suitable items for recommendation following this distribution. We devise a diî€erentiable sampling strategy, which enables the selection of relevant items to be jointly optimized with the model training procedure. The experimental results demonstrate that our model outperforms state-of-the-art KG-based recommender systems. The code is available online at https://github.com/YuWang-1024/DSKReG. â€¢ Information systems â†’ Collaborative î€›ltering;Recommender systems; Personalization. ACM Reference Format: Yu Wang, Zhiwei Liu, Ziwei Fan, Lichao Sun, and Philip S. Yu. 2021. DSKReG: Diî€erentiable Sampling on Knowledge Graph for Recommendation with Relational GNN. In Proceedings of the 30th ACM International Conference on Information and Knowledge Management (CIKM â€™21), November 1â€“5, 2021, Virtual Event, QLD, Australia. ACM, New York, NY, USA, 5 pages. https: //doi.org/10.1145/3459637.3482092 Recommender systems have become essential tools for Internet applications to discover potential usersâ€™ interests [3,4,21,30,32]. The crucial part in a recommender system is to characterize collaborative signals from user-item interactions, and recommend similar users with correlated items [7,14,23]. However, only leveraging user-item interactions spoils recommendation performance when the data suî€ers cold-start issues [12,22]. Therefore, existing works [1,19,22] propose to incorporate knowledge graphs (KGs) as side information [11], which aî€ord additional semantics among items through intermediate entities, thus alleviating cold-start issues from item perspectives. Leveraging the information from KGs requires the model aggregating relevant interactions among items for recommendation [5, 22]. The successes of Graph Neural Networks (GNNs) [6,9,13, 17,26] inspire the community designing novel methods for information aggregation. KGCN [20] is one of the pioneering work that adopts GCN [9] layers to aggregate entities in KGs to infer item embeddings. KGNN-LS [19] further extends this idea by assigning user-speciî€›c scores on interactions, thus characterizing personalized interests. KGAT [22] employs graph attention layers [17] to aggregate both item and user embeddings from KGs. Moreover, ATBRG [5] constructs sub-graphs from KGs and proposes a relation-aware graph attention layer to adaptively search relevant interactions. Despite the eî€ectiveness of existing methods, two limitations are still under-explored: 1) node degree skewness and 2) noisy interactions. Node degree skewness refers that the number of edges for nodes in KGs exhibits a power-law distribution [2]. On the one hand, due to large number of nodes with low degrees and insuî€œcient neighbors, a multi-layer GNN aggregation is required to receive high-order information [22]. On the other hand, high-order aggregation for nodes with high degrees leads to exponential growth of their receptive î€›eld [29], thus suî€ering the over-smoothing problem [10,16]. The second limitation results from massive amount of recommendation-irrelevant interactions in KGs [5]. Existing methods infer item embeddings by aggregating all connected entities in KGs. However, directly aggregating those irrelevant entities has no contributions to the representation learning and even increases computational costs, which degrades the performance. To address the limitations above, we propose a sampling-based relational GNN to extract recommendation-relevant information from KGs. First, we connect items in KGs according to their intermediate entities and create new relations, such as creating a co-director relation if two movies are connected by a common director. We illustrate this process in Figure 1(a). This relational graph construction is inspired by works in heterogeneous graph [24,27]. In this way, we could explicitly reveal the item relationships. Second, we adopt sampling-based aggregation of neighbors to avoid the exponential growth of neighbor size, thus alleviating the over-smoothing issue. Figure 1: A toy example reî€ecting the framework of DSKReG. a) We construct user-item graph according to usersâ€™ collaborative interactions, and construct item-item graph by connecting high-order neighbor items. b) For the item ğ‘– relevance score vector ğ‘that consists of scores of neighbor items ğ‘– obtain an approximated one-hot encoderË†ğ‘¦. The value ofË†ğ‘¦indicates that neighbor item ğ‘– attentive aggregation on relational graph guided by usersâ€™ preferences. However, it is rather challenging to devise a suitable sampling method. Most sampling-based GNNs in KG-based recommendation employ uniform sampling [18â€“20] of neighbors, which is unable to distinguish recommendation-relevant relations. Moreover, existing sampling strategies [6,25,31,33] are independent of the optimization process, which further hinder the end-to-end training manner. RippleNet [18] detachedly samples a î€›xed-size set of neighbors to infer item embeddings. KGPolicy [25] employs a disjoint reinforcement learning agents to discover high-quality negative examples in KGs. Both methods separate the sampling procedure from the training phase, resulting in a sub-optimal selection of neighbors. Therefore, we propose a novel model,Diî€erentiableSampling onKnowledge Graph forRecommendation with RelationalGNN (DSKReG). Given an item, we î€›rst compute relevance scores of connected items conditioned on their associated relations and node embeddings. Relevance scores are used to sample top-ğ¾relevant neighbor items. As such, our model can distinguish the recommendationrelevant items among connected neighbors according to relation and item types. We also adopt Gumbel-Softmax reparameterization trick [8,28] into the sampling procedure, which approximates the sampling probability from a categorical distribution, thus enabling the sampling procedure to be diî€erentiable. Therefore, the sampling component is optimized jointly with the training objective, thus enjoying an end-to-end fashion. Our contributions are summarized as follows: 1) We compute relevance scores according to relation and item types for sampling, which can navigate model to select recommendation-relevant items. 2) We devise a diî€erentiable sampling strategy to enable the model to reî€›ne the sampling procedure jointly with the model optimization. 3) We conduct experiments on three public datasets, and demonstrate the eî€ectiveness of our model. In this section, we î€›rst formulate the problem of knowledge-aware recommendation. Then, we propose the DSKReG framework, which is shown in Figure 1. Gumbel Softmax and ğ‘–. Afterwards, we apply Gumbel-Softmax over ğ‘to The objective of knowledge-aware recommendation is to predict whether userğ‘¢has interest in itemğ‘£given historical interactions and the KG. Formally, the historical interactions from a set of users Uwith the set of itemsVare represented as a user-item bipartite graphG= {(ğ‘¢, ğ‘¦, ğ‘£)|ğ‘¢ âˆˆ U, ğ‘£ âˆˆ V}, whereğ‘¦=1 denotes that the userğ‘¢is interacted with the itemğ‘£through clicking, purchasing, and etc. The KG consists of item related properties, such as genres, directors, and casts for movies. We format the KG as a directed heterogeneous graphG= {(â„, ğ‘Ÿ, ğ‘¡)|â„, ğ‘¡ âˆˆ E, ğ‘Ÿ âˆˆ R}, such as (James Cameron, isdirectorof, Titanic), whereEandRdenote the set of entities and relations respectively. Thus, the knowledge-aware recommendation task can be formalized as follows: whereË†ğ‘¦is the prediction of userâ€™s interest in itemğ‘£, andFis the learned prediction function with weights Î˜. The node degree skewness limits the pool of available neighbor items for items with scarce connections in a KG. We propose â€œcointeractâ€ patterns to build up higher order item-item relationships for shortening the path distance between correlated items. Intuitively, those co-interact patterns are important for the recommendation. For example, a user might be interested in books written by the same author. We extract co-interact patterns from input KGG and construct an item-item co-interact undirected graphGwith a new set of co-relations, which is deî€›ned as follows: G= {(ğ‘–, ğ‘Ÿ, ğ‘–)| if (ğ‘–, ğ‘Ÿ, ğ‘¡) âˆˆ Gand (ğ‘–, ğ‘Ÿ, ğ‘¡) âˆˆ G}, (2) whereğ‘Ÿdenotes the new â€œco-ğ‘Ÿâ€ relationship. Following the navigation of these relations, we connect items that have co-interact patterns and construct the item-item graph as shown in Figure 1(a). In this way, we can connect high-order neighbors directly and avoid exponential growth of the receptive î€›eld. We unify both user-item bipartite graphGand item-item co-interact graphGinto one single graph denoted as relational graph. Thus, we can consider all these relations between users and items for subsequent tasks. Here, we introduce the proposed diî€erentiable sampling for neighbors selection. We only illustrate it from itemâ€™s perspective because it is the same process for users. The relevance of co-interact relationships to recommendation varies across users. For example, same genre has more impacts than co-director. Moreover, co-interact relationships are imbalanced. For example, item-item pairs of codirector are much less than the ones of the same category. This brings up an issue that highly relevant neighbors diminish when the pool of potential neighbors is large. The uniform sampling technique adopted by existing works [19,20] still fails to tackle this issue. In order to î€›lter out the noise and retain the truly relevant information, we introduce the relation-aware sampling method that assigns weights from relation perspective, as shown in Figure 1(b). The sampling procedure î€›rst deî€›nes a novel relation-aware relevance score distribution for each item and then samples from it. The relation-aware relevance score distribution of an item ğ‘– on its co-related neighbors N (ğ‘–) is deî€›ned as follows: ğ‘ (ğ‘£= 1|w,ğ‘) =exp(w[r||e] + ğ‘)Ãexp(w[r||e] + ğ‘) whereğ‘ (ğ‘£=1|w,ğ‘)denotes the plausibility of itemğ‘—being relevant to the target itemğ‘–;w âˆˆ Randğ‘ âˆˆ Rare the learnable weight and bias;râˆˆ Randeâˆˆ Rare embeddings of relation and neighbor item respectively, andğ‘‘is the dimension of embeddings. The co-relation and neighbor item together determine its neighbor relevance probability, which emphasizes the necessity of relation-awareness in relevance calculation for the sampling. We apply the same relevance calculation process to users. Given the calculated relevance distribution, we thus only select top-ğ¾most relevant items. Selection procedure of previous works [5] is independent of optimization. In other words, the recommendation performance is highly contingent on the result of selection procedure. To make this procedure diî€erentiable and joint with optimization process, we apply the Gumbel-Softmax reparameterization trick. Given a Gumbel noiseg âˆ¼ ğºğ‘¢ğ‘šğ‘ğ‘’ğ‘™ (0,1), we can draw a soft categorical sample with the following equation: wherepâˆˆ Rconsists of relevance scoreğ‘ (ğ‘£)for all the neighborsğ‘— âˆˆ N (ğ‘–)deî€›ned in Eq. (3), andğœis the annealing temperature. It has been proved [8,28] thatË†yis approximate to a one-hot encoder asğœgoes to 0. We repeat the above procedure forğ¾times and sum the approximated one-hot encoders. At each time, the relevance score inpof selected items will be set as 0. In this way, we can obtain ağ¾-hot vector representing the top-ğ¾relevant items selected for subsequent learning procedures. Besides the factor of relations, we should also consider user preference in the top-ğ¾neighbor messages propagation process. As users might have diî€erent preferences towards various relations, we take the relations into account in the aggregation. The aggregation procedure, as shown in Figure 1(c), infers the embedding of item ğ‘– as follows:îƒ• whereğ‘is theğ‘—-th position value in theğ¾-hot vector of the item ğ‘–obtained from sampling procedure, which indicates whether the itemğ‘—is selected as a neighbor of itemğ‘–. Theeâˆˆ Ris userâ€™s embedding. For users, we obtain the inferred user embeddingË†ğ‘’ in a similar procedure, but the attentions are calculated using the connected item embeddings. We use the dot-product to generate the preference score of userğ‘¢ to itemğ‘–with the inferred user/item embeddingsË†eandË†e, respectively. The prediction is calculated as follows: We use the pairwise BPR loss [15] to optimize top-ğ‘recommendation, which is deî€›ned as follows:îƒ• L=âˆ’logğœ(Ë†ğ‘¦(ğ‘¢, ğ‘–) âˆ’Ë†ğ‘¦(ğ‘¢, ğ‘—))+ ğœ†||Î˜|| whereDis a set of triplets, each of them is composed of userğ‘¢, an interacted itemğ‘–and one sampled negative item from items that user ğ‘¢ never interacts with. In this section, we introduce the experimental settings and compare our model with state-of-the-art methods on three common benchmark recommendation datasets. Then, we perform the ablation study and discuss eî€ects of the modelâ€™s components. Datasets.To evaluate the eî€ectiveness of our model, we perform experiments on three benchmark datasets: Last.FM, BookCrossing and MovieLens-Sub. Last.FM is a set of online listening information from Last.fm website. BookCrossing contains usersâ€™ ratings of books. MovieLens-Sub comes from a widely used benchmark dataset: MovieLens-1M, which contains usersâ€™ ratings of movies from MovieLens website. Table 2 provides detail empirical statistics of these datasets. We deî€›ne the density of a dataset as the division of the number of ratings by the number of users, which indicates the average number of ratings per user. During the empirical study of these datasets, we found the density of original MovieLens-1M is 62.4, which is extremely large compared to other datasets. To make the dataset î€›t the cold-start scenario, we only randomly chose 10% of all ratings to construct MovieLens-Sub. Baselines.We compare our model with state-of-the-art methods: KGAT [22], KGNN-LS [19], RippleNet [18] and knowledge embedding based method CFKG [1]. To evaluate top-ğ‘recommendation and preference ranking performance, we use three standard metrics: Recall, Precision, and NDCG. For each dataset, we randomly sample a subset of users for evaluation. Then, we rank the usersâ€™ preference scores over all items except training items. Finally, we compute the Recall, Precision, and NDCG on top 5, top 10, and top 20 items, respectively. As Table 1 shows, our model outperforms state-of-the-art methods signiî€›cantly in most cases. Compared to the strongest baseline model, we manage to improve the performance by 7.73%, 6.2%, and 9.03% on Last.FM on average for Recall, Precision, and NDCG respectively. Similarly, we outperform the best baseline model by 9.43%, 4.97%, and 19.83% on BookCrossing. On the MovieLens-Sub dataset, we improve the performance by 11.47%, 15.60%, and 45.47% respectively. These results indicate the eî€ectiveness of our model. Surprisingly, our model improve the NDCG by a signiî€›cant margin. Speciî€›cally, we improve the NDCG@20 by 14.2%, 32.0%, and 37.5% on three datasets respectively. Since NDCG measures the recommendation quality taking position signiî€›cance and the number of items into account, these results demonstrate the superiority of our model in recommendation. In this section, we perform the ablation study to better understand eî€ects of diî€erent components of our model. The Eî€ect of Relation-aware Sampling. To examine the eî€ect of relation-aware sampling, we compare our model with diî€erent sampling strategies. As shown in Figure 2, uniform indicates we randomly selectğ¾neighbors for each item; L2 means we use the ğ¿2-norm of diî€erence between relation and neighbor item embeddings as the categorical sampling distribution; Inner represents that we use the inner product between relation and item embeddings as sampling probability; We denote the diî€erentiable sampling method using Gumbel-Softmax as GS. The experimental results indicate that the GS outperforms the others on Last.FM and MovieLens-Sub. On BookCrossing, models using L2 distance and Inner product metrics can achieve comparable results with GS. The possible reason is that relations among items in this dataset are relatively simple. As shown in Table 2, BookCrossing has smaller number of relations in the original KG dataset than that in Last.FM, and smaller number of triples than that in MovieLens-Sub. The L2 distance and Inner product metric are suî€œcient to model the item relations. However, in dealing with complex item relations, GS signiî€›cantly outperforms the other metrics. The Eî€ect of Sampling Size. To examine the eî€ectiveness of neighbor size, we perform experiments with diî€erentğ¾, which is the size of the neighborhood after sampling. As shown in Figure 3, the best neighbor size is 8 for Last.FM, BookCrossing, and MovieLens-Sub. This indicates that only a small portion of items are relevant. Our model can correctly select this valuable information for aggregation, which enables our model to achieve the best performance with only eight neighbors. In this paper, we proposed a novel framework DSKReG to alleviate the node degree skewness and noisy interactions limitations when tackling KG-based recommendation. DSKReG is a sampling-based relational GNN, which extracts recommendation-relevant information from KGs. We devised a diî€erentiable sampling strategy for DSKReG, which is jointly optimized with the model to learn how to select top-ğ¾relevant items for aggregation. We conducted experiments on three public dataset to demonstrate the eî€ectiveness of DSKReG in improving the recommendation performance. This work is supported in part by NSF under grants III-1763325, III-1909323, III-2106758, and SaTC-1930941.
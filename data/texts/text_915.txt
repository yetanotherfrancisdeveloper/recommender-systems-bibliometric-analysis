<title>Towards Fair Recommendation in Two-Sided Platforms</title> <title>arXiv:2201.01180v1  [cs.IR]  26 Dec 2021</title> achieved by tailoring the recommendations according to the personalized preferences of individual customers, largely ignoring the interest of the producers. Several recent studies have shown how such customer-centric designs may undermine the well-being of the producers [ 20 27 36 38 ]. As more and more people are depending on two-sided platforms to earn a living, recently platforms have also started showing interest in creating fair marketplaces for all the stakeholders due to multiple reasons: (i) legal obligation (e.g., labor bill for the welfare of drivers on Uber and Lyft [ 50 ], fair marketplace laws for e-commerce [ 66 ]), (ii) social responsibility or voluntary commitment (e.g., equality of opportunity to all gender groups in LinkedIn [ 32 ], commitment of non-discrimination to hosts and guests by AirBnb [ ]), (iii) business requirement/model (e.g., minimum business guarantee by AirBnb to attract hosts [6]). In this paper, our focus is on the fairness of personalized recommendation services deployed on the two-sided platforms. Traditionally, platforms employ various state-of-the-art data-driven methods (e.g., neighborhood-based methods [ 51 ], latent factorization methods [ 43 46 ], etc.) to estimate the relevance scores of every product-customer pairs, and then recommend most relevant products to the corresponding customers. While such toprecommendations achieve high customer utility, our investigation on real-world datasets reinforces the presence of popularity bias [ 40 ] that is, they can create a huge disparity in the exposure of the producers (detailed in Â§4.2), which is unfair for the producers, and may also hurt the platforms in the long term. In these platforms, exposure often determines the economic opportunities (revenues) for the producers who depend on it for their livelihood. For instance, high exposure on Google Maps can increase the footfall in a local business, thereby increasing their revenue. High exposure on YouTube, Spotify or Last.fm can increase the traî€œc to a content producerâ€™s channel, and hence help them earn better platform-royalties or advertisement revenues. On the other hand, if only a few producers get most of the exposure, then the other producers would struggle on the platform, which could force them to either quit or switch to other platforms [ 25 49 60 ]. This, in turn, may limit the choices for the customers, degrading the overall experience on the platform. Thus, it is important to reduce exposure inequalities. However, extremely producer-centric ways of reducing inequality (e.g., recommending the least exposed producers to the customers) may result in loss and disparity in customer utilities (Â§4.2), making it ineî€œcient as well as unfair to the customers. To counter such unfairness for both producers and customers, we propose to tackle the challenging task of ensuring two-sided fairness while providing personalized recommendations. Speciî€›cally, we propose to ensure a minimum exposure guarantee for every producer such that no producer starves for exposure. Since the exposure guarantee on the producer side could incur losses on the customer side (i.e., reduction in customer utilities), we propose that the loss in utility should be fairly distributed among the customers. Motivated by a vast literature in social choice theory, we map this problem to the problem of fairly allocating indivisible goods (Â§5). In an allocation problem, there is often a predeî€›ned set of items and a set of agents with their valuations (how much an agent values an item), and the task is to allocate the items among the agents. To map our recommendation problem to an allocation problem, we assume the set of customers as the set of agents. Now we can strategically î€›x the set of items as the one which contains as many copies of each product (or producer) as the chosen exposure guarantee, and then allocate them among the customers. If we have an algorithm that does this task, then the strategic setting of the item-set and their allocation guarantee can, in turn, ensure minimum exposure for the producers. Besides, the algorithmâ€™s fairness guarantee for the agents during the allocation would also be able to guarantee customer fairness. Thus, the original recommendation problem becomes an interesting (constrained) extension to the existing fair allocation problemâ€”î€›nd an allocation that guarantees minimum exposure (upper bounded by maximin share of exposure or MMS) for the producers, and envy-free up to one item (EF1) [ 19 ] for the customers . We propose an algorithm FairRec (Â§6) which solves this problem and gives guarantees on both producer and customer side (proofs in Â§7). Extensive evaluations over multiple real-world datasets show the eî€ectiveness of FairRec in ensuring two-sided fairness while incurring a marginal loss in recommendation quality. In summary, we make the following contributions in this paper. We consider a two-sided fair recommendation problem that not only relates to social or judicial precepts but also to the long-term sustainability of two-sided platforms (Â§4). We design an algorithm, FairRec (Â§6), exhibiting the desired two-sided fairness by mapping the fair recommendation problem to a fair allocation problem (Â§5). Moreover, it is agnostic to the speciî€›cs of the data-driven model (that estimates the product-customer relevance scores) which makes it scalable and easy to adapt. In addition to the theoretical guarantees (Â§7), extensive experimentation and evaluation over multiple real-world datasets deliver strong empirical evidence on the eî€ectiveness of our proposal (Â§8). Finally, we also present a modiî€›ed version of FairRec (named as FairRecPlus) that uses an envy-cycle elimination and swapping technique to improve the performance on customer-side metrics, while maintaining the same two-sided fairness guarantees (Â§9). We brieî€y survey related works in two directions: (i) fairness in multi-stakeholder platforms, and (ii) fair allocation of goods. With the increasing popularity of multi-sided platforms, recently researchers have looked into the issues of unfairness and biases in such platforms. For example, Edelman et al . [27] investigated the possibility of racial bias in guest acceptance by Airbnb hosts, Lambrecht and Tucker [45] studied gender-based discrimination in career ads, Chakraborty et al . [24] proposed to ensure fair representation in crowdsourced recommendations. While these works deal with group fairness, Serbos et al . [58] proposed an envy-free tour package recommendations on travel booking sites, ensuring individual fairness for customers. On producer fairness, HannÃ¡k et al . [38] studied racial and gender bias in freelance marketplaces, and Dash et al . [26] investigated favoritism towards certain producers on e-commerce marketplace. In a social experiment, Salganik et al . [57] found that the existing popular producers often acquire most of the visibility while new but good ones starve for visibility. Banerjee et al . [9] also found popularity bias in location based recommendations. Kamishima et al . [41] and Abdollahpouri et al [2] proposed methods to reduce such popularity bias among producers. SÃ¼rer et al . [64] proposed to maximize total customer utility while ensuring some exposure for the producers. While these works have proposed to ensure some forms of producer-side fairness, they have not looked into the resulting unfairness on the customer-side, the trade-oî€ between producer and customer fairness, and the cost of achieving one over the other. Few past works have discussed fairness for both producers and customers. Abdollahpouri and Burke [1] and Burke [20] categorized diî€erent types of multi-stakeholder platforms and their desired group fairness properties, Chakraborty et al . [23] and SÃ¼hr et al . [63] presented mechanisms for two-sided fairness in matching problems while Patro et al . [53] addressed fairness issues arising due to frequent updates of platforms. In contrast, our paper addresses individual fairness for both producers and customers, which also answers the question of the long-term sustainability of two-sided platforms. There exists another line of work on fairness in ranking and recommendations, namely Biega et al . [12] , Singh and Joachims [59] , which propose to ensure the producers with expected exposures in proportion to their corresponding relevance scores in order to maintain individual fairness for producers in gig-economy platforms. One of the limitations of these works is that they assume the availability of true relevance scores of producers. However, these relevance scores are often estimated and usually contain noise, which is also highlighted in Raj et al . [56] . The noise is not the only issue here; if the estimated relevance scores themselves exhibit popularity bias, then ensuring exposure in proportion to these relevance scores could cause the same inequalities in producer exposures and can do very little towards producer fairness. Thus in this work, we try to isolate the considerations of exposure and relevance. Formally, we use the exposure of a producer as the measure of its utility, the relevance of recommended items as the utility of a customer (more details in Â§3), and î€›nally we deî€›ne fairness for both sides using the (in)equality in their individual utilities. The problem of fair allocation (popularly known as the cake-cutting problem) has been studied extensively in the area of computational social choice theory. The classical notions of fairness for this problem are envy-freeness (EF) [ 31 65 ] and proportional fair share (PFS) [ 61 ]. Recent literature on practical applications of fair allocation [ 18 28 ] has focused on the problem of allocating indivisible goods in budgeted course allocation [ 19 ], balanced graph partition [ 16 ], or allocation of cardinality constrained group of resources [ 14 ]. In such instances, no feasible allocation may satisfy EF or PFS fairness guarantees. Thus, the notable work of Budish [ 19 ] deî€›ned analogous fairness notions which are appropriate for indivisible goodsâ€”namely, envy-freeness up to one good ( EF1 ) and maximin share guarantee (MMS). The relevance of EF1 is substantiated by the fact that it is guaranteed to always exist under general monotone valuations and, in fact, such allocations can be obtained in polynomial time [ 48 ]. When the valuations are additive, Caragiannis et al [ 22 ] show that a simple greedy round robin algorithm is enough to ensure EF1. MMS fairness is another solution concept that has been extensively studied in the fair allocation space. In particular, Bouveret et al. [ 17 ] showed that an MMS allocation exists when the agentsâ€™ valuations are additive and binary (valuations are 0 or 1). However, Procaccia and Wang [ 55 ] and Kurokawa et al. [ 44 ] provided intricate counterexamples to refute the universal existence of MMS allocations, under additive and non-binary valuations. This motivated the study of approximate maximin share allocations, ğ›¼-MMS, where each agent obtains a bundle of value at least ğ›¼ âˆˆ (0, 1) times her maximin share. The existence of 2 3MMS and accompanying algorithms were developed in a sequence of results [ 11 55 ]. Later, Ghodsi et al. [ 33 ] improved the result by providing an eî€œcient algorithm that obtains 3/4-MMS allocations. The vast majority of work in the fair allocation space has solely focused on the unconstrained version of the problem; exceptions include the work of Biswas et al. [ 14 15 ] and GourvÃ¨s et al. [ 34 35 ]. Biswas et al. [ 14 ] provide algorithms for computing EF1 and 1 3MMS for the allocation problem where items are categorized into groups, and an upper bound restricts the number of items that can be allocated to each agent from each category. This is slightly diî€erent from the problem we consider (detailed in Â§5.3). A general version of the category-wise upper bound constraint, namely laminar matroid constraint, is studied by Biswas et al. [ 15 ] and the existence of EF1 is proved for identical valuations. A diî€erent problem is considered by GourvÃ¨s et al. [ 34 35 ] where the goal is to î€›nd MMS fair allocation that union of all the allocated goods is an independent set of a given matroid. Although these papers study fair allocation under several combinatorial constraints, they do not directly apply to the problem we consider. Moreover, all the above mentioned papers consider fairness among the agents but not among the items. In this work, we consider fairness across the agents as well as the items. We map the problem of fair recommendation to a fair allocation problem, which leads to an interesting extension of previously studied problems owing to the speciî€›c constraints pertaining to recommendations (detailed in Â§5.3). This paper is an extended version of our earlier work, titled â€œFairRec: Two-Sided Fairness for Personalized Recommendations in Two-Sided Platforms" [ 52 ]. In [ 52 ], we introduced the notions of two-sided fairness in recommendations and proposed the FairRec algorithm to ensure fairness for both producers and customers. In this work, we prove that FairRec ensures a stronger theoretical guarantee on the producer-side. Additionally, since we provide a tunable parameter to the platforms to regulate the minimum exposure guarantee for the producers, we present a detailed analysis on what actually happens when the value of is changed and its impact on both producerside and customer-side. In certain scenarios, the platforms might be interested in ensuring diî€erent levels of exposure guarantee for diî€erent producers; for example, the platform may want to give more exposure guarantee to higher-rated producers than the lower-rated ones. Thus, we also evaluate FairRec in such scenarios by tweaking the FairRec algorithm to entertain such requirements. We add several new baselines, such as MPB19 [ ], MSR18 [ 64 ], MixedTR, MixedTP, to compare against FairRec. Finally, we propose a new modiî€›cation of FairRec (named as FairRecPlus) that utilizes the envy graph to improve the recommendation performance for the customers, but comes at a cost of increased time complexity. In this section, we deî€›ne the terminology and notations used throughout the paper. In a few two-sided platforms focusing on physical establishments (e.g., Google Maps, Yelp), a producer typically owns one product (e.g., restaurant or shop); whereas in multimedia platforms like Spotify, YouTube or Netî€ix, an artist can produce multiple songs or videos; the same is also true for ecommerce platforms like Amazon and Flipkart, where one producer can list many products. To generalize our approach to both types of two-sided platforms, we consider products and producers to be equivalent, and use the terms â€˜productâ€™ and â€˜producerâ€™ interchangeably. Even for platforms where a producer can have multiple products, ensuring fairness at the product level can ensure fairness for individual producers â€“ where fairness can be ensured by making the exposure proportional to the producerâ€™s portfolio size. Let and be the sets of customers and producers respectively, where |ğ‘ˆ | = ğ‘š , and |ğ‘ƒ | = ğ‘› . Let be the number of products to be recommended to every customer. âŠ‚ ğ‘ƒ represents the set of products recommended to customer ğ‘¢; |ğ‘… | = ğ‘˜. The relevance of a product to customer , denoted as (ğ‘) , represents the likelihood that would like the product . Formally, relevance is a function from the set of customers and products to the real numbers ğ‘ˆ Ã— ğ‘ƒ â†’ R . Usually, the relevance scores are predicted using various data-driven methods (e.g., neighborhood-based methods [ 51 ], latent factorization methods [ 43 46 ], etc.), and (ğ‘) is a proxy for the utility gained by ğ‘¢ if product ğ‘ is recommended to her. The utility of a recommendation to a customer is proportional to the sum of relevance scores of products in . Thus, recommending the most relevant products will give the maximum possible utility. Let be the set of toprelevant products for . We use a normalized form of customer utility from ğ‘… , deî€›ned as: ğœ™ (ğ‘… ) = Exposure of a producer/product is the total amount of attention that receives from all the customers to whom has been recommended. In this paper, we assume a uniform attention model where customers pay similar attention to all recommended products, and express the exposure of a product as (ğ‘) , where (ğ‘) is 1 if ğ‘ âˆˆ ğ‘… , and 0 otherwise. The sum of exposures of all the products is = ğ‘š Ã— ğ‘˜ . Note that we assume the relevance of a product does not play any role in producerâ€™s utility (in contrast to Biega et al . [12] , Singh and Joachims [59]), and use only the exposure of a producer as her utility. Traditionally, the goal of personalized recommendation has been to recommend products that would be most relevant to a customer. This task typically requires learning the relevance scoring functions ( ), and several state-of-the-art data-driven methods [ 42 46 51 67 68 ] have been developed to estimate the product-customer relevance values. Once these values are obtained, the standard practice, across several recommender systems, is to recommend the top=size of recommendation) relevant products to corresponding customers. While this approach attempts to maximize the satisfaction of individual customers, it can adversely aî€ect the producers in a two-sided platform, as we explore next. We consider the impact of customer-centric toprecommendations on the exposure of the producers using real-world datasets. We use a state-of-the-art relevance scoring model (a very widely used latent factorization method [ 46 ]) and also a dataset-speciî€›c custom relevance scoring model over the datasets. 4.1.1 Google Local Ratings Dataset (GL). Google Local is a service to î€›nd nearby shops, restaurants on Google Maps (as Google Nearby feature) platform. We use the Google Local dataset released by He et al . [39] , which contains data about customers, local businesses (producers), and their locations (geographic coordinates), ratings, etc. We consider the active customers located in New York City and the business entities within 5 miles radius of Manhattan area with at least 10 reviews. The resulting dataset contains 11 172 customers, 855 businesses and 25 686 reviews. We consider the following two relevance scoring functions (ğ‘‰ ). (1) GL-CUSTOM: We use a custom relevance scoring function: ğ‘‰ (ğ‘¢, ğ‘) = , where ğ‘Ÿğ‘ğ‘¡ğ‘–ğ‘›ğ‘”(ğ‘) is the average rating of the producer (local business) and ğ‘‘ğ‘–ğ‘ ğ‘¡ğ‘ğ‘›ğ‘ğ‘’ (ğ‘¢, ğ‘) is the distance between customer ğ‘¢ and producer ğ‘. (2) GL-FACT: Here we use the state-of-the-art latent factorization model [ 43 46 ] to predict the relevance scores from the ratings. From here on, we refer to the above two datasets (relevance score sets) as GL-CUSTOM and GL-FACT respectively. 4.1.2 Last.fm Dataset (LF). We use the Last.fm dataset released by Cantador et al . [21] , which contains 1 892 customers, 17 632 artists (producers), and 92 834 records of play counts (the number of times a customer has played songs from an artist). We again use a latent factorization model [ 43 46 ] to î€›nd out the relevance scores from the play counts. From here on, we refer to this dataset as LF. We simulate topğ‘˜ = 20) recommendation on all three datasets, and calculate the exposure diî€erent producers get. Figures-1a,1b,1c are the Lorenz curves for producer exposures. In Exposure Lorenz curves, the cumulative fraction of total exposure is plotted against the cumulative fraction of the number of corresponding producers (ranked in increasing order of their exposures). The extent to which the curve goes below a straight diagonal line (or an equality mark) indicates the degree of inequality in the exposure distribution. We observe that the Lorenz curves for toprecommendations are far below the equal exposure marks, revealing that for conventional toprecommendation, 50% least exposed producers get only 32%, 5%, and 11% of total available exposure ğ‘š Â· ğ‘˜ ) in GL-CUSTOM (using the ratio of rating to distance to estimate relevance), GL-FACT (using latent factorization model [ 46 ]), and LF datasets (using latent factorization model [ 46 ]), respectively. Huge disparity is in nobodyâ€™s interest: In two-sided platforms, the exposure determines the economic opportunities. Thus, low exposure on a platform often puts many producers at huge losses, forcing them to leave the platform; this may result in fewer available choices for the customers, thereby degrading the overall quality of the platform. Thus, highly skewed exposure distribution of the customer-centric toprecommendation not only makes it unfair to the producers but also questions the long-term sustainability of the platforms. Thus, there is a need to be fair to the producers while designing recommender systems. A naive approach to reduce inequality in producer exposures is to implement a producer-centric recommendation (poorest): recommend the leastexposed products to the customer at any instant. Such producer-centric scheme makes the exposure of all the producers nearly equal, as seen in î€›gures-1a, 1b and 1c: Lorenz curves for poorestrecommendations are closer to the diagonal than those of toprecommendations. However, such poorestrecommendation decreases overall customer utilities (as seen in î€›gures-1d, 1e and 1f). Moreover, the poorestintroduces disparity among individual customer utilities, where some customers may suî€er much higher losses than other customers, making it unfair to them. To counter the above-mentioned issues, in this work, we propose the following fairness properties to be satisî€›ed by the recommendation to be fair to both producers and customers. A. Producer Fairness: Mandating a uniform exposure distribution over the producers can be too harsh on the system; it may heavily hamper the quality of the recommendation, and might also kill the existing competition by discouraging the producers from improving the quality of their products or services. Instead, we propose to ensure a minimum exposure guarantee for every producer such that no producer starves for exposure. The proposal is comparable to the fairness of minimum wage guarantee (e.g., as required by multiple legislations in the US, starting from Fair Labor Standards Act 1938 to Fair Minimum Wage Act 2007 [ 30 37 54 ]). Ensuring minimum wage does not itself guarantee equality of income; however it has been found to decrease income inequality [ 29 47 ]. Similarly, we want to ensure minimum exposure to every producer in the system. Note that we are not mandating a î€›xed exposure guarantee â€“ the exact value of the guaranteed minimum exposure can be decided by the respective platforms. B. Customer Fairness: As maintaining producer fairness can cause an overall loss in customer utility, we propose that the loss in utility should be fairly distributed among the customers To ensure this, products need to be recommended in a way such that no customer can gain extra utility by exchanging her set of recommended products with another customer â€“ a property called envy-freeness, as detailed in the next section. Given a set of items (say, ), a set of agents (say, ), and valuations (how much an agent values an item), the fair allocation problem aims at distributing the items fairly among the agents. In the discrete version of this problem, the items are discrete (no item can be broken into pieces) and non-shareable (no item can be allocated to multiple agents). If contains several copies of the same item, each copy can be thought of as non-shareable and discrete. The goal is to î€›nd a non-shareable and discrete allocation (A := {(ğ´ : ğ´ âŠ† P}) while ensuring fairness properties. The classical fairness notions, such as envy-freeness (EF) and proportional-fair-share (PFS), may not be achievable in most instances of the problem. For example, if there are two agents and one item, the item will be allocated to one of the agents, and the zero allocation to the other agent would violate both EF and PFS. Thus, for discrete items, relaxations of EF and PFS have been considered. Two such well-studied notions of fairness in the discrete fair allocation literature are (i) envy freeness up to one item ( EF1 ) and (ii) the maximin share guarantee ( MMS ), deî€›ned by Budish [19] Since then, these have been extensively studied in various settings for providing existential and algorithmic guarantees [7, 8, 10, 13â€“18, 22, 44, 55]. We now formally state these fairness notions: We propose to see the desired two-sided recommendation problem as a fair allocation problem. The set of products can be thought of as the set of items (there can be multiple copies of individual products) ; similarly, the set of customers as the set of agents , and the relevance scoring function as the valuations . Now the task of recommending products to customers is the same as allocating items in P to agents in U with certain constraints. â€¢ Setting P for Producer Fairness: As the total exposure of the platform is limited ( ğ‘˜ Â· |ğ‘ˆ | ), the maximum guarantee on minimum possible exposure for the producers is (this refers to the MMS value for the producers). One way to formally deî€›ne a lower threshold requirement is by using the notion of approximate maximin share (ğ›¼-MMS). More formally, Deî€›nition 5.1. An allocation A = (ğ´ , . . . , ğ´ is said to satisfy MMS for a î€›xed value ğ›¼ âˆˆ ( if and only if, for all agents ğ‘– âˆˆ {1, . . . , ğ‘›}, the following holds: (ğ´ ) â‰¥ ğ›¼MMS , where MMS = max argmin (ğ´ ). A platform can decide the exact value of and provide the minimum exposure guarantee ğ¸ = ğ›¼MMS for every producer. â€¢ Fair Allocation of P among U: Once is set according to the desired producer fairness, the entire task of fair recommendation boils down to the allocation of among while ensuring EF1 for agents/customers (to ensure fairness for customers, as introduced in Â§4.4). However, speciî€›c constraints related to the recommendation problem need a novel extension of the traditional fair allocation problem, as explained next. Traditionally, fair allocation literature aims at deî€›ning and ensuring fairness among the agents while allocating all items the set exhaustively. However, in the fair recommendation problem, along with customer fairness, the challenge is to attain producer (or product) fairness by providing a minimum exposure guarantee (where each product needs to be allocated to at least diî€erent customers). Thus, achieving producer fairness is the same as creating at least copies of each product and ensuring that all the copies are allocated, along with a feasibility constraint which enforces that no customer gets more than one copy of the same product. This extension of the problemâ€”where all the items are grouped into disjoint categories and no agent receives more than a pre-speciî€›ed number of items from the same categoryâ€”is called cardinality constrained fair allocation problem, proposed in [ 14 ]. In this paper, we consider a novel extension of the cardinality constrained problem by adding another constraint enforcing that exactly items are allocated to each customer. This requires tackling hierarchical feasibility constraintsâ€”an upper bound cardinality constraint of one on each product and a cardinality constraint of on the total number of allocated products. Moreover, this additional feasibility constraint makes it diî€œcult to decide how many copies of which product should be made available for a total of ( ğ‘˜ Â· |ğ‘ˆ | ) allocations, satisfying the feasibility constraints as well as the fairness requirement. Thus, unlike the fair allocation problem, we consider no restriction on the number of copies of each product that are made available. All these contrast points, along with the two-sided fairness guarantees make fair recommendation an interesting extension of the fair allocation problem. Overall, we aim to recommend a set of products, denoted as âŠ‚ ğ‘ƒ , to each customer ğ‘¢ âˆˆ ğ‘ˆ that satisî€›es the following constraints: ğ›¼ğ‘šğ‘˜ , for each producer ğ‘ âˆˆ ğ‘ƒ, for some ğ›¼ âˆˆ (0, 1]. (4) This formulation leads to a large number of constraints, of the order |ğ‘ˆ | + |ğ‘ƒ | . Standard Integer Linear Programming techniques for î€›nding a feasible solution, in this large constraint space, do not scale well, especially considering the real-world two-sided platforms. Hence, in the next section, we propose a greedy algorithm to solve the above-mentioned constraint satisfaction problem. Input: Set of customers ğ‘ˆ = [ğ‘š] , set of distinct products ğ‘ƒ = [ğ‘›] , recommendation set size (such that ğ‘˜ < ğ‘› and ğ‘› â‰¤ ğ‘˜ Â· ğ‘š), and the relevance scores ğ‘‰ (ğ‘). Output: A two-sided fair recommendation. = (ğ´ , . . . , ğ´ ) with ğ´ â† âˆ… for each customer ğ‘– âˆˆ [ğ‘š]. First Phase: ğœ (1), ğœ (2), . . . , ğœ (ğ‘š) â† ğ‘ƒ for each ğ‘¢ âˆˆ [ğ‘š]. denoting number of copies of each product. , . . . , ğ‘† ) with ğ‘† â† â„“, âˆ€ğ‘— âˆˆ [ğ‘›], this stores the number of available copies of each product. Second Phase: Set Î› = |ğ´ denoting the number of items allocated to the customer subsequent to ğ‘¥, according to the ordering ğœ. , . . . , ğ‘† ) with the value ğ‘š in order to allow allocating any product to any customer. (ğ‘–) â† ğœ ((ğ‘– + ğ‘¥ âˆ’ 1) (mod ğ‘š) + 1) for all ğ‘– âˆˆ [ğ‘š]. In this section, we provide a polynomial-time algorithm FairRec, for î€›nding an allocation which satisî€›es the desired two-sided fairness described in Â§4.4 (we prove the theoretical guarantees in Â§7). Note that we consider only the case of ğ‘˜ < |ğ‘ƒ | , and leave the trivial case of ğ‘˜ = |ğ‘ƒ | and the infeasible case of ğ‘˜ > |ğ‘ƒ | out of consideration. Also, we consider |ğ‘ƒ | â‰¤ ğ‘˜ Â· |ğ‘ˆ | , otherwise, at least ( |ğ‘ƒ | âˆ’ ğ‘˜ Â· |ğ‘ˆ | producers can not be allocated to any customer. FairRec (Algorithm 1) executes in two phases. The î€›rst phase ensures EF1 among all the customers (Lemma 7.2.1) and tries to provide a minimum guarantee on the exposure of the producers (Lemma 7.2.2). However, the î€›rst phase may not allocate exactly products to all the users, which is then ensured by the second phase while simultaneously maintaining EF1 for customers. The î€›rst phase creates â„“ = copies of each product. Note that is the maximin value of any producer when ğ‘šğ‘˜ slots are allocated among producers, and thus represents the -MMS value for each producer. The algorithm then initializes each component of the vector of size |ğ‘ƒ | to to ensure that at most copies from each product are allocated in the î€›rst phase. Feasible sets for each customer are then initialized to ensure that each customer receives at most one copy of the same product. Then, assuming an arbitrary ordering of customers, Algorithm 2 is executed and the allocation B is obtained. The second phase checks if all the customers have received exactly products (by looking at the number of products allocated to the customer ğ‘¥ + 1 which is next-in-sequence to the last allocated customer of the î€›rst phase). If the customer ğ‘¥ + 1 has received products, then no further allocation is required; if not, then Algorithm 2 is called again with a new ordering obtained by left-cyclic rotations of . The remaining number of items is stored in which are to be allocated among the customers. Also, each component of the vector is updated to |ğ‘ˆ | to allow allocating any feasible product without any limit on the available number of copies. The second phase retains EF1 fairness among the customers. Both phases use a modiî€›ed version of the Greedy-round-robin (Algorithm 2) [ 14 22 ]: it follows the ordering in a round-robin fashion (i.e., it selects customers, one after the other, from ğœ ( to ğœ (ğ‘š) ), and iteratively assigns to the selected customer her most desired unallocated product (feasibility maintained by the vector and sets and ties are broken arbitrarily). This process is repeated over several rounds until one of the two disjoint conditions occur: (i) ğ‘‡ == 0: a total of allocations have occurred, or (ii) ğ‘ == âˆ… : no feasible product available (for the current customer ğœ (ğ‘–) , we have âˆ© {ğ‘ } = âˆ… ). Finally, it returns an allocation , . . . , ğµ with each âŠ† [ğ‘›] for all ğ‘¢ âˆˆ [ğ‘š]. Note that while we choose minimum exposure guarantee and EF1 as fairness constraints for producers and customers respectively, it does not necessarily mean that merely satisfying them is enough. Apart from ensuring fairness, we also need to perform well in what any recommender system is originally designed to do, i.e., to provide good (relevant) recommendations to the customers. Thus, in Algorithm 2 which allocates products to customers in greedy-round-robin manner, we try to allocate (in step-7) the best product which is available and feasible in every round. We believe this is the reason why FairRec shows good performance in overall customer utility as well (based on experimental results in Â§8). In this section, we provide a few important properties of Algorithm 2 in Proposition 7.1. Later, we establish the fairness guarantees and time complexity of our proposed algorithm FairRec in Theorem 7.2 using Lemma 7.2.1, 7.2.3 and 7.2.4. Proposition 7.1. The allocation obtained by the Greedy Round Robin (Algorithm 2) exhibits the following four properties: (ğ‘ƒ for any two indices and , where ğ‘¥ < ğ‘¦ , the customer ğœ (ğ‘¥) (who appears earlier than ğœ (ğ‘¦) according to the ordering ğœ) does not envy customer ğœ (ğ‘¦), i.e., ğ‘‰ (ğµ ) â‰¥ ğ‘‰ (ğµ ). (ğ‘ƒ ) the allocation B obtained by Algorithm 2 is EF1. (ğ‘ƒ each customer is allocated at most one item from the same producer, thus ensuring the cardinality constraint is satisî€›ed for each producer (category). (ğ‘ƒ for any two customers, say and , the allocation obtained by Algorithm 2 satisî€›es the following: âˆ’1 â‰¤ |ğµ | âˆ’ |ğµ â‰¤ 1. Proof. The properties and have been observed by Biswas and Barman [14] and Caragiannis et al . [22] , respectively. For completeness, we repeat the arguments towards these two properties. Input : Number of customers , number of producers , an array with number of available copies of each product ğ‘†, total number of available products ğ‘‡ > 0, relevance scores ğ‘‰ (ğ‘) and feasible product set ğ¹ for each customer, and an ordering ğœ of [ğ‘š]. Output: An allocation of products among customers, the residual feasible set and the last allocated index ğ‘¥. , . . . , ğµ ) with ğµ â† âˆ… for each customer ğ‘– âˆˆ [ğ‘š]. (ğ‘ â† ğµ âˆª ğ‘. â† ğ¹ \ ğ‘. â† ğ‘† âˆ’ 1. , . . . , ğµ ), ğ¹ = (ğ¹ , . . . , ğ¹ ) and index ğ‘¥. â‡’ğ‘‰ (ğµ ) â‰¥ ğ‘‰ (ğµ ) âˆ’ ğ‘‰ (ğ‘ ) (5) Equation 5 shows that the customer ğœ (ğ‘¦) stops envying ğœ (ğ‘¥) when only one item is (hypothetically) removed from B (namely, ğ‘ ). Thus, the allocation B is EF1, i.e., ğ‘ƒ holds. The property is satisî€›ed by the use of the feasible sets for each customer . Each contains the set of producers who have not yet been allocated to the customer . At any round , step 7 of Algorithm 2 selects the most relevant producer among the producers who had not been allocated to in any earlier rounds < ğ‘Ÿ . Once, a producer is allocated to a customer , step 9 of Algorithm 2 removes ğ‘ from ğ¹ . Thus, each customer is allocated at most one item from the same producer. The property states that, for any pair of customers and , the number of allocated items |ğµ(ğ‘¢)| and |ğµ(ğ‘£)| , diî€er by at most 1. It is straightforward to see that, except for the last feasible round, all customers are allocated exactly one item at each round. Thus, all the customers receive the same number of allocations until the second last feasible round. In the last feasible round, some customers may not get any allocation (if there is no available feasible product) and thus may receive one item less than the others. â–¡ We now state the main theorem (Theorem 7.2) that establishes the fairness guarantees of our proposed algorithm. Theorem 7.2. Given producers, the proposed polynomial time algorithm, FairRec , returns an EF1 allocation among customers while allocating exactly items to each customer, when ğ‘˜ < ğ‘› â‰¤ ğ‘šğ‘˜ Moreover, it ensures non-zero exposure among all the producers and MMS guarantee among at least 1 âˆ’ fraction of the producers. Proof. We prove the fairness guarantees of customers and producers in Lemma 7.2.1 and 7.2.3, respectively. In Lemma 7.2.4, we show that FairRec executes in polynomial time. â–¡ Lemma 7.2.1. Given producers, customers, and a p ositive integer (such that ğ‘˜ < ğ‘› â‰¤ ğ‘šğ‘˜ ), FairRec returns an EF1 allocation among customers while allocating exactly items to each customer. Proof. To prove this, we show that both phases of FairRec satisfy EF1 . Since Algorithm 2 guarantees EF1 (by property ), the allocation at step 9 of FairRec is EF1 . Thus, for any two customers and , there exists an item ğ‘— âˆˆ ğµ such that (ğµ ) â‰¥ ğ‘‰ (ğµ )âˆ’ğ‘‰ ( ğ‘—) . Next, the second phase creates |ğ‘ˆ | copies of each product and calls Algorithm 2 to obtain the allocation . Note that the second phase assigns the most valued item to each customer at each round, that is, it allocates topfeasible producers to each customer, where = ğ‘˜ âˆ’ |ğµ . Thus, (ğ¶ ) â‰¥ ğ‘‰ (ğ¶ . Thus, (ğµ ) +ğ‘‰ (ğ¶ ) â‰¥ ğ‘‰ (ğµ ) âˆ’ğ‘‰ ( ğ‘—) +ğ‘‰ (ğ¶ , which implies EF1 (ğµ âˆªğ¶ ) â‰¥ ğ‘‰ (ğµ âˆªğ¶ ) âˆ’ğ‘‰ ( ğ‘—) This completes the proof that FairRec ensures EF1 among all the customers while recommending exactly ğ‘˜ products to each customer. â–¡ We now establish the fairness guarantees of FairRec for the producers. For ease of exposition, we î€›rst consider ğ›¼ = 1 to show exact MMS fairness guarantees are satisî€›ed by at least fraction of the producers (in Lemma 7.2.2). Subsequently, we provide a stronger guarantee in Lemma 7.2.3 considering any ğ›¼ âˆˆ (0, 1]. Lemma 7.2.2. Given producers, customers, a positive integer (such that ğ‘˜ < ğ‘› â‰¤ ğ‘šğ‘˜ ), and ğ›¼ = 1, FairRec ensures non-zero exposure among all the producers. Moreover, it assures MMS -fairness among at least ğ‘› âˆ’ ğ‘˜ producers. Proof. We î€›rst prove that the î€›rst phase guarantees non-zero exposure for producers. The allocation obtained by Algorithm 2 in the î€›rst phase may have terminated for one of the two conditions (1) ğ‘‡ == 0: this means that all the â„“ = âŒŠ copies of each producer have been allocated among all the customers. Thus, each producer receives exactly the maximin threshold â„“. Hence MMS fairness is achieved by all the ğ‘› producers. (2) ğ‘ == âˆ… : this happens when ğ‘‡ â‰  0 and 0 for a customer (at termination). That is, 0 for each producer ğ‘ âˆˆ ğ¹ . Thus, all â„“ = âŒŠ copies of the producers in the set have been allocated, and hence they attain MMS fairness. On the other hand, the producers in the set (the set recommended to customer ) is allocated to at least one producer. Thus, a minimum value of 1 is achieved by all the producers. Also, |ğ¹ | + |ğµ | = ğ‘› and |ğµ | â‰¤ ğ‘˜ , implies that |ğ¹ | â‰¥ ğ‘› âˆ’ ğ‘˜. Therefore, at least ğ‘› âˆ’ ğ‘˜ producers attain MMS-fairness. Since the thresholds are already satisî€›ed in the î€›rst phase, adding more allocations in the second phase retains the threshold-based fairness guarantees. This completes the proof that FairRec ensures a non-zero exposure among all the producers and assures MMS -fairness among at least ğ‘› âˆ’ ğ‘˜ producers. â–¡ One consequence of Lemma 7.2.2 is that, when is much lower than , a large fraction of producers are guaranteed to attain MMS fairness. We formally state this property of FairRec algorithm in Corollary 7.2.2.1. Corollary 7.2.2.1. Given producers, a positive integer ğ›¼ = 1, and ğ›½ âˆˆ ( such that ğ‘˜ â‰¤ ğ›½ğ‘› FairRec ensures MMS-fairness among at least (1 âˆ’ ğ›½)ğ‘› producers. Lemma 7.2.3. Given producers, customers, recommendation size such that ğ‘˜ < ğ‘› < ğ‘šğ‘˜ , and a î€›xed value ğ›¼ âˆˆ ( , FairRec ensures a minimum exposure of 1 for all the producers and an MMS guarantee to at least 1 âˆ’ fraction of the producers. î€—î€’ ğ›¼ğ‘šğ‘˜ â‡’ ğ›½ â‰¥ 1 âˆ’ (10) ğ‘š + 1 The Inequality 10 implies that the fraction of producers who achieve MMS guarantee is at least 1 âˆ’ . â–¡ Finally, in Lemma 7.2.4, we show that FairRec executes in polynomial time. Lemma 7.2.4. The time complexity of FairRec has a worst case bound of O(ğ‘šğ‘›ğ‘˜). Proof. The time complexity of FairRec is the same as the complexity of Algorithm 2. Over the two phases, Algorithm 2 allocates ğ‘šğ‘˜ items. For each allocation, it î€›nds the maximum possible feasible producer which can be done in at most O(ğ‘›) time. Thus, the total time complexity of the algorithm is O (ğ‘šğ‘›ğ‘˜). â–¡ We run the proposed FairRec algorithm (Â§6) for all three Experimental Setup and Baselines: datasets (as listed in Â§4.1) considering diî€erent values of the recommendation-size . For comparison, we use the following methods as baselines. (1) Top-ğ‘˜: This is the traditional way of recommending the top-ğ‘˜ relevant products. (2) Random-ğ‘˜: Here, we randomly recommend products to all customers. Random recommendations can give equal chance to all producers, thus can serve as a baseline which has only producersâ€™ interest in mind. (3) Poorest-ğ‘˜: Unlike random, this is a deterministic producer-centric method where least exposed products are recommended to each customer in a round robin manner. Note that poorest-k and random-k are not real recommendation algorithms, and we consider them as baselines in the paper because of their theoretical property of bringing down inequality among producers and serve as some of the most equitable options from the producersâ€™ perspective. (4) MixedTR-ğ‘˜: Here, we choose top relevant products at î€›rst and then the remaining ğ‘˜ âˆ’ high customer utility while randomcould help in improving provider-side performance by giving equal chances to all producers to appear in the second half. (5) MixedTP-ğ‘˜: Here, we choose top relevant products at î€›rst and then the poorest ğ‘˜ âˆ’ intermediate scores and express the modiî€›ed relevance score as 0 Ã— ğ‘‰ (ğ‘) + the second part of the modiî€›ed score promotes less exposed producers. (7) MSR18: SÃ¼rer et al . [64] proposed to introduce producer-side constraints similar to exposure guarantees in our paper and then optimize overall customer utility. However, as the proposed constrained optimization problem becomes a very hard combinatorial problem, the authors did a Lagrangian relaxation and proposed to use iterative subgradient method to optimize the relaxed problem. Although this methodology is not quite suitable for large scale online platforms as optimizing the hard combinatorial problem could demand huge computing resources and time, we use this as a baseline by limiting the number of iterations to 100. Experiments: We run three sets of experiments. First in Â§8.1, we set the exposure guarantee as ğ¸ = MMS and run FairRec. However, the platforms may not always want to ensure the maximum possible exposure guarantee for the producers as it might cause degradation of customer utility. They might want to set a lower exposure guarantee in such cases. Thus, we set lower exposure guarantees i.e., by considering ğ¸ = ğ›¼Â· MMS where 0 â‰¤ ğ›¼ â‰¤ 1 (in Â§8.2). While Â§8.1 and Â§8.2 show the eî€œcacies of FairRec, Â§8.3 digs deeper into the functioning of FairRec and discusses how phases 1 and 2 of FairRec work towards better performance on producer and customer sides. Finally in Â§8.4, we also test FairRec for scenarios where the platforms may want to ensure diî€erent levels of exposure guarantee for diî€erent categories of producers. For evaluating FairRec and the baselines, we use the following producer-side and customer-side metrics. 8.0.1 Producer-Side Metrics. The evaluation metrics for capturing the fairness and eî€œciency among the producers are: Fraction of Satisî€›ed Producers (ğ»): We call a producer satisî€›ed iî€ its exposure is more than the minimum exposure guarantee ğ¸. The fraction of satisî€›ed producers can be calculated as below. is 1 if â‰¥ ğ¸ , otherwise 0. The value of ranges between 0 and 1. The higher the , the fairer is the recommender system to producers. Inequality in Producer Exposures (ğ‘): We earlier observed in Â§4 that conventional toprecommendation causes huge disparity in individual producer exposures. To capture how unequal the individual producer exposures are, we employ an entropy-like measure as below. Note that the base of the logarithm above is which is the number of producers. Since each of the customers is given -sized recommendations, total available exposure is ğ‘šğ‘˜ . If every producer gets same exposure, i.e., recommended exactly times, then the above entropy metric will be: producer is allowed to get all the exposure, then the value entropy expression in equation-12 will be . The lower the , the more unequal individual producer exposures are. Exposure Loss on Producers (ğ¿): As FairRec tries to ensure minimum exposure guarantee for all the producers, some producers may receive a lower exposure in comparison to what they would have got in toprecommendations. To capture this, we compute the loss as the mean amount of impact (loss in exposure) caused by FairRec, compared to the top-ğ‘˜ recommendations. This metric takes the top-k recommendations (which is the regular recommendation based on the estimated relevance scores, but with no additional constraints) as a reference point, and then evaluates how much exposure is lost on average if some other method is used for the recommendations. The lower the exposure loss metric, lower is the negative impact, and the better is the recommendation algorithm. 8.0.2 Customer-Side Metrics. The evaluation metrics for capturing the fairness and eî€œciency among the customers are: Mean Average Envy (ğ‘Œ): Although FairRec ensures EF1 guarantee for customers by design, here we capture how eî€ectively this guarantee can reduce overall envy among customers in comparison to the baselines. We deî€›ne the mean average envy as below. utility would have received if she had received the recommendation that had been given to ) instead of her own allocated recommendation . The lower the envy ( ), the fairer the recommender system is for the customers. Mean and Standard Deviation of Customer Utilities (using ğœ‡ ): FairRec may not allocate the most relevant products to the customers, which may introduce a loss in customer utilities. This loss can be captured using the expression . Higher the utility (i.e., lower utility loss), the more eî€œcient is the recommender system for the customers. We also calculate the standard deviation of customer utilities, that is, . The lower the ğ‘ ğ‘¡ğ‘‘ , lesser is the disparity in individual customer utilities. 8.1 Experiments with MMS Guarantee Here we test FairRec with exposure guarantee ğ¸ = MMS (or ğ›¼ = 1), recommendation size in 1 to 20, and discuss the results. of FairRec and poorest, since MSR18 is observed to be ensuring exposures close to MMS for most of the producers. In summary, FairRec, poorest, and MSR18 seem to be good at maintaining fairness on the producer-side by keeping exposure inequality low. Exposure Loss (ğ¿): Figures 2g, 2h, and 2i show that randomand poorestcause the highest amounts of exposure loss in comparison to top; this is because both of them favor equality in producer exposure (randomgives equal chance to all producers to be recommended while pooresttries to increase the exposure of least exposed producer). On the other hand, mixedTR- mixedTPcause smaller losses as only up to half of their recommendations are diî€erent from top. FairRec causes only up to 0 2 fraction or 20% loss in exposure in comparison to topowing to its intelligent selection approach. It is worth noticing that MMS for LF is low (MMS 0 for ğ‘˜ < 10, MMS 1 for ğ‘˜ âˆˆ [ 10 18 MMS 2 for ğ‘˜ âˆˆ [ 20 29 ,...). MMS is satisî€›ed for all producers until ğ‘˜ = 9; but at k=10, MMS is not guaranteed for all producers, and thus, we see a drop in performance at ğ‘˜ = 10 which happens again at ğ‘˜ = 19. Such changes in MMS speciî€›c to LF make its plots diî€erent from other datasets. In summary, both FairRe c, poorestperform the best in producer fairness while they cause exposure loss for very popular producers to compensate for the exposure given to less popular producers. 8.1.2 Customer-Side Results. All customer-side results are plotted in Figure-3. Mean Average Envy (ğ‘Œ ): Figures 3a, 3b, and 3c reveal that topcauses the lowest possible (i.e., 0) mean average envy among the customers; this is because it gives the maximum possible utility of 1 to every customer thereby leaving no chances of envy among customers. Even mixedTRmixedTP, MPB19, and MSR18 also show similarly low envy. FairRec generates very low values of envy which are very comparable to those of tophere. On the other hand both randomand poorestcause the highest envy as they do not consider customer preferences at all during recommendation. Mean and Standard Deviation of Customer Utility (ğœ‡ ,ğ‘ ğ‘¡ğ‘‘ ): From Figures 3d, 3e, and 3f, we see that both randomand poorestcause huge losses in customer utility (i.e., low customer utility) as they neglect customer preferences. The mixedTRand mixedTPperform moderately. On the other hand, FairRec causes very small utility loss and performs almost at par with the customer-centric top. The utility losses in MPB19 and MSR18 are higher as they do not guarantee anything on the customer-side. This certiî€›es that FairRec strikes a good balance between customer utility and producer fairness. The standard deviation plots: î€›gures-3g, 3h, and 3i reveal that for larger sizes of recommendation, randomand poorestshow large disparities in customer utilities while FairRec, mixedTR-ğ‘˜ and mixedTP-ğ‘˜ show relatively fewer disparities. As top-ğ‘˜ is customercentric and provides the maximum utility of 1 to all the customers, it shows 0 standard deviation. Besides MPB19 and MSR18 show higher disparities on customer-side as they do not speciî€›cally guarantee anything on customer-side. In summary, FairRec strikes a good balance between fairness on both producer-side and customerside while causing only marginal losses in customer utility. Here we î€›x ğ‘˜ = 20, and test FairRec with diî€erent values of minimum exposure guarantee i.e., ğ¸ = ğ›¼ Â· (where 0 â‰¤ ğ›¼ â‰¤ 1) by varying in between 0 and 1 (or in other words varying in between 0 and MMS); we plot the results in Figures 4 and 5. 8.2.1 Producer-Side Results. All the relevant producer-side results are plotted in Figure 4. Producer Satisfaction (ğ»): Figures 4a, 4b, and 4c reveal that FairRec satisî€›es almost all the producers (as is close to 1) for all the tested settings in all the datasets. However the performances of the baselines in terms of metric reduces with the increase in ; this is because the criteria for the producer satisfaction (as ğ¸ âˆ ğ›¼ ) increases with the increase in while the baseline results do not explicitly change with the change in ğ›¼. Exposure Inequality (ğ‘): From Figures 4d, 4e, and 4f, we see that increasing minimum exposure guarantee (i.e., increasing ) results in lower inequality in producer exposures (as high signiî€›es lower inequality) for FairRec in all the cases. On the other hand, as the baselines do not depend on , their performances remain the same; thus the baseline performances are just horizontal straight lines. At ğ›¼ = 0, as the exposure guarantee by FairRec becomes 0, the results given by FairRec are the same as that of topin all the datasets. While FairRecâ€™s performance in terms of crosses that of mixedTRat ğ›¼ = 7, ğ›¼ = 7, and ğ›¼ = 5 in GL-CUSTOM, GL-FACT, and LF respectively, it becomes close to that of producer-centric poorest-ğ‘˜ at ğ›¼ = 1 in all the datasets. Exposure Loss (ğ¿): Increasing values of are observed for increased in Figures-4g, 4h, 4i. This suggests that increasing minimum exposure guarantee can cause higher exposure losses for previously popular producers. Just like , here also the baseline performances are just horizontal straight lines as they do not depend on . We see that at ğ›¼ = 0, FairRec performs same as topwith no losses. With the increase in settings, the losses increase and at ğ›¼ = 1, the losses in FairRec are very close to those of poorest(as discussed earlier, poorestis the best performing baselines for producer side). 8.2.2 Customer-Side Results. All the relevant customer-side results are plotted in Figure 5. As the baselines do not depend on , the customer-side results of baselines are just horizontal straight lines. We î€›nd almost no change in Mean Average Envy ( ) of FairRec with the change in (refer Figures 5a, 5b, 5c). On the other hand, with the increase in (i.e., higher exposure guarantee for producers) there is a small decrease in customer utility (refer Figures-5d, 5e, 5f), and a small increase in the standard deviation of customer utilities. In summary, although a larger exposure guarantee can help platforms achieve better producer fairness, it might hurt the overall customer satisfaction and also the satisfaction of highly popular producers of the platforms. Thus, the platforms, which are interested in similar minimum exposure guarantees, should not ignore the above trade-oî€s. To understand how phase-1 and phase-2 of FairRec work towards better performance on producer and customer sides, we plot the metrics at the end of both phase-1 and phase-2 (i.e., the end of FairRec) in Figures 6 and 7. guarantee to producers happens in phase-1 of FairRec, and phase-2 of FairRec does not explicitly work towards these goals. Thus, there is very little change in the relevant metrics of producer satisfaction ( in Figures 6a, 6b, 6c), exposure inequality ( in Figures 6d, 6e, 6f), and exposure loss in Figures 6g, 6h, 6f) after phase-2 than those at the end of phase-1. However, at a few settings of in GL-CUSTOM and LF where phase-1 falls a bit short in producer satisfaction ( ), phase-2 seems to improve it by a small extent (refer Figures 6a and 6c respectively). because the number of allocations in phase-1 increases with the increase in . Customer utility after phase-2 is higher than that of phase-1 (refer Figures 7d, 7e, 7f); however, the utility improvement in phase-2 reduces with the increase in as more number of allocations happen in phase-1 and the number of rounds in phase-2 becomes less for higher . We also observe that phase-2 reduces the disparity in customer utilities than what is observed at the end of phase-1 (refer Figures 7g, 7h, 7i); this is because phase-2 allows best possible allocations to every customer thereby compensating for customer-side inequalities and losses incurred in phase-1. In summary, phase-1 of FairRec tries to achieve better performance from the producer-side, whereas the phase-2 mostly improves the performance from the customer-side. In addition to that the customer-side improvement in phase-2 is often more when the values are smaller as it increases the number of allocations happening in the second phase. The platforms may also need to ensure diî€erent levels of exposure guarantee for diî€erent producers; for example the platform may want to give more exposure guarantee to high-rated producers than low-rated ones. Thus, we also test FairRec in such a scenario. Here, we î€›x Ã— âŒŠğ‘Ÿğ‘ğ‘¡ğ‘–ğ‘›ğ‘”(ğ‘)âŒ‹ ; i.e., exposure guarantee is Ã—ğ‘€ğ‘€ğ‘† . We test FairRec with the above settings on GL-CUSTOM and GL-FACT, and plot the results in Figure 8. Figure 8b shows the distribution of producers in Google Local dataset with diî€erent exposure guarantees (set based on their respective ratings). Figures 8a and 8d plot for every group of producers with diî€erent exposure guarantees in GL-CUSTOM and GL-FACT respectively; we î€›nd FairRec to be satisfying all the producers in both the cases. Metrics and are skipped here, as they are irrelevant in case of diî€erent exposure guarantees for diî€erent producers. We plot customer-side results in Figures 8c and 8e, GL-CUSTOM and GL-FACT respectively; we î€›nd that FairRec is able to achieve high customer utility ( very close to 1) while maintaining customer fairness (small ğ‘Œ and ğ‘ ğ‘¡ğ‘‘ ) in both cases. While FairRec provides two-sided fair recommendations, it can be further tweaked to improve the recommendation performance for the customers. We propose such a modiî€›cation of FairRec in Â§9.1 as FairRecPlus, and then evaluate it against FairRec in Â§9.2. However, the improvement in FairRecPlus comes at a cost of an increased computation time. Thus, in scenarios where platforms can aî€ord more time to compute a recommendation, FairRecPlus can be used to improve customerside performance while still maintaining the same fairness guarantees on both sides. Input: Set of customers ğ‘ˆ = [ğ‘š] , set of distinct products ğ‘ƒ = [ğ‘›] , recommendation set size (such that ğ‘˜ < ğ‘š and ğ‘› â‰¤ ğ‘˜ Â· ğ‘š), and the relevance scores ğ‘‰ (ğ‘). Output: A two-sided fair recommendation. = (ğ´ , . . . , ğ´ ) with ğ´ â† âˆ… for each customer ğ‘– âˆˆ [ğ‘š]. ğœ (1), ğœ (2), . . . , ğœ (ğ‘š) â† ğ‘ƒ for each ğ‘¢ âˆˆ ğ‘ˆ . denoting number of copies of each product. , . . . , ğ‘† ) with ğ‘† â† â„“, âˆ€ğ‘— âˆˆ [ğ‘›], this stores the number of available copies of each product. | < ğ‘˜ then |) items from ğ¹ (based on ğ‘‰ (Â·) scores). â† ğ´ âˆª ğ». Input : Number of customers , number of producers , an array with number of available copies of each product ğ‘†, total number of available products ğ‘‡ > 0, relevance scores ğ‘‰ (ğ‘) and feasible product set ğ¹ for each customer, and an ordering ğœ of [ğ‘š]. Output: An allocation of ğ‘‡ products among ğ‘š customers and the residual feasible set ğ¹ , . . . , ğµ ) with ğµ â† âˆ… for each customer ğ‘– âˆˆ [ğ‘š]. (ğ‘ Update B = {ğµ , . . . , ğµ to obtain an acyclic envy graph G(B) using Lemma 9.0.1. â† ğµ âˆª ğ‘. â† ğ¹ \ ğ‘. â† ğ‘† âˆ’ 1. Update B = {ğµ , . . . , ğµ to obtain an acyclic envy graph G(B) using Lemma 9.0.1. , . . . , ğµ } to obtain an acyclic envy graph G (B) using Lemma 9.0.1. , . . . , ğµ ) and ğ¹ = (ğ¹ , . . . , ğ¹ ). to balance the extent of envy between each pair of agents by maintaining an acyclic envy-graph after each round. An envy graph is a directed graph that captures the envy between agentsâ€”the nodes in the envy graph represent the agents and it contains a directed edge from to if and only if, envies , i.e., if and only if (ğµ ) < ğ‘£ (ğµ , where and are partial allocations to agents and , respectively. It was established in [ 48 ] that one can always eî€œciently update a given partial allocation such that the resulting envy graph is acyclic. Lemma 9.0.1. (Lipton et al . [48] ) Given a partial allocation (ğ´ , . . . , ğ´ , we can î€›nd another partial allocation B=(ğµ , . . . , ğµ ) in polynomial time such that (i) The valuations of the agents for their bundles do not decrease: ğ‘£ (ğµ ) â‰¥ ğ‘£ (ğ´ ) for all ğ‘– âˆˆ [ğ‘š]. (ii) The envy graph ğº (B) is acyclic. After this reallocation (ğµ ) â‰¥ ğ‘£ (ğ´ for all ğ‘– âˆˆ [ğ‘›] . Furthermore, the number of edges in ğº (B) is strictly less than ğº (A) : the directed edges â†’ ğ‘– â†’ . . . â†’ ğ‘– â†’ ğ‘– do not appear in the envy graph of (ğµ , . . . , ğµ and if an agent starts envying an agent in the cycle, say agent then must have been envious of in . Edges between agents and which are not in the cycle remain unchanged, and edges going out of an agent in the cycle can only get removed, since â€™s valuation for the bundle assigned to her bundle increases. Therefore, we can repeatedly remove cycles and keep reducing the number of edges in the envy graph to eventually î€›nd a partial allocation B that satisî€›es the stated claim. â–¡ The worst-case time complexity of eliminating envy cycles, to obtain a directed acyclic graph (DAG) at each round, is ğ‘‚ (ğ‘š . A topological ordering of the acyclic directed graph G(B) can be computed for updating the in ğ‘‚ (ğ‘š) time. This new ordering is then used for allocating the next round of items in a round-robin manner. The second phase checks if all the customers have received exactly products. If yes, then no further allocation is required; if not, then allocate each agent , their most valuable items from until they receive ğ‘˜ items. The time complexity of FairRecPlus is governed by the envy cycle elimination step which takes ğ‘‚ (ğ‘š ğ‘˜) over rounds. Moreover, for each of the ğ‘šğ‘˜ items, î€›nding the maximum valued feasible producer takes ğ‘‚ (ğ‘›) time. Thus, the total time complexity of FairRecPlus is ğ‘‚ (ğ‘š ğ‘˜+ğ‘šğ‘›ğ‘˜) . Therefore, for a large number of customers, FairRecPlus would take a huge time to compute a two-sided fair allocation. Although this modiî€›cation requires more computation, we empirically observe that, it improves on the customer-side metrics. We test the FairRecPlus algorithm on all the datasets with ğ‘˜ = 20 while varying from 0 to 1 in separate trials. The results on producer-side and customer-side are plotted in î€›gs. 9 and 10 respectively. While the producer-side plots for FairRec and FairRecPlus (î€›g. 9) seem to completely overlap, they are marginally diî€erent from each other; for example, at ğ›¼ = 5 in GL-CUSTOM, the , and metrics for FairRecPlus are 1, 0 9908, and 0 0376 respectively while those in FairRec are 99, 0 9910, and 0 0380 respectively. The producer-side performances of FairRecPlus is very similar to that of FairRec since the modiî€›cation does not change any guarantee on the producer side. On the other hand, the modiî€›cation introduces only the envy-cycle removal rounds which reduces the envy on customer-side. We observe that FairRecPlus reduces the mean customer envy (check in î€›gs. 10a to 10c). On the other hand, the performances of FairRecPlus in other customer-side metrics are similar to those of FairRec (î€›gs. 10d to 10i); for example at ğ›¼ = 5 in GL-CUSTOM, the mean and standard deviation of customer utilities are 0 9841 and 0 0169 in FairRecPlus, against the corresponding values 0.9834 and 0.0167 in FairRec. In this work, we propose the notion of two-sided fairness for recommendations in two-sided platforms. For producers, we consider a minimum exposure guarantee while we try to ensure less inequality in customer utilities. Note that we assume the relevance of a product does not play any role in producerâ€™s utility (in contrast to Biega et al . [12] , Singh and Joachims [59] ), and use only the exposure of a producer as her utility. We provide a scalable and easily adaptable algorithm that exhibits desired two-sided fairness properties while causing a marginal loss in the overall quality of recommendations. We establish theoretical guarantees and provide empirical evidence through extensive evaluations of real-world datasets. Furthermore, we propose a modiî€›cation of our algorithm and show that it performs better on customer-side metrics while being two-sided fair, but at the cost of additional computation time. Our work can be directly applied to fair recommendation problems in scenarios like mass recommendation/promotion sent through emails, app/web notiî€›cations. Though our work considers the oî€Ÿine recommendation scenario where the recommendations are computed for all the registered customers at once, it can also be extended for online recommendation settings by limiting the set of customers to only the active customers at any particular instant. However, developing a more robust realization of the proposed mechanism for a completely online scenario remains future work. Going ahead, we also want to study attention models that can handle position bias [ ], where customers pay more attention to the top-ranked products than the lower-ranked ones. Acknowledgements: This work was conducted when A. Biswas was a PhD student at the Indian Institute of Science. She gratefully acknowledges the support of a Google PhD Fellowship Award. G. K Patro acknowledges the support by TCS Research Fellowship. This research was supported in part by an European Research Council (ERC) Advanced Grant for the project â€œFoundations for Fair Social Computing" (grant agreement no. 789373), and an European Research Council (ERC) Marie Sklodowska-Curie grant for the project â€œNoBIAS â€” Artiî€›cial Intelligence without Bias" (grant agreement no. 860630), both funded under the EUâ€™s Horizon 2020. Reproducibility: Code, dataset and other details are available at https://github.com/gourabkumarpatro/ FairRec.
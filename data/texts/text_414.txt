The MIPS (maximum inner product search), which î€›nds the item with the highest inner product with a given query user, is an essential problem in the recommendation î€›eld. It is usual that ecommerce companies face situations where they want to promote and sell new or discounted items. In these situations, we have to consider a question: who are interested in the items and how to î€›nd them? This paper answers this question by addressing a new problem called reverse maximum inner product search (reverse MIPS). Given a query vector and two sets of vectors (user vectors and item vectors), the problem of reverse MIPS î€›nds a set of user vectors whose inner product with the query vector is the maximum among the query and item vectors. Although the importance of this problem is clear, its straightforward implementation incurs a computationally expensive cost. We therefore propose Simpfer, a simple, fast, and exact algorithm for reverse MIPS. In an oî€Ÿine phase, Simpfer builds a simple index that maintains a lower-bound of the maximum inner product. By exploiting this index, Simpfer judges whether the query vector can have the maximum inner product or not, for a given user vector, in a constant time. Besides, our index enables î€›ltering user vectors, which cannot have the maximum inner product with the query vector, in a batch. We theoretically demonstrate that Simpfer outperforms baselines employing state-of-the-art MIPS techniques. Furthermore, our extensive experiments on real datasets show that Simpfer is at least two orders magnitude faster than the baselines. The MIPS (maximum inner product search) problem, orğ‘˜-MIPS problem, is an essential tool in the recommendation î€›eld. Given a query (user) vector, this problem î€›nds theğ‘˜item vectors with the highest inner product with the query vector among a set of item vectors. The search result, i.e.,ğ‘˜item vectors, can be used as recommendation for the user, and the user and item vectors are obtained via Matrix Factorization, which is well employed in recommender systems [5,8,13,30]. Although some learned similarities via MLP (i.e., neural networks) have also been devised, e.g., in [36,38], [26] has actually demonstrated that inner product-based (i.e., Matrix Factorization-based) recommendations show better performances than learned similarities. We hence focus on inner product between ğ‘‘-dimensional vectors that are obtained via Matrix Factorization. Theğ‘˜-MIPS problem is eî€ective for the case where a user wants to know items that s/he prefers (i.e., user-driven cases), but ecommerce companies usually face situations where they want to advertise an item, which may be new or discounted one, to users, Table 1: Example of reverse MIPS where q = p. The rows at right illustrate the result of MIPS on P for each u âˆˆ Q. uâŸ¨3.1, 0.1âŸ© pâŸ¨2.8, 0.6âŸ© up uâŸ¨2.5, 2.0âŸ© pâŸ¨2.5, 1.8âŸ© up uâŸ¨1.5, 2.2âŸ© pâŸ¨3.2, 1.0âŸ© up uâŸ¨1.8, 3.2âŸ© pâŸ¨1.4, 2.6âŸ© up which corresponds to item-driven cases. Trivially, an eî€ective advertisement is to recommend such an item to users who would be interested in this item. In the context of theğ‘˜-MIPS problem, if this item is included in the top-k item set for a user, we should make an advertisement of the item to this user. That is, we should î€›nd a set of such users. This paper addresses this new problem, called reverseğ‘˜-MIPS problem. To ease of presentation, this section assumes thatğ‘˜ =1 (the general case is deî€›ned in Section 2). Given a query vectorq(the vector of a target item) and two sets ofğ‘‘-dimensional vectorsQ(set of user vectors) andP(set of item vectors), the reverse MIPS problem î€›nds all user vectors u âˆˆ Q such that q = arg maxp Â· u. Example 1. Table 1 illustratesQ,P, and the MIPS result, i.e.,p= arg maxu Â· p, of each vector inQ. Letq = p, and the result of reverse MIPS is{u, u}becausepis the top-1 item foruandu. Whenq = p, we have no result, becausepis not the top-1 item âˆ€u âˆˆ Q. Similarly, when q = p, the result is {u}. From this example, we see that, if an e-commerce service wants to promote the item corresponding top, this service can obtain the users who would prefer this item through the reverse MIPS, and sends them a notiî€›cation about this item. The reverseğ‘˜-MIPS problem is an eî€ective tool not only for item-driven recommendations but also market analysis. Assume that we are given a vector of a new item,q. It is necessary to design an eî€ective sales strategy to gain a proî€›t. Understanding the features of users that may prefer the item is important for the strategy. Solving the reverseğ‘˜-MIPS of the query vectorqsupports this understanding. The above practical situations clarify the importance of reverse MIPS. Because e-commerce services have large number of users and items,|Q|and|P|are large. In addition, a query vector is not pre-known and is speciî€›ed on-demand fashion. The reverseğ‘˜-MIPS is therefore conducted online and is computationally-intensive task. Now the question is how to eî€œciently obtain the reverse MIPS result for a given query. A straightforward approach is to run a state-of-the-art exact MIPS algorithm for every vector inQand check whether or notq = arg maxu Â· p. This approach obtains the exact result, but it incurs unnecessary computation. The poor performance of this approach is derived from the following observations. First, we do not need the MIPS result ofuwhenqdoes not have the maximum inner product withu. Second, this approach certainly accesses all user vectors inQ, although many of them do not contribute to the reverse MIPS result. However, it is not trivial to skip evaluations of some user vectors without losing correctness. Last, its theoretical cost is the same as the brute-force case, i.e.,ğ‘‚ (ğ‘›ğ‘šğ‘‘)time, where ğ‘› = |Q|andğ‘š = |P|, which is not appropriate for online computations. These concerns pose challenges for solving the reverse MIPS problem eî€œciently. To address the above issues, we propose Simpfer, a simple, fast, and exact algorithm for reverse MIPS. The general idea of Simpfer is to eî€œciently solve the decision version of the MIPS problem. Because the reverse MIPS of a queryqrequires a yes/no decision for each vectoru âˆˆ Q, it is suî€œcient to know whether or not qcan have the maximum inner product foru. Simpfer achieves this inğ‘‚ (1)time in many cases by exploiting its index built in an oî€Ÿine phase. This index furthermore supports a constant time î€›ltering that prunes vectors in a batch if their answers are no. We theoretically demonstrate that the time complexity of Simpfer is lower than ğ‘‚ (ğ‘›ğ‘šğ‘‘). The summary of our contributions is as follows: â€¢We address the problem of reverseğ‘˜-MIPS. To our knowledge, this is the î€›rst work to study this problem. â€¢We propose Simpfer as an exact solution to the reverse MIPS problem. Simpfer solves the decision version of the MIPS problem at both the group-level and the vector-level efî€›ciently. Simpfer is surprisingly simple, but our analysis demonstrates that Simpfer theoretically outperforms a solution that employs a state-of-the-art exact MIPS algorithm. â€¢We conduct extensive experiments on four real datasets, MovieLens, Netî€ix, Amazon, and Yahoo!. The results show that Simpfer is at least two orders magnitude faster than baselines. â€¢Simpfer is easy to deploy: if recommender systems have user and item vector sets that are designed in the inner product space, they are ready to use Simpfer via our open source implementation. This is because Simpfer is unsupervised and has only a single parameter (the maximum value ofğ‘˜) that is easy to tune and has no eî€ect on the running time of online processing. This paper is an error-corrected version of [3]. We î€›xed some writing errors and minor bugs in our implementation, but our result is consistent with [3]. Organization.The rest of this paper is organized as follows. We formally deî€›ne our problem in Section 2. We review related work in Section 3. Our proposed algorithm is presented in Section 4, and the experimental results are reported in Section 5. Last, we conclude this paper in Section 6. LetPbe a set ofğ‘‘-dimensional real-valued item vectors, and we assume thatğ‘‘is high [22,27]. Given a query vector, the maximum inner product search (MIPS) problem î€›nds The general version of the MIPS problem, i.e., theğ‘˜-MIPS problem, is deî€›ned as follows: Definition 1 (ğ‘˜-MIPS problem). Given a set of vectorsP, a query vectorq, andğ‘˜, theğ‘˜-MIPS problem î€›ndsğ‘˜vectors inPthat have the highest inner products with q. For a user (i.e., query), theğ‘˜-MIPS problem can retrieveğ‘˜items (e.g., vectors inP) that the user would prefer. Diî€erent from this, the reverseğ‘˜-MIPS problem can retrieve a set of users who would prefer a given item. That is, in the reverseğ‘˜-MIPS problem, a query can be an item, and this problem î€›nds users attracted by the query item. Therefore, the reverseğ‘˜-MIPS is eî€ective for advertisement and market analysis, as described in Section 1. We formally deî€›ne this problem. Definition 2 (Reverseğ‘˜-MIPS problem). Given a query (item) vectorq,ğ‘˜, and two sets of vectorsQ(set of user vectors) andP(set of item vectors), the reverseğ‘˜-MIPS problem î€›nds all vectorsu âˆˆ Q such that q is included in the ğ‘˜-MIPS result of u among P âˆª {q}. Note thatqcan beq âˆˆ P, as described in Example 1. We useğ‘›and ğ‘š to denote |Q| and |P|, respectively. Our only assumption is that there is a maximumğ‘˜that can be speciî€›ed, denoted byğ‘˜. This is practical, becauseğ‘˜should be small, e.g.,ğ‘˜ =5 [16] orğ‘˜ =10 [4], to make applications eî€ective. (We explain how to deal with the case ofğ‘˜ > ğ‘˜in Section 4.1.) This paper develops an exact solution to the new problem in Deî€›nition 2. Exact ğ‘˜-MIPS Algorithm.The reverseğ‘˜-MIPS problem can be solved exactly by conducting an exactğ‘˜-MIPS algorithm for each user vector inQ. The î€›rst line of solution to theğ‘˜-MIPS problem is a tree-index approach [9,17,25]. For example, [25] proposed a tree-based algorithm that processesğ‘˜-MIPS not only for a single user vector but also for some user vectors in a batch. Unfortunately, the performances of the tree-index algorithms degrade for large ğ‘‘ because of the curse of dimensionality. LEMP [28,29] avoids this issue and signiî€›cantly outperforms the tree-based algorithms. LEMP uses several search algorithms according to the norm of each vector. In addition, LEMP devises an early stop scheme of inner product computation. During the computation ofu Â· q, LEMP computes an upper-bound ofu Â· q. If this bound is lower than an intermediateğ‘˜-th maximum inner product,ğ‘cannot be in the î€›nal result, thus the inner product computation can be stopped. LEMP is actually designed for the topk inner product join problem: for eachu âˆˆ Q, it î€›nds theğ‘˜-MIPS result ofu. Therefore, LEMP can solve the reverseğ‘˜-MIPS problem, but it is not eî€œcient as demonstrated in Section 5. FEXIPRO [19] further improves the early stop of inner product computation of LEMP. Speciî€›cally, FEXIPRO exploits singular value decomposition, integer approximation, and a transformation to positive values. These techniques aim at obtaining a tighter upper-bound ofu Â· qas early as possible. [19] reports that state-ofthe-art tree-index algorithm [25] is completely outperformed by FEXIPRO. Maximus [1] takes hardware optimization into account. It is, however, limited to speciî€›c CPUs, so we do not consider Maximus. Note that LEMP and FEXIPRO are heuristic algorithms, and ğ‘‚ (ğ‘›ğ‘šğ‘‘) time is required for the reverse ğ‘˜-MIPS problem. Approximation ğ‘˜-MIPS Algorithm.To solve theğ‘˜-MIPS problem in sub-linear time by sacriî€›cing correctness, many works proposed approximationğ‘˜-MIPS algorithms. There are several approaches to the approximationğ‘˜-MIPS problem: sampling-based [7,22,35], LSH-based [15,24,27,33], graph-based [21,23,39], and quantization approaches [10,14]. They have both strong and weak points. For example, LSH-based algorithms enjoy a theoretical accuracy guarantee. However, they are empirically slower than graphbased algorithms that have no theoretical performance guarantee. Literature [4] shows that the MIPS problem can be transformed into the Euclidean nearest neighbor search problem, but it still cannot provide the correct answer. Besides, existing works that address the (reverse) nearest neighbor search problem assume low-dimensional data [34] or consider approximation algorithms [20]. Since this paper focuses on the exact result, these approximation ğ‘˜-MIPS algorithms cannot be utilized. In addition, approximate answers may lose eî€ectiveness of the reverseğ‘˜-MIPS problem. If applications cannot contain users, who are the answer of theğ‘˜MIPS problem, these users may lose chances of knowing the target item, which would reduce proî€›ts. On the other hand, if applications contain users, who are not the answer of theğ‘˜-MIPS problem, as an approximate answer, they advertise the target item to users who are not interested in the item. This also may lose future proî€›ts, because such users may stop receiving advertisements if they get those of non-interesting items. To eî€œciently solve the reverse MIPS problem, we propose Simpfer. Its general idea is to eî€œciently solve the decision version of the ğ‘˜-MIPS problem. Definition 3 (ğ‘˜-MIPS decision problem). Given a queryq,ğ‘˜, a user vectoru, andP, this problem returns yes (no) ifqis (not) included in the ğ‘˜-MIPS result of u. Notice that this problem does not require the completeğ‘˜-MIPS result. We can terminate theğ‘˜-MIPS ofuwhenever it is guaranteed thatq is (not) included in the ğ‘˜-MIPS result. To achieve this early termination eî€œciently, it is necessary to obtain a lower-bound and an upper-bound of theğ‘˜-th highest inner product ofu. Letğœ™andğœ‡respectively be a lower-bound and an upper-bound of theğ‘˜-th highest inner product ofuonP. Ifğœ™ â‰¥ uÂ· q, it is guaranteed thatqdoes not have theğ‘˜highest inner product withu. Similarly, ifğœ‡ â‰¤ u Â· q, it is guaranteed thatqhas theğ‘˜ highest inner product withu. This observation implies that we need to eî€œciently obtainğœ™andğœ‡. Simpfer does pre-processing to enable it in an oî€Ÿine phase. Besides, sinceğ‘› = |Q|is often large, accessing all user vectors is also time-consuming. This requires a î€›ltering technique that enables the pruning of user vectors that are not included in the reverseğ‘˜-MIPS result in a batch. During the preprocessing, Simpfer arrangesQso that batch î€›ltering is enabled. Simpfer exploits the data structures built in the pre-processing phase to quickly solve the ğ‘˜-MIPS decision problem. The objective of this pre-processing phase is to build data structures that support eî€œcient computation of a lower-bound and an upper-bound of theğ‘˜-th highest inner product for eachuâˆˆ Q, for arbitrary queries. We utilize Cauchyâ€“Schwarz inequality for upperbounding. Hence we need the Euclidean normâˆ¥uâˆ¥for eachuâˆˆ Q. To obtain a lower-bound of theğ‘˜-th highest inner product, we need to access at leastğ‘˜item vectors inP. The norm computation and lower-bound computation are independent of queries (as long as ğ‘˜ â‰¤ ğ‘˜), so they can be pre-computed. In this phase, Simpfer builds the following array for each uâˆˆ Q. Definition 4 (Lower-bound array). The lower-bound arrayğ¿of a user vectoruâˆˆ Qis an array whoseğ‘—-th element,ğ¿, maintains a lower-bound of the ğ‘—-th inner product of uon P, and |ğ¿| = ğ‘˜. Furthermore, to enable batch î€›ltering, Simpfer builds a block, which is deî€›ned below. Definition 5 (Block). A blockBis a subset ofQ. The set of vectors belonging toBis represented byQ(B). Besides, we useğ¿(B)to represent the lower-bound array of this block, and The block size|Q(B)|can be arbitrarily determined, and we set |Q(B)| = ğ‘‚ (log ğ‘›) to avoid system parameter setting. Pre-processing algorithm.Algorithm 1 describes the pre-processing algorithm of Simpfer. (1) Norm computation: First, for eachu âˆˆ Qandp âˆˆ P, its norm is computed. Then, Q and P are sorted in descending order of norm. (2) Lower-bound array building: LetPbe the set of the î€›rstğ‘‚ (ğ‘˜) vectors inP. For eachuâˆˆ Q,ğ¿is built by usingP. That is, ğ¿= uÂ· p, wherep âˆˆ Pyields theğ‘—-th highest inner product for u âˆˆ P. The behind idea of using the î€›rstğ‘‚ (ğ‘˜)item vectors inPis that vectors with large norms tend to provide large inner products [21]. This means that we can obtain a tight lower-bound at a lightweight cost. (3) Block building: After that, blocks are built, so that user vectors in a block keep the order and each block is disjoint. Given a new blockB, we insert user vectorsuâˆˆ QintoQ(B)in sequence â† the î€›rst ğ‘‚ (ğ‘˜) vectors in P while updatingğ¿(B), until we have|Q(B)| = ğ‘‚ (log ğ‘›). When |Q(B)| = ğ‘‚ (log ğ‘›), we insertBinto a set of blocksB, and make a new block. Example 2. Figure 1 illustrates an example of block building. For ease of presentation, we useğ‘as a block size andğ‘› =3ğ‘. For example, Q(B) = {u, ..., u}, and âˆ¥uâˆ¥ â‰¥ ... â‰¥ âˆ¥uâˆ¥. Generally, this pre-processing is done only once. An exception is the case where a query withğ‘˜ > ğ‘˜is speciî€›ed. In this case, Simpfer re-builds the data structures then processes the query. This is actually much faster than the baselines, as shown in Section 5.7. Analysis.We here prove that the time complexity of this preprocessing is reasonable. Without loss of generality, we assume ğ‘› â‰¥ ğ‘š, because this is a usual case for many real datasets, as the ones we use in Section 5. Theorem 1. Algorithm 1 requires ğ‘‚ (ğ‘›(ğ‘‘ + log ğ‘›)) time. Proof. The norm computation requiresğ‘‚ ((ğ‘› + ğ‘š)ğ‘‘) = ğ‘‚ (ğ‘›ğ‘‘)time, and sorting requiresğ‘‚ (ğ‘› log ğ‘›)time. The building of lower-bound arrays needsğ‘‚ (ğ‘› Ã— ğ‘˜)time, sinceğ‘‚ (|P|) = ğ‘‚ (ğ‘˜). Because ğ‘˜= ğ‘‚ (1),ğ‘‚ (ğ‘›Ã—ğ‘˜) = ğ‘‚ (ğ‘›). The block building also requires ğ‘‚ (ğ‘› Ã— ğ‘˜) = ğ‘‚ (ğ‘›)time. In total, this pre-processing requires The space complexity of Simpfer is also reasonable. Theorem 2. The space complexity of the index is ğ‘‚ (ğ‘›). Proof. The space of the lower-bound arrays of user vectors isÃ ğ‘‚ (|ğ¿|) = ğ‘‚ (ğ‘›), sinceğ‘‚ (|ğ¿|) = ğ‘‚ (1). Blocks are disjoint, and the space of the lower-bound array of a block is alsoğ‘‚ (1). We hence haveğ‘‚ ()lower-bound arrays of blocks. Now this theorem is Before we present the details of Simpfer, we introduce our techniques that can quickly answer theğ‘˜-MIPS decision problem for a given queryq. Recall thatQandPare sorted in descending order of norm. Without loss of generality, we assume thatâˆ¥uâˆ¥ â‰¥ âˆ¥uâˆ¥ for eachğ‘– âˆˆ [1, ğ‘› âˆ’1]andâˆ¥pâˆ¥ â‰¥ âˆ¥pâˆ¥for eachğ‘— âˆˆ [1,ğ‘š âˆ’1], for ease of presentation. Given a queryqand a user vectoruâˆˆ Q, we haveuÂ·q. Although our data structures are simple, they provide eî€ective and â€œlightweightâ€ î€›lters. Speciî€›cally, we can quickly answer theğ‘˜-MIPS decision problem on q through the following observations. Lemma 1. IfuÂ· q â‰¤ ğ¿, it is guaranteed thatqis not included in the ğ‘˜-MIPS result of u. Proof. Letpbe the vector inPsuch thatuÂ· pis theğ‘˜-th highest inner product inP. The fact thatğ¿â‰¤ uÂ· pimmediately derives It is important to see that the above lemma provides â€œnoâ€ as the answer to theğ‘˜-MIPS decision problem onqinğ‘‚ (1)time (after computinguÂ· q). The next lemma deals with the â€œyesâ€ case inğ‘‚ (1) time. Lemma 2. IfuÂ· q â‰¥ âˆ¥uâˆ¥âˆ¥pâˆ¥, it is guaranteed thatqis included in the ğ‘˜-MIPS result of u. Proof. From Cauchyâ€“Schwarz inequality, we haveuÂ·pâ‰¤ âˆ¥uâˆ¥âˆ¥pâˆ¥. Sinceâˆ¥pâˆ¥is theğ‘˜-th highest norm inP,uÂ· p â‰¤ âˆ¥uâˆ¥âˆ¥pâˆ¥, where pis deî€›ned in the proof of Lemma 1. That is,âˆ¥uâˆ¥âˆ¥pâˆ¥is an upper-bound ofuÂ· p. Now it is clear thatqhasuÂ· q â‰¥ uÂ· p if uÂ· q â‰¥ âˆ¥uâˆ¥âˆ¥p We next introduce a technique that yields â€œnoâ€ as the answer for all user vectors in a block B in ğ‘‚ (1) time. Lemma 3. Given a blockB, letube the î€›rst vector inQ(B). If âˆ¥uâˆ¥âˆ¥qâˆ¥ â‰¤ ğ¿(B), for alluâˆˆ Q(B), it is guaranteed thatqis not included in the ğ‘˜-MIPS result of u. Proof. From Cauchyâ€“Schwarz inequality,âˆ¥uâˆ¥âˆ¥qâˆ¥is an upperbound ofuÂ· qfor alluâˆˆ Q(B), sinceQ(B) = {u, u, ...}. We haveğ¿(B) â‰¤ ğ¿for alluâˆˆ Q(B), from Equation (1). Therefore, if âˆ¥uâˆ¥âˆ¥qâˆ¥ â‰¤ ğ¿(B), uÂ· q cannot be the ğ‘˜ highest inner product. â–¡ If a user vectorucannot obtain a yes/no answer from Lemmas 1â€“3, Simpfer uses a linear scan ofPto obtain the answer. Letğœbe a threshold, i.e., an intermediateğ‘˜-th highest inner product foru Algorithm 2: Linear-scan(ğ‘¢) Input: u âˆˆ Q, P, q, and ğ‘˜ during the linear scan. By using the following corollaries, Simpfer can obtain the correct answer and early terminate the linear scan. Corollary 1. Assume thatqis included in an intermediate result of theğ‘˜-MIPS ofuand we now evaluatepâˆˆ P. IfuÂ· q â‰¥ âˆ¥uâˆ¥âˆ¥pâˆ¥, it is guaranteed thatqis included in the î€›nal result of theğ‘˜-MIPS ofu. Proof. Trivially, we haveğ‘— â‰¥ ğ‘˜. Besides,âˆ¥uâˆ¥âˆ¥pâˆ¥ â‰¥ uÂ· pfor all From this corollary, we also have: Corollary 2. When we haveğœ > uÂ· q, it is guaranteed thatqis not included in the î€›nal result of the ğ‘˜-MIPS of u. Algorithm 2 summarizes the linear scan that incorporates Corollaries 1â€“2. Now we are ready to present Simpfer. Algorithm 3 details it. To start with, Simpfer computesâˆ¥qâˆ¥. Given a blockB âˆˆ B, Simpfer tests Lemma 3 (line 4). If the user vectors inQ(B)may have yes as an answer, for eachuâˆˆ Q(B), Simpfer does the following. (Otherwise, all user vectors inQ(B)are ignored.) First, it computesuÂ· q, then tests Lemma 1 (line 7). Ifucannot have the answer from this lemma, Simpfer tests Lemma 2. Simpfer insertsuinto the result setQif uÂ· q â‰¥ âˆ¥uâˆ¥âˆ¥pâˆ¥. Otherwise, Simpfer conducts Linear-scan(u) (Algorithm 2). If Linear-scan(u)returns 1 (yes),uis inserted intoQ. The above operations are repeated for eachB âˆˆ B. Finally, Simpfer returns the result set Q. The correctness of Simpfer is obvious, because it conducts Linearscan(Â·)for all vectors that cannot have yes/no answers from Lemmas 1â€“3. Besides, Simpfer accesses blocks sequentially, so it is easy to parallelize by using multicore. Simpfer hence further accelerates the processing of reverse ğ‘˜-MIPS, see Section 5.6. We theoretically demonstrate the eî€œciency of Simpfer. Speciî€›cally, we have: Input: Q, P, q, ğ‘˜, and B â† âˆ…, Compute âˆ¥qâˆ¥ Theorem 3. Letğ›¼be the pruning ratio (0â‰¤ ğ›¼ â‰¤1) of blo cks inB. Furthermore, letğ‘šbe the average number of item vectors accessed in Linear-scan(Â·). The time complexity of Simpfer isğ‘‚ ((1âˆ’ ğ›¼)ğ‘›ğ‘šğ‘‘). Proof. Simpfer accesses all blocks inB, and|B| = ğ‘‚ (). Assume that a blockB âˆˆ Bis not pruned by Lemma 3. Simpfer accesses all user vectors inQ(B), so the total number of such user vectors is(1âˆ’ ğ›¼) Ã— ğ‘‚ () Ã— ğ‘‚ (log ğ‘›) = ğ‘‚ ((1âˆ’ ğ›¼)ğ‘›). For these vectors, Simpfer computes inner products withq. The evaluation cost of Lemmas 1 and 2 for these user vectors is thusğ‘‚ ((1âˆ’ ğ›¼)ğ‘›ğ‘‘). The worst cost of Linear-scan(Â·)for vectors that cannot obtain the answer from these lemmas isğ‘‚ ((1âˆ’ ğ›¼)ğ‘›ğ‘šğ‘‘). Now the time complexity of Simpfer is ğ‘‚ (ğ‘›log ğ‘›+ (1 âˆ’ ğ›¼)ğ‘›ğ‘‘ + (1 âˆ’ ğ›¼)ğ‘›ğ‘šğ‘‘) = ğ‘‚ (ğ‘›log ğ‘›+ (1 âˆ’ ğ›¼)ğ‘›ğ‘šğ‘‘) Remark.There are two main observations in Theorem 3. First, because we practically haveğ‘š< ğ‘šandğ›¼ >0, Simpfer outperforms a ğ‘˜-MIPS-based solution that incursğ‘‚ (ğ‘›ğ‘šğ‘‘)time. (Our experimental results show thatğ‘š= ğ‘‚ (ğ‘˜)in practice.) The second observation is obtained from Equation (2), which implies the eî€ectiveness of blocks. If Simpfer does not build blocks, we have to evaluate Lemma 1 for allu âˆˆ Q. Equation (2) suggests that the blocks theoretically avoids this. This section reports our experimental results. All experiments were conducted on a Ubuntu 18.04 LTS machine with a 12-core 3.0GHz Intel Xeon E5-2687w v4 processor and 512GB RAM. Datasets.We used four popular real datasets: MovieLens, Netî€ix, Amazon, and Yahoo!. The user and item vectors of these datasets were obtained by the Matrix Factorization in [6]. These are 50dimensional vectors (the dimensionality setting is the same as [19, 29]). The other statistics is shown in Table 2. We randomly chose 1,000 vectors as query vectors from P. Evaluated algorithms.We evaluated the following three algorithms. â€¢LEMP [29]: the state-of-the-art all-ğ‘˜-MIPS algorithm. LEMP originally does ğ‘˜-MIPS for all user vectors in Q. â€¢FEXIPRO [19]: the state-of-the-artğ‘˜-MIPS algorithm. We simply ran FEXIPRO for each u âˆˆ Q. â€¢Simpfer: the algorithm proposed in this paper. We setğ‘˜= 25. These algorithms were implemented in C++ and compiled by g++ 7.5.0 with -O3 î€ag. We used OpenMP for multicore processing. These algorithms return the exact result, so we measured their running time. Note that [19,29] have demonstrated that the other exact MIPS algorithms are outperformed by LEMP and FEXIPRO, so we did not use them as competitors. (Recall that this paper focuses on the exact answer, thus approximation algorithms are not appropriate for competitors, see Section 3.) In addition, LEMP and FEXIPRO also have a pre-processing (oî€Ÿine) phase. We did not include the oî€Ÿine time as the running time. We î€›rst clarify the eî€ectiveness of blocks employed in Simpfer. To show this, we compare Simpfer with Simpfer without blocks (which does not evaluate line 4 of Algorithm 3). We set ğ‘˜ = 10. On MovieLens, Netî€ix, Amazon, and Yahoo!, Simpfer (Simpfer without blocks) takes 10.3 (22.0), 58.6 (100.8), 117.6 (446.2), and 1481.2 (1586.2) [msec], respectively. This result demonstrates that, although the speed-up ratio is aî€ected by data distributions, blocks surely yield speed-up. We investigate howğ‘˜aî€ects the computational performance of each algorithm by using a single core. Figure 2 depicts the experimental results. We î€›rst observe that, asğ‘˜increases, the running time of each algorithm increases, as shown in Figures 2(a)â€“2(d). This is reasonable, because the cost of (decision version of)ğ‘˜-MIPS increases. As a proof, Figures 2(e)â€“2(h) show that the number of inner product (ip) computations increases asğ‘˜increases. The running time of Simpfer is (sub-)linear toğ‘˜(the plots are log-scale). This suggests that ğ‘š= ğ‘‚ (ğ‘˜). Second, Simpfer signiî€›cantly outperforms LEMP and FEXIPRO. This result is derived from our idea of quickly solving theğ‘˜-MIPS decision problem. The techniques introduced in Section 4.2 can deal with both yes and no answer cases eî€œciently. Therefore, our approach functions quite well in practice. Last, an interesting observation is the performance diî€erences between FEXIPRO and Simpfer. Let us compare them with regard to running time. Simpfer is at least two orders of magnitude faster than FEXIPRO. On the other hand, with regard to the number of inner product computations, that of Simpfer is one order of magnitude lower than that of FEXIPRO. This result suggests that the î€›ltering cost of Simpfer is light, whereas that of FEXIPRO is heavy. Recall that Lemmas 1â€“3 need onlyğ‘‚ (1)time, and Corollaries 1â€“2 need ğ‘‚ (ğ‘˜)time in practice. On the other hand, for each user vector inğ‘„, FEXIPRO incursÎ©(ğ‘˜)time, and its î€›ltering cost isğ‘‚ (ğ‘‘), where ğ‘‘< ğ‘‘. For high-dimensional vectors, the diî€erence betweenğ‘‚ (1) andğ‘‚ (ğ‘‘)is large. From this point of view, we can see the eî€œciency of Simpfer. We next study the scalability toğ‘› = |Q|by using a single core. To this end, we randomly sampledğ‘  Ã— ğ‘›user vectors inQ, and this sampling rateğ‘ hasğ‘  âˆˆ [0.2,1.0]. We setğ‘˜ =10. Figure 3 shows the experimental result. In a nutshell, we have a similar result to that in Figure 2. As ğ‘›increases, the running time of Simpfer linearly increases. This result is consistent with Theorem 3. Notice that the tendency of the running time of Simpfer follows that of the number of inner product computations. This phenomenon is also supported by Theorem 3, because the main bottleneck of Simpfer is Linear-scan (Â·). The scalability toğ‘š = |P|by using a single core is also investigated. We randomly sampledğ‘  Ã— ğ‘šuser vectors inP, as with the previous section. Figure 4 shows the experimental result whereğ‘˜ =10. Interestingly, we see that the result is diî€erent from that in Figure 3. The running time of Simpfer is almost stable for diî€erentğ‘š. In this experiment,ğ‘›andğ‘˜were î€›xed, and recall thatğ‘š= ğ‘‚ (ğ‘˜). From this observation, the stable performance is theoretically obtained. This scalability of Simpfer is an advantage over the other algorithms, since their running time increases as ğ‘š increases. We study the gain of multicore processing of Simpfer by setting ğ‘˜ =10. We depict the speedup ratios compared with the single-core case in Table 3. We see that Simpfer receives the beneî€›t of multicore processing, and its running time decreases as the number of available cores increases. We here explain why Simpfer cannot obtain speedup ratioğ‘, whereğ‘is the number of available cores. Each core deals with diî€erent blocks, and the processing cost of a given blockBis diî€erent from those of the others. This is because it is unknown Figure 2: Impact of ğ‘˜: Running time (top) and #ip computations (bottom). â€œÃ—â€ shows LEMP, â€œâ—¦â€ shows FEXIPRO, and â€œâ–³â€ shows Simpfer. Figure 3: Impact of |Q |: Running time (top) and #ip computations (bottom). â€œÃ—â€ shows LEMP, â€œâ—¦â€ shows FEXIPRO, and â€œâ–³â€ shows Simpfer. #cores MovieLens Netî€ix Amazon Yahoo! whetherBcan be pruned by Lemma 3. Even if we magically know the cost, it is NP-hard to assign blocks so that each core has the same processing cost [2,18]. Therefore, perfect load-balancing is impossible in practice. The Yahoo! case in particular represents this phenomenon. Because many user vectors in Yahoo! have large norms, blocks often cannot be î€›ltered by Lemma 3. This can be seen from the observation in Figure 3(h): the number of inner product computations on Yahoo! is larger than those on the other datasets. Figure 4: Impact of |P|: Running time (top) and #ip computations (bottom). â€œÃ—â€ shows LEMP, â€œâ—¦â€ shows FEXIPRO, and â€œâ–³â€ shows Simpfer. The costs of Corollaries 1â€“2 are data-dependent (i.e., they are not pre-known), rendering a fact that Yahoo! is a hard case for obtaining a high speedup ratio. Table 4: Pre-processing time of Simpfer [sec] Last, we report the pre-processing time of Simpfer. Table 4 shows the results. As Theorem 1 demonstrates, the pre-processing time increases asğ‘›increases. We see that the pre-processing time is reasonable and much faster than the online (running) time of the baselines. For example, the running time of FEXIPRO on Amazon withğ‘˜ =25 is 1206 [sec]. Whenğ‘˜ =25 (i.e.,ğ‘˜ = ğ‘˜), the total time of pre-processing and online processing of Simpfer is 15.10+0.16=15.26 [sec]. Therefore, even ifğ‘˜ > ğ‘˜is speciî€›ed, re-building blocks then processing the query by Simpfer is much faster. This paper introduced a new problem, reverse maximum inner product search (reverse MIPS). The reverse MIPS problem supports many applications, such as recommendation, advertisement, and market analysis. Because even state-of-the-art algorithms for MIPS cannot solve the reverse MIPS problem eî€œciently, we proposed Simpfer as an exact and eî€œcient solution. Simpfer exploits several techniques to eî€œciently answer the decision version of the MIPS problem. Our theoretical analysis has demonstrated that Simpfer is always better than a solution that employs a state-of-the-art algorithm of MIPS. Besides, our experimental results on four real datasets show that Simpfer is at least two orders of magnitude faster than the MIPS-based solutions. This research is partially supported by JST PRESTO Grant Number JPMJPR1931, JSPS Grant-in-Aid for Scientiî€›c Research (A) Grant Number 18H04095, and JST CREST Grant Number JPMJCR21F2.
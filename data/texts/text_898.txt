thanhdatn@student.unimelb.edu.authanh.ld164834@sis.hust.edu.vn Graph Neural Networks (GNNs) have recently emerged as a robust framework for graph-structured data. They have been applied to many problems such as knowledge graph analysis, social networks recommendation, and even Covid19 detection and vaccine developments. However, unlike other deep neural networks such as Feed Forward Neural Networks (FFNNs), few analyses such as veriî€›cation and property inferences exist, potentially due to dynamic behaviors of GNNs, which can take arbitrary graphs as input, whereas FFNNs which only take î€›xed size numerical vectors as inputs. This paper proposes an approach to analyze GNNs by converting them into FFNNs and reusing existing FFNNs analyses. We discuss various designs to ensure the scalability and accuracy of the conversions. We illustrate our method on a study case of node classiî€›cation. We believe that our approach opens new research directions for understanding and analyzing GNNs. Property Inference, Formal Explanations, Graph Neural Networks ACM Reference Format: Thanh-Dat Nguyen, Thanh Le-Cong, ThanhVu H. Nguyen, Xuan-Bach D. Le, and Quyet-Thang Huynh. 2022. Toward the Analysis of Graph Neural Networks. In Proceedings of The 44th International Conference on Software Engineering (ICSE 2022). ACM, New York, NY, USA, 5 pages. https://doi.org/ 10.1145/nnnnnnn.nnnnnnn Deep Neural Networks (DNNs) have emerged as one of the most eî€ective and modern approaches in solving problems, from common ones such as movies recommendations, image recognition thanghq@soict.hust.edu.vn Hanoi University of Science and to important ones such as collision control and "fake" news and information detection. Just like software, these DNN models can be misused and attacked (e.g., small perturbations to the inputs can result in misclassifying results). Thus, over the last decade, researchers have developed many powerful techniques to analyze DNNs, e.g., verifying that for certain inputs, a DNN will result in a certain output or have a desirable property, and more recently, inferring properties or facts to help explain behaviors of a DNN, which is typically treated as blackbox. Despite the proliferation of DNNs analyses, most eî€ective ones focus only on certain types of DNNS, such as Feedforward Neural Network (FFNNs), in which the inputs are presented as î€›xed-size vectors of numbers and a î€›xed structure network. One of the more complicated DNNs that has recently been used in practice is Graph Neural Networks (GNNS), which take inputs as graphs of various sizes (even each of the nodes in the graph is attached with information encoded as a vector of numbers) and have a dynamic network that depends on the structure and information from the input graphs. GNNs have been applied to solve many practical problems, e.g., knowledge graphs analysis [12], recommendation system for social networks [16], chemical and protein classiî€›cation [4,10], reasoning the structure of graphics and images [13], and even advanced COVID19 detection [11,19] and vaccine development [2, 6, 17]. Just as with standard DNNs, complex GNNs are often used as blackbox and can be vulnerable to adversary attacks, all of which lead to concerns about safety, fairness, and privacy of GNNs [3,14, 18], e.g., a new Covid vaccine developed by unknown and attackedprone ML technique can only further increase doubts and hesitancy from the public. However, unlike popular FFNNs, in which there are many eî€ective formal analyses, to the best of our knowledge, few exist for GNNs, potentially due to the vast diî€erences between the two types of networks. In this paper, we propose an approach to analyze GNNs, both in veriî€›cation and property inference, by converting GNNs to FFNNs and reusing developed techniques for FFNNs. While analyses explicitly designed for GNNs can be more eî€œcient, they can be diî€œcult and time-consuming to develop due to the diî€erences between two types of networks. Thus, we believe our approach of leveraging existing eî€œcient techniques and tools can be achieved quicker and also as eî€ectively, as we can rely on existing powerful FFNN tools. This kind of approach is similar to many techniques in software engineering that encode the analysis task as a logical formula that can be eî€œciently analyzed by existing constraint solving techniques and tools (e.g., SAT and SMT solvers). Fig. 1 gives an overview of our idea. The main challenge in analyzing GNNs and converting them to FFNNs is that the input graphs of a GNN can have various topological structures and the GNN has a dynamic structure depending on its input graphs. To solve this challenge, we mine inî€žuential sub-structures of input graphs to summarize the structural input space of a GNN. Then for each sub-structure, which represents a class of input graphs, we "unroll" the structure to create an equivalent FFNN for each node update operation of GNN, and then combine these FFNNs into a î€›nal FFNN representing the original GNN computation of the substructure. While inî€žuential substructure should contribute signiî€›cantly toward GNN prediction, additional nodes that are noninî€žuential can still aî€ect the î€›nal computation result of the GNN. To deal with this, we î€›nd conditions on which the rolled out FFNN on the substructure and the original GNN is equivalent to ensure our results. Finally, given the equivalent condition, we can now extend the existing DNN analyses to the rolled out FFNN of each substructure and obtain results for the original GNN. Existing veriî€›cation techniques for DNNs attempt to check that the DNN satisî€›es a user-supplied property (e.g., a certain range over Figure 2: GNN message passing and unrolling inputs results in a certain output). In contrast, property inference attempts to automatically infer such properties from the DNN. In both cases, the property to be veriî€›ed or inferred has the form pre =â‡’ post, wherepreis a condition over the inputs andpost is certain requirement on the outputs. Typically, we are interested in verifying or inferring theprefor some speciî€›cpost, e.g., we want to î€›nd input conditions that make the DNN classiî€›es an image as a "dog". For this work, we will consider GNN models for the standard problem of graph node classiî€›cation, which takes as input a graph ðºand gives a classiî€›cationð‘for each nodeð‘£ âˆˆ ðº. For such GNNs, thepreare input properties, which are logical predicates capturing common structure and featuresof the input graphs that lead to a certain classiî€›cation of the target node. Below we use a concrete example given in Fig. 2 to describe the steps of our approach, whose overview is given in Fig. 1. Unlike an FFNN, a GNN does not have a î€›xed structure: it can take arbitrary graphs and the behaviors of GNN itself also change depending on the structure of the inputs (e.g., the inî€žuence of a node depends on its neighbors). Thus, a direct, naÃ¯ve way of converting a GNN to an FFNN does not scale as it would result in a diî€erent FFNN for each diî€erent input graph and the FFNN can also be very large if the input graph is large. To solve this challenge, we will create FFNNs that support classes of input graphs. We leverage existing works in network graphs and GNNs to mine common and inî€žuential substructures from sample input graphs. These substructures are compact and summarize important behaviors of a GNN[9,15], and existing works such as GNNExplainer and PGExplainer [9,15] can extract substructures that are important to each GNN prediction (e.g., sets of edges, nodes, and features that are important to the output of target nodeâ€™s prediction). These substructures are crucial for the generation and analysis of FFNNs in subsequent tasks. For example, comparing to individual graphs these inî€žuential substructures are compact, which are crucial to achieving FFNNs with manageable sizes. Fig. 1 illustrates how we mine inî€žuential substructures (substructure miner). For a trained GNN model, we take in a set of input graphs that have the desired classiî€›cation and use an existing tool such as GNN explainer to extract subgraphs that are common from the input graphs and inî€žuential to the classiî€›cation result of the target node. In Figure 1, from the two input graphsðºandðº, GNNExplainer would extract three substructuresðº, ðº, ðºthat have been determined to contribute signiî€›cantly (inî€žuential) towards the target red-color node prediction while also being present in both graphs from the training dataset (frequented). Our approach thus focuses on analyzing GNNs over input graphs that we have knowledge about (through the extracted inî€žuential substructures). The better the sample of graph inputs we have, the larger and more accurate set of inî€žuential substructures we learnâ€”this leads to larger classes of supported graphs. Just as with most DNNs, sources of obtaining training samples vary, e.g., public benchmarks. If available, we can also reuse input graphs that were used to train the GNN models we are analyzing. Many existing DNNs and program analyses encode problems into logical formulae that can be reasoned about using constraint solving. Here, we encode the obtained graph substructures as logical predicatesðœŽ, so that we can leverage existing automating reasoning tools such as SAT and SMT solvers. An important use for these structure predicates is to check if an input graph contains the considered substructures. If it does, we are conî€›dent that our approach and result will hold; and if it does not, we can support it by adding it to our training data to learn about its inî€žuential substructures. These predicates are also a crucial part of the inferred properties that help explain the behaviors of the GNN to the user. To determine if an input graph satisî€›es a substructure, we check if the graph and the substructure, which is also a graph, is isomorphic. By adapting existing work such as CFL-match [1], we can apply logical reasoning over the obtained structure predicates to check if there exist a mapping from the querying substructure graph to some subgraph of input graph that would make both graphs isomorphic. Fig. 1 shows these steps. For each obtained substructure, we create a predicate capturing that structure by using standard graph isomorphic checking. As an example structure predicate ensuring present ofðºwhich has three nodesð‘¥(green),ð‘¥(blue) andð‘¦ (red) to be matched to input graphðº = (ð‘‰, ð¸)whereð‘‰is the set of nodes andð¸is the set of edges, can has the following form (note that we have omitted node-label checking for readability): Concerning the implementation side, this can be done with existing analysis tools by transforming from a graph problem to Ã¢a satisî€›ability problem (e.g., nodes represented as boolean variables and edges as logical connections among variables). Notice if we perform graph isomorphism checking on some input graph such as ðºin the Figure 1, we will see that it is isomorphic to the predicate of substructure ðºbecause they share the same substructure. Obviously, all trained input sets would be isomorphic to at least one of the structure predicates. After obtaining inî€žuential substructures and their corresponding substructural predicates, we are now ready to create an FFNN to represent the GNN model. As it turns out, it is actually straightforward to convert a GNN with a î€›xed substructure directly to an FFNN. We assume our GNN uses the the popular message passing process[4] adopted in most types of GNNs. This process works by updating the value of a node in the graph based on the information of its neighboring nodes. Then, to create an FFNN from a GNN with a set of substructures, we essentially create a FFNN to simulate how message passing is done on a substructure using the â€œunrollâ€ technique similar to one introduced in [7] for RNN unrolling. Finally, we combine all FFNNs to obtain a î€›nal FFNN representing the original GNN (that supports graph inputs isomorphic to the considered substructures). Figure 2 shows how message passing works on the substructure ðºobtained in Fig. 1. Again,ðºconsists of 3 nodesð‘¥, ð‘¥ andð‘¦, for illustration purposes, we use a GNN with 2-layer and the weightð‘Što represent the values of features of each node. For layer 1, the GNN contains three message passing processes labelled (1), (2), (3) that correspond to the three nodesð‘¦,ð‘¥, andð‘¥. The results of these message passing processes are updated as newly computed node features ofð‘¦, ð‘¥andð‘¥, which are used for next layer. For î€›nal layer 2, we only need to consider target nodeð‘¦â€™s message passing from the result of (1), (2) (3), followed by a simple linear transformation and we have a message processing process labeled (4) in Figure 2. Now, we unroll each message passing process in layerð‘–of the GNN into a correspondingð‘–-layer FFNN. For the three messagepassing processes in Layer 1 in Figure 2a, we obtain the three 1-layer FFNNs shown in Figure 2b and for the message passing process in layer 2 in Figure 2a, we have the 2-layer FFNN shown in Figure 2b (4). Finally, we connect these individual FFNNs to construct a î€›nal (large) FFNN as shown in Figure 2b to represent the original GNN. Using Existing FFNN analyses. We can apply existing analyses for FFNNs to our rolled out FFNN. For instance, we can apply the Prophecy tool [5] to infer properties for FFNNs. This work derives predicates over the inputs of an FFNN, which convex regions over inputs values, that map to a desired output classiî€›cation. We can also apply FFNN veriî€›cation tools such as Marabou (the successor of the popular Reluplex work [8]) to check if an inferred or usersupplied property is correct. For the running example in Figure 2, given some speciî€›c weights in Figure 2a, running Prophecy on the resulting FFNN can gives the following predicates representing a convex region over the inputs space that result in the desired classiî€›cation of the target node in the GNN. Here the inputð‘¥of the FFNN represents the featureð‘— of node ð‘¥of the GNN. ðœŽ= (ð‘¥+ ð‘¥âˆ’ ð‘¥âˆ’ ð‘¥> 0) Ideally, the mined inî€žuential substructures truly represent the behaviors of the considered GNN and the obtained FFNN is thus equivalent to the GNN. In practice, this does not happen as many nodes, especially those that are not part of the inî€žuential substructures but are neighbors with those in the substructure, can inî€žuence the î€›nal GNN classiî€›cation result. Thus, we want to analyze how these neighboring nodes can directly aî€ect those in the inî€žuential substructures and thus the î€›nal result. Our experiences with GNNs show that a node in a inî€žuential substructure is aî€ected by their "outside" neighbors (those that are not in the substructures) in two ways: the number of outside neighbors it has comparing to its total number of neighbors (connectivity ratio) and the mean contribution of the outside neighbors. Given this knowledge, we compute additional conditions over substructures to make them represent the GNN more accurately. To do this, we use decision trees to compute predicates over the two features representing connectivity and mean contribution. We split the input graphs (e.g., used in the beginning to obtain substructures) into those that are and are not isomorphic to the substructures. With respect to each inî€žuential substructure, we collect the supporting input graph set from the training dataset. Following this, for each input in the supporting graph set, we perform two predictions of target nodeð‘¦â€™s output: 1) using only the inî€žuential substructure and 2) using the full input graph. We collect statistics onconnectivity ratioandmean contributionto predict whether the output on target node ð‘¦ remains the same throughout two scenario. Using this set of training data, we can leverage decision tree to determine conditions over the two features representing connectivity ratio and mean contribution that lead to equivalent or non-equivalent classiî€›cation. Each paths in the tree represents an additional predicate that can help strengthen the substructures, allowing them to represent the GNN more accurately. For example, the decision tree in Fig. 3 produces several predicates such as which says that node 0 with connectivity ratio>0.2 , node 1 with connectivity ratio<=0.5, and the mean contribution of feature 0 in node 0â‰¥0.2 are likely needed as conjunction for the feature predicate on the substructure holds for all graphs. Thus, this approach allows us to obtain a setðœŽof predicates to strengthen the substructure predicates, ensuring they represent the GNN more accurately. Figure 3: Example of using decision tree to predict whether substructure computation will be equivalent to the input graphs At the end, our approach produces a propertyðœŽof a given GNN in form of whereðœŽis predicate capturing graph isomorphism (Section 2.2), ðœŽare input properties of the converted FFNN (Section 2.3), ðœŽis the additional constraints helping the FFNN more accurate to the original GNN (Section 2.4), and Q is the output property of some target nodeð‘¦(e.g.ð‘œ< ð‘œ). This means for an an input graph with target nodeð‘¦that is isomorphic to some of the mined substructure (satisî€›esðœŽ), has certain requirements about neighboring substructure nodes (satisî€›es ðœŽ), with node features lie within certain regions (satisî€›esðœŽ), then this graph will have the property ð‘„ on its target node. Currently, we only have worked out our idea on several small examples by hand. We are now moving to implementing these ideas to automate the process. After that, we will evaluate the approach with existing GNN benchmarks. We anticipate several challenges that would arise in this direction. First, for complex GNNs, the converted FFNNs might be too complex and contain non-trivial, e.g., nonlinear-arithmetic. These would give diî€œculties to standard FFNN veriî€›cation tools such as Reluplex. Second, we use sample inputs to mine substructures and feature predicates, and thus can obtain inaccurate results. While we might be able to obtain "groundtruths" or manually check results of small GNNs, we will not have an eî€ective way to formally verify our results on complex and real-world GNNs. Third, obtaining realistic benchmarks for GNNs might be more diî€œcult as they are not as abundent and well-studied as benchmarks of FFNNs. However, we can start with existing dataset from the literature such as those from [13] for autnomous driving and [4, 20] for drug interactions. Finally, there is always a chance that this entire approach does not work well in practice, e.g., it does not scale or becomes too inaccurate for converting complex GNNs. It might be that designing algorithms directly to solve GNN would give more beneî€›ts in the long run. However, as with any research problem, especially those with few existing attempts, we have to start somewhere, and converting it to something we do know how to do well seems to be a good place to start.
Recommender Systems (RSs) in real-world applications often deal with billions of user interactions daily. To capture the most recent trends eî€ectively, it is common to update the model incrementally using only the newly arrived data. However, this may impede the modelâ€™s ability to retain long-term information due to the potential overî€›tting and forgetting issues. To address this problem, we propose a novelAdaptiveSequentialModelGeneration (ASMG) framework, which generates a better serving model from a sequence of historical models via a meta generator. For the design of the meta generator, we propose to employ Gated Recurrent Units (GRUs) to leverage its ability to capture the long-term dependencies. We further introduce some novel strategies to apply together with the GRU meta generator, which not only improve its computational eî€œciency but also enable more accurate sequential modeling. By instantiating the model-agnostic framework on a general deep learning-based RS model, we demonstrate that our method achieves state-of-the-art performance on three public datasets and one industrial dataset. â€¢ Information systems â†’ Recommender systems;â€¢ Computing methodologies â†’ Lifelong machine learning. ACM Reference Format: Danni Peng, Sinno Jialin Pan, Jie Zhang, and Anxiang Zeng. 2021. Learning an Adaptive Meta Model-Generator for Incrementally Updating Recommender Systems. In Fifteenth ACM Conference on Recommender Systems (RecSys â€™21), September 27-October 1, 2021, Amsterdam, Netherlands. ACM, New York, NY, USA, 11 pages. https://doi.org/10.1145/3460231.3474239 Recommender Systems (RSs) serve to identify the products or services that could be of potential interest to users by leveraging personal interaction records and various contextual information. With the prevalence of deep learning in recent years, sophisticated deep models are also adopted in RSs owing to their outstanding performance. As the RS models become increasingly complex and cumbersome, how to update them eî€œciently and eî€ectively in a data-streaming environment (which is often the case in real-world applications) has emerged as a challenge [25, 29]. To capture the most recent interest drift of user and change in item popularity, it is important to periodically update the model as new data arrives. Various methods have been proposed to update conventional RS algorithms in the streaming setting [4,14,17,22, 23]. From the perspective of data utilization, the model can be updated using only the newly arrived data (termedincremental update) or using the most recentğ‘¤periods of data (termedbatch update), whereğ‘¤is the size of the sliding window [12,13,25]. In practice, incremental update is often preferred over batch update. Apart from the more eî€œcient training, incremental update can also result in better performance most of the time, as training exclusively with the most recent data can help capture the fast-changing trends and short-term user interests more accurately, which are highly valuable for the near future prediction [1, 6, 9]. However, there exists the problem of forgetting for incremental update, which limits the performance of models updated in this manner [5,12,24,30]. Since the model is only trained to î€›t the data from the current period, it is diî€œcult for it to retain and consolidate the long-term memory, as the past knowledge learned is constantly overwritten by the new knowledge representing a distinct distribution. In fact, the forgetting issue is not exclusive to RS incremental update. It generally exists when updating neural networks with data from a diî€erent distribution [10]. Continual learning is a î€›eld of study that speciî€›cally tackles this problem, which has developed eî€ective methods for applications in Computer Vision (CV) and Natural Language Processing (NLP). However, when it comes to RSs incremental update, directly adopting these methods may not lead to desirable outcomes. This is because the two problems have diî€erent ultimate goals: continual learning aims to perform well for the current task without sacriî€›cing performance on previous tasks, while incremental update of RSs only cares about the performance on future tasks [29]. Hence, the main focus of incremental update lies in how to eî€ectively transfer past knowledge especially useful for future predictions. To overcome the speciî€›c forgetting issue in RSs incremental update, two lines of research have been developed inspired by some of the methods in continual learning [13], namelysample-based approachandmodel-based approach. Despite the eî€ectiveness of both approaches, there exist some major limitations. For the sample-based approach, although the individual samples are carefully selected to be the â€˜informativeâ€™ ones, they can hardly represent the big picture of the overall distribution. To tackle this, the modelbased approach which considers transfer of knowledge between past and present models was recently proposed. However, a major limitation of the existing model-based methods is that, none of them explores the potential of the long-term sequential patterns exist in model evolution, which can be very useful information for generating a better model for future serving. Inspired by this, we propose a novelAdaptiveSequentialModel Generation (ASMG) framework for incrementally updating RSs, which encodes a sequence of historical models to generate a better up-to-date serving model via a meta generator. The meta generator is adaptively trained to optimize for the next period data to extract past knowledge that is specially useful for future serving. For the design of the meta generator, we propose to employ Gated Recurrent Units (GRUs) to leverage its ability to capture long-term dependencies. We also introduce some novel strategies to train the GRU meta generator, which not only improve the training efî€›ciency, but also enable better sequential modeling ability. More speciî€›cally, we propose to train the GRU meta generator concurrently at multiple steps on the truncated sequence by continuing on a previously learned hidden state. To demonstrate its eî€ectiveness, we instantiate the model-agnostic updating framework on a general deep learning-based Embedding&MLP model, and conduct extensive experiments compared with state-of-the-art updating methods. Our main contributions are summarized as follows: â€¢We propose an ASMG framework which generates a better model by encoding a sequence of historical models. â€¢We introduce a GRU-based meta generator design that is capable of capturing the sequential dependencies. We further develop some training strategies to improve its computational eî€œciency and sequential modeling ability. â€¢We demonstrate the eî€ectiveness of our method by conducting extensive experiments on three widely-used public datasets and one industrial production dataset from Lazada. Methods developed for continual learning generally fall under three categories: experience replay, regularization-based methods, and model fusion. Experience replay prevents forgetting by reusing past samples together with the new data to update the model [18]. Generative methods are later on developed to alleviate the burden of storing real data [21]. Regularization-based methods retain past knowledge by constraining the parameters update based on some measure of importance [10,28]. Some works also employ distillation techniques to regularize the update direction [16,26]. Model fusion supports continual learning of tasks by gradually incorporating sub-networks. Both expandable [19] and î€›xed-size network methods [11] are developed. Though these methods have shown promising results in CV and NLP, how to adapt them to incrementally update RS models is non-trivial, as they lack mechanism to explicitly optimize for the future performance. To overcome the speciî€›c forgetting problem in RSs incremental update, two lines of research have been developed in recent years, which are closely related to some of the methods in continual learning [13]. This line of works relies on reusing historical samples to preserve past memory, analogous to experience replay in continual learning. Most often, a reservoir is maintained to keep a random sample of history [5]. After that, heuristics are designed to select samples from the reservoir for model updating, prioritising recency [1,30] or the extent of being forgetten [8,15,24]. Sample-based approach can be seen as an intermediate between incremental update and training on full historical data, aiming to î€›nd a balance between short-term interest and long-term memory. However, an apparent limitation of this approach is that the individual samples, though carefully selected with some measure of informativeness, are insuî€œcient to represent the big picture of overall distribution. In contrast, the historical models learned from the historical data can be seen as a better summarization of the past knowledge. Hence, model-based approach which focuses on transferring knowledge between past and present models was later on developed. This approach aims to overcome forgetting by transferring knowledge between past and present models. Similar to the regularizationbased methods in continual learning, [25] incorporates a knowledge distillation loss to regularize the model update, using previous incremental model as the teacher model. [27] and [13] also employ the distillation techniques and speciî€›cally target at GNN-based and session-based RSs respectively. However, simply constraining the change in networks does not guarantee that the knowledge useful for future prediction is extracted. A recently proposed method termed Sequential Meta-Learning (SML) [29] achieves this by introducing a mechanism to explicitly optimize for the next period data. It devises a transfer module to combine the past and present models, which is adaptively trained in a sequential manner to optimize for future serving. However, the major limitation of both SML and the distillation methods is that they only consider transfer between models of two consecutive incremental periods, ignoring the long-term sequential patterns that may be highly valuable for generating a better model for future serving. Conventional incremental update of RS models involves restoring the last period model as initialization and updating it with the newly arrived data to obtain the most recent model. Formally, let ğ·denote the dataset collected from periodğ‘‡forğ‘¡ âˆˆ {1, 2, 3, ...}, whereby a period can be a certain length of time (e.g., a day, a week) or until a certain amount of data is collected. The modelÎ˜updated from Î˜is obtained by minimizing loss on ğ·: whereL(Î˜|ğ·, Î˜)is the loss onğ·withÎ˜as initialization (for recommendation tasks, the loss can be pointwise log loss or pairwise BPR loss). The initial modelÎ˜can be obtained by random initialization or pre-training with suî€œcient amount of historical data. Without any post-processing, the updated modelÎ˜is directly deployed to serve for periodğ‘‡, from whichğ·can be obtained for training the next period modelÎ˜. The overall procedure of conventional incremental update is illustrated in Figure 1(a). Although this updating method is widely adopted due to its efî€›ciency and eî€ectiveness, the model trained in this manner can easily overî€›t to the current data and forget past patterns learned. To address this issue, we propose anAdaptiveSequentialModel Generation (ASMG) framework to apply on a sequence of incrementally updated models. For the ASMG framework, instead of direct deployment of the updated model, we introduce a meta generator to take in a sequence of historical models (including the newly updated one), and generate a better model to be deployed for serving the next period. The input sequence of models are obtained from regular incremental update, which means that the model at each period is only trained on the data collected from that period. This allows us to obtain a sequence of models that are highly representative of the respective period. Mining the temporal trends exist in this sequence can have great potential in generating a better model for the next periodâ€™s serving. Formally, letMdenote the meta generator that takes in a sequence of models untilÎ˜, the output modelÎ˜used for serving ğ‘‡is obtained by: whereÎ˜is a sequence of models of lengthğ‘¡fromÎ˜toÎ˜. Note thatÎ˜is excluded from the input sequence, as it is obtained from random initialization or pre-training instead of regular incremental update. The desired properties of an ideal meta generator include 1) good capability of modeling the temporal dependencies exist in the sequence, and 2) stable performance in generating a good model for the next periodâ€™s serving. The î€›rst property is related to the speciî€›c network design of the meta generator, which will be discussed in details in the next section. The second property, on the other hand, can be achieved via proper optimization process of the meta generator. To generate model that is particularly good at serving the next period, we need to ensure that past knowledge that is specially useful for the next periodâ€™s serving is extracted. To achieve this, we propose to update the meta generator by adaptively optimizing the output model towards the next period data. More speciî€›cally, let ğœ”denote the parameters ofM, i.e.,M= M, the parameters ğœ”are updated from ğœ”by optimizing Î˜towards ğ·: whereL(Î˜|ğ·, ğœ”)is the loss onğ·withğœ”as initialization. The loss function here is the same as that in (1). To ensure that the meta generator is suî€œciently trained before it can be deployed for online model generation, we performğœperiods of meta generator warm-up training prior to the online deployment. During the online deployment phase, the meta generator will still need to be adaptively updated in order to keep up with the most recent sequential trends. The overall procedure of the ASMG framework is depicted in Figure 1(b) and described in Algorithm 1. There are many possible designs for the meta generator. In this work, we propose to employ Gated Recurrent Unit (GRUs) [3] to leverage its ability to capture the sequential patterns. For simplicity, we apply the GRU meta generator coordinate-wise on the base modelÎ˜. That is to say, for each individualğœƒ âˆˆ Î˜, we generate the output parameterğœƒby applying the GRU meta generator on a sequence of its historical values, independently of parameters Input: Sequence of historical datasets {ğ·}and incrementally updated models {Î˜} Output: Trained meta generator Mfor ğ‘¡ â‰¥ 2, and incrementally Oî€line Warm-up Training: Randomly initialize ğœ” for ğ‘¡ = 1 to ğœ do ğœ”â† arg minL ( M(Î˜) |ğ·, ğœ”) // update the meta generator end Online Deployment & Update: while ğ‘¡ â‰¥ ğœ + 1 do Generate output model Î˜= M(Î˜), deploy Î˜to serve for ğ‘‡and obtain ğ· Î˜â† arg minL (Î˜ |ğ·, Î˜) // update the base model ğœ”â† arg minL ( M(Î˜) |ğ·, ğœ”) // update the meta generator end at all the other coordinates. The î€›nal serving model is therefore Î˜= {ğœƒğ‘ }. More speciî€›cally, at each stepğ‘– âˆˆ {1, ..., ğ‘¡ }, the hidden stateâ„âˆˆ Ris computed from the last step hidden stateâ„âˆˆ R and ğœƒ âˆˆ R of the current step input model Î˜âˆˆ R: whereğ‘Ÿ, ğ‘§âˆˆ Rare gates that control how much of past and present information to be retained,ğ‘Š,ğ‘Š,ğ‘Šâˆˆ Rare learnable weights,ğœ (Â·)is the sigmoid function,[Â·, Â·]denotes concatenation, andâŠ™denotes element-wise multiplication. The initial hidden state â„is zero-initialized. The output parameterğœƒâˆˆ Rof the î€›nal serving modelÎ˜âˆˆ R at stepğ‘–is obtained from the respective hidden stateâ„via a linear transformation: whereğ‘Š âˆˆ Randğ‘ âˆˆ Rare also learnable parameters. All the learnable parameters are shared across ğ‘¡ steps. If we assign one unique GRU meta generator (i.e., unshared set of learnable parameters) at each coordinate in the base model, the space complexity of the GRU meta generator will beO(ğ‘›ğ‘‘)where ğ‘‘is the GRU hidden size andğ‘›is the base model parameter size. Note that the size of the GRU meta generator is unrelated to the sequence length. In this section, we introduce two training strategies speciî€›cally tailored to the GRU meta generator to further improve its training eî€œciency and sequential modeling ability. 3.4.1 Training GRU Meta Generator on Truncated Sequence. One main drawback of GRUs is that the computation time increases linearly with sequence length. Hence, applying GRU meta generator on the full sequence of historical models is not practical, as the sequence length will continuously increase as time goes by, i.e., the computational complexity isO(ğ‘¡ğ‘›ğ‘‘), linear in the current time stepğ‘¡. An alternative is simply to truncate the sequence and start training from an intermediate step with zero-initialized input hidden state. However, using a zero-initialized input hidden state inevitably discards earlier models and prevents the retention of longer-term information. To tackle this problem, we propose to train the GRU meta generator on truncated sequence by continuing on a previously learned hidden state. By doing so, we not only improve training eî€œciency with shorter sequence, but also preserve long-term memory by reusing a hidden state learned from the past. For consistency, we î€›x the sequence length atğ‘˜for some1 â‰¤ ğ‘˜ â‰¤ ğ‘¡for all training periods. Speciî€›cally, when trainingM, we take in a sequence ofğ‘˜most recent modelsÎ˜as inputs, and a learned hidden stateâ„ obtained from the training of the previous meta generatorMas the initial hidden state for the current training. Consistently applying this strategy at every training period endows a nice eî€ect that consolidates all the previous modelsÎ˜into hidden stateâ„. Formally, this strategy modiî€›es the way of generating output model in(2)toÎ˜= M(Î˜, â„). The overall optimization is as follows: ğœ”= arg minL(Î˜|ğ·, ğœ”) Here,Mis the GRU meta generator that maps many to one. This strategy is illustrated in Figure 2 from (a) to (b). 3.4.2 Training GRU Meta Generator at Multiple Steps Concurrently. To enable more accurate sequential modeling, we further propose a second strategy to perform concurrent training at multiple steps. The intuition behind is to enforce that the hidden states generated at diî€erent steps are on the right track and able to produce model that serves well for the respective next period. More specifically, when trainingM, instead of optimizing the last model Î˜towardsğ·only, we optimize all{Î˜}towards all {ğ·}concurrently. To take into account that the later data is less seen before and hence more informative, we assign greater weightğœ†to loss of the more recent data. Further incorporating this strategy results in the following optimization: = arg minğœ†L(M(Î˜, â„)|ğ·, ğœ”), whereğœ†is the weight for lossL= L(Î˜|ğ·, ğœ”), computed from a linear decay function, i.e.,ğœ†=forğ‘— âˆˆ {1, 2, ..., ğ‘˜ }. This strategy is illustrated in Figure 2 from (b) to (c). Note that for this strategy, we slightly violate the proposed ASMG framework by training the meta generator on data from multiple periods. However, we later on show that this strategy is able to further boost the performance and outperform all the existing model updating methods, including those that also involve Figure 2: Training of GRU meta generator under the ASMG framework for three consecutive periods (i.e., training of M and M). Transition from (a) to (b) illustrates the î€›rst strategy, which trains the GRU meta generator on truncated sequence (here we use sequence length ğ‘˜ = 3) by continuing on a previously learned hidden state. Transition from (b) to (c) illustrates the second strategy, which performs concurrent training by optimizing data at multiple steps, with greater weights assigned to the more recent data. ASMG-GRUsingle and ASMG-GRUmulti are depicted by (b) and (c) respectively. multiple periods of data. Furthermore, this strategy should be distinguished from batch update, as the the data from earlier periods are used to train the meta generator instead of the base model. The base modelÎ˜, as the inputs to meta generator, are still trained by regular incremental update. We term our proposed method that employs GRU meta generator under the ASMG framework asASMG-GRU. We further diî€erentiate the two strategies by naming the î€›rst one that trains on a single period of data asASMG-GRUsingle, and the second one that trains on multiple periods of data as ASMG-GRUmulti. The proposed ASMG-GRU is model-agnostic. To test its eî€ectiveness, we instantiate it on a general deep learning-based Embedding&MLP model, a network architecture that most of the ClickThrough Rate (CTR) prediction models developed in recent years are based on [2,7,20,31]. The model mainly comprises embedding layers that transform high-dimensional sparse features into low-dimensional dense vectors, and Multi-Layer Perceptron (MLP) layers that learn the interaction of the concatenated feature embeddings. More speciî€›cally, given userğ‘–withğ‘ƒcategorical features, the concatenated feature embedding ğ‘¢is obtained by: whereğ¸âˆˆ Rwithğ‘‘â‰ª ğ‘‘is the embedding matrix for categorical featureğ‘ âˆˆ {1, Â· Â· Â· , ğ‘ƒ}of user, andğ‘§âˆˆ Ris the one-hot or multi-hot vector for categorical feature ğ‘ of user ğ‘–. Similarly, for itemğ‘—withğ‘„categorical features, the concatenated feature embedding ğ‘£is obtained by: whereğ¸âˆˆ Rwithğ‘‘â‰ª ğ‘‘is the embedding matrix for categorical featureğ‘ âˆˆ {1, Â· Â· Â· , ğ‘„}of item, andğ‘§âˆˆ Ris the one-hot or multi-hot vector for categorical feature ğ‘ of item ğ‘—. The predicted preference of userğ‘–on itemğ‘—is then obtained by passing the concatenated feature embeddings through a two-layer MLP, followed by a sigmoid function to normalize the score: The parameters of the Embedding&MLP base modelÎ˜therefore include both the embedding matrices{E, E}, and the weights and biases ofMLP(Â·). For CTR prediction, we adopt log loss to update the base model Î˜ as described in (1): L(Î˜|ğ·) = âˆ’1|ğ·|log(^ğ‘¦) +log(1 âˆ’^ğ‘¦) whereğ·is obtained by randomly sampling 1 unobserved interaction for each observed interaction in ğ·. To apply the proposed ASMG-GRU, we assign one unique meta generator to each individual weight and bias parameter in the MLP layers. However, for the embedding layers of sparse ID features (i.e., user ID and item ID), the parameter size is large while the training samples for each ID are limited. Assigning one unique meta generator for each parameter in the embedding layers signiî€›cantly increases the complexity and can easily lead to overî€›tting. Hence, we assign one unique meta generator at each dimension of the embedding vector and share it across all IDs. Take for instance, for theğ‘-th user embedding matrixğ¸âˆˆ R, we assignğ‘‘ distinct meta generators along the î€›rst dimension, and share them acrossğ‘‘IDs along the second dimension. The space complexity of the GRU meta generators forğ¸will therefore be signiî€›cantly reduced from O (ğ‘‘ğ‘‘ğ‘‘) to O (ğ‘‘ğ‘‘), as ğ‘‘is often large. 4.1.1 Datasets. Experiments are conducted on three widely-used public datasets and one private industrial production dataset collected from Lazada mobile app. â€¢ Tmallcontains user-item interaction records from Tmall.com. We extract 31-day data from October 2014, splitting into 31 periods by treating each day as a period. We select the top 50,000 users with the most interactions and î€›lter out items with less than 20 interactions. In the end, the pre-processed dataset contains 3,047,101 observed interactions with 49,986 users and 43,571 items from 634 categories. â€¢ Sobazaaris also an e-commerce dataset that contains useritem interaction records from Sobazaar mobile app from September 2014 to December 2014. We split the 4-month data into 31 periods such that each period has equal amount of data. This results in around 4 days per period. In the end, the pre-processed dataset contains 842,660 observed interactions with 1,7126 users and 2,4785 items. â€¢ MovieLenscontains explicit user ratings for movies on a scale of 0 to 5. We use the largest 25M dataset and extract data from 2014 to 2018. We split the 5-year data into 31 periods based on equal amount of data, which gives around 2 months per period. For movie recommendations, it makes sense to have each period to span longer time (as compared to the ecommerce domain), as the userâ€™s taste in movies is more of a long-term interest and less time-sensitive. To make it suitable for our binary classiî€›cation base model, we follow [24] and label ratings above 3 as positive, and the rest as negative. In the end, the pre-processed dataset contains 6,840,091 samples (including both positive and negative samples) with 43,181 users and 51,142 movies from 20 genres. â€¢ Lazadais an industrial production dataset collected from Lazada mobile app, the largest e-commerce platform in Southeast Asia. Samples are constructed from the impression logs of users, with clicked records labeled as positive and unclicked records labeled as negative. A 31-day data from December 2020 is extracted and split into 31 periods by treating each day as a period. We randomly select 10,000 users for our experiments. In the end, the pre-processed dataset contains 6,659,828 samples (including both positive and negative samples) with 10,000 users and 43,878 items from 3,860 categories. For all datasets, we collect the most recent 30 positive feedbacks of each user to form the user sequence feature. 4.1.2 Baselines. We compare the following model updating methods applying on the same Embedding&MLP model. â€¢ Incremental Update (IU): This method updates the model incrementally using only the new data ğ·. â€¢ Batch Update (BU-w): This method updates the model using the most recentğ‘¤periods of data{ğ·, Â· Â· Â· , ğ·}. We experiment the window sizeğ‘¤for 3, 5, and 7 periods. Note that IU is equivalent to BU-1. â€¢ SPMF[24]: This method is a sample-based approach. It maintains a reservoir of historical samples, from which the samples with lower predicted ranks are selected to mix with the new datağ·for current model updating. We tune the reservoir size as a fraction of the total dataset size from 0.1 to 0.5. â€¢ IncCTR[25]: This method is a model-based approach that incorporates a knowledge distillation loss when training the current model withğ·. We implement the version that uses the previous incremental model as teacher model. We tune the weight assigned to the knowledge distillation loss from 0.1 to 0.5. â€¢ SML[29]: This method is another model-based approach that has recently achieved the state of the art. It employs a CNN-based transfer module to leverage the previous model while training the current model onğ·. The transfer of knowledge is only between models of two consecutive periods. SML is originally proposed to instantiate on Matrix Factorization (MF) base model. For a fairer comparison, we also implement this version and term itSML-MF. We tune the number of CNN î€›lters in{2, 5, 8, 10}, and the MLP hidden size in {10, 20, 40, 80}. â€¢ ASMG-Linear: To compare with the proposed GRU meta generator design under ASMG framework, we implement another î€›xed-length meta generator that linearly combinesÃ the sequence of models, i.e.,Î˜=ğ›¼Î˜, where ğ›¼is the weight assigned to model at periodğ‘–. We tune the sequence length ğ‘˜ from 1 to 6. â€¢ ASMG-GRU: This is our proposed method to employ the GRU meta generator under the ASMG framework. Incorporating the proposed training strategies, we compareASMGGRUsingleandASMG-GRUmultiagainst the above baselines. We tune the sequence lengthğ‘˜from 1 to 6, and the GRU hidden size in {4, 8, 12, 16}. For all the compared methods, we use Adam optimizer to update the trainable parameters (i.e., the base model, the meta generator under ASMG, and the transfer module under SML) and tune the learning rate in {1e-2, 1e-3, 1e-4}. We also tune the number of epochs for each update period in{1, 5, 10, 20}. The batch size is set to be 256 for the Sobazaar dataset and 1024 for other datasets. 4.1.3 Evaluation Protocols. All datasets are split into 31 periods. The î€›rst 10 periods are used to pre-trained an initial modelÎ˜. Model updating will be conducted for the remaining 20 periods. As mentioned earlier in section 3.2, we need to reserve some periods for warm-up training of the meta generator. For input sequence of lengthğ‘˜, the training of the meta generator can only start from period10+ğ‘˜, as we will need to î€›rst obtain a sequence of incrementally updated models of lengthğ‘˜from period11to10 + ğ‘˜. Hence, to allow for at least 5 periods of eî€ective warm-up training for a maximum sequence length ofğ‘˜ = 6in our experiments, we split the 20 periods into train/validation/test sets by10/3/7. Evaluation of the model updated at each test period is based on its prediction performance for the respective next period. The metrics used areAUC (Area Under ROC) andLogLoss(binary cross-entropy), which are good measurements of CTR prediction performance. We conduct 5 runs of model updating experiment for each compared method. Table 1 presents the overall performance for the compared methods, from which we have the following observations: â€¢BU methods withğ‘¤ â‰¥ 2are not comparable to IU in terms of serving for the next period, and the degradation increases for larger window size. This observation is consistent with [6,25], which have identiî€›ed that in non-stationary environment, batch update is inferior as compared to incremental update. This may be due to that the newly collected data can better represent the latest trends, which are highly related to the upcoming period. Expanding the window size aî€ects the recency of the training data, and hence will be less eî€ective in capturing the latest trends and fast-changing short-term user interests for the near future prediction. â€¢SPMF and IncCTR only improve over IU marginally. The former is a sample-based approach. The latter is a model-based approach but only utilizes the historical model indirectly via knowledge distillation. The fact that SML performs the best among all the baseline methods demonstrates that directly incorporating the previous model to derive the transfer patterns can be very eî€ective for generating a better current model. Moreover, the mechanism of SML to train the transfer module by optimizing towards the next period data helps extract knowledge that is particularly useful for future prediction. â€¢SML-MF is not comparable to other methods due to a different choice of base model. This justiî€›es our choice of a deep learning-based Embedding&MLP model which is more sophisticated in modeling complex feature interaction. Another beneî€›t of this base model of our choice is that it is general in the sense that many state-of-the-art RS models are developed from the same architectural paradigm. Being able to achieve success on this model implies that similar eî€ects may also be obtained for other deep learning models with similar architectures. â€¢Under the proposed ASMG framework, the improvement of ASMG-Linear over IU is minor, and it is sometimes outperformed by other baselines that do not make use of the historical models. This shows that choosing the right design for the meta generator is important, and a simple linear combination is not suitable/suî€œcient to model the sequential eî€ects. Also, having to drop the models outside of the sliding window limits its ability to accumulate longer-term information. â€¢Both ASMG-GRUsingle and ASMG-GRUmulti outperform all the baselines by a signiî€›cant margin of around 1% in AUC on all four datasets. Note that in the industry,1%increase in oî€Ÿine AUC is considered very signiî€›cant [7,31], and it is likely to translate to greater improvement in online CTR [2]. The strong results demonstrate the beneî€›ts of 1) directly incorporating the historical models and learning by optimizing towards the future (vs SPMF and IncCTR), 2) involving a longer sequence for more informative sequential mining (vs SML), and 3) employing the GRU-based meta generator which is a better design for sequential modeling (vs ASMG-Linear). Figure 3 shows the disentangled performance at each test period. We can see that both ASMG-GRUsingle and ASMG-GRUmulti consistently outperforms all the other methods at each test period. We purposely divide the periods of diî€erent datasets to have diî€erent time spans, so that we can test the robustness of our method to diî€erent model updating frequencies. Furthermore, we observe that there are drastic î€uctuations across periods, which indicates the dynamically changing sequential trends and validates the necessity to adaptively update the meta generator. In this section, we focus on ASMG-GRUmulti and test the eî€œcacy of its various designs in regard to the training of GRU meta generator. We compare ASMG-GRUmulti with the following variants, each disables a diî€erent design: â€¢ ASMG-GRUfull: This variant trains GRU meta generator on the full sequence of historical models. Illustration of this variant is shown in Appendix A Figure 5(a). â€¢ ASMG-GRUzero: This variant uses zero-initialized input hidden state for every periodâ€™s training instead of continuing on a previously learned hidden state. Illustration of this variant is shown in Appendix A Figure 5(b). â€¢ ASMG-GRUunif: This variant assigns uniform weights to the loss at diî€erent time steps. Illustration of this variant is the same as ASMG-GRUmulti, as the weights assigned are not explicitly shown in the diagram. â€¢ ASMG-GRUsingle: This variant performs single-step training at the last output model towards the newly collected data only. Illustration of this variant is shown in Figure 2(b). 4.3.1 Prediction Performance. Table 2 presents the prediction performance of four variants. Firstly, by comparing ASMG-GRUmulti with ASMG-GRUfull, we see that they yield comparable performance on MovieLens and Lazada datasets. This demonstrates that ASMG-GRUmulti is able to maintain the performance while achieving better eî€œciency by training on truncated sequence. We also observe that for Tmall and Sobazaar, the performance of ASMGGRUfull slightly drops as compared to ASMG-GRUmulti. This suggests that training on full-length sequence may not always be helpful, as the models at earlier stage may no longer be relevant. Secondly, we see that ASMG-GRUmulti clearly outperforms ASMGGRUzero. This shows that reusing the previously learned hidden state can help to preserve long-term information. Thirdly, ASMGGRUmulti also outperforms ASMG-GRUsingle, signifying the beneî€›t of multi-step concurrent training. Finally, ASMG-GRUmulti and ASMG-GRUunif give very similar performance, implying that a simple average of losses may be good enough. The weight decay strategy can be applied on a case-by-case basis. 4.3.2 Computational Eî€›iciency. To show that ASMG-GRUmulti serves to improve eî€œciency as compared to ASMG-GRUfull, we report the training time of GRU meta generator for both methods at the last test period (i.e., period 30) in Table 3. Experiments are conducted using NVIDIA GeForce GTX 1080 Ti with 11GB memory. Table 1: Average AUC & LogLoss over 7 test periods for four datasets. The results are reported in mean Â± std, compute d from 5 runs of model updating experiment. imp% indicates the relative improvement over the IU baseline. ASMG-GRUmulti 0.8289 Â± 0.0010 1.33% 0.8108 Â± 0.0017 1.38% 0.7564 Â± 0.0009 0.93% 0.6452 Â± 0.0005 1.11% ASMG-GRUmulti 0.5079 Â± 0.0018 5.63% 0.5309 Â± 0.0017 2.87% 0.5806 Â± 0.0011 1.11% 0.4299 Â± 0.0003 0.65% Figure 3: Prediction performance at each test period for four datasets, averaged over 5 runs of model updating experiment. Note that we omit BU and SML-MF here, as they are not comparable to the rest. For ASMG-GRUmulti, we set sequence lengthğ‘˜ = 3. For ASMGGRUfull, the sequence length increases to20at period 30. From the results, we see that the training time of ASMG-GRUfull is about 6.5âˆ¼7 times longer than that of ASMG-GRUmulti, consistent with the fact that the training time is linear in sequence length. The results empirically show that î€›xing the sequence length can greatly improve the computational eî€œciency, especially at the later training periods. We further conduct sensitivity analysis to investigate the eî€ects of two important factors, input sequence length and GRU hidden size, on the performance of ASMG-GRUmulti. Here we only present the analysis in AUC. For results in LogLoss, see Appendix B. 4.4.1 Eî€›ect of Input Sequence Length. To study the eî€ect of sequence length, we î€›x the hidden size at 4 and vary the sequence length from 1 to 6. Figure 4(a) shows the performance of ASMGGRUmulti w.r.t diî€erent sequence lengths. Firstly, we see that ASMG-GRUmulti is able to outperform all the baselines regardless of sequence length. Even forğ‘˜ = 1(i.e., applying ASMG-GRUmulti on the most recent model only), ASMG-GRUmulti is still slightly better than the strongest baseline SML, which is a model-based method that considers transfer between 2 periods (i.e., sequence length is 2). This can be attributed to the GRU design which better Table 2: Prediction performance (average AUC & LogLoss over 7 test periods) of ASMG-GRUmulti and its four variants. Table 3: Training time (in minutes) of GRU meta generator for the two metho ds at the last test period (i.e., period 30). Figure 4: Prediction performance (average AUC over 7 test periods) of ASMG-GRUmulti w.r.t (a) diî€erent input sequence lengths and (b) diî€erent GRU hidden sizes. models the sequential patterns, and also the strategy to continue from a previously learned hidden state, which helps retain longer memory. Secondly, we observe from the trends that as long as the sequence length is long enough for eî€ective training of GRUs (e.g., the minimum length should be 2 for Tmall and Lazada, 3 for Sobazaar, and 4 for MovieLens), the performance tends to stabilize at a satisfactory level. However, it is also noticed that further increasing the sequence length may degrade the performance (e.g., downward trend observed for Sobazaar after 4 and Lazada after 5). Longer sequence length is also not desirable due to the expensive computation. Therefore, the optimal range of sequence length should be from 3 to 5. 4.4.2 Eî€›ect of GRU Hidden Size. We also study the eî€ect of GRU hidden size on the performance of ASMG-GRUmulti. By î€›xing the sequence length at 3, we vary the hidden size in{4, 8, 12, 16}. The results are shown in Figure 4(b). We can see that the performance generally drops for more than 4 hidden units. For MovieLens, the degradation is so severe that the performance becomes worse than some of the baselines. This implies that overî€›tting may occur if the meta generator is over-parameterized by increasing the GRU hidden size. Furthermore, complex GRU meta generator is also expensive to train. Hence, we suggest that setting the hidden size to 4 is a good starting point. In this work, we study the model updating strategies for RSs, aiming to achieve recency with incremental update while still being able to prevent forgetting of past knowledge. To this end, we propose a novel ASMG framework, which produces a better serving model by encoding a sequence of incrementally updated models in the past via a meta generator. We introduce a meta generator design based on GRUs and further develop some strategies to improve its training eî€œciency and sequential modeling ability. By instantiating the proposed method on a general deep learning-based RS model, we demonstrate that it achieves the state of the art on four realworld datasets. In the future, we will investigate more eî€ective meta generator designs considering diî€erent base model architectures. This research is supported, in part, by Alibaba Group through Alibaba Innovative Research (AIR) Program and Alibaba-NTU Singapore Joint Research Institute (JRI), Nanyang Technological University, Singapore.
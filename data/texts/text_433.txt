Abstract: N-of-1 trials, single participant trials in which multiple treatments are sequentially randomized over the study period, can give direct estimates of individual-speciï¬c treatment eï¬€ects. Combining nof-1 trials gives extra information for estimating the population average treatment eï¬€ect compared with randomized controlled trials and increases precision for individual-speciï¬c treatment eï¬€ect estimates. In this paper, we present a procedure for designing n-of-1 trials. We formally deï¬ne the design components for determining the sample size of a series of n-of-1 trials, present models for analyzing these trials and use them to derive the sample size formula for estimating the population average treatment eï¬€ect and the standard error of the individual-speciï¬c treatment eï¬€ect estimates. We recommend ï¬rst ï¬nding the possible designs that will satisfy the power requirement for estimating the population average treatment eï¬€ect and then, if of interest, ï¬nalizing the design to also satisfy the standard error requirements for the individual-speciï¬c treatment eï¬€ect estimates. The procedure is implemented and illustrated in the paper and through a Shiny app. Keywords: Multilevel model; N-of-1 trial; Sample size; Shiny app; Treatment eï¬€ect estimation. In the presence of treatment eï¬€ect heterogeneity, population average treatment eï¬€ects from parallel-group randomized controlled trials may not accurately represent the risk to individual participants, making individualized treatment recommendations challenging (Kravitz et al., 2004; Greenï¬eld et al., 2007; Olsen et al., 2007). N-of-1 trials, single participant crossover trials in which multiple treatments are given in sequentially randomized treatment periods (Nikles and Mitchell, 2015), where we refer to a certain length of time where the same treatment is given as a treatment period, have been recommended as suitable designs for estimating individual-speciï¬c treatment eï¬€ects (Duan et al., 2013). Combining data from a series of n-of-1 trials oï¬€ers several advantages compared to using data from randomized controlled trials or from a single n-of-1 trial. Firstly, repeated measures on each participant provide more information for estimating population average treatment eï¬€ects compared to measuring each participant only once in most randomized controlled trials. Secondly, because crossover trials reduce the number of participants needed to achieve the pre-speciï¬ed power, a series of n-of-1 trials with multiple crossovers is even more eï¬ƒcient at estimating the population average treatment eï¬€ect. Lastly, the ability to borrow information from other participants increases the eï¬ƒciency for estimating individual-speciï¬c treatment eï¬€ects compared to using only data from a single n-of-1 trial (Zucker et al., 2010; Senn, 2019). Designing a series of n-of-1 trials that achieve the desired power for estimating the population average treatment eï¬€ect, and that, if of interest, satisfy the standard error requirements for the individual-speciï¬c treatment eï¬€ect estimates requires specifying the sequences with diï¬€erent orders of treatments assigned to the treatment periods, the number of participants (or trials; we can refer to trials as participants because n-of-1 trials are single participant trials and we will use â€œparticipantsâ€ in later development) assigned to each sequence, and the number of measurements in each period. Previous work on estimating sample sizes for n-of-1 trials has been limited. Johannessen and Fosstvedt (1991) derived the power for estimating an individual-speciï¬c treatment eï¬€ect using a single n-of-1 trial. Senn (2019) presented sample size formulae for estimating the population average treatment eï¬€ect and variances of individual-speciï¬c treatment eï¬€ect estimates when combining multiple n-of-1 trials. Both approach assumed speciï¬c orders of treatments assigned to treatment periods in the sequences, one measurement in each period, and independent measurements on each participant. In this paper, we present methods for designing a series of n-of-1 trials. Section 2 deï¬nes the design components for determining the sample size of a series of n-of-1 trials. Section 3 presents models for estimating the population average treatment eï¬€ect and the individual-speciï¬c treatment eï¬€ects. Section 4 and 5 derive the sample size formula for estimating the population average treatment eï¬€ect and the standard error of the individual-speciï¬c treatment eï¬€ect estimates, respectively. Section 6 provides details about ï¬nding the possible combinations of the design components using the derived formulae. We implement and illustrate the procedure in Section 7 and in a Shiny app described in Section 8. Section 9 summarizes our ï¬ndings and points to some future extensions. Let Y be the outcome and let A be the treatment assignment. Figure 1 presents a schematic for the design of a series of n-of-1 trials where the outcome Y is measured repeatedly at times to which treatments are assigned. Let i, i = 1, . . . , I, index the sequences with diï¬€erent orders of treatments assigned to treatment periods; let j, j = 1, . . . , J index the K kth treatment period for participant j assigned to sequence i. Therefore, Y on the outcome in the kth treatment period for participant j assigned to sequence i with corresponding treatment assignment A where treatments are assigned to a number of treatment periods in which a number of measurements are taken. The design components consist of: 1) the sequences with diï¬€erent orders of treatments assigned to periods in the sequences, which in turn determines the number of sequences I and the number of treatment periods in each sequence K of measurements in each period L I and K We make the following assumptions in our derivations. We assume that there are two treatments in the series of n-of-1 trials and refer to the two treatments as intervention and reference treatment; therefore, let treatment assignment A be an indicator for being assigned to the intervention of interest, taking on value of 1 if assigned to the intervention and 0 if assigned to the reference treatment. We assume that the outcome is continuous. The participants are independent and the repeated measurements on each participant, indexed by k and l, can be correlated. There is no underlying trend in the outcome or carryover eï¬€ects from one treatment to the other throughout the trials. We now describe the models for estimating treatment eï¬€ects using n-of-1 trials and start by the naive estimates for estimating the individual-speciï¬c treatment eï¬€ects, which only use the data from a single treatment periods in sequence i; let l, l = 1, . . . , L, index the Lmeasurements in the because a diï¬€erent number of treatment periods leads to a diï¬€erent sequence. Figure 1: Indices for measurements in a series of n-of-1 trials. A is the treatment assignment; we present the scenario where there are two treatments in the trials and A is an indicator for being assigned to the intervention of interest. i, j, k and l are used to index the sequences in trials, participants assigned to each sequence, treatment periods in each sequence and measurements in each treatment period, respectively. in sequence i and the number of measurements in the kth treatment period of participant j assigned to sequence i, respectively. participant for estimation, where m, the intercept, is the mean of the responses when given the reference treatment, Î´, the slope, is the diï¬€erence between the mean responses of the intervention and reference treatments, and î€ error. The estimate for Î´ gives the naive estimate for the individual-speciï¬c treatment eï¬€ect. We specify the variance matrix for the residual error vector to account for the correlation among the repeated measurements on a single participant. Using data from a series of n-of-1 trials, we can model the intercepts and the slopes for each participant with some structure to estimate the population average treatment eï¬€ect, The intercept Âµ pooling (i.e., ï¬xed for each participant), 2) partial pooling (i.e., random from a common distribution), or ğ‘– = 1:â‹¯ and Lare the number of participants assigned to sequence i, the number of treatment periods 3) complete pooling (i.e., common across all participants). We usually do not ï¬t the models with complete pooling of the intercepts because they make the strong assumption that the means of the responses on the reference treatment across the participants are the same, which usually do not hold; we also do not use the models with no pooling of the slopes for estimating the population average treatment eï¬€ect because they do not give the estimate directly, but if we use the model with no pooling of both intercepts and slopes, we will have the models for each participant giving the naive estimates for the individual-speciï¬c treatment eï¬€ects. Therefore, four diï¬€erent models span the realm of possibilities for estimating the population average treatment eï¬€ect, where the intercepts can either be ï¬xed or random and the slopes can either be random or common. The estimate for the common slope in the common slope models or for the average of the random slopes in the random-slope models estimates the population average treatment eï¬€ect. Random slopes are more commonly used in order to allow for heterogeneous treatment eï¬€ects across participants. They also suggest the shrunken estimates for the individual-speciï¬c treatment eï¬€ects by borrowing information from other participants in the series of trials. Assuming a common slope implies that the individual-speciï¬c treatment eï¬€ects are the same in all trials (Jackson et al., 2018). When the number of measurements for each trial is small, one may choose to model the population average treatment eï¬€ect using a common slope for more stable estimation. While it is common to assume random slopes, assuming random intercepts is more controversial. Some recommend ï¬xed intercepts so that estimation of the intercepts does not bias the estimation of the population average treatment eï¬€ect or of the shrunken estimates for the individual-speciï¬c treatment eï¬€ects. Others have produced simulations showing that the use of ï¬xed intercepts may bias downward the maximum likelihood estimate of the variance for the random slopes (Jackson et al., 2018). Random intercepts may also be helpful in cases where the information per trial is weak and ï¬xed intercepts are poorly estimated (e.g., cases where there are a small number of measurements per period). We refer readers to previous studies for details on the use of random or common slopes and the use of ï¬xed or random intercepts (Legha et al., 2018; Riley et al., 2020; White et al., 2019) and will focus on the derivations using all four possible models. In Model (2), participants are assumed to be independent, but repeated measurements on each participant may be correlated. We specify the variance matrix of the residual error vector for each participant to account for the correlation. A general model incorporating ï¬xed or random intercepts, random or common slopes, and a ï¬‚exible residual error structure on each independent participant is the general linear mixed model Here, Y to sequence i, Î¸ and b matrices for ï¬xed and random eï¬€ects, respectively, where i = 1, . . . , I and j = 1, . . . J matrix for between-individual errors and Î£ Speciï¬cations of Î£ measurements on each participant. The illustrations in Section 7 and the Shiny app described in Section 8 implemented commonly-used variance matrices with homogeneous residual errors and independent, exchangeable and ï¬rst order autoregressive (AR-1) correlation structures. Table 1 summarizes the elements in Model (3) for the four possible models that combine ï¬xed or random intercepts with random or common slopes. We denote the ï¬xed and random intercepts as m respectively, and the common and random slopes as Î´ and Î´ + Î³ random components for the random intercepts and slopes, respectively. The standard error for the generalized least squares estimator of the population average treatment eï¬€ect (Laird and Ware, 1982), where C or the variance for the treatment eï¬€ect estimate from the corresponding variance matrix; Î£ matrix for the outcome vector Y and î€are the outcome and residual error vectors of lengthPLfor participant j assigned is the contrast matrix that pulls oï¬€ the coeï¬ƒcient for treatment eï¬€ect from the ï¬xed eï¬€ects vector For a given pre-speciï¬ed type I error Î±, a minimal clinically important treatment eï¬€ect âˆ†, and variance matrices for the between-individual errors when applicable, D, and for the within-individual errors, Î£ we can achieve power of at least 1 âˆ’ Î² for estimating the population average treatment eï¬€ect by ï¬nding the design components for a series of n-of-1 trials (i.e., the sequences, J condition, where Î¦(Â·) and Z normal distribution, respectively. The ï¬rst term on the right hand side is small and is commonly ignored in practice. The model we propose expands upon that of Senn (2019) in deriving sample sizes for n-of-1 trials in several ways. First, Senn (2019) assumed intervention and reference treatments are randomized to each pair of consecutive treatment periods and that limits the sequences to which participants can be assigned. Second, he worked with the diï¬€erences between the outcomes in each pair of consecutive treatment periods where the outcome on each treatment was measured once. Third, he assumed no correlation among the repeated measurements on each participant. In our formulation, we allow more ï¬‚exible sequences with diï¬€erent orders of treatments assigned to the treatment periods, work with outcome measurements directly so the number of measurements in each period can also vary, and allow correlation among the repeated measurements on each participant. We derive the standard error of the individual-speciï¬c treatment eï¬€ect estimates in this section. Section 5.1 and 5.2 present the standard error of naive and shrunken estimates respectively. To specify the heterogeneous residual error variance and correlation among the repeated measurements on the participant of interest, we write Model (1) in vector notation for participant j iof interest, for whom we will derive the standard error of the naive estimate for the individual-speciï¬c treatment eï¬€ect, Here, Y to the treatment periods and Î¸ variance and correlation among the repeated measurements on the participant of interest. The standard error of the resulting naive estimate for the individual-speciï¬c treatment eï¬€ect, where C The naive estimates have limitations which show the advantage of the shrunken estimates. At least two treatments are required to estimate the treatment eï¬€ect and standard error using the data from a single participant. Additionally, estimating Î£ uncertainty (Senn, 2019). Model (2) suggests the shrunken estimate for the individual-speciï¬c treatment eï¬€ect for a given participant jassigned to sequence i and î€are the outcome and the residual error vectors, respectively, of lengthPL, is the design matrix with one column for intercept and the other for treatment indicators corresponding = (0, 1). accounts for the additional variation in random treatment eï¬€ects (Laird and Ware, 1982), is Var( where C with random intercepts (i.e., Random-Random in Table 1); the remaining terms are as deï¬ned in Table 1. The square root of the variance gives the standard error for the shrunken estimate. We recommend that practitioners take the following two steps when designing n-of-1 trials. Firstly, use the sample size formula for estimating the population average treatment eï¬€ect to ï¬nd the possible combinations of the design components that achieve the pre-speciï¬ed power requirement; secondly, if they are further interested in estimating the individual-speciï¬c treatment eï¬€ects, they will ï¬nalize the design by picking the combinations of the design components that also satisfy the standard error requirements for the individualspeciï¬c treatment eï¬€ect estimates. Illustrations in Section 7 and the Shiny app described in Section 8 will follow these two steps. In this section, we discuss the ways to ï¬nd the possible combinations of the design components using the formulae in Section 4 and 5. Among the design components, the sequences with diï¬€erent orders of treatments assigned to periods in the sequences, which in turn determines the number of sequences I and the number of treatment periods in each sequence K each treatment period L the sequences in the series of trials. Sequences can be speciï¬ed in two general ways, manually or by randomization. Manual determination usually pre-speciï¬es sequences for a speciï¬c purpose. For example, one might wish to start with a placebo, followed by an intervention and then alternate these two treatments a certain number of times. Or one might constrain the number of times the same treatment could be given consecutively when choosing sequences. We can also follow randomization schemes to determine the sequences. Randomization schemes include is 1 for the model with ï¬xed intercepts (i.e., Fixed-Random in Table 1) and is (0, 1) for the model , the number of participants assigned to each sequence J, and the number of measurements in but are not limited to: 1) alternating sequences, where the two treatments alternate with the ï¬rst period assigned at random, 2) pairwise randomization, randomly allocating the order of the two treatments in each consecutive pair of treatment periods, where we refer to the consecutive pairs of treatment periods as blocks, 3) restricted randomization, randomly assigning treatments in the sequence with the restriction that each treatment is assigned to the same number of periods, or 4) unrestricted randomization, completely randomizing treatments to treatment periods in the sequence (Johannessen and Fosstvedt, 1991). If the number of treatment periods in the sequences are the same (i.e., K derive the number of sequences I from the number of treatment periods K in each sequence following the randomization schemes (Table 2). Except under unrestricted randomization, each treatment is generally assigned to the same number of treatment periods in each sequence so all the sequences in a two treatment design will have an even number of treatment periods. Here, we include odd number of treatment periods for completeness. For odd number of treatment periods in each sequence: 1) under pairwise randomization, we randomly allocate the order of the two treatments in each consecutive pair of periods in the ï¬rst K âˆ’ 1 periods and randomly assign a treatment to the last period; 2) under restricted randomization, we randomly assign treatments with the restriction that there is only one period diï¬€erence between the number of periods assigned with the two treatments, regardless of the direction. Table 2: The number of sequences I under diï¬€erent randomization schemes given the number of treatment periods K in the sequence. â€Odd Kâ€ and â€Even Kâ€ refer to scenarios where there are odd and even number of treatment periods in the sequences respectively. When there are odd number of periods in each sequence: 1) under pairwise randomization, we randomly allocate the order of the two treatments in each consecutive pair of crossover periods in the ï¬rst K âˆ’ 1 periods and randomly assign a treatment to the last period; 2) under restricted randomization, we randomly assign treatments with the restriction that there is only one period diï¬€erence between the number of periods assigned with the two treatments, regardless of the direction. We will be able to determine the number of sequences I and the number of treatment periods K quences are speciï¬ed manually and the relationship between I and K when following randomization schemes for designs with the same number of periods across sequences. The next step is to determine the number of participants assigned to each sequence J We focus on balanced designs in which the number of participants assigned to each sequence, J of treatment periods in each sequence, K are the same so that J numbers of treatment periods in the sequences, diï¬€erent numbers of participants assigned to the sequences, or diï¬€erent numbers of measurements in the treatment periods are much more complex and have more moving parts making optimization diï¬ƒcult. Furthermore, if balance is not desired, the nature of the imbalance is often speciï¬ed. It will be possible to ï¬x one or more of the design components and solve a constrained optimization problem. Because both the number of participants, IJ and the number of repeated measurements on each participant, KL, aï¬€ect the cost and practicality of the series of trials (Senn, 2002), determining J and L once I and K are determined trades oï¬€ between the number of participants and the number of repeated measurements per participant. We can therefore ï¬x either KL or IJ and then ï¬nd the other. Speciï¬cally, if we choose to ï¬rst ï¬x KL, I and K are determined when investigators specify sequences manually, and L will be ï¬xed because K is determined; when following randomization schemes we ï¬nd the possible combinations of K and L that lead to the ï¬xed product and I will be determined by K following the relationship in Table 2. We will then be able to calculate the possible values for the number of participants assigned to each sequence, J, using Equation (5) in both scenarios. Alternatively, if we choose to ï¬rst ï¬x IJ, following a similar procedure, we will also be able to calculate the possible values for the last element in this case, the number of measurements in each treatment period, L. These calculations ï¬nd the possible combinations of the design components that satisfy the power requirement for estimating the population average treatment eï¬€ect. One can then ï¬nalize the design using Equations (6) or (7) to calculate the standard errors of the individualspeciï¬c treatment eï¬€ect estimates if these are of interest and choose the designs that also achieves the required precision. To illustrate the trade-oï¬€s between the number of participants and the number of measurements per participant, we consider a balanced design with pairwise randomization, probably the most common type of n-of-1 design. In balanced designs, the dimensions of within-individual error variance matrices, Î£ the same across participants. We assume that the variance matrices do not vary by participants and equal to Î£ structure with a correlation coeï¬ƒcient of 0.4. We set a minimal clinically important treatment eï¬€ect of . Additionally, the residual errors are homogeneous with a variance of 4 and have an AR-1 correlation âˆ† = 1, Type I error rate of Î± = 0.05 and Type II error rate of Î² = 0.2. When applicable in the model, the variance of the random intercepts (Ïƒ random intercepts and the random slopes (Ïƒ random slopes is 0.5). Figure 2 shows the change in the average required number of measurements across a series of n-of-1 trials (IJKL) as a function of the number of measurements per participant (KL, left) and the number of participants (IJ, right) for optimized designs when ï¬xed-intercept models are used for estimating the population average treatment eï¬€ect. Optimized designs refer to designs that achieve criteria with the smallest possible value of the last element with all the other elements in I, J, K and L ï¬xed. For example, if given the number of sequences I, the number of participants assigned to each sequence J, and the number of treatment periods in each sequence K, a design with L â‰¥ 5 measurements in each treatment period will achieve the pre-speciï¬ed power, the design with L = 5 measurements in each treatment period will be the optimized design and will be presented. Analogous optimization applies if I, J or K is the last component. The shaded area around the lines represent the range of the required number of measurements across trials from diï¬€erent combinations of K and L (left) and of I and J (right) that lead to the same product and the dots on the lines represent the average if there are multiple combinations. As Appendix S.2.1 shows that the form of intercepts has almost no eï¬€ect on the optimized designs for estimating the population average treatment eï¬€ect, we show results from models with ï¬xed intercepts and by the form of slopes. Legha et al. (2018) also reported that using restricted maximum likelihood to estimate the population average treatment eï¬€ect, which gives unbiased estimates of the variances compared with our assumed known variances, the coverage for the eï¬€ect estimate with ï¬xed or random intercepts are very similar for continuous outcomes. In general, the required number of measurements across a series of n-of-1 trials is larger when we use the average of random slopes to estimate the population average treatment eï¬€ect compared to when using a common slope for estimation because the random slope model contains an extra source of variability from the between-individual variance. Additionally, the required number of measurements across trials stays stable with increasing number of measurements per participant when a common slope is used for estimation, while that increases when we allow random eï¬€ects around the slope; the required number of measurements across trials decreases with increasing number of participants for models with either form of slopes and the decreasing rate is faster when the random-slope model is used for estimation, which leads to the decreasing discrepancy between the required number of measurements across trials for the common- and random-slope model with more participants in Figure 2: Average required number of measurements across a series of n-of-1 trials versus number of measurements per participant (KL, left) and number of participants (IJ, right) for optimized designs when ï¬xed-intercept models are used for estimating the population average treatment eï¬€ect. â€œCommon Slopeâ€ and â€œRandom Slopesâ€ refer to â€œFixed-Commonâ€ and â€œFixed-Randomâ€ models in Table 1, respectively. Number of measurements per participantNumber of participants trials. These results are consistent with those in Senn (2019). There, in a special case of our model described earlier (trials with independent repeated measurements on each participant, one measurement per treatment period and the same number of periods for the two treatments in the sequence), the required number of measurements across trials varied little with the number of measurements per participant for the common eï¬€ect approach but increased for the random-eï¬€ect approach. The discrepancy between the required number of measurements per participant for the two approaches also decreased with more participants in trials. Figure 3 shows the standard errors of the naive and shrunken estimates for individual-speciï¬c treatment eï¬€ects versus the number of measurements per participant given the number of participants (ï¬xed at 32, left) and versus the number of treatment periods in the sequence further given the number of measurements per participant (ï¬xed at 24, right) for all possible designs that satisfy the power requirement for estimating population average treatment eï¬€ect. The shaded areas around the lines represent the range of standard errors from diï¬€erent combinations of K and L that lead to the same product (left) and from trials with the same number of treatment periods but with diï¬€erent orders of treatments assigned to the periods (right) and the dots on the lines represent the average if there are multiple combinations. Note that all possible designs for the series of n-of-1 trials are plotted in the ï¬gure because as described in Section 6 in practice, after using Figure 2 to ï¬nd designs that satisfy the power requirement for estimating the population average treatment eï¬€ect, we want to further use Figure 3 to ï¬nalize the design by picking from all the possible designs that satisfy both the power requirement for estimating population average treatment eï¬€ect and the standard error requirement for estimating the individual-speciï¬c treatment eï¬€ect. For example, if the required total number of measurements is reasonable when we recruit 32 participants in a series of n-of-1 trials in Figure 2 and we require the standard error of the shrunken estimates with ï¬xed intercepts for individual-speciï¬c treatment eï¬€ects to be lower than 1, all the designs on the â€œShrunken Estimates-Fixed Interceptsâ€ curve in Figure 3 will satisfy the requirement. Additionally, if we are able to measure the outcome 24 times on each participant, Figure 3 (right) gives all the possible designs. A speciï¬c design can be a series of trials with I = 4 possible sequences, J = 8 participants assigned to each sequence, K = 4 treatment periods per sequence, and L = 6 measurements per treatment period. Detailed information for all the possible designs is given in the Shiny app (part (e) in Figure 4). As expected, the results in Figure 3 show the advantage of shrunken estimates over naive estimates for estimating individual-speciï¬c treatment eï¬€ect. Given ï¬xed number of participants, the standard error of naive estimates is larger than that of shrunken estimates. The diï¬€erence decreases with increasing number of measurements per participant, but even then the standard errors for naive estimates are larger. Naive Figure 3: Standard error of naive and shrunken estimates for individual-speciï¬c treatment eï¬€ect versus number of measurements per participant given total number of participants across trials (ï¬xed at 32, left) and versus number of treatment periods per sequence further given number of measurements per participant (ï¬xed at 24, right) for all possible designs that satisfy the power requirement for estimating population average treatment eï¬€ect. â€œNaive Estimatesâ€, â€œShrunken Estimates-Fixed Interceptsâ€ and â€œShrunken EstimatesRandom Interceptsâ€ refer to the standard error of naive estimates, shrunken estimates in the ï¬xed- and random-intercept model, respectively. estimates beneï¬t more from larger number of treatment periods in the sequence when we further ï¬x the number of measurements on each participant, with a larger drop in standard error when we increase the number of treatment periods in the sequence compared to shrunken estimates. We also found in Figure 3 that the standard error of the shrunken estimates in the random-intercept model is slightly smaller than that in the ï¬xed-intercept model. To evaluate the sensitivity of the results to the varying parameters, Appendix S.2 includes the following additional illustrations: â€¢ Appendix S.2.2 presents results where we use alternative values for the type I and II errors. The â€¢ Appendix S.2.3 presents results with alternative parameterizations for the residual error variance ma- â€¢ Appendix S.2.4 presents results with alternative parameterizations for the random-eï¬€ect variance maaverage required number of measurements across trials increases with smaller type I and II errors; the rate of increase is higher if 1) we want to reduce smaller type I and II errors, 2) the number of measurements per participant is larger, and 3) the number of participants in trials is smaller. trix. We show results assuming 1) independent and exchangeable correlation structure, and diï¬€erent values for 2) the homogeneous residual error variance and 3) residual correlation coeï¬ƒcient under ï¬rst order autoregressive correlation structure. Trials with exchangeable correlation structure require the fewest measurements across trials, followed by independent correlation structure. Under ï¬rst order autoregressive correlation structure, the required number of measurements across trials 1) is similar to that under exchangeable correlation structure when the number of measurements per participant is small and the correlation coeï¬ƒcient is large, 2) becomes larger than that under independent correlation structure when the number of measurements per participant is large and the correlation coeï¬ƒcient is small, and 3) increases linearly with homogeneous variance and the rate of increase is higher when the number of measurements per participant is larger and when the number of participants in trials is smaller. trix. Variance of random intercepts and correlation between random intercepts and slopes do not aï¬€ect the optimized designs that satisfy the power requirement. Holding the number of measurements per participant the same, the average required number of measurements across trials increases linearly with the variance of random slopes; the rate of increase is larger when the number of measurements per participant is larger. Holding the number of participants the same, the average required number of measurements across trials increases more at larger values for the variance of random slopes. â€¢ Appendix S.2.5 presents results with alternative minimal clinically important treatment eï¬€ects. The We implemented our methods in a Shiny app to allow investigators to design n-of-1 trials interactively without requiring programming knowledge or familiarity with a speciï¬c software. The Shiny app is available at http://jiabeiyang.shinyapps.io/SampleSizeNof1/. Figure 4 presents the layout of the Shiny app, where we replicated Figure 2 (right) and 3 in Section 7. In Figure 4, part (a) shows the input panel of the app, where investigators are allowed to specify the parameters for designing the series of n-of-1 trials. Part (b)-(e) present information for the possible designs that will satisfy the power and standard error requirements speciï¬ed by the investigators. Part (b) presents the speciï¬ed parameters in the input panel and how the average required number of measurements across trials changes as a function of the number of participants for optimized designs (Figure 2, right). Part (c) and (d) show the detailed design information for optimized designs and the standard errors of the individual-speciï¬c treatment eï¬€ect estimates for all possible designs that satisfy the power requirement (Figure 3), respectively, when one ï¬xes the number of participants across trials by clicking on a speciï¬c point in the ï¬gure in part (b). Part (e) shows the detailed information for all possible designs that satisfy the power and standard error requirements when one further ï¬xes the number of measurements per participant by clicking on a point in the ï¬gure in part (d). If investigators want to know how the average required number of measurements across trials changes as a function of the number of measurements per participant (Figure 2, left), they can choose â€œTotal # of measurements vs. # of measurements per participantâ€ under â€Design optionâ€ in the input panel. The output in part (d) of the Shiny app will be replaced accordingly by presenting the standard errors versus the number of participants in the trials given the number of measurements per participant. The Shiny app implements both alternating sequences and pairwise randomization and also allows the user to upload manually speciï¬ed sequences through â€œPossible sequencesâ€-â€œUser-speciï¬ed sequencesâ€ in the input panel. Because the number of possible sequences under restricted and unrestricted randomization becomes large as the number of treatment periods in the sequences increases (Table 2) and many sequences may be required number of measurements across trials increases with smaller minimal clinically important treatment eï¬€ect; the rate of increase is higher if 1) we want to reduce a smaller minimal clinically important treatment eï¬€ect, 2) the number of measurements per participant is larger, and 3) the number of participants in trials is smaller. Figure 4: Screenshot of Shiny app. Part (a) allows investigators to specify parameters for designing the series of n-of-1 trials; part (b)-(e) present the possible designs that satisfy the power and standard error requirements speciï¬ed by the investigators. impractical if the same treatment is given in too many consecutive treatment periods, users can complete calculations for these two randomization schemes by picking speciï¬c sequences of interest and uploading them through â€œUser-speciï¬ed sequencesâ€. Additionally, we provide an option to only optimize designs over the scale of the y-axis in part (b) of the Shiny app. Because of the current optimization, even if we allow large number of participants in the trials, the maximum number of participants presented in part (b) of the Shiny app will be small because designs with more participants are not optimized using our deï¬nition of optimized designs. Therefore, this option will present all the possible designs within the speciï¬ed range for the x-axis, only optimized on the scale of the y-axis. Finally, if investigators are not interested in estimating the individual-speciï¬c treatment eï¬€ects, they can clear â€œCalculate standard error for individual-speciï¬c treatment eï¬€ect estimatesâ€ and only part (b) and (c) will be displayed in the output. We present a procedure for calculating the sample size for n-of-1 trials. We formally deï¬ne the design components for determining the sample size of a series of n-of-1 trials which include the sequences with diï¬€erent orders of treatments assigned to periods in the sequences, the number of participants assigned to each sequence, and the number of measurements in each treatment period. We present models for analyzing n-of-1 trials and use them to derive the required sample size for estimating population average treatment eï¬€ect and the standard error of individual-speciï¬c treatment eï¬€ect estimates. We recommend that investigators ï¬rst use the sample size formula to ï¬nd the possible combinations of the design components that will satisfy the power requirement for estimating the population average treatment eï¬€ect, and, if of interest, use the standard error formulae to pick the combinations of design components that will also satisfy the standard error requirements for the individual-speciï¬c treatment eï¬€ect estimates. We implement and illustrate the procedure in the paper and through a Shiny app. Several directions of future research are practically useful. First, the current derivations assume that the variance components, either for residual errors or for random eï¬€ects, are known or estimated with adequate precision. Taking into account the fact that the variance components are estimated will involve using a distribution instead of the standard normal distribution when deriving power in Section 4 and will facilitate more accurate planning of the n-of-1 trials. Second, it will be helpful to extend the results to discrete outcomes, although correlation among the repeated measurements would then need to be handled diï¬€erently (Zeger, 1988). Additionally, it will be valuable to extend the results to trials with more than two treatments (Kravitz et al., 2020) and with multiple outcomes of interest (Barr et al., 2015). Lastly, to avoid carryover eï¬€ects, we can introduce washout periods into the derivations when switching from one treatment to another. These periods will limit the number of switches between diï¬€erent treatments in the sequences. The R code for illustrations and the Shiny app and an example input ï¬le for the Shiny app are available on http://github.com/jiabei-yang/SampleSizeNof1. The Shiny app is hosted at http://jiabeiyang. shinyapps.io/SampleSizeNof1/.
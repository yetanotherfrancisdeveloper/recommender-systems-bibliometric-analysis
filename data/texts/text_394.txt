The travel marketing platform of Alibaba serves an indispensable role for hundreds of diî€erent travel scenarios from Fliggy, Taobao, Alipay apps, etc. To provide personalized recommendation service for users visiting diî€erent scenarios, there are two critical issues to be carefully addressed. First, since the traî€œc characteristics of diî€erent scenarios, e.g., individual data scale or representative topic, are signiî€›cantly diî€erent, it is very challenging to train a uniî€›ed model to serve all. Second, during the promotion period, the exposure of some speciî€›c items will be re-weighted due to manual intervention, resulting in biased logs, which will degrade the ranking model trained using these biased data. In this paper, we propose a novel Scenario-Aware Ranking Network (SAR-Net) to address these issues. SAR-Net harvests the abundant data from diî€erent scenarios by learning usersâ€™ cross-scenario interests via two speciî€›c attention modules, which leverage the scenario features and item features to modulate the user behavior features, respectively. Then, taking the encoded features of previous module as input, a scenario-speciî€›c linear transformation layer is adopted to further extract scenario-speciî€›c features, followed by two groups of debias expert networks, i.e., scenario-speciî€›c experts and scenario-shared experts. They output intermediate results independently, which are further fused into the î€›nal result by a multi-scenario gating module. In addition, to mitigate the data fairness issue caused by manual intervention, we propose the concept of Fairness Coeî€œcient (FC) to measures the importance of individual sample and use it to reweigh the prediction in the debias expert networks. Experiments on an oî€Ÿine dataset covering over 80 million users and 1.55 million travel items and an online A/B test demonstrate the eî€ectiveness of our SAR-Net and its superiority over state-of-the-art methods. SAR-Net has also been deployed in the online travel marketing platform of Alibaba and is serving hundreds of travel scenarios. â€¢ Information systems â†’ Recommender systems. Recommender system, Click-through rate prediction, Scenarioaware, Fairness coeî€œcient ACM Reference Format: Qijie Shen, Wanjie Tao, Jing Zhang, Hong Wen, Zulong Chen, and Quan Lu. 2021. SAR-Net: A Scenario-Aware Ranking Network for Personalized Fair Recommendation in Hundreds of Travel Scenarios. In Proceedings of the 30th ACM International Conference on Information and Knowledge Management (CIKM â€™21), November 1â€“5, 2021, Virtual Event, QLD, Australia. ACM, New York, NY, USA, 10 pages. https://doi.org/10.1145/3459637.3481948 In recent years, Recommender Systems (RS) have played an increasingly important role in e-commerce platforms [26,35,36,40]. It not only boosts businesses via traî€œc utilization, but also greatly reduces the time cost for users to î€›nd items of interest. There are two main phases in a typical e-commerce RS, i.e., Matching and Ranking, where Matching is able to retrieve several thousands of candidate items from hundreds of millions of items, while Ranking is responsible for sorting these candidates according to speciî€›c metrics, such as click-through rate (CTR) [7,32,37] or conversion rate prediction (CVR) [18,34â€“36]. Sometimes, after Ranking, there is an additional phase called Reranking, which is sometimes utilized to adjust the ranking results based on some manually deî€›ned rules, especially during the promotion period, such as the Double-Eleven Shopping Festival in China. As a speciî€›c instance of RS, the Alibaba travel marketing platform aims to provide personalized recommendation service to users from hundreds of travel scenarios in Fliggy, Alipay, and Taobao apps. For providing preeminent service for users visiting diî€erent travel scenarios, there are two critical issues encountered in practice. On the one hand, due to the individual topic or data scale for each scenario, the data distribution among these travel scenarios is signiî€›cantly diî€erent, resulting in the diî€œculty of training a uniî€›ed model to serve all. We call it as the Multi-Scenario Modeling Issue. On the other hand, to ensure the deî€›niteness of traî€œc for certain important merchants and items during the promotion period, there is always manual intervention to adjust the ranking results in the Reranking phase, which will make the real exposure traî€œc be biased towards those intervened merchants or items. Consequently, when training with the biased logs, the model in Ranking phase will inevitably learn more information towards these overexposed intervened items, resulting in unexpected self-reinforcement in the ranked results, i.e., systematic discrimination of disadvantaged items. We call it as the Data Fairness Issue. For the Multi-Scenario Modeling Issue, there are typically three kinds of solutions: 1) training individual ranking model for each scenario [42,43]; 2) training a uniî€›ed ranking model with all scenario data; and 3) using a multi-task learning framework to output multiple prediction results simultaneously [4,17,20], and each result for each scenario. However, the î€›rst method has obvious shortcomings. First, as the number of scenarios increases, maintaining individual model for each scenario requires a huge amount of cost. Second, since the data scale from certain scenarios is small, it is diî€œcult to train an excellent ranking model only leveraging data from their own data. Alternatively, the second type of methods try to utilize the data of all scenarios. However, since the traî€œc characteristics of diî€erent scenarios are signiî€›cantly diî€erent, it is very challenging to train a uniî€›ed model that performs well in all scenarios. The third type of methods focus on the multi-task learning approaches while trying to harvest all data by discovering the explicit relationships among diî€erent scenarios. And existing multi-task learning approaches adopt an early-sharing strategy by learning a shared feature embeddings among diî€erent tasks, followed by feeding them into individual task-speciî€›c sub-network, respectively. However, the traditional multi-task modeling methods ignore the modeling of user interest transfer across scenarios, which consequently are not able to predict user interest accurately. In addition, the importance of input information from diî€erent scenarios is inevitably diî€erent while previous methods do not capture it explicitly. For the Data Fairness Issue, recent related studies on the bias issue mainly focus on exposure bias [22,31,33], selection bias [21,27], etc. However, to the best of our knowledge, there is no previous research on intervention bias in recommender systems. A straightforward way to handle this problem is to down-sampling the overexposed items caused by intervention. However, this method requires too much engineering tricks and manpower to manually adjust the data set, which are not applicable due to the frequently changing intervention rules, especially during promotion period. Additionally, over down-sampling the data set will inevitably lead to serious wastage of usable data. To address the above two issues, we propose a Scenario-Aware Ranking Network (SAR-Net) in this paper. The network structure is based on a multi-expert network. Two attention modules are employed to extract the userâ€™s cross-scenario interest considering the scenario features and item features, respectively. A scenariowise linear transformation is devised to strengthen the important information for each individual scenario. The linear transformation uses an element-wise operation, which almost does not increase the overall parameters of the model, but can leverage the diî€erences and commonness between scenarios. To address the data fairness issue caused by manual intervention, we propose a Fairness Coeî€œcient to measure the importance of samples in the scenario. It acts as the weight of the sample in the loss function and a useful feature in the bias-expert net of the expert network, which will be removed when deployed online. In this way, the proposed SAR-Net can not only fully learn the diî€erences and relationship between scenarios, but also reduce the impact of intervention bias. The main contributions of this work are summarized as follows: â€¢We propose a novel SAR-Net that can predict usersâ€™ crossscenario interest given the scenario features and item features and extract important scenario-speciî€›c information across diî€erent scenarios adaptively. â€¢We investigate the data fairness problem caused by manual intervention in recommender systems and propose a simple yet eî€ective solution through the design of network structure and loss function. â€¢Evaluation on both the oî€Ÿine dataset and online A/B test demonstrate the superiority of the proposed SAR-Net over representative methods. SAR-Net has been serving all travel scenarios of Alibaba and brought more than 5% CTR increase. Our proposed method speciî€›cally tackles the multi-scenario prediction problem and data fairness problem, so we brieî€y review the most related work from the following aspects: 1) Single-Scenario CTR Prediction, 2)Multi-Task Learning, 3)Bias and Unfairness in Recommender System. Existing CTR prediction works mainly focus on single scenario modeling from the following several aspects: 1) feature interaction (e.g., FM [24], deepFM [10]); 2) user historical behavior (e.g., DIN[43], DIEN [42]); and 3) combining matching and ranking (e.g., DMR [16]). Factorization Machine (FM) is proposed to model feature interactions explicitly, while previous generalized linear models such as Logistic Regression (LR) [25] and Follow-The-Regularized-Leader (FTRL) [19] lack the ability to solve interaction issue. Wide&Deep [6] and DeepFM [10] combine wide part (low-order) and deep part (high-order) features to improve the performance. FmFM [29] makes each î€›eld feature have diî€erent embedding dimensions, so as to reduce the amount of model parameters and avoid over î€›tting problem. DIN [43] utilizes the attention mechanism to capture relative interests from the user behavior sequence with regard to the candidate item. DIEN [42] further uses a GRU structure to capture the evolution of user interest. Considering a single vector might be insuî€œcient to capture complicated user patterns, DMIN [38] models userâ€™s multiple interests by a special designed extractor layer. DSIN [9] introduces a hierarchical view of behavior sequence by dividing it into sessions. DMR [16] considers the relevance between user and item to achieve better performance. Multi-Task Learning (MTL) [4] aims to improve generalization by sharing knowledge across multiple related tasks. The shared knowledge and task-speciî€›c knowledge are explored to facilitate the learning of each task. There have been some studies applying the gate structure and attention network for information fusion. MOE [11] has a shared-bottom model structure, where the bottom hidden layers are shared across tasks. MMOE [17] extends MOE to utilize diî€erent gates network for each task to obtain diî€erent fusion weights in MTL. Similarly, MRAN [41] applies multi-head self-attention to learn diî€erent representation subspaces at different feature sets. Cross-Stitch [20] uses linear cross-stitch units to learn an optimal combination of task-speciî€›c representations. To address the seesaw phenomenon, PLE [30] separates shared components and task-speciî€›c components explicitly and adopts a progressive routing mechanism to extract and separate deeper semantic knowledge gradually. User behavior data are observational rather than experimental. leading to various biases in the data, such as exposure bias, popularity bias, and unfairness bias [5]. Blindly î€›tting the data without considering the inherent biases will cause many serious issues, e.g., the discrepancy between oî€Ÿine and online performance, and reducing userâ€™s satisfaction and trust on the recommendation service. Exposure bias happens as users are only exposed to a part of speciî€›c items so that unobserved interactions do not always represent negative preference. Popularity bias can be explained as popular items are recommended even more frequently than their popularity would warrant [1]. Unfairness bias can be explained as the system systematically and unfairly discriminates against certain individuals or groups of individuals in favor others [3,8,12,15,28]. The intervention bias investigated in this paper shares similarity with unfairness bias, both of which are caused by the unbalanced data distribution. Consequently, a model trained on the data is biased. The diî€erence is that unfairness bias refers to the imbalance of users, which misleads the model to lean towards the interests of speciî€›c users, which will aî€ect the performance for long-tail users. The intervention bias causes the data fairness issue where external manual intervention adjusts the ranking results, biasing the model towards certain items or merchants. Trained on such unbalanced data, the model will overî€›t over-represented items and reinforce them in the ranked results, resulting in a systematic discrimination that reduces the visibility of disadvantaged items. In a recommender system, the user-item interaction is typically formulated as a matrixY = {ğ‘¦}, whereğ‘€andğ‘denote the numbers of users and items, respectively. The interactionğ‘¦is either implicit feedback [2], e.g., click or explicit user rating [14]. In this work, we focus on the CTR prediction task, implying that the matrixYconsists of 0 and 1. Speciî€›cally,y= 1means that userğ‘¢ has clicked itemğ‘–in scenarioğ‘ , otherwisey= 0. Moreover, each interaction is associated with a timestampğ‘¡that records the time of interaction. Therefore, the data in the recommender system are denoted by a set of quintupletsÎ“ = {(ğ‘¢, ğ‘–, ğ‘ , ğ‘¡, ğ‘¦)}, each of which includes the userğ‘¢ âˆˆ ğ‘ˆinteracts with an itemğ‘– âˆˆ ğ¼in scenarioğ‘  at a recommendation timeğ‘¡. For a target quadruple(ğ‘¢, ğ‘–, ğ‘ , ğ‘¡), an interaction probability should be predicted. In this work, the CTR prediction model aims to estimate the probability of interactionË†ğ‘¦between a target userğ‘¢ âˆˆ ğ‘ˆand a candidate itemğ‘– âˆˆ ğ¼in scenarioğ‘ , with the consideration of the scenario context and item context. In this section we will detailedly present the SAR-Net, with its overall architecture illustrated in Figure 1. SAR-Net takes cross-scenario user behaviors, user basic proî€›les, contextual scenario features, and target item as input. It î€›rstly embeds these input features as lowdimensional vectors by an embedding layer. Then, it extracts user cross-scenario interest transfer from usersâ€™ historical behaviors by devising a Cross-Scenario Behavior Extract Layer after considering the scenario features and item features. Next, taking the encoded features of previous module as input, a scenario-wise linear transformation layer is adopted to strengthen the important information for each individual scenario. Finally, the Mixture of Debias Experts, i.e., scenario-speciî€›c experts and scenario-shared experts, output intermediate results independently, which are further fused into the î€›nal result by a multi-scenario gating module. Now, we will introduce each module in detail. Intervention bias makes the data distribution biased towards the weighted items. When training on such unbalanced data, the recommendation models will inevitably tend to learn more about these over-represented items, resulting in unexpected self-reinforcement in the ranked results, i.e., systematic discrimination of disadvantaged items. Therefore, to address this issue, we propose the concept of Fairness Coeî€œcient (FC), which measures the importance of individual sample and represents the degree of intervention of diî€erent items. AssumingD,ğ‘‘,ğ‘denotes the whole data of all scenarios in one day, the partial data of itemğ‘–exposing in scenarioğ‘ , the number of items in scenarioğ‘ , respectively, whereğ‘‘âˆˆ D. Then, we deî€›neğ‘ƒğ‘‰ (ğ‘–, ğ‘ )andğ¹ (ğ‘–, ğ‘ )as the number of samples fromğ‘‘, the sum of the values predicted by the proposed SAR-Net for all samples fromğ‘‘with an oî€Ÿine manner, respectively. Therefore, the Fairness Coeî€œcient, denoted asğ‘¤, indicating the degree of intervention of diî€erent items in diî€erent scenarios, deî€›ned as follows: Where the numerator is a constant, which has no relationship with whether items intervened, while denominator aî€ected by intervention. Therefore, as the increment of exposure volumes caused by intervention, the FC will become smaller, vice versa. FC will act as the weight of the sample in the loss function and a useful feature in the bias-expert net of the expert network. There are î€›ve groups of features, i.e., user proî€›les, user crossscenario behavior, scenario context feature, target item, and intervention bias. User proî€›le contains features related to the user, e.g., user id, country, etc. Target item feature refers to the candidate item with corresponding features such as item id, category id, statistical oî€Ÿine scores, etc. Scenario context feature is a group of features including but not limited to time, current scenario id, current scenario type, etc. User cross-scenario behavior, with behavior type clicking, purchasing or add-to-cart, is a list of user interacted items in all Figure 1: The overview architecture of our proposed model SAR-Net. Cross-Scenario Behavior Extract Layer harvests the abundant data from diî€erent scenarios by learning usersâ€™ cross-scenario interest via two remarkable attention modules. Then, a Scenario-Speciî€›c Transform Layer is adopted to further extract scenario-spe ciî€›c information, followed by two groups of debias expert networks. We use a Fairness Coeî€œcient to measure the importance of individual sample and use it to reweigh the prediction in the debias expert networks. A multi-scenario gating module is used to fuse these predictions into the î€›nal one. scenarios, where each item in this list not only has same feature î€›elds as the target item but also has the scenario context features at the moment that the behavior happened. Intervention bias feature is the Fairness Coeî€œcient of each sample which is computed after one-day data is generated. Each feature can be encoded into an one-hot vector with high-dimension. We î€›rst encode features into one-hot encodings. For theğ‘–th feature, its one-hot encoding is denoted as: wherevâˆˆ Ris a vector with 1 at theğ‘–th entry and 0 elsewhere, and N is the number of unique features. We then map the sparse and high-dimensional one-hot encodings to dense and low-dimensional embedding vectors that are suitable for neural networks. In particular, we deî€›ne a learnable embedding matrixE âˆˆ R, where ğ· â‰ª ğ‘is the dimension. Theğ‘–th feature is then projected to its corresponding embedding vector eâˆˆ Ras: Existing multi-task modeling methods do not consider the userâ€™s interest transfer in diî€erent scenarios. In fact, most users reside in more than one scenario, with diî€erent preference for respective scenario. For example, users prefer items such as tickets of scenic spots in the travel-surrounding theme scenario, while prefer items with higher living quality or with a place suitable for children to play in the parent-child theme scenario. And in the couple-travel theme scenario, romantic scenery and travel experience will become the primary consideration. Therefore, for reî€ecting userâ€™s signiî€›cant travel intention for diî€erent scenarios and portraying userâ€™s interest transfer, the modeling for userâ€™s cross-scenario behaviors is very critical. With this in mind, we can aggregate userâ€™s cross-scenario behaviors into a uniî€›ed representation. In general, the aggregated strategy can be deî€›ned as: whereğ›¼is a weight assigned toğ‘¥, indicating its importance during aggregation. The remaining issue is how to compute the weight. A naive way isğ›¼= 1/|ğ‘¥|, i.e., each one of clicked items has equal importance. It is clearly not a wise choice because some items may not be indicative for the target item. Inspired by this insight, DIN [43] applies the attention mechanism to extract relevant interests from userâ€™s behaviors, which considers the degree of correlation between historical behavioral items and target items. However, in multi-scenario modeling, the scenario context information at the moment that the behavior happened also carry a lot of information. For example, a userâ€™s historical behaviors in three themed scenarios, namely travel-surrounding, parent-child travel, and northwestern travel, provide informative context when users are looking for items they are interested in at the couple-travel theme scenario. The behavioral mentality of users in diî€erent scenarios in the past is diî€erent from that of the current scenario. Among them, the relevance of parent-child travel is weaker, therefore we need to consider the userâ€™s behavior in strong relevance scenarios to make recommendations. Speciî€›cally, we extract usersâ€™ cross-scenario interests via two speciî€›c attention modules, which leverage the scenario features and item features to modulate the user behavior features, respectively. Furthermore, a userâ€™s cross-scenario behavior can be split into two parts, i.e., item behavior sequencep(ğµ) = {p, p, Â· Â· Â· , p} and scenario context sequencep(ğµ) = {p, p, Â· Â· Â· , p}, wherepis obtained by concatenating the kth corresponding item feature embedding vectors, including item id, category, destination, etc, i.e.,p= [e||e||e|| Â· Â· Â· ].pis obtained by concatenating the kth corresponding scenario context feature embedding vectors, including scenario id, scenario type, behavior time, etc, i.e.,p= [e||e||e|| Â· Â· Â· ], where || is the vector concatenation operator. Additionally, we deî€›neğ›¼andğ›¼, indicating the relevance between userâ€™s kth behavior item and the target item or target scenario, respectively, shown as follows. Where,pandprepresenting the embeddings of target item and target scenario, respectively. Andğœ“ (ğ‘¥, ğ‘¦), taking two vectorsğ‘¥and ğ‘¦as input, output the weight value by employing the feed-forward attention operator, illustrated in Figure 1. Finally, we aggregate pwith the consideration of both ğ›¼and ğ›¼as follows to get the user cross-scenario interest transfer v. After generating user interest transfer vectorv, user basic proî€›les vectorv, target item feature vectorvand the scenario context feature vectorv, we can obtain the gathered representationvby concatenating the corresponding feature embedding vectors, i.e., v = [v||v]||v||v]. Next, for further extracting scenario-aware speciî€›c information, we apply a scenario-wise transform module to process the previous representationv. Speciî€›cally, for theğ‘–th scenario, we compute vâ€™ as follows: where, the vectorsğ›½andğ›¾are scenario-aware parameters, which have the same dimension withv, andâŠ—is an element-wise operator. Because sharing the parameters among diî€erent tasks is diî€œcult to describe the heterogeneity of diî€erent tasks and may potentially result in the negative transfer issue, we use a multi-expert network as the core structure of the feature extraction part. In order to further model the diî€erence between homogeneous tasks, each scenario has some scenario-speciî€›c experts and all the scenarios share several common experts. Compared with the shared-only experts structure, our network alleviates the seesaw phenomenon, i.e., the model has a proî€›t in one of the tasks but a negative proî€›t in the other task. In order to alleviate the inî€uence of intervention bias on model prediction, we divide each expert network into two parts: Bias net and Main net. Both modules are composed of a fully connected network and a batch normalization layer. Main net takes user interest transfer vectorv, user basic proî€›les vectorv, target item feature vectorv, and scenario context feature vectorvas input, and aims to predict the click-through rate of users on the target item. Bias net receives the input of Fairness Coeî€œcientv, taking one speciî€›c value from setğ‘¤according to scenario-aware and item-aware principle, and predicts the degree of intervention bias to reweigh the predicted score of main net. Bias net is used only during training and will be removed when deployed online. After the Mixture of Debias Experts, we have the predicted scores from both scenario-speciî€›c experts and scenario-shared experts. Denotingğ‘¥as the input representation,ğ‘šas the quality of scenario ğ‘˜â€™s scenario-speciî€›c experts, andğ‘šas the quality of scenarioshared experts, we have: ğ‘†(ğ‘¥) = [ğ‘œ, ğ‘œ, Â· Â· Â· , ğ‘œ, ğ‘œ, ğ‘œ, Â· Â· Â· , ğ‘œ] The structure of the multi-gate network is based on a single-layer feed-forward network with a SoftMax activation function. It acts as a selector to calculate the weighted sum of the selected predicting scores. More precisely, the output of scenarioğ‘˜â€™s gating network is formulated as follows: which is indeed the î€›nal predicted score of scenario ğ‘˜. To mitigate the intervention bias issue, we propose the concept of Fairness Coeî€œcient to measure the importance of each sample and hope that the proposed model can get more information from samples with high Fairness Coeî€œcients, due to the fact that these type of samples are less intervened. Furthermore, we use the binary cross entropy with the consideration of Fairness Coeî€œcient, deî€›ned as below: whereğ‘™ğ‘œğ‘ ğ‘ isğ‘™th sample of scenarioğ‘˜and itemğ‘–.ğ‘¤is the Fairness Coeî€œcient of scenarioğ‘˜and itemğ‘–.ğ‘™ğ‘œğ‘ ğ‘ is computed as follows: ğ‘™ğ‘œğ‘ ğ‘ = âˆ’ğ¼log ğ‘âˆ’ (1 âˆ’ ğ¼)ğ‘™ğ‘œğ‘”(1 âˆ’ ğ‘ whereğ‘is the output of SAR-Net,ğ¼is the label ofğ‘™th sample of scenarioğ‘˜and itemğ‘–.ğ¼= 1indicates the current user will click the recommended item and 0 otherwise. To comprehensively evaluate the proposed SAR-Net, we conduct experiments to answer the following research questions: RQ1: How does SAR-Net perform compared with state-of-the-art models for multi-task CTR prediction? RQ2: How about training a single model for each scenario using its own data or training a uniî€›ed model for all scenarios using all data compared with the proposed SAR-Net? RQ3: How about the impact of each part on the overall model? 5.1.1 Datasets. Due to the lack of public datasets for the multiscenario CTR prediction task, we use Alibaba production data containing user click behaviors on 20 scenarios to perform the oî€Ÿine evaluation. The dataset contains usersâ€™ logs from the travel platform of Alibaba in one month, which is collected from October 20th to November 20th, 2020, with the Double-Eleven Shopping Festival, one of the most important annual festivals of Alibaba Group, included during this period. The dataset is further organized into the training dataset and the testing dataset. The training dataset covers over 80 million users and 1.55 million travel items. Table 1 shows the percentage of training dataset and average CTR of each scenario. Table 2 shows the percentage of users that visited certain number of scenarios in past 30 days. It is obvious that diî€erent scenario has diî€erent distribution, and nearly 90% of users have visited multiple scenarios in past 30 days. 5.1.2 Competitors. We will compare our SAR-Net with multi-task models and single-scenario models. Since existing multi-task models are usually to model diî€erent tasks for the same scenario, we will adapt them to the multi-scenario CTR prediction task in this paper to model the same task (CTR) for diî€erent scenarios. Speciî€›cally, Multi-Task Models include: 1) Hard Parameter-Sharing: HPS [4] is the most basic and commonly used MTL structure, where the parameters are straightforwardly shared between diî€erent tasks. 2) Cross-Stitch: Cross-Stitch [20] proposes to learn static linear combinations to fuse representations of diî€erent tasks. 3) MMOE: MMOE [17] applies gating networks to combine bottom experts based on the input to handle the diî€erences between tasks. 4) CGC: Compared with MMOE, CGC [30] separates the expert layer into shared experts and unique experts, enabling diî€erent types of experts to concentrate on learning diî€erent knowledge eî€œciently without interference. 5) PLE: Compared with CGC, PLE [30] adopts a progressive routing mechanism to extract and separate deeper semantic knowledge gradually. and Single-Scenario Models include: 1) Wide&Deep: Wide&Deep [6] combines LR (wide part) and DNN (deep part). 2) PNN: PNN [23] automatically learns feature representations and high-order feature interactions. 3) DIN: Deep Interest Network [43] models dynamic user interest based on historical behavior for CTR prediction. 5.1.3 Parameter Seî€ings. Adam [13] is used as the optimizer with the learning rate of 0.001 for all methods and the batch size is 2048. For all methods, the truncation length of user behavior is 50. For SAR-Net, each scenario has 2 speciî€›c experts, and 8 experts are shared for each scenario. DIN, PNN and Wide&Deep use singlescenario data and mix-scenario data for training respectively. We run each method 10 times and report the average results. 5.1.4 Metrics. (1)AUC: AUC denotes the Area Under the ROC Curve over the test set. It is a widely used metric for CTR prediction, which reî€ects the probability that a model ranks a randomly chosen positive instance higher than a randomly chosen negative instance. The larger AUC is, the better the CTR prediction model performs. It is noteworthy that a small improvement in AUC is likely to lead to a signiî€›cant increase in online CTR [43]. Concretely, we use the AUC of each scenario and overall AUC (mixing samples from all scenarios to calculate the overall AUC) as the metrics. (2) RelaImpr: RelaImpr is introduced in [39] to measure the relative improvement of a target model over a base model. Since the AUC of a random model is 0.5, RelaImpr is deî€›ned as: ğ‘…ğ‘’ğ‘™ğ‘ğ¼ğ‘šğ‘ğ‘Ÿ =ğ´ğ‘ˆ ğ¶ (ğ‘¡ğ‘ğ‘Ÿğ‘”ğ‘’ğ‘¡ ğ‘šğ‘œğ‘‘ğ‘’ğ‘™) âˆ’ 0.5ğ´ğ‘ˆ ğ¶ (ğ‘ğ‘ğ‘ ğ‘’ ğ‘šğ‘œğ‘‘ğ‘’ğ‘™) âˆ’ 0.5âˆ’ 1 As illustrated in Table 3, the consistent improvement of our SARNet over diî€erent contenders validates its eî€œcacy. Note that the overall performance of Mix-Scenario models are worse than the single-scenario model and the multi-scenario models, which proves obscuring scenario diî€erence hurts the modeling of multi-scenario CTR prediction. Besides, HPS, Cross-Stitch, MMOE, CGC, and PLE Table 2: The percentage of users that visited certain number of scenarios (NoS) in past 30 days. Percentage 11.21% 13.40% 25.30% 32.10% 11.52% 6.47% all achieve better overall performance than single-scenario methods and mix-scenario methods, demonstrating the importance of exploiting the distinctions and relationship between scenarios. Although single-scenario methods all achieve better performance than mix-scenario methods, it is notable that in scenario #18, the AUCs of single-scenario methods are worse than mix-scenario methods. We suspect that it is because the data of scenario #18 which is 0.15 percent of training dataset as illustrated in Figure 1, is not suî€œcient to train a reasonable model, while mix-scenario method has enough data to make it. On the other hand, in scenario #8, the DIN model trained in the single-scenario manner achieves better performance than HPS, Cross-Stitch, MMOE, CGC, and PLE, which is opposite to the overall performance results, it shows that in some scenarios, existing multi-task models fail to extract deeper information about the scenarios and users. In contrast, the proposed SAR-Net exhibits superior performance across all scenarios compared with single-scenario methods and mix-scenario methods. Besides, SAR-Net also achieves consistent improvement than HPS, Cross-Stitch, CGC, and PLE, which shows the superiority of explicitly modeling the userâ€™s interest transfer and extracting scenario-speciî€›c information. 5.3.1 Cross-Scenario Behavior Extract Layer. In this section, we investigate the impact of the attention mechanism in the CrossScenario Behavior Extract Layer. The base model is SAR-Net, which extracts user behavior using a mean pooling operator (No Attention). In particular, we consider the following settings: 1) Target Attention: taking the target item as the query and the behavior item as the key in the attention mechanism; 2) Scenario Attention: taking scenario context feature as the query and the scenario context information at the moment that the behavior happened as key; 3) Concatenate Attention: concatenating target item feature and scenario context feature as query; 4) Hierarchical Attention: using a two-layer attention. In the î€›rst layer, scenario context feature concatenated with the target item is used as query. In the second layer, scenario context feature is used as the query. Multiplication of the weights of the two attention layers is used to generate the î€›nal pooling weights; and 5) Attention mechanism used in SAR-Net: target item and scenario context feature are respectively used as queries to learn the two-layer weights and element-wise item is used to generate the î€›nal pooling weights. As illustrated in Table 4, â€œNo attentionâ€ perform the worst, showing that useful signals could be easily buried in noise without distilling. In addition, either target item attention or scenario attention can improve the AUC compared with the base model, demonstrating that considering the relevance of target item or scenario context information both can bring gains. The third and fourth attention mechanisms that consider both target item and scenario context features perform better than the base model but worse than target attention, implying that directly concatenating target item and scenario context feature as the query could not fully attend and exploit the useful information. In contrast, SAR-Net learns attention weights from the perspective of target item and scenario context respectively and achieves the best performance. It shows that learning weights separately will avoid mutual interference, and can extract usersâ€™ interest transfer across diî€erent scenarios. 5.3.2 Bias Net and Bias Adapting Loss. In this section, we investigate the impact of the Bias Net and Bias Adapting Loss in SAR-Net, which are used to mitigate the intervention bias issue. In particular, we try the loss without the weight of fair coeî€œcients and the model without the bias net structure in the Expert Net as the base model, called SAR-Net. We consider the following Settings: 1) subsampling items that are overexposed due to manual intervention. Sampling ratios were 0.9,0.8,0.7,0.6; 2) introducing the bias net to the expert network; 3) using the bias adapting loss; and 4) using the bias net and bias adapting loss. As can be seen from Table 5, when the biased items being manual intervened are sub-sampled, the performance was improved slightly at î€›rst and then decreased. When the sub-sampling ratio is 0.7, the performance is the best. This is because sub-sampling will reduce the proportion of intervened items in the dataset, so that the model can learn the information of each type of items in a more fair way. However, when the proportion gradually decreases, the performance of the model will decrease, showing that excessive sub-sampling leads to the reduction of samples and the interaction information between users and items is not fully utilized. Bias net that is introduced to each expert net to reweigh the prediction of expert during training achieves better performance compared with base model and the sub-sampling method. Besides, bias adapting loss can make the model adaptive to the biased data and learn information according to the importance of samples. Our SAR-Net with both bias net and bias adapting loss can further boost the performance, demonstrating the eî€ectiveness of the Bias Adapting Loss and Bias Net and their complementarity. 5.3.3 Scenario-Specific Transform Layer. Scenario-speciî€›c transform layer further models the diî€erences and relations between scenarios by strengthening the key information of diî€erent scenarios. In this section, we take SAR-Net without the scenario-wise transform layer as the base model SAR-Netand consider the following settings: 1) referring to PLE [30], a multi-layer expert network Table 3: AUC of diî€erent models on the oî€line Alibaba production dataset. Single-Scenario denotes that models are trained using single scenario data indep endently. Mix-Scenario denotes that models are trained using all-scenario data. Multi-Scenario denotes that models are trained based on multi-task learning. â€œOverallâ€ denotes that mixing samples from all scenarios to calculate AUC. Table 4: Ablation study of the Cross-Scenario Behavior Extract Layer. SAR-Netis the base model by replacing the Cross-Scenario Behavior Extract Layer with mean pooling. SAR-Net SAR-Net SAR-Net SAR-Net SAR-Net is used to extract features. And the number of layers is set to 2, 3, 4, 5, respectively; and 2) a single layer expert network is used and the scenario-wise transform layer is added before the expert network (SAR-Net). It can be seen from Table 6 that the beneî€›t of the multi-layer extraction network structure converges gradually with the increase of the number of layers. Compared with the multi-layer expert extraction structure, scenario-speciî€›c transform layer achieves better results with less parameters. We conduct the online A/B test by deploying our SAR-Net to handle real traî€œc in the personalized scenarios of Fliggy, Taobao and Alipay for seven days in November 2020, where the base model is Table 5: Ablation study of the Bias Net and Bias Adapting Loss. SAR-Netdenotes the base model that removes the bias net and uses the naive binary cross-entropy loss. MMOE [17]. The online evaluation metric is real CTR, which deî€›ned as the number of clicks over the number of item impressions. The experimental results are shown in Figure 2. It is clear that SARNet outperforms the base model MMOE [17] consistently, demonstrating the eî€ectiveness of SAR-Net in practical multi-scenario CTR tasks. SAR-Net has been deployed in the online travel marketing platform in Alibaba and is now serving hundreds of travel scenarios. Moreover, we analyzed the performance of SAR-Net as per different categories compared with the base model. As illustrated Table 6: Ablation study of the Scenario-Sp eciî€›c Transform Layer. SAR-Netdenotes the base model without the Scenario-Speciî€›c Transform Layer. Figure 2: Online CTRs of SAR-Net and the base mo del in seven days in November 2020. Figure 3: Online exposure ratios of SAR-Net and the base model as per category in seven days in November 2020. The intervened samples are removed from the statistics. Exposure ratio denotes the number of categoryâ€™s exposure over the number of all test data. Figure 4: Online CTRs of SAR-Net and the base model as per category in seven days in November 2020. The intervened samples are removed from the statistics. in Figure 3 and Figure 4. We found that: 1) SAR-Net makes the exposure ratio of each category more even; 2) SAR-Net achieves consistent improvement in all categories; and 3) the improvement is more obvious on the categories with smaller traî€œc. These results demonstrate that SAR-Net eî€ectively mitigates the intervention bias issue and achieves fair recommendation for each item. In this paper, we propose a novel Scenario-Aware Ranking Network (SAR-Net) to address two issues encountered in the context of Alibaba travel marketing platform, i.e., multi-scenario modeling issue and data fairness issue. SAR-Net harvests the abundant data from diî€erent scenarios by learning usersâ€™ cross-scenario interests via two speciî€›c attention modules. Then, a scenario-speciî€›c transformation layer is adopted to further extract scenario-speciî€›c features, followed by two groups of debias expert networks. Furthermore, above intermediate results are fused into the î€›nal result by a multi-scenario gating module. In addition, we propose the concept of Fairness Coeî€œcient to measure the importance of individual sample and use it to reweigh the prediction in the debias expert networks. In this way, SAR-Net can address above two issues eî€œciently. The experimental results on both oî€Ÿine dataset and from online A/B test demonstrates the superiority of SAR-Net over representative methods for multi-scenario prediction. SARNet has been deployed in the online travel marketing platform of Alibaba and is serving hundreds of travel scenarios, bringing a 5% improvement on CTR. In the future, we intend to investigate the impact of introducing more user î€›ne-grained behaviors.
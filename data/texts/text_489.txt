Recent advents in recommender systems, especially in text-aided methods and Cross-Domain Recommendation (CDR), lead to promising results in solving data-sparsity and cold-start problems. Despite such progress, existing CDR approaches have some critical defects such as requiring overlapping users for the knowledge transfer or ignoring domain-aware features. In addition, text-aided methods, in general, emphasize aggregated item reviews and fail to capture the latent of individual reviews. To overcome such limitations, we propose a novel method, named Domain-aware Feature Extraction and Review Encoder (DaRE), which consists of the key components; domain-aware text analysis module, and review encoders. DaRE debilitates noises by separating domain-invariant features from domain-speciî€›c features through selective adversarial training. Then, with the features extracted from aggregated reviews, the review encoder î€›ne-tunes the representations by aligning them with the features derived from individual reviews. The experiments on four real-world datasets show the superiority of DaRE over state-of-the-art single-domain and cross-domain methodologies, achieving 9.2 % and 3.6 % improvements, respectively. â€¢ Information Systems â†’ Recommender Systems. Cross-Domain Recommendation; Disentangled Representation Learning; Domain Adaptation; Textual Analysis; Data Sparsity ACM Reference Format: Yoonhyuk Choi, Jiho Choi, Taewook Ko, and Chongkwon Kim. 2021. DaRE: A Cross-Domain Recommender System with Domain-aware Feature Extraction and Review Encoder. In Proceedings of ACM Conference (Conferenceâ€™17). ACM, New York, NY, USA, 12 pages. https://doi.org/10.1145/ With the rapid growth of e-commerce, recommender systems have become an obligatory tool for interconnecting customers with relevant items. Early schemes suî€er from the cold-start problem caused by data insuî€œciency. To tackle the problems, some of them exploit auxiliary information such as social relations [12], the trustworthiness of reviewers [1], item images [40], and textual information. Especially, textual or linguistic information such as reviews are commonly available, and many text-aided recommendation algorithms have been introduced [6, 9, 10, 36, 45]. Most text-aided schemes deal with aggregated reviews rather than individual texts since aggregation provides richer information. Some studies infer the preferences of users by applying NLP techniques such as topic modeling [2,28] to aggregated texts. More recently, [13,44,45] adopt DNN-based FEs (Feature Extractors), while others utilize attention mechanism [6,10]. Extracted preferences or features are fed into prediction modules in the forms of MF or MLP. Contrary to the prior methods that ignore individual texts, we propose to utilize individual texts as well as aggregated reviews, simultaneously. We extract features via two diî€erent routes, one from aggregated reviews and the other from individual texts, and align them using a review network. Along with the text-based recommender systems, numerous Cross-domain recommendation (CDR) algorithms [13,18,42] and transfer learning methods [16,41] have been introduced. CDR leverages the information learned from source domains to improve a recommendation quality in a target domain. Some schemes [38,41] use network î€›ne-tuning, but they may suî€er from catastrophic forgetting [7]. Context mapping techniques [15,23,25,42], which map shareable information from a source to the target domain, is another branch of transfer learning popularly adopted in CDRs. These approaches require the same contexts like overlapped users or features, a restriction that can conî€›ne their applicability severely [19]. In real-world datasets, overlapped users are scarce and, more importantly, the contributions of overlapped users may not be signiî€›cant, prompting further investigations for a model oblivious to overlapped users. As one solution, some CDR algorithms focus on capturing domain-invariant features common to both source and target domains [5,14,20,30,44], which is independent of sharing same contexts. Though domain common knowledge improve the accuracy of recommendations, italicizing this kind of information only may lead to sub-optimal performance, especially when two domains have diî€erent distributions. To solve such constraints: require duplicate users, only capturing domain-invariant features, we propose a novel domain adaptation algorithm that extracts domain-aware knowledge from review texts, including both domain-invariant and domain-speciî€›c features without depending on the user or item overlap. Domain adversarial approaches extract domain-invariant features by minimizing source risk as well as H-divergence [4,14,21,22]. However, these methods are highly dependent on the consistency of source and target distributions (e.g., similar category). To mitigate such restriction, we extend the concept of domain adaptation, which emphasizes the extraction of domain-speciî€›c feature to distill pertinent knowledge from multiple seemingly counterproductive domains. Summarizing the above insights, Domain-aware Feature Extraction and Review Encoder (DaRE) adopts the following key components; domain-aware feature extraction, and a review encoder. Two mechanisms are closely coupled and interact with each other. DaRE extracts domain-aware features using three pairs of FEs, two for domain-speciî€›c features and one for domain-invariant feature. For domain-aware learning, we cleverly utilizes the domain adversarial technique that adequately controls the importance of domainspeciî€›c features or domain-invariant features. Through a selective adoption of the gradient reversal layer, three FEs are trained to capture these features. Another property of DaRE is that it utilizes individual texts as well as aggregated reviews. The review encoder network î€›ne-tunes representations extracted from aggregated texts by aligning them with those extracted from individual reviews. The example of domain-aware feature extraction and review encoder can be seen in Figure 9 and 10, respectively. We perform extensive experiments on real datasets to compare DaRE with several state-of-the-art algorithms. Experimental results show that DaRE outperforms all baselines. Also, the ablation studies scrutinize the contributions of the key modules of DaRE, showing all components are indispensable to performance enhancement. The contributions of our work is summarized as follows. â€¢We propose a novel algorithm that adaptively extracts domaininvariant and domain-speciî€›c features depending on the characteristics of the source and target distributions. DaRE is a comprehensive method where domain-awareness is closely integrated with text-based feature extraction. Its domain adversarial gradient updates eventually modify the text-based FEs and capture domain-speciî€›c and domain-invariant features concurrently. â€¢Unlike previous CDR approaches that require duplicate entities such as common users or items from heterogeneous domains, DaRE focuses on retrieving review information that is domain-independent. Consequently, DaRE enjoys wide applicability and can be applied regardless of source and target domain homogeneity or heterogeneity. â€¢We propose a unique review encoder that compares features extracted in two routes. It î€›ne-tunes features extracted from aggregated information using features from individual reviews. The review encoder improves the accuracy of representation and the quality of recommendation. â€¢We perform extensive experiments to answer the important research questions. Our results indicate the superiority of DaRE and the eî€ectiveness of all key modules. We delve into the two types of categories; text-based recommender algorithms and CDR. Textual information is the most popular side information and many text-based methods [8â€“10,45] have been proposed. Most techniques integrate DNN based feature extraction with MF for a rating prediction. DeepCoNN [45] utilizes two parallel CNNs, while NPT [24] adopts Gated Recurrent Units for review analysis. Attention mechanisms are widely used also to pinpoint useful words and reviews [6,10,34,35]. Even though prior works show the usefulness of textual information, the limitation of review information due to the limited size of training data, the irrelevance of reviews toward target items have been raised also [33,43]. Unlike the prior works, DaRE utilizes both aggregated reviews and individual reviews. Also, DaRE couples the domain adversarial mechanism with three textbased FEs. To the best of our knowledge, this is the î€›rst attempt that integrates the two mechanisms. CDR utilizes information from source domains to alleviate the coldstart problem in the target domain. Early studies [11,26] adopt feature mapping technique that requires overlapped users. For example, RC-DFM [13] applies Stacked Denoising Autoencoder (SDAE) to each domain, where the learned knowledge of the same set of users are transferred from source to target domain. To overcome the restrictive requirement of overlapped users, CDLFM [37] and CATN [44] employ neighbor or similar user-based feature mapping. However, this kind of cross-domain algorithm implicates defects [46] like î€›ltering noises or requiring duplicate users. DA (Domain Adaptation) with the powerful mechanism of adversarial training has been adopted for various î€›elds; VQA [32] for question answering, DAREC [42] for a recommendation. TDAR [39] assumes no user or item overlap and extracts domain-invariant textual features. However, these approaches focus on domain shareable knowledge ignoring domain-speciî€›c features. MMT [20] considers domain-speciî€›c features as well as domaininvariant knowledge, but it simply adopts user and item embedding as domain-speciî€›c features. DADA [30] suggests domain-agnostic learning, but its domain discriminator focuses on domain-invariant feature extraction only also, leaving domain-speciî€›c feature extraction to be solely guided for the minimization of mutual information with MINE [3], which has proven to have some defects [27]. DaRE clears the aforementioned limitations, adopting a framework for the simultaneous extraction of domain-speciî€›c and domain-invariant knowledge through the modiî€›cation of domain adaptation. Assume two datasets,ğ·andğ·, be the information from the source and target domains, respectively. Each dataset consists of tuples, (ğ‘¢, ğ‘–, ğ‘¦, ğ‘Ÿ)which represents an individual reviewğ‘Ÿwritten by a userğ‘¢for itemğ‘–with a ratingğ‘¦. The two datasets take the form ofğ·= (ğ‘¢, ğ‘–, ğ‘¦, ğ‘Ÿ)andğ·= (ğ‘¢, ğ‘–, ğ‘¦, ğ‘Ÿ), respectively. The goal of our task is to predict an accurate rating scoreğ‘¦, using ğ·and a partial set ofğ·. A detailed explanation of the notations can be seen in Table 1. On the upper side of Figure 1 (training phase), our model Domainaware Feature Extraction and Review Encoder (DaRE) starts with review embedding layers followed by three types of feature extractors (FEs). Integrated with domain discriminator, three FEs are trained independently for the parallel extraction of domain-speciî€›c ğ‘‚, ğ‘‚and domain-common knowledgeğ‘‚, ğ‘‚. Then, for each domain, the review encoder generates a single vectorğ¸, ğ¸with extracted featuresğ‘‚by aligning them with individual reviewğ¼, ğ¼. Finally, the regressor predicts an accurate rating that the user will give on an item. Here, shared parameters across two domains are common FE and a domain discriminator. We now explain each component precisely. We adopt text analysis method [45] that extracts user and item features from aggregated reviews using two parallel networks. Unlike the previous techniques [6,10,45] that use one or two pairs of parallel networks, DaRE adopts three pairs of FEs (Feature Extractors),ğ¹ğ¸,ğ¹ğ¸, andğ¹ğ¸, named source, common, and target, for the separation of domain-speciî€›c, domain-common knowledge. The three FEs share the same architecture with unshared parameters,ğœƒ, ğœƒ, ğœƒ. As illustrated in Figure 2, each FE consists of a user feature extraction networkğ¹ğ¸and an item feature extraction networkğ¹ğ¸. To distinguish the domain identiî€›er from the FE identiî€›er, we use a superscriptğ‘‘to denote the domains of datasets (ğ‘ for source andğ‘¡for target) andğ‘˜to represent three FE types (ğ‘ ,ğ‘, ğ‘¡). Note that the common FE (i.e.ğ¹ğ¸) uses both source and target domain reviews as an input. ğ·, ğ·Source and target domain datasets ğ‘¢, ğ‘–, ğ‘¦, ğ‘ŸUser, item, rating, and review Figure 2: The architecture of a single review feature extractor. DaRE has three parallel review feature extractors of the same architecture with diî€erent inputs and parameters. Another distinctive characteristic is that DaRE utilizes individual texts as well as aggregated reviews, simultaneously. First, all reviews (except for individual reviewğ‘Ÿ) written by userğ‘¢are concatenated to a singleğ‘…. Likewise,ğ‘…for each itemğ‘–is the concatenation of user reviews. Each individual review,ğ‘Ÿ, î€›ne-tunes the î€›nal representations ofğ‘…andğ‘…through the review encoder. Anğ¹ğ¸begins with a word embedding layer. We utilize î€›rstğ‘› ğ‘¤ğ‘œğ‘Ÿğ‘‘ğ‘  inğ‘…orğ‘…and adopt GloVe [31] for word vectorization. The words are mapped toğ‘-dimensional vectorsğœ™ (ğ‘¤). Word vectors are concatenated to formğ‘‰= ğœ™ (ğ‘¤) âŠ• ğœ™ (ğ‘¤) âŠ• ... âŠ• ğœ™ (ğ‘¤), whereğœ™and âŠ•are embedding and concatenation function, respectively. Then 2-D convolutional network with î€›ltersğ¹ âˆˆ Rextract features fromğ‘‰, followed by non-linear activation function ReLU with max pooling layer. Speciî€›cally,ğ‘—-th î€›lter,ğ¹for user feature extraction yields ğ‘“as follows: Figure 3: The architecture of (a) Domain adaptation, and (b) Domain-aware feature extraction. The dotted line (blue and red) denotes back-propagation for domain loss ,ğ‘is a bias term. The representationğ‘‚,ğ‘‚of userğ‘¢and item ğ‘–is the concatenation of the scalar outputs ğ‘“, , whereğ½is the number of î€›lters. The î€›nal representationğ‘‚is a simple concatenation of ğ‘‚and ğ‘‚. Likewise, we derive the embeddingğ´of an individual review ğ‘Ÿwith three FEs as follows: As shown in Figure 1, the input for source and target FEs are (ğ‘…, ğ‘…, ğ‘Ÿ)and(ğ‘…, ğ‘…, ğ‘Ÿ), respectively. The common FE accepts both inputs. The outputs of three FEs are denoted as follows: from ğ¹ğ¸. We propose a mechanism that separates the domain-invariant features from the domain-speciî€›c features. The DANN [14] architecture, which utilizes a domain-shareable module, eî€ectively transfers knowledge between two diî€erent domains. As can be seen in Figure 3-(a), a domain discriminator gives a penalty to prevent a common FE from capturing domain-speciî€›c knowledge. One drawback of DANN is that it is vulnerable to domain-mismatches (e.g., categories) resulted in prohibitive applicability. To subjugate the limitation, we additionally adopt source and target FEs to capture domain-speciî€›c knowledge. Figure 3-(b) is the architecture of the proposed scheme. The domain-awareness module is closely coupled with the three text-based FEs explained before. Using the domain of reviews as a label, the domain discriminator prevents a common FE from capturing domain-speciî€›c features. On the contrary, the domain discriminator penalizes the source and the target FEs if source featureğ‘‚or target featureğ‘‚has insuî€œcient domain-speciî€›c information. In this way, our scheme can adaptively secure robustness against similarity or diî€erence between source and target domains; if source and target domains are different, then domain-speciî€›c features will be emphasized, and vice versa. For a domain discriminator, we utilize two layers of a fullyconnected neural network as below: , whereğ‘”is an activation function andğ», ğ»are the parameters of the MLP.bğ‘‘denotes predicted domain label of featureğ‘‚. A domain loss can be calculated through binary cross-entropy between true ğ‘‘and predictedbğ‘‘label as follows: whereğ‘andğ‘are the number of training data in source and target domains, respectively. The domain labelğ‘‘is a binary value, {0, 1} for source and target, respectively. The proof of Equation 6 can be seen in supplementary material. Through Figure 3-(b), we can see that a domain discriminator is being updated with four types of losses. Then, two losses âˆ’L, âˆ’L(blue arrows) with Gradient Reversal Layer (GRL) updates the common FE, while another lossesL, L(red arrows) updates source, target FE, respectively. During back-propagation, GRL multiplies a negative constant, which is positioned between common FE and domain discriminator. Thus, the common FE is trained to capture domain-indiscriminative knowledge: fooling domain discriminator. This reinforces common convolution î€›lterğ¹. On the contrary, domain loss without GRL prompts the source and the target FEs to capture domain-discriminative information: minimizing domain loss, which updates source or target convolution î€›lters ğ¹, ğ¹. 3.3.1Remark.The domain-aware feature extraction employs the idea of domain disentanglement [30] but they diî€er in two perspectives. First, we selectively adopt GRL for domain-aware feature extraction without calculating mutual information. Second, our method notably focuses on the review analysis rather than image classiî€›cation. Figure 4 illustrates the architecture of a review encoder taking a userğ‘¢and an itemğ‘–as an example. Prior methods only utilize Figure 4: A simple architecture of review enco der the gross review information such asğ‘…andğ‘…and ignore peculiar informationğ‘Ÿthatğ‘¢gives onğ‘–. Intuitively, to retrieve the detailed latent representations, we propose a novel review encoder that handles speciî€›c review ğ‘Ÿfrom ğ‘‚and ğ‘‚. First, from an individual review, its î€›nal representation,ğ¼, is extracted as the summation of two vectors as shown in Figure 1: Also, we can obtain the representation of user and item from aggregated texts. From aggregated reviewsğ‘…, ğ‘…, FEs obtain representationsğ‘‚andğ‘‚, respectively. We devise the review encoder to align the latent from an individual reviewğ¼with the latent from aggregated reviews. Two embeddingsğ‘‚, ğ‘‚are loaded to the encoder (fully connected network), generating a î€›nal representation ğ¸as: To align the two vectors,ğ¼, ğ¸, we adopt Euclidean distance as the loss function, The regressor predicts a rating score that userğ‘¢will give to the itemğ‘–. A single deep feed-forward neural network consists of two layers serves as the regressor. For each domain, the predicted ratings ğ¸and ğ¼are, bğ‘¦= ğ‘…ğ‘’ğ‘”ğ‘Ÿğ‘’ğ‘ ğ‘ ğ‘œğ‘Ÿ(ğ¸) = ğ‘Šğ‘”(ğ‘Šğ¸+ ğ‘) + ğ‘ bğ‘¦= ğ‘…ğ‘’ğ‘”ğ‘Ÿğ‘’ğ‘ ğ‘ ğ‘œğ‘Ÿ(ğ¼) = ğ‘Šğ‘”(ğ‘Šğ¼+ ğ‘) + ğ‘, wherebğ‘¦is a predicted rating based on aggregated reviews and bğ‘¦is an inferred rating from an individual review in domainğ‘‘. Finally, we can deî€›ne a regression loss function: the diî€erence between predicted scoresbğ‘¦,bğ‘¦and true labelğ‘¦. We adopt MSE loss for the objective function as below: During the inference phase, DaRE utilizes the trained modules (common and target FEs, target review encoder, target regressor) with the entire aggregated reviews of user and item. Finally, the rating prediction in a target domain is as follows: ğ‘‚, ğ‘‚= [ğ¹ ğ¸(ğ‘…) âŠ• ğ¹ ğ¸(ğ‘…)], [ğ¹ğ¸(ğ‘…) âŠ• ğ¹ğ¸(ğ‘…)] , For the optimization, we can deî€›ne the objective function through the weighted sum of three Equations 6, 9, 11 as below: The hyper-parametersğ›¼,ğ›½balance the domain and encoder losses. From our experiment,ğ›¼ =0.1,ğ›½ =0.05 yield the best performance (details are in supplementary material).ğœƒdenotes all parameters of our model andğ›¾is a regularization term. We update the modelâ€™s parameters through the gradient descent by minimizing Equation 13, where the parameter update for each module can be seen in Figure 1 with three basic shapes. A shape with a horizontal stripe denotes a loss from the source domain. For training, we adopt a mini-batch with Adam optimizerğ‘™ğ‘Ÿ =1ğ‘’ and early stopping. The trainable parameters of DaRE are three FEs, a domain discriminator, two review encoders, and two regressors. We now explain the parameter updates of each module in detail. First, let us assume the parameters of source and target regressor asğœƒ, ğœƒ. The loss function associated with the update ofğœƒ, is a regression error deî€›ned in Equation 11 (see purple triangles in Figure 1). We can simply update the parameters of regression layer, ğœƒand ğœƒwith proper learning rate ğœ‡ as follows: Then, we can deî€›ne the losses for the update of two review encoders ğœƒusing chain rule: , where L= ||ğ¸âˆ’ ğ¼||(blue circles in Figure 1). For a domain discriminator, the parameterğœƒis updated with the summation of domain-invariantL, Land domainspeciî€›cL, Llosses (red squares in Figure 1), which is deî€›ned in Equation 6: Finally, we can deî€›ne the update functions for three FEsğœƒ, ğœƒ, ğœƒ, integrating three types of losses as follows: In this section, we conduct experiments with multiple real-world datasets of diî€erent categories to answer the following research questions: â€¢ RQ1:Does DaRE outperforms compared with several stateof-the-art recommendation approaches? â€¢ RQ2:Does the core components of DaRE: domain-aware feature extraction and review encoder, are essential for the recommendation quality? â€¢ RQ3:How well the properties of domain-aware knowledge and peculiar information are preserved in extracted features? We systematically conduct experiments with publicly available datasets Amazonand Yelp. The target domain includes the following four categories of Amazon: Oî€œce Products(OP), Automotive(Au), Patio Lawn and Garden(PL), and Instant Video(IV). The source domain consists of four datasets: three categories, Baby, Kindle Store(KS), Toys and Games(TG) from Amazon and one from Yelp. We adopt Yelp data to scrutinize the eî€ect of excluding duplicate users for CDR scenario. Also, to lens on the cold-start problem, we designate datasets with sparse interactions as the target domain. The statistical details of datasets are summarized in Table 2. Like previous studies, each target dataset is divided into three parts: 80 percent for training, 10 percent for validation, and another 10 percent for testing. We randomly sample source domain data such that its size equals that of the target domain data. For word embedding, we use Glove with a î€›xed embedding dimension of 100. We apply 100 convolution î€›lters of sizeğ¹ âˆˆ R. The performance is evaluated based on the validation score with early stopping under 300 iterations. We upload our codefor a reproducibility. We select 10 exemplary state-of-the-art single-domain and crossdomain approaches. Detailed explanations are as follows: 4.2.1 Single-Domain Approaches. â€¢ PMF[29] is a classical probabilistic matrix factorization method. â€¢ NeuMF[17] combines deep neural networks with a probabilistic model. NeuMF achieves great performance enhancement over classical methods. â€¢ DeepCoNN[45] leverages review texts for rating prediction. They retrieve usersâ€™ interest from textual reviews and jointly encode the latent of user and item with two parallel neural networks. â€¢ NARRE[6] improves the DeepCoNN by employing attention mechanisms to measure the usefulness of reviews. â€¢ AHN[10] proposes a hierarchical attention mechanism: review embedding is generated by applying sentence-level attention, followed by review-level attention for retrieving user and item embedding. 4.2.2 Cross-Domain Approaches. â€¢ DANN[14] proposes the seminal domain adversarial technique that extracts domain-invariant features from two different domains. Here, review texts are embedded as 5,000dimensional feature vectors. â€¢ DAREC[42] assume the same set of users between two domains and integrate AutoEncoder with domain adaptation to transfer rating patterns from a source to the target domain. â€¢ RC-DFM[13] fuses review texts with rating information. With SDAE, it preserves the latent features with rich semantic information. For a fair comparison, we additionally train the text convolution layer for each domain. â€¢ CATN[44] transfers knowledge at an aspect level. The model extracts multiple aspects from review texts and learns aspect correlation across domains with an attention mechanism. â€¢ MMT[20] adopt domain-invariant components shared across two domains. Here, we adopt text convolution layers for a knowledge transfer (review texts can act as domain-invariant information). Also, the trained parameter of the text convolution layer is retrained in a target domain for performance enhancement. DaRE consistently outperforms all single-domain approaches. Table 3 shows the MSE score of DaRE with state-of-the-art approaches. For single-domain methodologies, rating-based PMF and NeuMF performed worse than text-based methods indicating the usefulness of textual information. NARRE and AHN which adopt attentions outperform DeepCoNN. Nonetheless, with the aid of domain-aware knowledge transfer and review encoder, DaRE outperforms AHN, which is competitive rather than attention mechanism. The quality of cross-domain recommendation can be degraded with respect to the domain discrepancy.We î€›rst investigate the performance of î€›ve cross-domain algorithms. Like DaRE, DANN and MMT transfer knowledge without user overlapping. The results show that DANN and MMT are unstable depending on Figure 5: Performance of DaRE excluding core components; domain-aware feature extractor and review encoder the pairing of source and target, which reveals the limitation of DANN and MMT. Typically, in the case of Patio Lawn and Garden, AHN with single-domain achieves the best performance among all baselines. This result demonstrates that utilizing additional domains without considering noises can degrade the recommendation quality. In contrast, DaRE shows stable performance highlighting that its domain-aware feature extraction eî€ectively alleviates noises from the source domain. Knowledge transfer of overlapping users has limited contribution for the cross-domain recommendation quality.Some argued [19] that the knowledge transfer based on overlapping users has a limited impact on the overall performance. Note that DAREC, RC-DFM require duplicate users for a knowledge transfer. Speciî€›cally, DAREC, which utilizes rating information of duplicate users only, shows relatively low performance, again suggesting the usefulness of review information. Compared to DAREC, RC-DFM achieves the best performance for the two datasets. However, even excluding a knowledge transfer by removing duplicate users (selectingğ‘Œğ‘’ğ‘™ğ‘as a source domain), the performance of DAREC and RC-DFM varies insigniî€›cantly (no more than 1% on average). Though CATN utilizes auxiliary reviews of another user who gave the same rating, does not show outstanding performance in our experiments. Instead, DaRE eî€œciently utilize additional domain through the adoption of review texts, which is less restrictive for the selection of a domain. Summary.The performance of DaRE exceeds the state-of-theart single (AHN) and cross-domain (RC-DFM or MMT) approaches about 9.2 % and 3.6 %, respectively. We assume two variants of DaRE to show the inî€uence of excluding a domain-aware feature extractor and the review encoder. In Figure 5, the mean and variance of the variants of DaRE are plotted, with respect to each target domain. Here, the purple and green box denotes the performance of excluding domain-aware feature extractor (DaRE - Da), and review encoder (DaRE - RE), respectively. Domain-aware feature extraction is fundamental for debilitating noises.First, we exclude domain discriminator from Figure 6: With the output of FEs and review encoder, we highlight most similar words of user, itemâ€™s past reviews DaRE (DaRE - Da). Through Figure 5, we can see that the performance of DaRE - Da shows higher variance (purple boxes) compared to DaRE - RE (green boxes), suggesting the domain discrepancy is critical for overall performance. For example, in Figure 5-(b), the adoption of Yelp as source domain leads to the performance improvement for Instant Video (IV), while the selection of Toys and Games (TG) can degrade the recommendation quality. Review encoder contributes to the overall performance signiî€›cantly.Compared to DaRE - Da, DaRE - RE shows relatively stable results independent of a category of source domain. Though the mechanism of domain-aware feature extraction eî€ectively controls the mismatches between two diî€erent domains, we notice that the excluding review encoders are critical for the recommendation quality. Speciî€›cally, we notice that DaRE - RE shows relatively lower performance compared to DaRE - Da except for Figure 5-(c). Here, we empirically show the signiî€›cance of utilizing a domainaware feature extractor, and the review encoder, respectively. Based on the above results, we contemplate that DaRE systematically improves the recommendation quality under the cross-domain scenario, through the integration of two novel mechanisms. To provide intuitive analysis, we investigate the interpretability of DaRE. We adopt Toys and Games and Automotive as source and target domains, respectively. Figure 6-(a) and 6-(b) denote speciî€›c user and item reviews in the target domain. 6-(c) is a review that the user has written after purchasing the item. A detailed aspect of this item can be available in Amazon Automotive with its code (id: B00002243X). First, we apply the common and target feature extractors for each review and retrieve its embedding vectorsğ‘‚, andğ‘‚, respectively. Then, for each word embedding in Figure 6-(a) and (b), we highlight the most similar words, e.g., cosine similarity, compared toğ‘‚andğ‘‚. Speciî€›cally, the blue highlighted words are the most similar to the output of the common feature extractor ğ‘‚, while the red highlighted words are the most similar to the output of the target feature extractorğ‘‚. As can be seen, the blue words are more related to the semantic meaning of words which can be domain-indiscriminative (e.g., nice and good quality), while red words are relevant to domain-speciî€›c knowledge (e.g., cable and vehicle). Similarly, in Figure 6-(c), we highlight top-2 similar words (green) compared to the output of review encoderğ¸, which is generated fromğ‘‚andğ‘‚. Here, a review encoder well captures (e.g., high quality and cable) that the user will be interested in. To summarize, DaRE not only well predicts the accurate rating (4.89 for 5.0) but also demonstrates the vitality of domain-aware feature extractor and review encoder for capturing the transferable knowledge and relatedness between the user and item. In this paper, we propose DaRE, a novel domain adaptation method utilizing review texts from multiple domains for a knowledge transfer. Compared to previous approaches, our method is able to capture domain-invariant and domain-speciî€›c information of diî€erent categories with the aid of domain-aware feature extraction. Moreover, we suggest the use of a review encoder, to better represent the attribute of reviews that the users will generate after purchasing a speciî€›c item. Extensive experiments and ablation studies on real datasets conî€›rm the superiority of our method which is independent of users and items of diî€erent domains. In Equation 13, we deî€›ne the two hyper-parametersğ›¼andğ›½to balance the signiî€›cance of domain and encoder loss. In Figure 7, the x-axis denotes the value ofğ›¼, the y-axis is the value ofğ›½, and the z-axis demonstrates MSE score. For a simpliî€›ed analysis, we Figure 8: Convergence analysis w.r.t. MSE score for test data simply visualize the performance of a single target domain Instant Video, adopting Baby as a source domain. First, we start withğ›¼which denotes a weight hyper-parameter for a domain loss. Three feature extractors (FEs) are trained based on three losses. Generally, whenğ›¼becomes large, e.g., 1.0, the FEs focus on the minimization of domain loss, while disregarding the reduction of classiî€›cation loss (making an inaccurate prediction). On the contrary, whenğ›¼gets lower, e.g.,ğ›¼ =0, DaRE solely focuses on decreasing classiî€›cation loss, which is independent of domainaware feature extraction. Here, DaRE achieves the best performance if the value of ğ›¼ is 0.1. Likewise, forğ›½, the weight hyper-parameter aî€ects three FEs and the encoder to generate similar embeddings between the individual review and aggregated reviews. In our experiments,ğ›½with 0.05 shows better performance compared to other values. As can be seen, proportional to the value ofğ›¼andğ›½, the prediction error increases. Through a grid search, we systematically deî€›ne parameters,ğ›¼ =0.1 withğ›½ =0.05, which shows relatively higher performance compared to another value. For a convergence analysis, we plot the MSE score based on four target domain datasets in Figure 8. Each î€›gure demonstrates the MSE score of the target domain data based on four source domains, respectively. Here, we update the parameter of DaRE for 500 iterations. The x-axis and y-axis denote the number of iterations and MSE scores. At the beginning of training, DaRE shows relatively unstable performance due to the domain and encoding losses. As learning progresses, the domain and encoding losses decrease, leading to the convergence of parameters. Near 300 iterations, we can see that DaRE shows relatively stable results. Figure 9: Example of domain-aware feature extraction. We assume two phases: training and inference, with two different domains: Musical Instruments and Toys & Games for cross-domain recommendation scenario The domain labelğ‘‘, ğ‘‘consists of binary values, {0, 1} for source and target domain, respectively. Since a domain classiî€›cation can be identiî€›ed as a binary classiî€›cation task, to retrieve a domain loss, we adopt binary cross-entropy loss for calculation. First, we can induce a domain probability[bğ‘‘,bğ‘‘]with interleaved common features[ğ‘‚, ğ‘‚], respectively. The true label is [0,1], for source and target domain features. Here, we can deî€›ne a binary cross entropy loss for common features as follows: Figure 10: Example of review encoder. With user and itemâ€™s previous reviews, the encoder assumes a real feedback that user will leave after purchasing an item We can substitute domain labelsğ‘‘, ğ‘‘with[0,1], redeî€›ne Equation 18 as: Likewise, we can derive domain-speciî€›c losses with domainspeciî€›c featuresbğ‘‘,bğ‘‘as follows: Substitute domain labelsğ‘‘, ğ‘‘with[0,1], we can derive domainspeciî€›c losses L, L, which are deî€›ned in Equation 6. In Figure 9, we show an example of domain-aware feature extraction from a real-world benchmark dataset Amazon. The scenario assumes a training phase with source (Fig 9-(a), upper) and target (Fig 9-(b), lower) domain. The diî€erence is that a common FE (red box) is shared across domains, while the source and target FEs (green and blue boxes) are domain-speciî€›c networks. Taking Fig 9-(a) as an example, the objective is predicting a rating that a userğ´gives on item 2. Excluding individual review, userğ´ğ‘ review on item 2, the source and common extractors distillate latent of user and item respectively. Speciî€›cally, for user ğ´inğ‘€ğ‘¢ğ‘ ğ‘–ğ‘ğ‘ğ‘™ğ¼ğ‘›ğ‘ ğ‘¡ğ‘Ÿğ‘¢ğ‘šğ‘’ğ‘›ğ‘¡ğ‘ , a source FE captures domain-speciî€›c knowledge that she makes much of sound quality, while common FE extracts domain-common information like beautiful, and nice price. The analysis for item 2 follows the same mechanism. To summarize, our model not only considers domain-shareable knowledge with common FE but also reî€ects domain-speciî€›c information through the source and target FE. For the training of a review encoder, we utilize individual review that userğ´has written on item 2 (blue box) as another label. Taking Figure 10-(a) as an example, the review encoder (purple box) takes four types of inputs which are extracted from the source and common FEs. Then, the encoder generates a single output, which contains mixed information of userğ´and item 2. Here, the encoder is trained to infer an individual review, negative feedback of userğ´ who takes sound quality into account. Likewise, another encoder in a target domain can be trained in a same manner.
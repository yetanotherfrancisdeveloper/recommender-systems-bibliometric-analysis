Harvard-Smithsonian center for Astrophysics, 60 Garden St., Cambridge, MA 02138, USA Center for Computational Astrophysics, Flatiron Institute, 162 Fifth Avenue, New York, NY 10010, USA Institute for Computational Cosmology, Department of Physics, Durham University, Durham DH1 3LE, UK ABSTRACT We describe a method for generating halo catalogues on the light cone using the AbacusSummit suite of ğ‘-body simulations. The main application of these catalogues is the construction of realistic mock galaxy catalogues and weak lensing maps on the sky. Our algorithm associates the haloes from a set of coarsely-spaced snapshots with their positions at the time of light-cone crossing by matching halo particles to on-the-ï¬‚y light cone particles. It then records the halo and particle information into an easily accessible product, which we call the AbacusSummit halo light cone catalogues. Our recommended use of this product is in the halo mass regime of ğ‘€> 2.1 Ã— 10ğ‘€/â„ for the base resolution simulations, i.e. haloes containing at least 100 particles, where the interpolated halo properties are most reliable. To test the validity of the obtained catalogues, we perform various visual inspections and consistency checks. In particular, we construct galaxy mock catalogues of emission-line galaxies (ELGs) at ğ‘§ âˆ¼ 1 by adopting a modiï¬ed version of the AbacusHOD script, which builds on the standard halo occupation distribution (HOD) method by including various extensions. We ï¬nd that the multipoles of the auto-correlation function are consistent with the predictions from the full-box snapshot, implicitly validating our algorithm. In addition, we compute and output CMB convergence maps and ï¬nd that the auto- and cross-power spectrum agrees with the theoretical prediction at the subpercent level. Halo light cone catalogues for 25 base and 2 huge simulations at the ï¬ducial cosmology is available at DOI:10.13139/OLCF/1825069 Key words: methods: data analysis â€“ methods: ğ‘-body simulations â€“ galaxies: formation â€“ galaxies: haloes â€“ cosmology: theory, large-scale structure of Universe In the near future, galaxy surveys such as the Dark Energy Spectroscopic Instrument (DESI) survey (DESI Collaboration et al. 2016) and Euclid (LaureÄ³s et al. 2011) will measure the expansion history of the Universe and the growth of cosmic structure, which will enable us to understand the nature of dark matter and dark energy, and place constraints on cosmological parameters. This progress will be achieved through precise measurements of the galaxy clustering, baryon acoustic oscillations (BAO) peak, and weak lensing. However, in order to reach this level of precision, it is necessary to study and quantify the systematic uncertainties present in those surveys, which calls for the development of accurate mock catalogues (Baugh 2008). One beneï¬t of using a mock catalogue is that the â€˜trueâ€™ value of any statistic can be measured directly and unambiguously, so we can check how reliable our tools for analyzing real observations are. Another beneï¬t is that mocks allow us to test observational strategies and quantify levels of sample incompleteness. In many cases, it is not possible to assign a ï¬bre to every galaxy due to mechanical constraints (e.g. Hawkins et al. 2003; Guo et al. 2012; Burden et al. 2017; Hahn et al. 2017; Pinol et al. 2017) and even if a ï¬bre is assigned, the Â© 2021 The Authors redshift measurement can fail if the emission lines of the galaxy or the surface brightness are not strong enough. An incomplete sample may aï¬€ect signiï¬cantly the inferred clustering measurements, and in order to mitigate its eï¬€ects on the measured signal, we need to model it reliably and in detail. Mock catalogues with realistic galaxy populations can be generated by using cosmological ğ‘-body simulations. In order to obtain a measurement of the BAO peak, which is crucial for upcoming galaxy surveys, the volumes of these simulations needs to be a few Gpc. While producing a hydrodynamical simulation of that volume at the required level of resolution is currently unfeasible due to the computational expense, dark-matter-only simulations are much less expensive. The downside of using such simulations is that one needs to adopt a scheme for â€œpaintingâ€ galaxies on top of the darkmatter haloes. Several well-known population mechanisms are often adopted: the halo occupation distribution (HOD) (e.g. Peacock & Smith 2000; Seljak 2000; Scoccimarro et al. 2001; Berlind & Weinberg 2002; Kravtsov et al. 2004; Zheng et al. 2005), which describes the probability a halo with mass ğ‘€contains ğ‘galaxies; subhalo abundance matching (SHAM) (e.g. Vale & Ostriker 2004; Conroy et al. 2007), which relates directly subhalo properties (such as mass and circular velocity) to galaxy properties (such as luminosity and stellar mass); and semi-analytic models (SAMs) (e.g. Baugh 2006; Benson 2012; Somerville et al. 2008), which uses analytic prescriptions to model the formation and evolution of galaxies by usually utilizing the halo merger histories. A prerequisite for applying a SAM to a simulation is the existence of high-resolution merger trees, which are diï¬ƒcult to construct for large simulations. Nevertheless, there are approaches which can augment the resolution of the simulation merger trees (e.g. de la Torre & Peacock 2013; Angulo et al. 2014; Benson et al. 2016), but a lot of questions regarding the tuning of the various SAM parameters are still poorly understood. The SHAM prescription, on the other hand, requires a complete subhalo catalogue, which can be hard to obtain, since smaller-mass subhaloes often undergo multiple mergers, and the ability of a subhalo to survive a merger is strongly dependent on the resolution of the simulation. Finally, the HOD prescription can be applied to lower-resolution simulations because satellite galaxies do not need to be placed on subhaloes but instead, can either follow an analytical distribution or the dark-matter particle distribution (e.g. Angulo & White 2010). The ideal procedure for emulating observations involves populating haloes with galaxies on a light cone that has been directly output from a simulation. However, most simulations only output snapshots at discrete times and thus, apply the HOD method to a single snapshot. The downside of using discrete time epochs is that the halo bias is constant in time rather than evolving with redshift, which aï¬€ects the clustering measurements. To ameliorate that eï¬€ect, one could join together multiple snapshots, but there would be discontinuities at the boundaries, and objects may appear multiple times at the boundary or be completely missing (e.g. Fosalba et al. 2015). Moreover, the baseline HOD and SHAM techniques do not take into consideration evolution of the galaxy population, although there have been attempts in SHAM modeling that aim to, e.g., reproduce the observed stellar mass function at diï¬€erent redshifts (Moster et al. 2010). As for the HOD method, there is currently no robust way to model its evolution, as it is strongly dependent on the type of galaxies under study. For example, Nicola et al. (2020) allow for time evolution of the HOD parameters by Taylor expanding them as a function of scale factor and constraining both their ï¬ducial values as well as their ï¬rst derivatives. Karim et al. (2021) adopt an interpolation scheme for obtaining the HOD parameters at diï¬€erent redshifts, while Contreras et al. (2015) use SAMs to parametrize their evolution. In this paper, we describe the halo light cone catalogues of the AbacusSummit simulation, which are designed for generating realistic mock catalogues that meet the requirements of current galaxy surveys. Our procedure involves the following steps. First, we construct a halo light cone catalogue from the simulation by interpolating the positions of haloes between snapshots, using merger tree information. We then ï¬nd the subsampled particles belonging to the haloes in the on-the-ï¬‚y particle light cones, obtaining a light cone catalogue with haloes and particles. We recommend using this product in the halo mass regime of ğ‘€> 2.1 Ã— 10ğ‘€/â„, corresponding to haloes with 100 or more particles. This catalogue can then be easily populated with galaxies using an HOD prescription, reproducing the observed eï¬€ect of measuring clustering on the sky. In an accompanying paper (Yuan et al. 2021), an augmented HOD method for populating dark-matter haloes from the AbacusSummit simulation is described. This paper is organized as follows: Section 2 presents the AbacusSummit simulation and accompanying products, such as particle subsamples, merger trees, and light cones. Section 3 outlines the method for generating the halo light cone catalogues, and Section 4 tests it. We describe some potential applications of the halo light cone catalogues in Section 5 by comparing mock catalogues obtained MNRAS 000, 1â€“16 (2021) on the light cone with those coming from a full simulation snapshot and testing predictions of cross-correlation measurements with CMB lensing. Section 6 summarizes our main results and conclusions. The AbacusSummit suite of high-performance cosmological ğ‘body simulations (Maksimova et al. 2021) is designed to meet the Cosmological Simulation Requirements of the Dark Energy Spectroscopic Instrument (DESI) survey and run on the Summit supercomputer at the Oak Ridge Leadership Computing Facility. The simulations are run with Abacus (Garrison et al. 2019, 2021), a highaccuracy cosmological ğ‘-body simulation code, which is optimized for GPU architectures and for large-volume, moderately clustered simulations. Abacus is extremely fast, performing 70 million particle updates per second on each node of the Summit supercomputer, and also extremely accurate, with typical force accuracy below 10. The near-ï¬eld computations run on a GPU architecture, whereas the far-ï¬eld computations run on CPUs. For full details on all data products, see Maksimova et al. (2021). The AbacusSummit halo light cone catalogues are available at DOI:XXXXX for the 25 base simulations (AbacusSummit_base_c000_ph{000-024}) and the two huge the ï¬ducial AbacusSummit cosmology: Î©â„= 0.02237, Î©â„= 0.02237, â„ = 0.6736, 10ğ´= 2.0830, ğ‘›= 0.9649, ğ‘¤= âˆ’1, ğ‘¤= 0. The box sizes of the base and huge simulations are 2000 Mpc/â„ and 7600 Mpc/â„, respectively, whereas the particle masses are ğ‘€= 2.1Ã—10ğ‘€/â„ and ğ‘€= 2.1Ã—5Ã—10ğ‘€/â„ corresponding to 6912and 8640particles. The halo light cone catalogues have been designed with the aim of supporting the construction of mock catalogues using halo occupation distributions and enabling eï¬ƒcient access to measurements of the density ï¬elds. The base catalogues are generated for the redshift epochs: ğ‘§ = 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.575, 0.65, 0.725, 0.8, 0.875, 0.95, 1.025, 1.1, 1.175, 1.25, 1.325, 1.4, 1.475, 1.55, 1.625, 1.7, 1.775, 1.85, 1.925, 2.0, 2.25, 2.5. And the huge catalogues are available for all epochs until ğ‘§ = 2.25. In the next sections, we summarize the AbacusSummit products that we utilized in the creation of the halo light cone catalogues. Particle subsamples are available at 12 primary and 21 secondary redshift epochs. They are composed of two subsamples, A and B, covering 3% and 7% of all particles, respectively. The subsampled particles are selected randomly and are consistent across redshift, which enables us to associate halo catalogues to the light cones and also to build merger trees. The intended use of the subsamples is to serve as proxies for satellite galaxies in galaxy-halo models. 0.1, 0.2, 0.3, 0.4, 0.5, 0.8, 1.1, 1.4, 1.7, 2.0, 2.5, and 3.0. At these epochs, we output the positions, velocities and IDâ€™s of the subsamples. For the 21 secondary redshifts, covering redshifts ğ‘§ = 0.15 âˆ’ 8.0, we only output the particle IDâ€™s. The particle IDâ€™s also encode information about the Lagrangian positions of the particles, their â€œlocal densityâ€ and whether they have been part of the largest L2 halo (within an L1). The base resolution AbacusSummit boxes include a light cone stretching from the corner of the main box and two periodic copies of that box, seamlessly attached to it in the ğ‘¦ and ğ‘§ directions (see Fig. 1). The exception to that are the AbacusSummit huge boxes, which place the observer at the centre of the box and utilize only a single copy of the box. At the base resolution of the AbacusSummit boxes (6912particles, 2 Gpc/â„ box), the halo light cone catalogues cover an octant of the sky to ğ‘§ â‰ˆ 0.8 and about 1800 degextending to ğ‘§ â‰ˆ 2.45. The huge boxes (8640particles, 7.5 Gpc/â„ box) provide light cone information of the full sky until ğ‘§ â‰ˆ 2.18 and extend further towards the corners of the box. At every timestep, Abacus identiï¬es particles that belong to the light cone and outputs their positions, velocities, particle IDs, and HEALPix pixel number, which can be used to form projected density maps. The pixel orientation is such that the +ğ‘§ direction coincides with the North Pole. The HEALPix maps are output from all particles with resolution of ğ‘= 16384, which is more than suï¬ƒcient for performing accurate weak lensing analysis, whereas the particle outputs contain only a 10% subsample of the particles, the so-called A and B subsamples (see Section 2.1). Storing all particles in the form of high-resolution HEALPix maps required setting aside only 0.3 bytes per particle after compression, which is a much smaller expense than storing all particles individually. For more details on these products, we refer the reader to Maksimova et al. (2021). The geometrical arrangement of the light cones is shown in Fig. 1. For a simulation with box length of 2000 Mpc/â„ on a side, the light cone observer is positioned at (-990, -990, -990), or, in other words, 10 Mpc/â„ inside the corner of the original box. Three boxes form the eligible space of the light cone, centered at (0, 0, 0), (0, 0, 2000), and (0, 2000, 0), respectively (measured in Mpc/â„ units). Particles are output from every time step, where their trajectories are linearly interpolated to ï¬nd the time when the light cone intersects their paths. Their positions and velocities are updated to this time. This provides an octant to a distance of 1990 Mpc/â„ (ğ‘§ â‰ˆ 0.8), shrinking to two patches each about 900 square degrees at a distance of 3990 Mpc/â„ (ğ‘§ â‰ˆ 2.45). For the huge boxes (ğ‘ = 8640and ğ¿= 7500 Mpc/â„), the light cone is simply one copy of the box, centered at (0, 0, 0), providing a full-sky light cone to the the half-distance of the box (3.75 Gpc/â„), and further toward the eight corners. In Fig. 2, we show a narrow strip of the light cone stretching from the corner of the original box (starting at ğ‘§ = 0.1) to the corner furthest from it, belonging to a copy of the box, at a distance of âˆ¼ 4900 Mpc/â„. The observer sits at the top left of the ï¬gure, where the structures seen have formed most recently. The bottom right corresponds to the most distant time epochs that have available light cone outputs. Haloes in AbacusSummit are deï¬ned using the Competitive Assignment to Spherical Overdensities (CompaSO) halo ï¬nder (Hadzhiyska et al. 2021a), an optimized on-the-ï¬‚y method for identifying groups of particles in cosmological ğ‘-body simulations. CompaSO builds upon existing spherical overdensity (SO) algorithms by taking into consideration the tidal radius around a smaller halo before competitively assigning halo membership to the particles. In this way, the CompaSO ï¬nder allows for more eï¬€ective deblending of haloes in close proximity of each other as well as the formation of new haloes on the outskirts of larger ones. It further requires that a particle that becomes a halo centre has the highest local density among its immedi- Figure 1. Visualization of the geometrical arrangement of the AbacusSummit light cones. The original box, of length 2000 Mpc/â„, is centered at (0, 0, 0), while two identical copies are placed at (0, 0, 2000) and (0, 2000, 0) Mpc/â„. The observer is located at the corner of the original box, at (-990, -990, -990) Mpc/â„. ate neighbors. CompaSO is developed as a highly eï¬ƒcient on-the-ï¬‚y group ï¬nder, which is crucial for enabling good load-balancing between the GPU and CPU and the creation of high-resolution merger trees. Halo ï¬nding is performed with a density threshold of 200 times the mean density, level-1 (L1), and 800 times the mean density, level-2 (L2). However, the AbacusSummit halo catalogues store only L1 halo information. The centre-of-mass of the largest L2 subhalo is used to deï¬ne the centre relative to which all L1 halo statistics are output. For a detailed description of the algorithm, performance tests and comparisons with other halo ï¬nders, see Hadzhiyska et al. (2021a). The merger tree method used in AbacusSummit tracks the cores of haloes to determine associations between objects across multiple timeslices and records information about their progenitors and descendants. For details on the merger tree algorithm, we refer the reader to Bose et al. (2021). For each halo, the method identiï¬es the list of progenitor (Progenitor) haloes as well as the main progenitor (MainProgenitor) halo at the preceding redshift catalogue that share a substantial fraction of their particles with the halo at the present catalogue. We use the progenitor history of the halo to determine its trajectory through time and interpolate to get its position and velocity at the time of intersection with the observerâ€™s light cone. The choice of whether an object is identiï¬ed as a halo by any haloï¬nding algorithm can be somewhat arbitrary. In the case of SO-based Figure 2. Visualization of the particle light cone, showing a narrow strip of width 80 Mpc/â„ and thickness 10 Mpc/â„, stretching from the corner of the original box, (-990, -990, -990) Mpc/â„, to the corner of one of the box copies (1000, 3000, 1000) Mpc/â„, and covering a comoving distance of nearly 4600 Mpc/â„. MNRAS 000, 1â€“16 (2021) methods (as is the case for CompaSO), the halo boundary is starkly determined by the SO threshold density, while for FoF-based ï¬nders, it is strongly dependent on the linking length parameter. This choice becomes even more challenging in dense regions of the simulation as well as for merging haloes and splashback events, where dynamical processes such as ï¬‚y-bys, partial mergers, splits often take place. To overcome these issues in AbacusSummit, we have â€˜removedâ€™ objects in the CompaSO halo catalogues that may have been compromised. Haloes ï¬‚agged as unphysical have their masses added to a massive neighbour that they share history with at the time they attain peak mass. The aggregated halo remains merged for all subsequent outputs, and the ï¬‚agged halo is removed from the halo catalogue at each of the subsequent outputs. The particle list of the aggregate halo is the union of the particles of the original halo and all haloes that have been merged with it. The AbacusSummit halo light cone catalogues are designed to generate mock catalogues via the AbacusHOD model, a sophisticated routine hat builds upon the baseline HOD model by incorporating various generalizations pertaining to halo-scale physics and assembly bias. AbacusHOD allows the user to specify diï¬€erent tracer types: emission-line galaxies (ELGs), luminous red galaxies (LRGs), and quasistellar objects (QSOs). The AbacusHOD model is based on the GeneRalized ANd Diï¬€erentiable Halo Occupation Distribution (GRAND-HOD) model (see Yuan et al. 2018) and is described in detail in Yuan et al. (2021). The decorations parameters incorporated in the AbacusHOD model are listed below: â€¢ s is the satellite proï¬le modulation parameter, which modulates how the radial distribution of satellite galaxies within haloes deviate from the radial proï¬le of the halo. â€¢ s_v is the satellite velocity bias parameter, which modulates how the satellite galaxy peculiar velocity deviates from that of the local dark matter particle. â€¢ alpha_c is the central velocity bias parameter, which modulates the peculiar velocity of the central galaxy. â€¢ s_p is the perihelion distance modulation parameter. â€¢ A_c or A_s are the concentration assembly bias parameters for centrals and satellites, respectively. â€¢ B_c or B_s are the environment assembly bias parameters for centrals and satellites, respectively. To deï¬ne halo environment, we adopt the same formalism as Hadzhiyska et al. (2020). We note that the assembly bias implementation preserves the overall galaxy number density by reranking haloes based on their pseudomass. In this section, we describe the algorithm for obtaining the halo light cone catalogues of AbacusSummit by combining information from the merger trees, cleaned CompaSO halo catalogues, and the particle light cones. The ï¬nal product includes various statistical properties of the haloes and spatial information about the particles, which can be used to generate mock catalogues. Here we describe the method for the AbacusSummit base simulations, but the general approach remains the same for all boxes. The intended application of the AbacusSummit halo light cone catalogues is the construction of high-ï¬delity mocks for galaxy clustering and weak lensing surveys. For this reason, we take special care to output as accurately as possible the interpolated velocities and positions of the haloes, which are utilised as proxies for the central galaxies. The satellites are selected from the particle subsamples. An accurate placing of the centrals and satellites is key to modeling large-scale structure probes such as galaxy clustering and lensing measurements in redshift surveys. The catalogues are designed to support galaxy embeddings via the AbacusHOD script (see Section 2.6), but can also be used independently. One route for obtaining such catalogues is to run a halo ï¬nder on all particles on the light cone with a halo boundary that evolves with comoving distance. This requires storing a huge amount of particle data, which is infeasible for a simulation suite as large as AbacusSummit. Another approach is to use the halo information from the full-box redshift catalogues to construct halo light cones. The simplest method to select haloes for the light cone is with a â€œcookie cutterâ€, where the halo allegiance to a light cone catalogue is determined solely by its momentary position at some redshift epoch. However, this method suï¬€ers from several issues: In practice, the haloes are not stationary but instead traverse a non-negligible distance between any two redshift catalogues. Therefore, by assuming that they are at rest, we risk duplicating and missing haloes that reside on the boundary between two redshift epochs. In addition, this would also lead to an unphysically large diï¬€erence between the halo position and the positions of its particles, which would in turn alter the onehalo term and the cross-correlation measurement between galaxies and the matter ï¬eld. The approach we adopt in AbacusSummit, however, is more sophisticated, since the main application is the forward modeling of cosmological surveys. The aim of the algorithm is to ï¬nd the position and properties of the haloes at the time of light cone crossing, using a combination of interpolation and particle matching. The interpolation is done using merger tree information: knowing a haloâ€™s position, velocity, and mass at the current epoch and its main progenitor in the previous epoch, one can interpolate these properties to the moment of light-cone crossing. While the particle light cones are output with excellent time granularity (every Abacus time step, i.e. Î” log ğ‘ âˆ¼ 0.001), the redshift catalogues, and thus the merger tree associations, are output only at epochs corresponding to the primary and secondary redshifts. However, this output resolution is suï¬ƒcient for reliably tracking the dense cores of haloes across time and ï¬nding their light-cone crossing times. Before proceeding with the details of the algorithm, we oï¬€er an estimate of the error introduced by interpolation (we measure such eï¬€ects in Section 4). The initial step is to linearly interpolate the halo positions and velocities between the coarser redshift catalogues, assuming that the halo trajectories are kinematic. The bulk velocity of a typical halo is highest, 500 km/s (0.5 kpc/Myr), at low redshifts, ğ‘§ . 0.5. The redshift catalogues there are spaced by Î”ğ‘§ = 0.05 (Î” log ğ‘ â‰ˆ 0.04, or âˆ¼500 Myr), so on average the haloes would move by âˆ¼300 kpc. The distance traveled is, thus, small enough that the assumption of linear motion does not contribute substantial bias to the interpolation. This is in fact a conservative estimate, as a fraction of the halo velocity comes from the infall of haloes into large clusters. Alternatively, one can compare the halo crossing time to the time intervals between the redshift catalogues. The time interval between two redshift catalogues expressed in units of the redshift-dependent Hubble time is given by Î”ğ‘¡ = Î” log ğ‘/ğ» (ğ‘). The halo crossing time is given by ğ‘¡= 2ğ‘…/ğ‘‰, withî° ğ‘‰=2ğº ğ‘€/ğ‘…and ğ‘€= 4/3ğœ‹ğ‘…Î”(ğ‘)ğœŒ(ğ‘), where ğœŒ(ğ‘) = 3ğ»(ğ‘)/(8ğœ‹ğº) is the redshift-dependent critical density of the Universe and Î”(ğ‘) is the virial density contrast, which in Abacus is given by the ï¬tting function (Bryan & Norman 1998): Î”(ğ‘) â‰¡ Î”= (200/18ğœ‹) (18ğœ‹+ 82ğ‘¥ âˆ’ 39ğ‘¥) with ğ‘¥ = Î©(ğ‘) âˆ’ 1 (Hadzhiyska et al. 2021a). Simplifying, weî° obtain ğ‘¡= 2/(Î”(ğ‘)ğ»(ğ‘)). For ğ‘§ . 0.5, Î” log ğ‘ â‰ˆ 0.04 and Î”(ğ‘) â‰ˆ 110, so the time interval is Î”ğ‘¡ â‰ˆ 0.04/ğ» (ğ‘) and the crossing time is ğ‘¡â‰ˆ 0.2/ğ» (ğ‘). Thus, the time interval between the catalogues is about 20% of the crossing time of haloes, demonstrating that we retain accuracy in interpolating between the redshift epochs to track the motion of haloes. The ï¬rst step in this process is ï¬nding the haloes that intersect the observerâ€™s light cone for each redshift catalogue. This task is realized by using the halo catalogues and the halo merger trees, described in Section 2.4. The halo light cone catalogues are segmented into redshift catalogues, starting at ğ‘§= 0.1 and ï¬nishing at ğ‘§= 8. A catalogue at redshift ğ‘§corresponds to a comoving distance to the light coneî‚¯ ğœ’, with ğœ’=ğ‘ğ‘‘ğ‘¡/ğ‘(ğ‘¡), ğ‘¡the present time, and ğ‘¡â‰¡ ğ‘¡ (ğ‘§). We aim to select haloes that cross the light cone between ğ‘§and ğ‘§. The â€œhalf redshiftsâ€, ğ‘§, are deï¬ned as ğ‘§((ğœ’+ ğœ’)/2). We diï¬€erentiate between haloes with merger tree information and haloes without merger tree information, i.e. haloes at ğ‘§whose main progenitor has been successfully identiï¬ed in the previous catalogue, When merger tree information is available, we compute the time at which each halo is crossed by the light cone to determine whether it belongs to the halo catalogue, ğ‘§. (i) We ï¬rst compute the distance between each halo in the current epoch (ğœ’) and the light cone origin, ğ‘Ÿ, the distance between the haloâ€™s main progenitor in the preceding epoch (ğœ’) and the origin, ğ‘Ÿ, and the distance between the haloâ€™s descendant in the next epoch (ğœ’) and the origin, ğ‘Ÿ. (ii) We determine the comoving distances to the light cone crossing time, ğœ’, for all haloes in the catalogue by assuming that they move radially with a constant velocity given by (ğ‘Ÿâˆ’ğ‘Ÿ)/(ğœ’âˆ’ğœ’). For haloes with light cone crossing times between ğœ’< ğœ’< ğœ’, the interpolation is obtained via: whereas if ğœ’â‰¤ ğœ’â‰¤ ğœ’, it is (iii) Once we have determined the comoving distance ğœ’, we interpolate to ï¬nd the mass, position and velocity of the halo at the time of crossing, assuming that the halo moves in a straight line at a constant velocity between the two epochs and that its mass changes linearly: MNRAS 000, 1â€“16 (2021) Figure 3. Percentage of haloes at ğ‘§ = 0.8 whose main progenitor in the preceding redshift (ğ‘§ = 0.875) is not identiï¬ed. The eï¬€ect is most pronounced for small-mass haloes and about 5% of the haloes with âˆ¼100 particles, 2.5% of the haloes with âˆ¼1000 particles, and 1% of the haloes with âˆ¼10000 particles. where ğ‘ = {x, v, ğ‘€} can stand for position, velocity or mass. (iv) In order to avoid the duplication of particles in multiple haloes, before proceeding with the next redshift, ğ‘§, we mark ineligible for future consideration the progenitors of all selected haloes When no merger tree information is available, we only select haloes whose distances to the observer at the current redshift, ğ‘§, lie between ğ‘§and ğ‘§. Their interpolated velocities and masses are copied over from their â€œstationaryâ€ equivalents at ğ‘§, whereas the interpolated (comoving) position is obtained via: x= x+ v[ğ‘¡ (ğ‘Ÿ) âˆ’ ğ‘¡ (ğœ’)] (1 + ğ‘§ where ğ‘¡(ğ‘Ÿ)is the proper time corresponding to the comoving distance of each halo to the light cone origin and ğ‘¡ (ğœ’) is the proper time of the ğ‘–-th redshift catalogue. At a given redshift, the objects without merger associations make up about 1/3 of all haloes (since a large portion of the haloes are small and hard to track in time), but only about 5% of the haloes with âˆ¼100 particles, 2.5% of the haloes with âˆ¼1000 particles, and 1% of the haloes with âˆ¼10000 particles (see Fig. 3). To clean up the selection of haloes, we follow these additional steps: â€¢ We discard haloes and their particles from the edges of the light cones, since they cannot reliably be matched to the light cone particles due to the periodic boundary conditions. The light cone edges are deï¬ned as 10 Mpc/â„ within the boundaries of the light cone boxes, i.e. we retain haloes with coordinates âˆ’990 Mpc/â„ < ğ‘¥ < 990 Mpc/â„, âˆ’990 Mpc/â„ < ğ‘¦ < 3000 Mpc/â„, and âˆ’990 Mpc/â„ < ğ‘§ < 3000 Mpc/â„. â€¢ We also remove all repeated haloes and their particles (about 0.4% overall), keeping only the ï¬rst instance of each halo. These instances occur because at any redshift catalogue there is a small number of instances where haloes point to the same main progenitor. This is typically the case for the most massive haloes (about 25% of the haloes with 10000 particles), since they have more complex substructure that occasionally gets arbitrarily segmented into several distincts haloes. Special care is taken for haloes on the boundary between two boxes (i.e. the original one and each of the two copies), where we keep the unique haloes located closer to the observer at (-990, -990, -990) Mpc/â„. Note that this choice preserves the small fraction of overlapping haloes in the two copies of the original box, which inevitably appear in redshift catalogues beyond ğ‘§ & 0.8 due to the geometry of the light cones. â€¢ Finally, we clean the haloes that have been deemed â€œunphysicalâ€ by the merger tree cleaning algorithm (see Section 2.5) and record the halo properties of the surviving CompaSO objects. We thus eliminate all the â€˜removedâ€™ haloes and add their particles to a more massive companion that they share recent merger history with. Associating particle lists with the halo catalogues is useful for providing a proxy for the placement of satellite galaxies in a mock catalogue and also for reï¬ning and testing our interpolation technique by examining the spatial distribution of the particles. We match the subsample A and B particles (3% and 7%, respectively) belonging to the selected haloes from Section 3.2 to the light cone outputs. Note that the light cone outputs are available for all three boxes (see Fig. 1), but haloes in catalogues with ğ‘§ < 0.8 come solely from the original box. We record the position and velocity on the light cone of each matched particle in the halo catalogues. We do not include in the halo light cone catalogues the particles that have no matches in the light cone catalogues. The unmatched particles constitute âˆ¼0.0003% of the total, and upon visualizing them, we ï¬nd that they are located exactly at the boundary between two light cone shells. The most likely explanation for why those particles are missing is that they have traversed a larger than anticipated distance in the radial direction (relative to the observer), jumping to the next shell and escaping the output condition of the Abacus code. Since those events are extremely rare and aï¬€ect all haloes equally (regardless of their mass, position on the sky, etc.), we do not expect them to cause any substantial problems with the generated mock catalogues and the inferred large-scale structure probes. The data for each halo light cone catalogue is stored in two ï¬les, lc_halo_info.asdf and lc_pid_rv.asdf: â€¢ lc_halo_info.asdf contains the summary statistics of the haloes. In addition to the standard halo properties computed for the largest L2 subhalo (see Section 2.3), which are documented in Maksimova et al. (2021), we record various interpolated quantities: the number of particles, N_interp; the centre of mass position of the largest L2 subhalo, pos_interp; the centre of mass velocity of the largest L2 subhalo, vel_interp; the averaged positions and velocities of the subsample A and B particles in each halo, pos_avg and vel_avg. The averaging procedure is more accurate for haloes containing many particles and can be used for testing the interpolation scheme as well as for placing central galaxies. The properties unique to the halo light cone catalogues are enumerated in Table 1. â€¢ lc_pid_rv.asdf contains the particle information, i.e. the positions, pos, and velocities, vel, of the subsample A particles for each halo. The reason we opt for the A particles is that 3% of the total output is more than suï¬ƒcient for our target application of painting satellite galaxies onto the particle subsamples by adopting halo occupation techniques. The low tail of the central galaxy halo-mass distribution is above 100 particles (âˆ¼ 2 Ã—10ğ‘€/â„) for all tracers of interest to current and near-future surveys, so the satellites are nearly always coming from halos with well above 100 particles and thus 3% is enough to provide satellite location proxies. The ï¬les are compressed to save space and can be loaded, read, and unpacked with the CompaSO reader, available at https:// github.com/abacusorg/abacusutils. For more details on the compression scheme, we refer the reader to Maksimova et al. (2021). In this section, we present tests of the validity of the halo light cone catalogues constructed using the algorithm described in the previous section. We perform a number of visual tests, consistency checks and compare theoretical predictions of the clustering with those inferred from galaxy mock light cone catalogues. Such tests were crucial, as they helped us identify implementation errors in the algorithm and also check that the interpolated positions and velocities did not introduce any unwanted features into the clustering measurements. As a useful visual examination of the halo light cone catalogues, we study their properties through a map of the overdensity and the gravitational tidal forces (Doroshkevich 1970; Hahn et al. 2007; Forero-Romero et al. 2009). The tidal tensor, deï¬ned as the Hessian of the gravitational potential, is symmetric and therefore can always be diagonalized at any point in space. In this section, we also display the eigenvalues of the tidal tensor, which inform us of the strength of the tidal forces in independent orthogonal directions. Below we outline the method for computing the projected halo overdensity and tidal tensor. For more details on the relationship between the two-dimensional quantities computed here and the standard three-dimensional deï¬nition (see Alonso et al. 2016). Throughout the analysis, we use the HEALPix pixelization scheme (GÃ³rski et al. 2005) with a resolution parameter ğ‘= 128, corresponding to pixels with an area of âˆ¼ 0.21 deg. (i) We compute the overdensity ï¬eld on the full sky by counting the number of haloes in each pixel ğ‘and dividing by the average number of haloes per pixelÂ¯ğ‘. The ï¬eld in pixel ğ‘ is then given by: (ii) In order to suppress the numerical noise in the subsequent computation of derivatives on the sky, we ï¬rst smooth the overdensity ï¬eld using a Gaussian smoothing kernel, with standard deviation Î”ğœƒ = 1. (iii) We then compute the two-dimensional gravitational potential ğœ™, from the smoothed density ï¬eld ğ›¿ by solving Poissonâ€™s equation on the sphere, which in harmonic space states: ğœ™= âˆ’ğ›¿â„“(â„“ + 1) (iv) The two-dimension tidal tensor is obtained by diï¬€erentiating the potential, i.e. ğ‘¡â‰¡ ğ»ğœ™, where the Hessian operator is given Ë†ğ» â‰¡ğœ•ğœ•(ğœ•/sin ğœƒ)ğœ•(ğœ•/sin ğœƒ) ğœ•/sinğœƒ + cot ğœƒğœ• Here we compute the Hessian using the routines provided by HEALPix, which perform the derivatives in harmonic space. The tidal tensor in each pixel is then diagonalized to obtain the two eigenvalues (ğœ†â‰¥ ğœ†). Since the observer is placed at the centre of the huge box, at (0, 0, 0), full-sky light cones are available for the AbacusSummit huge Table 1. Partial list of the halo ï¬eld names for a single output redshift of the AbacusSummit halo light cone catalogue. For a full list of the missing ï¬elds, see Maksimova et al. (2021). The ï¬eld names shown here are reported only in the halo light cone catalogs. Note that all quantities are computed using the particles in the L2 largest subhalo of each halo. simulation (until ğ‘§ = 2.18). For this exercise, we choose AbacusSummit_huge_c000_ph201, which has ğ‘ = 8640particles and a size of ğ¿= 7500 Mpc/â„. In Fig. 4, we show the projected halo overdensity, and the largest and smallest eigenvalues of the tidal tensor ï¬eld (top and bottom, respectively). The sum of the eigenvalues maps recovers the projected overdensity. We have selected all haloes between redshifts ğ‘§ = 0.8 and ğ‘§ = 1.1, corresponding to comoving distances of 1937 and 2455 Mpc/â„. While the light cones of the AbacusSummit huge boxes cover the entire sky (41253 deg), the AbacusSummit base boxes cover a smaller fraction, since the observer is not placed at the centre of the box, but rather at the very corner of the original box (see Fig. 1). For closer redshifts (ğ‘§ â‰¤ 0.8), the light cone information that reaches the observer comes from the original box and thus covers roughly an octant of the sky (âˆ¼5300 deg), while at more distant redshifts, there are contributions from the two copies of the original box. Geometrically, the most distant available light cone shell is located at ğœ’ = 3990 Mpc/â„, corresponding to ğ‘§ â‰ˆ 2.45, for which the observer sees two patches (coming from the two copies), each of area âˆ¼900 deg. Thus, at higher redshifts (0.8 â‰¤ ğ‘§ â‰¤ 2.45), the area coverage decreases from an octant of the sky to about 1800 degat ğ‘§ â‰ˆ 2.45. We illustrate this in Fig. 5. The gray dashed vertical lines indicate the primary and secondary redshifts, at which the halo light cone catalogues are available. The green solid vertical line shows the redshift of the furthest light cone shell, at ğ‘§ â‰ˆ 2.45, while the red solid horizontal line marks an octant of the sky for reference. We note there are primary and secondary redshifts available past ğ‘§ = 2.5, but those are not present in the halo light cone catalogues, so we have not included them in the ï¬gure. The area at a distance ğœ’ from the observer (or equivalently ğ‘§) is computed by transforming the HEALPix pixels on the sky into Cartesian coordinates located on the surface of a sphere of radius ğœ’ and calculating the number of Cartesian points that fall within the volume deï¬ned by the three copies of the box. Knowing the number of points that are located within the simulation volume, we can infer the area covered since the HEALPix pixels are equi-areal. As a consistency check, we study the number of haloes and particles as a function of distance to the observer or equivalently as a function of redshift, ğ‘§, which would allow us to diagnose any issues related MNRAS 000, 1â€“16 (2021) Figure 4. Density ï¬eld (top panel) and eigenvalues of the two-dimensional tidal tensor of the halo light cone catalogue at 0.8 < ğ‘§ < 1.1, smoothed with a 1Gaussian kernel, for the AbacusSummit_huge_c000_ph201 box with the observer placed at (0, 0, 0). Figure 5. Sky coverage (in deg) as a function of redshift, speciï¬c to the base geometry. The observer is located at (-990, -990, -990), and looking at three identical copies of the box centered at (0,0,0), (0, 2000, 0) and (0, 0, 2000). All units are reported in Mpc/â„. The red solid horizontal line corresponds to an octant of the sky, while the gray dashed vertical lines correspond to the secondary and primary redshift catalogues, at which the halo light cone catalogues are available. The green solid vertical line indicates the redshift of the furthest light cone shell, at ğ‘§ â‰ˆ 2.45, covering a total of 1800 degof the sky. to missing haloes or particles as well as discontinuities along the redshift borders. In Fig. 6, we show the number of haloes as a function of redshift. Since the number density of haloes in each redshift catalogue is expected to be similar, we normalize the histogram by dividing each bin by its comoving distance to the observer squared. The shape of the resulting curve roughly follows the curve of the sky coverage as a function of redshift, as expected (see Fig. 5). The contributions from the haloes in each redshift catalogue are painted in alternating colors to make the distinction between the catalogue boundaries clearer. In addition, we only include haloes containing at least 100 particles (ğ‘€= 2.1 Ã— 10ğ‘€/â„), as this is the mass regime relevant for constructing galaxy mock catalogues for the various tracers targeted by modern galaxy surveys, e.g. emission-line galaxies (ELGs), luminous red galaxies (LRGs), quasistellar objects (QSOs), and also the interpolation mechanism adopted in our treatment is more accurate for higher-mass haloes (since lower-mass haloes have less reliable merger tree information and noisier statistics due to the lower number of particles). We have averaging over three of the c000 simulations in order to diminish the larger variance in the number of haloes at small redshifts due to large-scale structure. Another consistency check that we perform is the measurement of the dispersion velocity of haloes, ğ‘£, belonging to the light cone catalogues as a function of their distance from the redshift boundary. In this way, we can check whether the interpolated velocities of the haloes, v, are biased (hotter or colder) relative to the velocities of the light cone particles, which is very important when creating realistic mock catalogues. Similarly, we also check that the radial proï¬les of the haloes are not biased by computing the analogous [(h/Mpc) /Ï‡(z) Figure 6. Number of haloes, normalized by the square of the comoving distance to the observer and the sky coverage (in rad, see Fig. 5), as a function of redshift. The gray dashed vertical lines correspond to the secondary and primary redshift catalogues, at which the halo light cone catalogues are available. The haloes selected for this ï¬gure contain at least 100 particles, which corresponds to a mass threshold of ğ‘€= 2.1 Ã— 10ğ‘€/â„ at the base resolution. We expect that for higher-mass haloes, the interpolation scheme we have adopted will be more accurate, since their merger tree history is easier to track. Coincidentally, the regime above N = 100 is relevant for creating galaxy mock catalogues with diï¬€erent tracers. quantity for the interpolated halo positions and particles, ğ‘¥. The two properties are calculated for each halo as follows: where ğ‘ can either stand for the position ğ‘¥ or velocity ğ‘£, ğ‘– is an index between 0 and ğ‘ âˆ’ 1, with ğ‘ the total number of halo particles. In Fig. 7, we show the dispersion velocity and the analogous spatial quantity as a function of redshift. Those are computed by averaging the quantity ğ‘in bins of interpolated redshift (i.e. redshift at which the halo is estimated to have crossed the light cone) for haloes containing diï¬€erent numbers of particles. There are two eï¬€ects contributing to the shape of each of these quantities. For ğ‘£, those eï¬€ects come from the evolution of the dispersion velocity with redshift, empirically found to follow the relation ğ‘£âˆ (1 + ğ‘§) (Posti et al. 2014), and from the fact that the particles marked as belonging to the halo are selected at a single discrete time, the output snapshot for that redshift (i.e. at ğ‘§ = 0.8). Those particles are thus not guaranteed to be within the virial radius of the halo at ğ‘§ â‰  0.8. This leads to a systemic â€œcoolingâ€ of the particle velocities, as we move away from ğ‘§ = 0.8 and similarly, a positive quadratic increase of the second moment, ğ‘¥. Furthermore, when computing the second moment, we have converted the comoving coordinates of the particles and the haloes into proper ones to account for the fact that haloes are expected to maintain their proper sizes over short periods of time. As can be seen from the ï¬gures all of these eï¬€ects are small (at most around 2-4%) and can be absorbed by enabling extra HOD parameters that model the satellite positions and velocities. The AbacusHOD prescription provides three parameters to that end, s_v, s, and s_p (see 2.6). As described in Section 3.4, we also record the average particle positions and velocities for each halo belonging to the halo light cone catalogues, where the particles belong to subsample A and B, and their positions and velocities are taken from the light cone outputs. For haloes with a smaller number of particles (N < 100), the 10% subsamples (i.e. coming from both A and B) might give noisy estimates of these quantities. However, for larger haloes, these two ï¬elds give a good representation of the halo bulk velocity and position. Our recommended use of the halo light cone catalogues is thus in the N & 100 regime. Note that some haloes may have complex substructure, in which case the averaged position might be biased relative to the location of the halo nucleus, i.e. the densest particle which initiates the CompaSO halo ï¬nding (see Hadzhiyska et al. 2021a). In addition, we evaluate the diï¬€erence between the interpolated and the averaged halo positions and velocities, q and q. We ï¬nd that the diï¬€erence |qâˆ’ q| for haloes in the mass range of 2500 to 5000 particles is âˆ¼30 kpc/â„ for the positions and âˆ¼40 km/s for the velocities. These uncertainties can be absorbed through the inclusion of additional HOD parameters that model the velocity and spatial bias of the central galaxy. For example, the AbacusHOD code considers the parameter alpha_c, which allow for a velocity displacement of the central galaxy relative to the peculiar velocity of the halo centre. The halo mass function is an essential tool in cosmology, as dark matter haloes play a key role in modeling galaxies and galaxy clusters and performing large-scale-structure analysis. It allows us to understand the statistics of primordial matter inhomogeneities and the eï¬€ects of nonlinear structure on observations through, for instance, the Sunyaev-Zeldovich eï¬€ect and lensing. Another feature of the halo mass function is that it can be expressed as a universal function that relates the mass of haloes to the variance of the mass ï¬‚uctuations (e.g., Press & Schechter 1974; Sheth & Tormen 1999; Jenkins et al. 2001; White et al. 2001; Springel et al. 2005; Warren et al. 2006). As an additional test of the halo light cone catalogues, we compute the halo mass function at redshift ğ‘§ = 0.8 using both the full-box and the light cone halo catalogues: ğ‘‘ğ‘(ğ‘€, ğ‘§) â‰¡ ğ‘ where we have deï¬ned ğ‘‘ğ‘as the number of haloes in the mass range ğ‘‘ log ğ‘€ between log ğ‘€ = log 2 Ã— 10and log ğ‘€ = log 2 Ã—10, in units of ğ‘€/â„. The halo mass function from the full box and the light cones is presented in Fig. 8 for the base simulation AbacusSummit_base_c000_ph006. The CompaSO halo masses are deï¬ned as the total number of particles in a halo ({N, N_interp}, see Table 1) multiplied by the particle mass, ğ‘€= 2.1 Ã— 10ğ‘€/â„. The number of particles {N, N_interp} is taken from the cleaned CompaSO catalogues. We use both the non-interpolated (N) and interpolated (N_interp) halo numbers of particles, shown in red and blue, respectively, as a test of the eï¬€ect of interpolation on the onedimensional halo statistics. The lower segment of the panel shows the ratio of the two curves to the black full-box curve. We note that we have imposed a mass cut of ğ‘€= ğ‘Ã—ğ‘€= 2.1 10ğ‘€/â„, where ğ‘= 100, since this is the regime for which the halo light cone statistics are most reliable. All three curves appear in excellent agreement with each other (âˆ¼0.1%) until 10ğ‘€/â„. At higher halo masses, the ratio is dominated by noise, as the halo light cone catalogue, which has a signiï¬cantly smaller volume, has fewer examples of massive haloes. MNRAS 000, 1â€“16 (2021) 1.000 0.998 0.996 0.994 0.992v= 248.5 1.07N= 1000 âˆ’ 2500, x= 0.056 1.06N= 2500 âˆ’ 5000, x= 0.076N= 5000 âˆ’ 20000, x= 0.104 Figure 7. Dispersion velocity (top panel) and second moment (bottom panel) of haloes of diï¬€erent masses belonging to the light cone catalogue at ğ‘§ = 0.8 as a function of redshift. The black dashed line indicates roughly the average value of the quantity at ğ‘§ = 0.8. The shape of the ğ‘£curve is the result of two eï¬€ects. The ï¬rst is the evolution of the dispersion velocity with redshift, ğ‘£âˆ (1 + ğ‘§)(Posti et al. 2014), which leads to an approximately linear increase of the curve with redshift. The second is related to the fact that the determination of which particles belong to the halo happens at ğ‘§ = 0.8. As a result, the dispersion velocities will be systemically lower, as we move away from ğ‘§ = 0.8 (in either direction). This eï¬€ect also applies in the case of ğ‘¥and appears as a quadratic contribution (see bottom panel). Note that we convert all comoving coordinates to proper ones when computing ğ‘¥, since haloes are expected to maintain their proper size. These eï¬€ects are small (around 2-4%) and can be largely absorbed through the inclusion of extended HOD parameters, e.g. s_v, s, and s_p (see 2.6). The main application of the halo light cones is in creating galaxy mock catalogues and weak lensing maps, which play a central role in developing the pipeline for current and future galaxy surveys such as DESI and Euclid. One of the most widely used methods to conduct this so-called forward modeling of galaxy surveys is by â€œpaintingâ€ them onto a halo catalogue assuming a simple empirical Figure 8. Halo mass function (halo number density as a function of mass) at ğ‘§ = 0.8. The black curve corresponds to the halo mass function in the full simulation box, whereas blue and red correspond to the halo mass function in the halo light cone catalogues computed using the N_interp and N ï¬elds, respectively. The lower panel shows the ratio between the halo light cone curves and the full box curve. Halo mass is computed as {N, N_interp} Ã— 2.1 10ğ‘€/â„. The agreement between the halo mass functions is excellent for smaller haloes and dominated by noise for larger haloes, of which we have very few examples in the thin light cone strips at ğ‘§ = 0.8. relation between halo mass and galaxy occupation. Since the halo occupation distribution (HOD) framework provides one of the most eï¬ƒcient ways of populating cosmological ğ‘-body simulations with galaxies and producing the many realizations required for, e.g., estimating covariance matrices (e.g. Norberg et al. 2009; Manera et al. 2013), we have augmented the halo light cone scripts, which can be found in https://github.com/abacusorg/abacusutils/ tree/master/abacusnbody/hod, with a modiï¬ed HOD prescription (see Yuan et al. 2021, and Section 2.6). Many of the current and future cosmological surveys will target starforming emission-line galaxies (ELGs) whose spectrum is characterized by prominent [O II] and [O III] emission lines. These galaxies will be selected by a combination of color-color and magnitude cuts. To model their halo occupation distribution correctly, which is vital to creating accurate mock galaxy catalogues, one can study ELGlike samples through hydrodynamical simulations. Hadzhiyska et al. (2021b) study the HOD of ELGs in the state-of-the-art hydrodynamical simulation IllustrisTNG (Springel et al. 2018; Nelson et al. 2019; Pillepich et al. 2019) at three diï¬€erent time epochs: at ğ‘§ = 0.8, 1.1 and 1.4. However, in order to populate the halo light cones with ELGs that exhibit similar occupation statistics to those in IllustrisTNG, we need to parametrize these HOD curves. We do so by adopting the High Mass Quenched (HMQ) model proposed in Alam et al. (2020) for the central probability of ELGs: hğ‘i(ğ‘€) = 2ğ´ğœ™(ğ‘€)Î¦(ğ›¾ ğ‘€)+ ğœ™(ğ‘¥) = N(logğ‘€, ğœ Î¦(ğ‘¥) =ğœ™(ğ‘¡) ğ‘‘ğ‘¡ =121 +erfğ‘¥âˆš The occupation statistics of the satellites are assumed to obey the standard functional form: For more details on the HMQ model and an interpretation of the various parameters, see Alam et al. (2020). The HOD parameters that ï¬t the IllustrisTNG ELG samples at the three redshifts ğ‘§ = {0.8, 1.1, 1.4} are given below: log ğ‘€= {11.8, 12, 12.2}, ğœ… = {1.8, 1.65, 1.5}, ğœ = {0.58, 0.58, 0.58}, log ğ‘€= {13.73, 13.73, 13.73}, We have obtained these by roughly matching the HODs shown in Hadzhiyska et al. (2021b). To obtain the HOD shape at intermediate redshifts and beyond ğ‘§ = 1.4, we linearly interpolate the parameters in Eq. 15 at each of the available halo light cone redshifts. For 0.45 < ğ‘§ < 0.8, we assume that the HOD shape is identical to that at ğ‘§ = 0.8. An advantage of having mock catalogues on the light cone is that they can be used to construct forward models of various large-scale structure tracers, which are invaluable for modern galaxy redshift surveys such as DESI and Euclid. Measuring redshift space distortions (RSD) has become a standard application of galaxy surveys (e.g. Blake et al. 2011; Howlett et al. 2015; Alam et al. 2017; Pezzotta et al. 2017). Studies of RSD clustering statistics exist in both conï¬guration space and Fourier space, each coming with its own beneï¬ts and challenges. Here, we will concentrate on the real-space statistics. The clustering anisotropy introduced due to galaxy velocities may be described by a multipole expansion of the correlation function with respect to the local line of sight (Cole et al. 1994; Hamilton 1998), which permits a powerful compression of the information. To estimate the multipoles, one needs to measure the correlation as a function of separation ğ‘Ÿ and angle ğœ‡. For a catalogue with an arbitrary redshift distribution and arbitrary survey boundaries, in addition to counting pairs of the galaxy tracers, one also needs to consider pair counts of randomly distributed objects, exhibiting the same redshift distribution and survey boundaries. The Landy-Szalay (LS) estimator (Landy & Szalay 1993) combines all possible correlations between data, ğ·, and randoms, ğ‘…, to calculate the underlying correlation function between two arbitrary tracers in a nearly optimal way: where the angle brackets denote normalized pair counts at separation ğ‘Ÿ and angle ğœ‡. We can decompose the redshift-space correlation function into multipoles using the Legendre polynomials ğ‘ƒ(ğœ‡) as: ğœ‰(ğ‘Ÿ) =ğœ‰(ğ‘Ÿ, ğœ‡)(1 + 2â„“)ğ‘ƒ where the correlations in Eq. 16 need to be computed in bins of ğ‘Ÿ and ğœ‡ before taking the ratio. To test the mock catalogues obtained on the light cone, we compute the monopole and quadrupole, following the prescription above. In addition, we construct a second sample from the â€œstationaryâ€ snapshot catalogues by selecting the galaxies within a spherical shell of average radius âˆ¼ 1330 Mpc/â„ and thickness âˆ¼ 140 Mpc/â„, centered at the observerâ€™s location, (-990, -990, -990) Mpc/â„. The shell parameters are chosen such that they correspond to the thickness and radius of the halo light cone catalogue at that redshift. RSD eï¬€ects have been applied to the galaxies prior to the shell selection. We also study the eï¬€ect on the galaxy correlation function when the RSD eï¬€ects are switched oï¬€. Fig. 9 demonstrates that the agreement between the shell snapshot catalogue and the light cone catalogue is very good on all scales for both the monopole and the quadrupole. In addition, we ï¬nd that the quadrupole signal vanishes when the RSD eï¬€ects are neglected due to the isotropical distribution of the galaxies. In this section, we describe our method for computing the convergence maps from the particle light cones. Adopting the Born approximation and assuming ï¬‚at space, the convergence ï¬eld for lensing distortions is given by ğœ…(ğœƒ) =2ğ‘ğ‘‘ğœ’ ğ›¿(ğœ’, ğœƒ)(ğœ’âˆ’ğ‘Ÿ)ğœ’ğœ’ğ‘(18) where ğ»= 100â„ km/s/Mpc is the Hubble constant, Î©is the energy density of matter, ğ‘ is the speed of light, ğ›¿ is the 3-D matter overdensity at radial distance ğœ’(ğ‘) (for a corresponding scale factor ğ‘), ğœƒ is the angular position, and ğœ’is the distance to the lensing source(s). This equation can be discretized and used to compute the convergence map in an ğ‘-body simulation by adding up the dark-matter shells in the light cone weighted by the weak-lensing kernel at each redshift. This can be done as follows (Fosalba et al. 2008): ğœ…(ğ‘–) =2ğ‘ğ›¿(ğ‘–, ğ‘— )(ğœ’âˆ’ ğœ’)ğœ’ğœ’ğ‘ğ‘‘ğœ’(19) where ğ‘– indicates the pixel position in the sky and ğ‘— the radial bin index (at distance ğœ’of width ğ‘‘ğœ’) into which we have sliced the simulation. Note that since AbacusSummit uses a basic prescription for neutrinos, modeling them as a smooth, non-clustering matter component (Maksimova et al. 2021), we need to consider the contribution only from the gravitational components, i.e. baryons and cold dark matter, Î©= Î©+ Î©. The AbacusSummit treatment of neutrinos captures accurately the suppression on small scales, but does not account for the neutrino clustering on large scales. However, this is a secondary eï¬€ect and does not matter for most applications relevant for galaxy surveys. Denoting the number of particles in pixel ğ‘– and slice ğ‘— as ğ‘, we compute the overdensity as: ğ›¿(ğ‘–, ğ‘— ) =ğœŒ(ğ‘–, ğ‘—)Â¯ğœŒ MNRAS 000, 1â€“16 (2021) where Â¯ğœŒ = hğœŒ(ğ‘–, ğ‘—)i is the mean density, which we compute analytically as (ğ‘/ğ¿)Î”Î© ğœ’ğ‘‘ğœ’, and ğœŒ(ğ‘–, ğ‘—) =ğ‘ğ‘‘ğ‘‰=ğ‘Î”Î© ğœ’ğ‘‘ğœ’(21) where Î”Î© is the area of each pixel. During their travel from the last scattering surface to the observer, CMB photons interact with the matter inhomogeneities and information about the large-scale clustering of the Universe gets imprinted onto the CMB temperature and polarization anisotropies. One of the ways in which matter and the CMB interact is through gravitational lensing, which causes small but coherent deï¬‚ections of the path of CMB photons. Careful modeling of this eï¬€ect enables the reconstruction of the gravitational potential integrated along the line of sight (Hu & Okamoto 2002; Hirata & Seljak 2003). A relatively novel approach to studying CMB lensing is through cross-correlations with other tracers of large-scale structure. This allows us to constrain the evolution of dark matter density ï¬‚uctuations and dark energy at the dawn of cosmic acceleration. Cross-correlation measurements also encode information about the cosmic bias and the eï¬€ective halo masses associated with the tracer populations. The advantage of gaining that information through the cross-power spectra as opposed to or in addition to the auto-power spectra is that cross-correlation measurements do not suï¬€er from systematics that are not correlated between the two data sets. Thus, they can uncover unforeseen systematics in either dataset as well as constrain the galaxy bias in an independent fashion. To compute the CMB convergence ï¬eld in AbacusSummit, we can assume that the distance to the lensing source is constant and equal to ğœ’(ğ‘§) â‰ˆ 13873 Mpc, which corresponds to ğ‘§= 1089.3 at the ï¬ducial cosmology and substitute it in Eq. 18. The AbacusSummit light cone geometry provides complete light cone information for 0.1 â‰¤ ğ‘§ â‰¤ 2.45 covering 1800 deg(split between two patches of equal area). All subsequent measurements of the angular power spectra discussed in the text are calculated on the masked map of area 1800 deg, corrected for the fraction of sky covered. Note that this does not span the entire active domain of the CMB lensing kernel, so we need to be careful when comparing simulation observables with theory. To this end, we perform the line-of-sight integration necessary for the theoretical predictions only within the redshift range 0.1 â‰¤ ğ‘§ â‰¤ 2.45. Having obtained the CMB convergence map, we can compare it with the theoretically estimated angular power spectrum from pyccl (Chisari et al. 2019) given by: ğ¶(ğœ…) =4ğ‘ğ‘‘ğœ’ ğ‘ƒ(ğ‘˜, ğ‘§)(ğœ’âˆ’ ğœ’)ğœ’ğ‘(22) where ğ‘ƒ(ğ‘˜, ğ‘§) is the three-dimensional density power spectrum in the simulation at redshift ğ‘§ evaluated at ğ‘˜ = ğ‘™/ğœ’ in the Limber approximation (Limber 1953), valid for ğ‘™ > 10 within a few percent accuracy (see e.g., Bernardeau et al. 2002). In addition to the auto-power spectrum of the CMB convergence ï¬eld, we can calculate the cross-correlation signal between any largescale structure tracer and the CMB convergence ï¬eld. Similarly to Section 5.1, we will work with an ELG sample, as ELGs will take up a sizable portion of the objects studied by many current and future cosmological galaxy surveys such as DESI and Euclid. To create the ELG mock galaxy catalogue on the halo light cone, we follow the Figure 9. The monopole (left panel) and quadrupole (right panel) of the ELG correlation function at ğ‘§ = 0.5 with and without RSD eï¬€ects (solid and dashed lines, respectively). In blue, we show the prediction from the halo light cone catalogues, whereas in red, we show the result from the full snapshot catalogues. The full-snapshot sample is constructed by selecting a spherical shell of thickness and radius equal to that of the light cone catalogue at that redshift (âˆ¼ 140 Mpc/â„) and applying RSD eï¬€ects in the direction of the observer at (-990, -990, -990) Mpc/â„. The agreement between the halo light cone and the snapshot shell for both the monopole and the quadrupole is very good, which serves as an implicit validation of the halo light cone catalogues. With the RSD eï¬€ects are switched oï¬€, the monopole ğœ‰becomes the real-space correlation function ğœ‰ (ğ‘Ÿ), so the quadrupole vanishes. This is conï¬rmed in the right panel, where we see that the quadrupole signal is consistent with zero for both samples. same approach as in Section 5.1. The redshift dependence of the HOD parameters is obtained by linearly interpolating (and extrapolating assuming constant derivatives) between the three redshifts for which we have studied ELGs using the hydrodynamical simulation IllustrisTNG (Hadzhiyska et al. 2021b): ğ‘§ = 0.8, 1.1, and 1.4. Assuming that the observed galaxy sample has a Gaussian redshift distribution ğ‘ (ğ‘§) centered at ğ‘§ = 1.1 and with standard deviation of Î”ğ‘§ = 0.15, we downsample the galaxies in our mock catalogue. The galaxy bias passed to pyccl is assumed to be redshift-dependent and given by ğ‘(ğ‘§) = 1.14/ğ· (ğ‘§), where ğ·(ğ‘§) is the growth factor at redshift ğ‘§. A comparison between the measured power spectra and their respective theoretical predictions are shown in Fig. 10. We ï¬nd that the agreement between theory and observations for â„“ > 100 is very good for all three combinations: galaxy-galaxy (ğ‘” Ã—ğ‘”), galaxy-convergence ï¬eld (ğœ… Ã— ğ‘”), and convergence-convergence (ğœ… Ã— ğœ…). In particular, the pyccl prediction for ğ¶diï¬€ers by about 0.1% from the AbacusSummit estimate., while ğ¶and ğ¶are consistent with theory at the 0.1% and 1.7% level, respectively. This diï¬€erence is within the margins of the theoretical error. We note that since light cone information is available only for 0.1 â‰¤ ğ‘§ â‰¤ 2.45, we set the CMB lensing kernel to zero outside of that redshift range. Future studies combining early Universe probes such as CMB lensing with the late-time galaxy distribution will measure with great accuracy the very small scales around â„“ âˆ¼ 10000. Therefore, it is important that the halo light cone catalogues do not suï¬€er from substantial biasing of the galaxy-matter cross-correlation, resulting from the interpolation techniques we have adopted (see Section 3). The haloes whose positions and velocities are likely to be the most strongly aï¬€ected by interpolation eï¬€ects have light-cone crossing redshifts, ğ‘§, near the mid-point between any two redshift catalogues. We, thus, deï¬ne two galaxy subsamples using the ELG main sample used in Fig. 10. The ï¬rst subsample (â€œcloseâ€) consists of all galaxies that have ğ‘§< ğ‘§<= ğ‘§for all redshift catalogues, ğ‘§, whereas the second one (â€œfarâ€) contains the rest of the galaxies in the sample. We then compute the galaxy-convergence ï¬eld crosscorrelation power spectrum, ğ¶and show the ratio for the two subsamples in Fig. 11. We do not see signiï¬cant deviations of this ratio from one, indicating that the interpolation procedure does not aï¬€ect the smallest scales of the galaxy . The amount of cosmological information we extract from current and future cosmological surveys depends crucially on the techniques we adopt to emulate realistic galaxy catalogues through simulations. These so-called mock catalogues are useful for developing analysis tools, assessing incompleteness, making predictions, and computing accurate covariance matrices. In this paper, we have described the procedure for obtaining halo light cone catalogues from the AbacusSummit simulation. We ï¬rst create a halo light cone from the merger trees by calculating the interpolated positions and velocities of each halo at the redshift at which it crosses the observerâ€™s lightcone. We then associate the particles belonging to these haloes with the particle light cone outputs. For the AbacusSummit base simulations with a mass resolution of 2.109 Ã—10ğ‘€/â„ and a box of size ğ¿= 2 Gpc/â„, the halo light cone catalogue covers an octant of the sky extending to ğ‘§ âˆ¼ 0.8, making use of a single copy of the box, and about 1800 degextending to ğ‘§ â‰ˆ 2.45 when we utilize two additional copies. For the AbacusSummit huge simulations, the light cone comes from a single copy of the box. This provides a full-sky light cone to the the half-distance of the box (3.75 Gpc/â„, corresponding to ğ‘§ = 2.18), and further toward the eight corners (e.g. half the sky till ğ‘§ = 3.2). The ï¬nal product can then be populated with galaxies using the augmented AbacusHOD prescription. We recommend using the halo light cone products in Figure 10. Auto- and cross-power spectra for the CMB convergence ï¬eld and an ELG sample with ğ‘ (ğ‘§) = N(ğœ‡ = 1.1, ğœ = 0.15) described in Section 5.1. In red, we show the cross-power spectrum between galaxies and the CMB convergence ï¬eld, while in blue and gray, we show the auto-power spectra for the galaxies and convergence ï¬eld, respectively. The agreement between the theoretical predictions and the computed power spectra is very good for â„“ > 100: ğœ… Ã—ğœ… and ğ‘” Ã—ğ‘” diï¬€er respectively by 0.1% and 0.1% from the pyccl curve, while ğœ… Ã— ğ‘” deviates by about 1.7%, which is within the theoretical error. Figure 11. Ratio of the galaxy-CMB lensing cross-correlation power spectra for two ELG subsamples. The ï¬rst subsample (â€œcloseâ€) contains galaxies with light-cone crossing redshifts, ğ‘§, satisfying ğ‘§< ğ‘§<= ğ‘§, while the second one (â€œfarâ€) contains the rest of the galaxies in the ELG sample from Fig. 10. The ratio is very close to one, suggesting that the interpolation eï¬€ects introduced by our algorithm (see Section 3) are negligible even at these very small scales. MNRAS 000, 1â€“16 (2021) the halo mass regime of ğ‘€> 2.1 Ã— 10ğ‘€/â„, corresponding to haloes containing 100 particles or more. We perform multiple tests to check the validity of the generated halo light cone catalogues. In particular, we ï¬nd that there are no evident discontinuities at the boundaries between the diï¬€erent redshift catalogues and that the number of haloes as a function of redshift is consistent with the expectation of nearly constant halo density, accounting for the dependence of the sky coverage on redshift. In addition, we visualize the huge box for 0.8 < ğ‘§ < 1.1 and recover the full-sky projected density ï¬eld and tidal tensor, ï¬nding no unphysical features. We further study the accuracy of the interpolation technique we have adopted and ï¬nd that the diï¬€erence between the averaged particle velocity or position and the interpolated one is small (|xâˆ’x| = 30 kpc/â„ and |vâˆ’v| = 40 km/s for haloes containing 2500 to 5000 particles at ğ‘§ = 0.8). These diï¬€erences can have diï¬€erent causes: e.g., haloes that have rich substructure will report biased xand v, whereas smaller haloes might be harder to track reliably through time in particular as they ï¬‚y by large clusters. We also study the dispersion velocities and second moments of haloes and ï¬nd that while there are percent-level eï¬€ects coming from the fact that halo membership of the particles is reported at only a handful of redshifts. Luckily, these eï¬€ects can be absorbed through extra HOD parameters. Galaxies can be assigned to the halo light cone catalogues using a modiï¬ed version of AbacusHOD, detailed in Yuan et al. (2021), which takes as input the halo light cone catalogues rather than the full snapshot outputs. AbacusHOD oï¬€ers a sophisticated prescription of the standard HOD method that generalizes it with various halo-scale physics such as satellite distribution, velocity bias, closest approach distance, and assembly bias in the form of concentration and environment. We generate mock catalogues of emission-line galaxies (ELGs) on the light cone and compare our prediction for the compressed galaxy clustering statistics (i.e. the monopole and quadrupole of the two-point function) at ğ‘§ = 0.5 with the full snapshot result. We ï¬nd that our mock catalogues manage to recover the observables with very good accuracy. This application is based on creating a single galaxy mock catalogue at a ï¬xed cosmology, but in order to place tight constraints on cosmological parameters through galaxy surveys, we need to compute high-dimensional covariance matrices, which requires us to generate thousands of mock catalogues. This could be achieved by applying approximate fast methods for generating halo catalogues (e.g. Manera et al. 2013; Monaco et al. 2013; Tassev et al. 2013; White et al. 2014; Avila et al. 2015; Chuang et al. 2015; Kitaura et al. 2015), but a signiï¬cant advantage of the AbacusHOD model (Yuan et al. 2021) is that it is highly optimized and therefore well-suited for this task. In addition, we showcase a cross-correlation study between the galaxy clustering of ELGs at ğ‘§ âˆ¼ 1.1 and CMB lensing. The convergence maps of the CMB are computed using all available light cone outputs between 0.1 < ğ‘§ < 2.45, accounting for the way in which neutrinos are treated in AbacusSummit (i.e. as a non-clustering, smooth component). We ï¬nd that the auto-correlation of the convergence maps agrees with the theoretical prediction from pyccl at the 0.1% level. As for the slightly more noisy measurements of the galaxy-CMB lensing and galaxy-galaxy auto-power spectra, we ï¬nd those to be consistent with theory within 1.7% and 0.1%, where we have assumed a simple form of the redshift-dependent bias, i.e. ğ‘(ğ‘§) = 1.14/ğ·(ğ‘§). In the near future, multiple surveys will be mapping the distribution of galaxies, so developing eï¬ƒcient galaxy population tools that reproduce their clustering properties with a high degree of ï¬delity will become crucial to advancing precision cosmology. Applying these tools to simulations, we can obtain mock catalogues and build high-precision covariance matrices for quantifying the uncertainties in estimates of cosmological parameters. Such an endeavor could potentially bridge important gaps in light of future galaxy surveys and truly enable us to make remarkable subpercent inferences about the makeup of our Universe. We thank Sihan Yuan and Tanveer Karim for many illuminating discussions. We are also grateful to the anonymous referee for their helpful input and comments. This work has been supported by NSF AST-1313285, DOESC0013718, and NASA ROSES grant 12-EUCLID12-0004. DJE is supported in part as a Simons Foundation investigator. LHG is supported by the centre for Computational Astrophysics at the Flatiron Institute, which is supported by the Simons Foundation. SB is supported by Harvard University through the ITC Fellowship. This research used resources of the Oak Ridge Leadership Computing Facility, which is a DOE Oï¬ƒce of Science User Facility supported under Contract DE-AC05-00OR22725. Computation of the merger trees used resources of the National Energy Research Scientiï¬c Computing centre (NERSC), a U.S. Department of Energy Oï¬ƒce of Science User Facility located at Lawrence Berkeley National Laboratory, operated under Contract No. DE-AC02-05CH11231. The AbacusSummit simulations have been supported by OLCF projects AST135 and AST145, the latter through the Department of Energy ALCC program. We would like to thank the OLCF and NERSC staï¬€ for their highly responsive and expert assistance, both scientiï¬c and administrative, during the course of this project. The simulation data is available as part of AbacusSummit and is subject to the academic citations described at https:// abacussummit.readthedocs.io/en/latest/citation.html. Data access is available through OLCFâ€™s Constellation portal. The persistent DOI describing the data release is 10.13139/OLCF/1825069. Instructions for accessing the data are given at https://abacussummit.readthedocs.io/en/latest/dataaccess.html.
Online video services acquire new content on a daily basis to increase engagement, and improve the user experience. Traditional recommender systems solely rely on watch history, delaying the recommendation of newly added titles to the right customer. However, one can use the metadata information of a cold-start title to bootstrap the personalization. In this work, we propose to adopt a two-tower model, in which one tower is to learn the user representation based on their watch history, and the other tower is to learn the eî€ective representations for titles using metadata. The contribution of this work can be summarized as: (1) we show the feasibility of using two-tower model for recommendations and conduct a series of oî€Ÿine experiments to show its performance for cold-start titles; (2) we explore diî€erent types of metadata (categorical features, text description, cover-art image) and an attention layer to fuse them; (3) with our Amazon proprietary data, we show that the attention layer can assign weights adaptively to diî€erent metadata with improved recommendation for warm- and cold-start items. 1 INTRODUCTION Online video services like Amazon Prime Video add cold-start contents, i.e. titles that do not have any watch history, on a regular basis to their catalog. Newly added titles are typically the most interesting for users due to the novelty factor. In fact, many users scroll the page endlessly to î€›nd new titles that pique their interest. Thus, it is important to match these highly desired titles to the right users as soon as possible. Recommender systems based on watch history such as neural network-based architectures [ or matrix factorization techniques [ generate recommendations for a set of items seen during the model training. This hinders the recommendation to work eî€ectively typically for many days until enough watches have happened. Coldstart titles typically come with diî€erent types of metadata, including categorical features (i.e., genre, cast, release time, etc), synopses and cover art images. As in Figure 1, metadata always shows up on the content page to characterize the title and it helps users decide whether they are interested in a title or not. In this work, we postulate that we can utilize the metadata of the cold-start titles and match the right title to the right user, based on their previous watch history. Meanwhile, the metadata can work as supplementary information and help to infer usersâ€™ preferences on the warm-start titles. In this work, we adopt the two-tower architecture for recommendation of videos with heterogeneous metadata. The item and user representations are learned from two diî€erent neural towers, which can be used to infer the user-item preference with dot product operation. To support heterogeneous metadata, we develop an attention fusion layer to combine metadata from diî€erent modalities. In this work, we explore the use of three diî€erent metadata in Amazon Prime Video: categorical features (i.e., genres, actors and directors and release time), synopsis features, and cover art features. With the experiments, we show how diî€erent metadata contribute to the title representation learning and also contribute to both warm- and cold-start item recommendation. 2 RELATED WORK Context-aware recommender systems improve recommendations by incorporating contextual information of the userâ€™s decision into the recommendation process [1,6,18]. Previous research in video recommendation beneî€›ts a lot from diî€erent types of contextual information. In an early work, [3] tried to obtain the candidate videos based on co-visitation counts and ranks them utilizing the rule-based signals. To obtain informative user representations for candidate generation, the authors of [2] concatenated heterogeneous user features and input them into a deep neural network. To enable the recommendation for video with limited historic feedback, diî€erent content-based video recommendation framework is proposed recently. For example, [12] embedded all the videos relying on their raw video and audio content, and recommended the similar videos located closely on an embedding space. They concatenated heterogeneous user features and generate user embedding with a deep neural network. In our work, we are exploring the impacts of heterogeneous metadata with the two-tower model to conduct eî€œcient user modeling and video metadata modeling at the same time. Besides modeling user preferences on warm-start videos, we also aim to explore the feasibility of recommending the newly-available cold-start videos. In fact, cold-start item recommendation has been explored via mapping between metadata and the well-trained embedding [5] or training strategies like Dropout [17] and meta-learning [11]. These methods usually work on one particular type of metadata. In this work, we are focusing on exploring the feasibility of utilizing heterogeneous metadata in characterizing videos for cold-start recommendation. The two-tower structure we have adopted in this work has been applied in the industry to predict the relevance between a query and the candidate items (e.g., news, apps and documents) [4,9,15,20], in which one tower is used to model the query and the other one is for the candidate item. These works show that the two-tower model can be easily modiî€›ed and extended for multi-view learning, for cross-domain transfer learning or for supporting diî€erent negative sampling strategies. There are also previous works utilizing the two-tower model for user and item representation learning in recommendation systems [21]. However, those works usually rely on only one speciî€›c type of metadata or directly concatenate various types of metadata. We adopt the two-tower model for user-video preference prediction task and explore the design of the item tower with diî€erent item metadata. Ultimately, the model can generate predictions on both warm and cold-start items. 3 TWO-TOWER MODEL 3.1 Architecture As the name implies, the model has two components: user and item towers, each producing the corresponding embeddings, culminating in a dot product between the two and passing through a sigmoid activation function. User Tower.Users are represented by their watch histories in the training time period and some additional user-level features such as their country. We are adopting a user encoder architecture previously tested in production. Due to the focus on item encoder in this work, we did not experiment with diî€erent types of user encoder and have its architecture î€›xed. With the user input, the watch history is î€›rstly encoded with a position-aware attention layer to extract the sequential patterns. The user-level features are directly embedded with an MLP layer. Then the encoder concatenates watch history embeddings and user feature embeddings, passing them through the three residual blocks [ introduced to assist in training a deeper architecture and thus help to achieve better performance. Item Tower. one-hot encoding for all known items. The embedding layer of the ID feature is uniquely linked to the ID of the video and is updated during the training process. Meanwhile, each item also has other metadata available (genres, actors, directors, etc; synopsis, cover art image), which can be used to generate a dense item representation. More details are provided in the following subsections. Preference Prediction. with the corresponding towers. Then following the idea of matrix factorization [ approximate activation. In the training process, we use cross-entropy to calculate the loss. In the prediction process, we will predict usersâ€™ preference scores on the set of videos and recommend top scoring titles. 3.2 Metadata In the following section, we will elaborate on three types of metadata used in the item tower: categorical features, synopsis and cover art. Categorical features categorical features represented with a high-dimensional binary vector. For each item appearing in the training period, we can use so-calledID featurethat is in essence the ğ‘¢â€™s preference on itemğ‘–. Note that we also apply the Sigmoid functionğœ (Â·)on the dot productu Â· ias â€¢ Genreis used to indicate the topic of a title as displayed on the detail page, which covers 27 tags and 227 subgenre tags indicating more î€›ne-grained topics. We use a binary vector with 227+ 27 dimensions to represent this feature. â€¢ Actors/Directorsare important factors indicating the relevance of the title to a user. To avoid the long-tail issue, only the top-2000 actors and directors are taken into consideration. â€¢ Maturity Rating containing 17 diî€erent levels, indicating the maturity level of a title. â€¢ Country of Origin containing 159 diî€erent values, indicating the country/region title is created in. â€¢ Release Year indicating the time the title was released. â€¢ Acquisition Dateindicating when the title became available in Prime Video. We set the granularity to be 1-month to convert the release dates into categorical values. â€¢ Popularityis based on the number of views in a certain period. We use two diî€erent values, one is based on the 2-year watching history and the other one is based on the watching history of the most recent 60 days. We use the total number of views to normalize the values and use the log function to smooth the values. We apply uniform discretization transformation on the resulting values to covert them into categorical type of input. By concatenating the vectors generated from each of the features above, we obtain a high dimensional vector for each of the title. Synopsisis the short text (usually a few sentences) displayed on the detail page which summarizes a title. It can help users to make a decision on whether to watch a title or not. We encode the synopsis using TF-IDF-weighted sum of the word2vec [13, 14] embeddings of each word. Cover Artis the image displayed on the detail page to give a visual for the movie, which can also hint on the content and style of the title. In order to obtain an embedding for the cover art, we use a pre-trained 34-layer ResNet trained on ImageNet data [7], and extract the activations before the last layer. IDis used to represent titles present during the training. Note that we do not have IDs for cold-start users during training. During the evaluation process, we set the ID embedding to zero for cold-start titles. 3.3 Aî€ention Layer for Fusion After obtaining the ID, categorical, synopsis and cover art embeddings, we concatenate them all together. However, diî€erent components can have diî€erent inî€uences on the title representations. For example, some titles have informative cover arts but the others may not. Thus we need to fuse the metadata from diî€erent modalities considering their importance. We adopt the attention mechanism [16,19] to calculate the weights for each component. Letğ›¼denote the attention weight for metadata typeğ‘šof videoğ‘¡and M includes all the types of metadata that the model considering as input for the item tower. Then we will have the pre-score ğ‘‚: wherehrepresents the embedding for metadata typeğ‘šof titleğ‘¡,Pis the weight matrix,zis a transform vector andb is the bias vector. By applying softmax operation on the pre-scores, we can obtain the attention weights of diî€erent components which can sum up to be one. After we obtaining the weights, they will be multiplied with the metadata before the concatenation. In the end, a 1-layer perceptron is used to convert the fused embedding to have the same size of the user representation. Given that cold-start items havenâ€™t shown up in the training, the ID embedding will be a zero vector. Thus the item representation is purely based on its metadata. 4 EXPERIMENT In this section, we will î€›rst elaborate the experiment setup and then explore the feasibility of utilizing heterogeous metadata for both warm- and cold-start items in video recommendation with experiments on Amazon Prime Video streaming history. 4.1 Evaluation methodology and metrics To evaluate the proposed model, we conduct a series of oî€Ÿine experiments on real-world Amazon Prime Video data. As shown in Figure 3, during the training process, we use the watch history of users in a two-year time period ( watch behaviors in the following two-week period (ğ‘Œ). Then, in the scoring (testing) mode, given the watch history in the two-year period scores and predict usersâ€™ watch behavior for the following one-week time period overlap between ğ‘Œ For each user, we calculate preference scores for a list of candidate movies or TV shows. We rank these titles based on the predicted scores and select the Top-K titles for diî€erent categories (i.e.,movies and series). We pick simulate the use cases in Amazon Prime Video. With the top-k titles and the ground-truth, we adopt 4 diî€erent metrics to evaluate the recommendation performance. (1) the Top-K Recommendation; (2) recommendations; (3) (4)Converted Coverage@K watched. Data.We collect and split the data according to the scheme explained in Figure 3. Speciî€›cally, the training data with densityof 0.00672% has the length of 2-year in total (i.e., treated as labels. For the test set, we collect user streaming history in 2-year as input features to predict what user is going to watch in the next 7-day (Time Period recommendation we did a series of oî€Ÿine experiments. Here we have a set of items that have no watch history in time category. In the following experiments, during the scoring/evaluation, we only calculate preference scores for this set of cold-start titles and rank among them. Parameter Setup. a set of items the user hasnâ€™t watched before. We tried diî€erent negative sampling rates ranging from 1 to 30. We found that more negative samples can lead to better performance. Empirically, the recommendation performance becomes stable when the negative sampling rate is larger than 20. The embedding size before the dot product is also set to be 512. We used Adam optimizer with the learning rate of 0.001. ğ‘Œorğ‘‹but have at least one watch in time periodğ‘Œ. There are 360 movies and 75 TV series in total in this We use positive samples from a userâ€™s watch history, and negative samples from randomly sampling Table 1. Comparison on warm-start video recommendation. For fair comparison, NCF-extention extends NCF [8] by concatenating both the watch history embedding and user-level features embedding with the user ID embedding. (B) indicates the basline for percentage calculation. All numbers are reported in percentage (%) liî€œ w.r.t. the baseline. Synopsis, Cover art and Categorical denote the models use only categorical features, synopsis features or cover art features; Con concatenate all types of metadata directly, and feeds the concatenation into the 1-NN; Att means to fuse diî€›erent types of metadata using aî€ention. 4.2 Results 4.2.1 Warm-start Video Recommendation Task. To fully understand how diî€erent metadata and the proposed attention layer work for video recommendation, we evaluate the recommendations for the warm-start videos. The results are summarized in Table 1. First, we compare the models using only one type of metadata. We can see that the categorical features can result in the best oî€Ÿine performance under diî€erent evaluation metrics, indicating that the categorical features are more informative in characterizing the warm-start videos compared with other metadata. When we fuse the aforementioned metadata, the proposed attention layer can bring in signiî€›cant improvement compared to the models using one of the metadata, while the simple concatenation only works slightly better than those models. This observation illustrates the eî€ectiveness of the attention layer. Furthermore, if we take the ID embedding into consideration, under the warm-start setup, the models can perform better than all the models without ID embedding. The reason is that for items with abundant watch history, the ID embedding layer can learn an informative representation, which hints at the necessity of ID embedding in the warm-start setup. 4.2.2 Cold-start Item Re commendation Task. We compare the proposed two-tower model with the random baseline in which we just randomly select 6 cold-start titles to each user. For cold-start titles, during evaluation/scoring phase, we set their ID embedding to zero. To examine how the ID embedding will inî€uence the cold-start recommendation, we also compare the two-tower model with all the metadata and the version with metadata and ID embedding. The Table 2. Comparison on cold-start video recommendation. (B) indicates the baseline for percentage calculation. All numbers are reported in percentage (%) liî€œ w.r.t. the baseline. Random is the random recommendation strategy; Att w/o ID is the two-tower model with Aî€ention layer fusing all types of metadata; Att with ID is the two-tower model considering all types of metadata and ID embeddings, using Aî€ention layer to fuse those metadata and ID embeddings. results are summarized in Table 2. We can see that, both the versions with or without ID embedding can beat the random method signiî€›cantly, explaining the eî€ectiveness of the two-tower model with metadata. Further, the model with ID embedding falls behind the model without ID embedding in terms of precision@6 and recall@6. The reason is that higher weights are usually assigned to the ID embedding by the attention layer in the training phases, and leading to a weak representation for the metadata components. Thus if we remove the ID embedding, we can see the improvements for the cold-start item prediction task. Note, the convertedCoverage@6 and Coverage@6 are slightly higher for the two-tower model with ID embedding. We need to carefully consider this tradeoî€ scenario while designing an appropriate model for cold-start video recommendation. 4.3 Visualization To examine how attention layer works in controlling the fusion process, in Figure 4, we summarize the resulted weights for diî€erent types of metadata in TV shows and movies. The results for movie and TV shows are shown individually. We î€›nd that for both title categories, cover art feature gets the lowest weights, and categorical features get the highest weights. This is intuitive, since categorical data is rich with important features, whereas the cover art is only represented by a pre-trained embedding, and not î€›ne-tuned for this task. When comparing TV shows and movies, we î€›nd that synopsis features are more important for TV shows compared to movies. 5 CONCLUSION We proposed a two-tower model for cold- and warm-start item recommendation with heterogeneous metadata. We also explored diî€erent types of metadata, including categorical features, cover-art images and synopsis, With oî€Ÿine experiments, we show that the proposed framework can produce best recommendations by fusing diî€erent types of metadata using attention. By introducing the metadata with the well-designed attention layer, the two-tower model enables the recommendation for cold-start videos and also improve the recommendation for warm-start videos.
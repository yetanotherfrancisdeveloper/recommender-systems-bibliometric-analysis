Key Laboratory of Aerospace Information Security and Trusted Computing, Ministry of Education, School of Cyber Recently, micro-video sharing platforms such as Kuaishou and Tiktok have become a major source of information for peopleâ€™s lives. Thanks to the large traî€œc volume, short video lifespan and streaming fashion of these services, it has become more and more pressing to improve the existing recommender systems to accommodate these challenges in a cost-eî€ective way. In this paper, we propose a novel concept-aware denoising graph neural network (named Conde) for micro-video recommendation. Conde consists of a three-phase graph convolution process to derive user and micro-video representations: warm-up propagation, graph denoising and preference reî€›nement. A heterogeneous tripartite graph is constructed by connecting user nodes with video nodes, and video nodes with associated concept nodes, extracted from captions and comments of the videos. To address the noisy information in the graph, we introduce a user-oriented graph denoising phase to extract a subgraph which can better reî€ect the userâ€™s preference. Despite the main focus of micro-video recommendation in this paper, we also show that our method can be generalized to other types of tasks. Therefore, we also conduct empirical studies on a well-known public E-commerce dataset. The experimental results suggest that the proposed Conde achieves signiî€›cantly better recommendation performance than the existing state-of-the-art solutions. â€¢ Information systems â†’ Recommender systems. Micro-video Recommendation, Graph Neural Network, Graph Denoising ACM Reference Format: Yiyu Liu, Qian Liu, Yu Tian, Changping Wang, Yanan Niu, Yang Song, Chenliang Li. 2021. Concept-Aware Denoising Graph Neural Network for Micro-Video Recommendation. In Proceedings of the 30th ACM International Conference on Information and Knowledge Management (CIKM â€™21), November 1â€“5, 2021, Virtual Event, QLD, Australia. ACM, New York, NY, USA, 10 pages. https://doi.org/10.1145/3459637.3482417 Information overload has become an increasingly crucial challenge for todayâ€™s world. In the past few years, micro-video sharing platforms like Kuaishou have harnessed a huge user base on a global scale. Users on these platforms can share micro-videos ranging from a few seconds to minutes with their friends and the public. Due to the signiî€›cant cognitive load reduction empowered by visual communication, micro-videos have become the new time killer. As of early 2020, there are more than 300M daily active users (DAUs) and over 20B videos on the Kuaishou platform. Faced with a massive upsurge of micro-video data traî€œc, the key techniques to alleviate the information overload problem is recommender systems, which aim to precisely rank items in terms of the userâ€™s preference. A myriad of recommendation algorithms have been proposed in the past, including sequential based recommendation [17,18], graph-based recommendation [16,34] and a range of CTR prediction models that are practical in industrial settings [7, 9, 22, 23, 33, 36]. Nevertheless, the following three unique characteristics in microvideo sharing platforms impede the existing recommendation techniques to deliver good performance: C1:The existing multi-modal models that extract visual content are infeasible for micro-video sharing platforms due to the continuous and large traî€œc volume nature of the latter. On the other hand, exploiting the rich story expressed in a micro-video will help understand the userâ€™s preference to its maximum. C2:Although micro-video platforms provide users with "like" and "comment" buttons to interact with the video, the vast majority of user actions are still just swiping up to the next video, leaving very sparse user feedback. Without an explicit user interaction, it is hard to tell whether the user really likes what she/he watches. Although we can utilize watching time to speculate the userâ€™s preference (i.e., analogous to click behavior), there would still be many false positives which hinder the eî€ective preference learning for recommendation. C3:The average lifecycle of a micro-video is extremely short. In our data analysis over user behaviors from a large scale micro-video Figure 1: A snapshot of the popular micro-video platform kuaishou and its international version Kwai. The text information within a micro-video contains rich semantics, which can be extracted as millions of concepts in our work. sharing platform, it is observed that the number of user interactions over a micro-video reduces sharply just two days later after its announcement. Moreover, most of the user behaviors fall on the micro-videos uploaded by a few Internet celebrities. Speciî€›cally, the micro-videos that have less than 10 user clicks comprise about 85% in our dataset. This number goes up to 96% when we use 50 as the cutoî€ threshold. These long-tail ones are rarely recommended. The feedback loop underlying the recommender system further aggravates this recommendation bias, which is called "Matthew Eî€ect" [3]. All these characteristics together give rise to sparser user interactions and poor performance for micro-video recommendation, especially for long-tail ones. To this end, in this paper, we propose a novelconcept-awaredenoising graph neural network (named Conde) to address the above challenges. In Conde, we aim to build a marriage between textual information and graph neural network to support video content extraction and user preference learning. As illustrated in Figure 1, the caption and comments associated with a micro-video serve as a good proxy for the video content. Hence, to account for the rich semantics in a micro-video, we resort to extracting concepts mentioned in the captions and the comments of micro-videos. Here, the concepts are deî€›ned as the named entities and semantic key phrases (e.g., â€œheartwarmingâ€, â€œclassic HK movieâ€). By connecting the micro-videos to the associated concepts and users to their consumed micro-videos, we can form a tripartite heterogeneous graph, in which the concepts work as a backbone with rich semantic information. It is intuitive that not all concepts of a micro-video can reî€ect all diî€erent usersâ€™ preferences equally. Moreover, as aforementioned, there would be many false positives for user-video edges in the graph. Hence, we further introduce a personalized denoising procedure for each user when we derive her/his representation via graph convolution. Speciî€›cally, Conde utilizes a three-phase graph convolution process to derive user and item representations. In the warm-up propagation phase, we î€›rstly apply convolution by propagating semantic concept information to the related micro-videos and users through the aggregation order: conceptâ†’micro-video â†’user. Afterwards, we further perform another layer of convolution over the user-video edges to exploit the collaborative signals. With the user and item representations calculated by the warm-up phase, graph denoising phase aims to extract a subgraph for a given user where the noisy micro-videos, concepts and other users in the neighborhood are removed in a breadth-î€›rst search fashion. It is expected that the resultant subgraph could reî€ect the userâ€™s preference more precisely. At last, in preference reî€›nement phase, we again perform the same convolution as in the warm-up phase over the subgraph to derive the user representation. The extensive experiments over a large scale internal microvideo dataset and a traditional E-Commerce dataset in diî€erent languages demonstrate that the proposed Conde achieves signiî€›cantly superior recommendation performance to the existing state-of-theart technical alternatives. In summary, the main contributions of this paper are as follows: â€¢We fully exploit textual information to support video content extraction. The rich semantics in micro-videos demonstrate great potential in representing the userâ€™s preference. â€¢We propose a denoising phase for graph neural networks to help recommendation systems, especially those in a streaming fashion, get rid of noisy information and catch userâ€™s highly dynamic preference more precisely. â€¢To the best of our knowledge, this is the î€›rst attempt in recommendation systems to study the heterogeneous graph neural network with a denoising purpose. Since our work is related to micro-video recommendation, graphbased recommendation and denoising for graph and recommendation, we therefore mainly focus on reviewing existing methods in these three lines. Diî€erent from item purchase in E-Commerce sites, micro-videos contain much more storylines. To enable better semantic learning for micro-videos, MMGCN [32] incorporates multi-modal information into a collaborative î€›ltering framework. It captures modalspeciî€›c user preferences by separately constructing a user-item bipartite graph for each modality. ALPINE [11] also designs a graphbased sequential network for recommendation tasks, which can better model a userâ€™s diverse and dynamic interest. THACIL [2] proposes a hierarchical attention mechanism for modeling both short-term and long-term behaviors. Though encouraging performance is achieved by these eî€orts, they all require visual feature extraction. However, this heavy treatment could be too expensive to be adopted for a real-world application. Recent years have witnessed the superior performance of graph neural networks in many î€›elds that require network embedding and structure modeling. In practice, GNN methods have more expressive capacity than traditional feature-based methods. The key idea of GNN is to recursively aggregate information from local neighborhoods. Graph Convolution Networks [10] is the î€›rst work that introduces the convolution operation over a network structure, which gathers the information from source nodesâ€™ one-hop neighbors via the neighborhood aggregation, and achieves message passing by stacking multiple GCN layers. Graph Attention Network (GAT) [27] introduces the attention mechanism into GNNs, which enables the model to learn the importance of diî€erent neighbors during the information aggregation. These solutions are mainly devised for homogeneous graphs where all nodes or edges are of the same type. To deal with heterogeneous graph that contains diî€erent types of nodes and edges, HAN [31] extends the original GAT model with a semantic attention layer to learn the importance of diî€erent meta-paths. The major idea underlying these works has been widely adopted for diî€erent kinds of recommendation tasks. Speciî€›cally, a heterogeneous graph is generally built by considering users, items and relevant entities (e.g., side information) in a knowledge graph as nodes, and usersâ€™ behaviors like click, purchase, add-to-cart and other semantic relations as edges. Based on the real recommendation scenario, [1,4,5,35] extend the recommendation framework as a heterogeneous graph modeling mainly by aggregating the neighborhood information via meta-paths. GraphSAGE[6] extends the standard graph convolution network to the inductive setting, and utilize batch training and neighborhood sampling to support recommendation on large-scale graphs. AGNN [19] designs an attribute graph based on user-item interactions and utilizes VAE to learn the distribution of attributes for cold-start users/items. PinSAGE [34] combines random walks and graph convolution layers to aggregate and propagate neighborhood information. MG-BERT [12] utilizes the transformer architecture on the item homogeneous graph to pretrain the item representation, including graph structure reconstruction and masked node feature reconstruction. With rich semantic information in a knowledge graph, many eî€orts are devoted to explore auxiliary connections between users and items, therefore making recommendations more accurate and explainable. RippleNet [28] is a path-based method that î€›rst assigns entities in the KG with initial embeddings and then samples ripple sets from the KG based on the userâ€™s historically clicking items. It uses attention networks to simulate user preferences on sampled ripple sets to represent a user. Some of its extensions [21,24,30] focus on using the embedding propagation mechanism on the item Knowledge Graph. DKN [29] is another representative work that incorporates knowledge graph representation into news recommendations. Performing data denoising in a task-dependent fashion is a promising strategy to alleviate the adverse impact of noisy information. For example, kicking out task-irrelevant edges have been validated to enhance the performance of node classiî€›cation [13,37]. Very recently, [20] chose to remove the irrelevant historical records for better sequential recommendation. [26] perform knowledge pruning iteratively by removing irrelevant triples covered by the knowledge graph for better news recommendation. In this section, we present a concept-aware denoising graph neural network for micro-video recommendation. Speciî€›cally, the proposed Conde aims to derive the representations for users and microvideos by propagating the conceptual semantics to both relevant users and micro-videos. Illustrated in Figure 2, Conde consists of three phases: warm-up propagation, graph denoising and preference reî€›nement. In the following, we describe each phase following their usage order in Conde. Figure 2: The tripartite heterogeneous graph which is composed of three disjoint vertex sets: users, items, and concepts, such that no two graph vertices within the same set are adjacent. Firstly, after concept extraction for micro-videos, we form a tripartite heterogeneous graphG = (V, E), whereVandEare the node set and the edge set respectively. A nodeğ‘œ âˆˆ Vcould be a userğ‘¢, a micro-videoğ‘šor a conceptğ‘. Moreover, there are two kinds of edges inE, which connect a user with a micro-video when the user clicks the latter, and a micro-video with a concept when the concept is extracted from the micro-video. Figure 2 illustrates an example of this tripartite heterogeneous graph. Since we plan to inject the conceptual information into the user and item representations, at the beginning, we perform a series of graph convolution operations in terms of concepts in V. Speciî€›cally, given a micro-videoğ‘šwith a set of concept neighborsC, the hidden feature vectorhof micro-videoğ‘šcan be derived by aggregating the embeddings of its concept neighbors: h= ğ´ğºğº (e, {e, âˆ€ğ‘ âˆˆ C}), wheree, eare the embedding vector for micro-videoğ‘šand its concept neighborğ‘respectively. Given the simplicity and eî€ectiveness, we choose graph attention network[27] to instantiate ğ´ğºğº (Â·) function as follows: whereğ›¼is the attention weight indicating the importance of conceptğ‘,ğœis the LeakyReLU activation andâˆ¥is the vector concatenation operation. It is expected thathcould encode semantic information regarding the content of micro-video ğ‘š. Following similar operation, we then derive the hidden preference vectorhof userğ‘¢by using micro-video neighborsMof the latter:h= ğ´ğºğº (e, {h, âˆ€ğ‘— âˆˆ M}), whereeis the embedding vector of userğ‘¢, andhis the hidden feature vector of micro-video neighborğ‘—derived in Equation 1. It is clear now that we propagate the semantic information î€›rst from concepts to micro-videos, and then from micro-videos to users. So far, the whole propagation process is purely concept driven. Note that not all micro-videos are well expressed by their concept neighbors. Plus, the collaborative signals are not exploited during this process. Hence, we then apply another convolution operation for micro-videos by aggregating their user neighbors back. Speciî€›cally, the hidden feature vectorhof micro-videoğ‘šis updated with its user neighbor setU:h= ğ´ğºğº (h, {h, âˆ€ğ‘¢ âˆˆ U}). In this sense, we can propagate the conceptual semantics across the uservideo bipartite part further, enriching the feature representation of micro-videos, especially the long-tail ones. It is intuitive that diî€erent users would be interested in diî€erent aspects of the micro-video content. Plus, there are inevitably some noisy concepts and false clicks to distract the eî€ective representation learning for users. Although we have an attention mechanism in Equation 2, the irrelevant and noisy information still complicates the learning process. Here, we introduce a user-oriented denoising process to î€›lter the micro-videos and the concepts in a breadth-î€›rst search fashion. Speciî€›cally, we adopt a gated recurrent unit (GRU) as the compositer to î€›rstly identify the relevance between userğ‘¢and each of her micro-video neighbors as follows: wherehworks as the initial state of GRU, andfencodes the relevant information. Then, we perform the neighbor denoising as a sampling without replacement to retain onlyğ‘›micro-video neighbors:M= ğ·ğ‘’ğ‘›({f, âˆ€ğ‘š âˆˆ M})and|M| = ğ‘›. Theseğ‘› micro-videos are expected to convey the userâ€™s preference more precisely. In detail, we can utilize a fully-connected layer with a softmax function to derive the likelihood of retaining each microvideo neighbor ğ‘š as follows: wherewis the parameter vector for graph denoising. Note that instead of attention mechanism, the denoising process produces discrete selections, which are not diî€erentiable for model learning. Hence, we choose Gumbel-Softmax[8] to instantiateğ·ğ‘’ğ‘›(Â·)for diî€erentiable discrete sample generation: whereğœ–= âˆ’ log(âˆ’ log(ğ‘¥))andğ‘¥is i.i.d sampled from Uniform(0,1). The temperature parameterğœcontrols sharpness of the likelihood distribution. Whenğœis small, Equation 5 produces a multi-modal distribution. On the contrary, whenğœis large, the resultant distribution is nearly equivalent to a uniform one. Afterwards, we continue the above denoising process for the userâ€™s two-hop neighbors via each micro-videoğ‘šinM. Note that we only consider the concept of neighbors ofğ‘š:N= C. We have tried mixing user and concept neighbors in this second phase, which turns out to be inferior to using concept nodes only. We speculate that putting diî€erent types of nodes in GRU simultaneously could complicate the model learning, since heterogeneous information is diî€œcult to be fused together. Then, we still utilize the same compositer in the î€›rst-hop denoising to calculate the relevance information: wherehis the representation of two-hop neighborğ‘£. Here, the concept embeddingeis used (i.e.,h= e). Also, when we consider the neighboring users together, whenğ‘£is userğ‘¢, the hidden preference vectorhis used instead (i.e.,h= h). Then, we apply the similar denoising process forNand obtainğ‘›two-hop neighbors for userğ‘¢via micro-videoğ‘š:N= ğ·ğ‘’ğ‘›({f, âˆ€ğ‘– âˆˆ N})and |N| = ğ‘›. We can see that the whole denoising process is performed sequentially by starting with each user. Since the GRU-based compositor is initialized with the user preference vector of the warm-up phase, the userâ€™s neighborhood inGis reshaped to express the userâ€™s preference more precisely in a subgraphG, where the nodes are {ğ‘¢, M, N, âˆ€ğ‘š âˆˆ M}, and the corresponding edges between them in G are remained. Now, it is straightforward to reî€›ne the hidden preference representation for each user based on the correspondingG. Speciî€›cally, for each micro-videoğ‘šinM, we î€›rstly reî€›ne the hidden feature vectorhforğ‘š:h= ğ´ğºğº (e, {h, âˆ€ğ‘£ âˆˆ N}). Here, as toh, we adopt the same setting as in Equation 6. Then, we reî€›ne the hidden preference vectorh:h= ğ´ğºğº (e, {h, âˆ€ğ‘š âˆˆ M}). At last, the ranking score for a micro-videoğ‘šw.r.t. userğ‘¢is calculated as follows: wherehis the hidden feature vector derived in the warm-up phase for micro-video ğ‘š. Besides the embedding vectors and parameters for graph convolution, the key of Conde is to perform graph denoising in a personalized way to enhance the user preference learning. Following the work in [37], for each userğ‘¢, we can generateğ‘˜subgraphs {G, . . . , G}by repeating the denoising processğ‘˜times. After that, we calculate the cross-entropy loss with each subgraphG as follows: L= ğ‘¦log(Ë†ğ‘¦) + (1 âˆ’ ğ‘¦) log(1 âˆ’Ë†ğ‘¦ whereğ‘¦is the ground truth of micro-videoğ‘šclicked by userğ‘¢, Ë†ğ‘¦is the corresponding ranking score calculated with subgraph G. Finally, the total loss function is as follows: whereâˆ¥Î˜âˆ¥representsğ¿2 regularization over model parameters and ğœ† is the corresponding coeî€œcient. Discussion.After model training, we follow the order of warmupâ†’graph denoisingâ†’preference reî€›nement for each user and generate the corresponding subgraphGand user preference vectorh. We then maintain these preference vectors in memory for online service. There is no need to re-run the graph denoising and preference reî€›nement each time, since we believe that the learnt model is eî€ective in capturing the userâ€™s preference. The marginal change in the subgraph structure would introduce ignorable variations. Actually, all micro-video hidden feature vectors could be reused in the warm-up propagation phase for each user, by calculating hbeforehand. We evaluate our proposed Conde on two real-world datasets, hoping to answer the following three research questions:RQ1How does Conde perform compared with state-of-the-art graph-based methods?RQ2How do diî€erent components aî€ect Condeâ€™s performance?RQ3Can Conde provide reasonable explanations about user preferences towards items? In what follows, we î€›rst present the experimental settings in detail, (i.e., the datasets, baselines, evaluation protocols, and the parameter settings), then compare our modelâ€™s performance with state-of-the-art methods, followed by answering the above three questions. Micro-Videodataset is collected from a popular large scale Chinese micro-video sharing platform. It serves to record and share videos taken by a user and matches content to targeted consumers with the help of a recommender system. The recommendation model serves in a streaming setting, where users can swipe up on the touch screen to watch the next video one by one. To be as consistent as possible with the real-world online training setting, we construct a dataset by randomly sampling 100ğ¾users and their watched micro-videos over a period of two days. After î€›ltering the users and micro-videos with no click behavior, the dataset consists of 82,193 users and 784,863 clicked micro-videos, which is referred to as Micro-Video dataset in the rest of this paper. The user behaviors in î€›rst-day are used for training. We then shuî€Ÿe and split the second-dayâ€™s data equally for validation and testing respectively. Amazon Electronics[15] is a widely used benchmark whose task is to predict whether a user will write a review for a target item given her historical reviews (in English). Initially we wanted to î€›nd a public micro-video recommendation dataset in English but failed. So we have to turn to data from other î€›elds. Surprisingly, Conde works out quite well on other types of tasks and thus proving its robustness. Here, we select the î€›rst 70% of historical interactions as the training set. The last 10% interactions are used as the testing set. The remaining 20% is used as the validation set for hyper-parameter selection. We refer to this benchmark as the Amazon dataset. As for the Micro-Video dataset, we build a concept inventory by merging several proprietary knowledge bases and internal video tagging systems. Speciî€›cally, the resultant concept inventory contains about 2.32M named entities and semantic key phrases, covering a wide spectrum of topics in Micro-Video. The average length of a concept is 4. The concepts are extracted from textual information of a micro-video including comment, caption and hashtag by performing a longest match. As the user generated content contains a lot of Internet buzzwords and slangs, we î€›lter the corpus î€›rst by removing stop words, punctuation and emoji. After concept extraction, we calculate the TF-IDF score for each concept and micro-video pair, and retain the informative ones with a threshold î€›ltering. In total, we obtained 415,796 unique concepts. For the Amazon dataset, we utilize the TextBlob toolkitto extract the noun phrases as the concepts from the reviews written for each item. Similarly, a TF-IDF weighting scheme is adopted to î€›lter noisy concepts. The detailed statistics of the two datasets are reported in Table 1. â€¢ GraphSage[6] is a state-of-the-art method of GCN that aggregates neighborhood information into center nodes. In particular, it considers the structure information as well as the distribution of node features in the neighborhood. For a fair comparison, we form two homogeneous graphs based on user-item interaction. â€¢ PinSage[34] is designed to employ GraphSAGE on useritem graph, which performs eî€œcient, localized convolutions by sampling the neighborhood around a node and dynamically constructing a computation graph. In this work, we employ two graph convolution layers as suggested in the user-item interaction graph. â€¢ GAT[27] introduces a multi-head attention between each node and its neighbors to calculate aggregate coeî€œcients. â€¢ HAN[31] is a heterogeneous graph neural network with attention mechanism based on GAT, which deals with heterogeneous nodes via diî€erent meta paths to aggregate neighborhood information. We modify the model for topN recommendation. In detail, we make use of four types of meta-paths: user-item-user, user-item-concept-item-user, item-concept-item, and item-user-item. Therefore we construct four homogeneous graphs from the original graph for model learning. â€¢ NIA-GCN [25] models the interactions between neighbors with element-wise products by a bi-linear neighborhood aggregator. The Euclidean distance between users and items with their positive neighbors are added in loss function. The experimental setting is the same as the original NIA-GCN paper. This is the uptodate state-of-the-art solution in the paradigm of GNN. For those network embedding models (i.e., GraphSage, GAT and HAN), we also utilize Equation 7 to calculate the ranking score for a fair comparison. With the extracted concepts, a heterogeneous concept-aware graph is built by connecting the items to the associated concepts and users to their consumed items. Recall that we aim to propagate semantic concept information via graph convolution to represent users and micro-videos for preference learning. In the warm-up propagation phase, we derive coarse-level representations for micro-videos and users following the aggregation order of conceptâ†’micro-videoâ†’ user. Note that the concept-aware graph is not perfect but contains lots of noisy information. . At last, we again perform the same convolution as in the warm-up propagation phase over the subgraph to reî€›ne the user representation for recommendation. Evaluation Metrics.For performance evaluation metrics, we choose AUC (Area Under Curve), HIT@5, NDCG@5, MAP@5 which are widely adopted in many related works [20,26]. Note that we use UAUC here, which means AUC score for each user, and we calculate the mean of all usersâ€™ AUC scores as the î€›nal result. Meanwhile, We treat all unobserved interactions as the negative instances when reporting performance. It is worthwhile to mention that the positive and negative instances are highly imbalanced. As for model training, the ratio of true and negative samples in real production scenarios is approximate to 1:1. Hence, we also choose the same number of unobserved items for each user in evaluation. Hyperparameter Settings.Following PinSage [34], we perform mini-batch training and edge sampling for better training eî€œciency. According to the average number of concepts that an item contains, we randomly sample a subgraph for training by randomly pickingğ‘ neighbors in every epoch. We setğ‘ =40 for the Micro-Video dataset andğ‘ =100 for the Amazon dataset after grid search. The proposed Conde will select a î€›xed number of neighbors out of this subgraph Table 2: Performance comparison between methods on the Micro-Video and Amazon dataset. The * indicates the best p erformance of the baselines. The best results are highlighted in boldface. (i.e.,ğ‘› < ğ‘). For fair comparison, after grid search, we î€›x the embedding size and all hidden sizes to be 128 and 50 for the Micro-Video and the Amazon dataset respectively across diî€erent methods in comparison. As for Conde, we î€›rstly apply Word2Vec [14] to pretrain the word embeddings over the textual information of items in the Micro-Video dataset. Here, the textual information associated with a micro-video is merged as a single document. For the Amazon dataset, we use pre-trained GloVe word embeddings. The concept embeddings are î€›xed as the averaged embedding of their constituent words, and are not further î€›ne-tuned during the model training. Recall that the temperature parameterğœin Equation 5 could aî€ect the sample probabilities signiî€›cantly. The higher the temperature, the smoother the sampling probability is. Starting from a higher temperature, the model can gather information from more neighbors in the î€›rst few minibatches. In our experiments, the temperature starts at a high value and gradually anneal to a small one as follows: whereğœis the initial temperature to start with,ğœ‚is the hyperparameter, andğ‘¥is the number of minibatches. We setğœto be 10, andğœ‚to be 0.0002 and 0.001 for the Micro-Video and the Amazon dataset respectively. Table 2 reports the overall performance compared with baselines. For each model, we run î€›ve times and report the average results. From the results, we make the following observations. â€¢Conde consistently yields the best performance on all datasets. This result demonstrates the superiority of our conceptaware denoising framework for recommendation. â€¢It is no surprise that methods based on a bipartite graph like PinSage [34] and NIA-GCN [25] consistently yields poor performance on all evaluations, which indicates that learning user and item representations simply on a bipartite graph is not adequate. â€¢The results of GraphSage [6] show that homogeneous graphs with directly connected items and users can not make up for the negative impact of noisy information. Attention mechanism contributes a lot to GAT [27] performance improvement and HAN [31] are more powerful in information utilization and aggregation with item-concept connection when constructing item-item, user-user graph homogeneous graph. â€¢However, according to our experiments, none of them ever achieves the best result, which veriî€›es the advantages of the denoising optimization process of our proposed model. Long-Tail Performance.As to Micro-Video dataset, we divide the entire item space into hot and long-tail items by click frequency. We set 50 as a threshold and î€›nd that long-tail items take up a percentage of 96.0% in the entire item space. However, the majority of user-item interactions in the test set are dominated by hot items, leaving only 34.48% records for long-tail ones to share. We split the test set into two parts according to click frequency=50 and do the experiments on them separately. From Table 3 we can observe that the performance of each model for hot items is always much higher than that of long-tail items, which indicates the distributions of hot and long-tail items are inconsistent. Whatâ€™s more, the improvements of Conde over the baselines are remarkable. Therefore we can draw a conclusion that Conde shows its strong robustness on both hot and long-tail items, and proves its ability to learn better features in the entire space for diî€erent datasets and applications. Table 3: Performance comparison between the methods with Conde and other baselines on Micro-Video dataset. â€œHotâ€ represents hot items in the test set, â€œLong-tailâ€ represents long-tail items in the test set. Ablation Study.We conduct ablation studies on the Micro-Video dataset for each proposed component to justify its eî€ectiveness. For each setting, we run 5 times and report the average results. Note that our graph is tripartite, which is composed of three disjoint vertex sets: users, items, and concepts, such that no two graph vertices within the same set are adjacent. Therefore we perform the denoising algorithm in a two-phase strategy. Starting from a user, GRU î€›rst picks some candidate micro-videos out of its neighbors in the î€›rst phase. Then for every remaining micro-video, the same GRU picks some candidate concepts out of its neighbors in the second phase. The whole process can be split into two phases, hence we can do some ablation studies as follows: For better comparison, we split the denoising process into two phases and remove either phase with a random module, which randomly selects some micro-videos instead of denoising, to check if denoising operation really makes some diî€erence. Table 4: Ablation study on the Micro-Video dataset. From the results shown in Table 4, we make the following observations: 1) Cut out either denoising phase is detrimental to the î€›nal result. 2) The second phase of denoising plays a more important role. 3) The best performance appears when two phases work together, indicating that two phases should work together to enhance representation learning. This is reasonable since the userâ€™s representation is reî€›ned in terms of the relevant micro-videos whose representations are also dependent on the relevant concepts. This pipeline convolution nature for user representation learning requires us to denoising the irrelevant information in each step. Number of Remaining Neighbors.Given the graph to denoise, we choose a î€›xed number of nodes for information aggregation. To concentrate on crucial points, we mainly discuss the concept denoising in this paper. Note that we have also tested a diî€erent number of one-hop neighbors for each user, where we decide to pick 6 micro-videos for every user out of her 10 neighbors. Here, we test the number of remaining concepts amongst{6,10,20,30} out of 40. The number of subgraphs is î€›xed to be four in this case. From Table 5 we can draw a conclusion that if we leave too many neighbors, noisy information will still exist and harm the model training. Yet if we leave too few neighbors, the model is likely to be over-denoised and miss much important information. In general, this parameter is not very sensitive for model performance. We could suggest using a relatively small value to enhance computation eî€œciency. Number of SubgraphsApparently, the number of subgraphs is also an important parameter to Conde. Similarly, we test the number of subgraphs amongst{2,4,6}, and Table 6 indicates that adding the number of subgraphs improves the performance further. However the improvement of evaluation metrics can not keep the same Table 5: Performance over diî€erent ğ‘˜ values. Remaining NeighborsMicro-Video pace with the resultant increasing training time. As the training cost is proportional to the number of subgraphs and the model can not obtain further remarkable performance gain by adding more subgraphs, we use ğ‘˜ = 4 in this paper. Table 6: Performance over diî€erent ğº values. Impact of Diî€erent Temperatures.We also test Condeâ€™s sensitivity to diî€erent temperatures. Speciî€›cally speaking, we set different starting temperatures and annealing ratios, and the model performs best when ğœ = 10 and ğœ‚ = 2ğ‘’ âˆ’ 4 on Micro-Video dataset as shown in Table 7. Table 7: Performance over diî€erent temperature settings. We further investigate whether Conde can î€›lter out noise and retain more meaningful information. To better visualize the results, we pick some users and their corresponding tripartite subgraphs, with items and concepts connected to each other. As ID is not explicit to describe an item, we use each micro-videoâ€™s concept neighbors instead, to facilitate better understanding of its content. In order to demonstrate the explainability of Conde, we î€›rst choose two user pairs, each of which share at least one same relevant item after performing denoising, according to Condeâ€™s result. As demonstrated in Figure 4, the concepts of the item are split out by orange and blue lines are the relevant ones after 2-phase denoising for the two users respectively. Here we use the Micro-Video dataset and translate every concept in English for easy understanding. We can observe that although two users have the same relevant item, they focus on diî€erent points of interest. Figure 4 further indicates that a micro-video itself can include various points of interest. Whatâ€™s more, we î€›nd another pair of users who interacted with the same item, and this item is deleted for one user but kept for the other by Conde. We compare the related item and all remaining concepts of these two users in Figure 5. The result shows that there is an obvious divergence between their preferences. Overall, these results suggest that Conde is able to discover informative yet relevant concepts out of noisy ones, besides enhancing the recommendation performance, but also support recommendation explainability. In this paper, we propose a novelconcept-awaredenoising graph neural network (named Conde) to address information redundancy challenges. To make full use of the textual information in microvideo recommendation scenarios, we extract concepts from captions and the comments associated with micro-videos. In this way, we can form a tripartite heterogeneous graph by connecting user, microvideo, and concept nodes. As a user will interact with hundreds of micro-videos and a micro-videos will receive lots of comments everyday, neither all micro-videos nor all concepts of a micro-video can reî€ect usersâ€™ preference precisely. Hence, we propose a personalized denoising methodology to derive user and item representations via graph neural network. The extensive experiments over a large micro-video dataset and a traditional E-Commerce dataset in two diî€erent languages demonstrate the eî€ectiveness of Conde. By abundant ablation studies with diî€erent experiment settings, the proposed Conde has proven its excellent potential to reî€ect the userâ€™s preference. This work was funded by Kuaishou and National Natural Science Foundation of China (No. 61872278). Chenliang Li is the corresponding author.
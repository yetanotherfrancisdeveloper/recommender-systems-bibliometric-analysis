Motif-based graph decomposition is widely used to mine hierarchical dense structures in graphs. In bipartite graphs, wing and tip decomposition construct a hierarchy of butterî€y (2,2-biclique) dense edge and vertex induced subgraphs, respectively. They have applications in several domains including e-commerce, recommendation systems and document analysis. Existing decomposition algorithms use a bottom-up approach that constructs the hierarchy in an increasing order of subgraph density. They iteratively select the entities (edges or vertices) with minimum support (butterî€y count) and pe el them i.e. remove them from them graph and update the support of other entities. The amount of butterî€ies in real-world bipartite graphs makes bottom-up peeling computationally demanding. Furthermore, the strict order of peeling entities results in a large number of iterations with sequential dependencies on preceding support updates. Consequently, parallel algorithms based on bottom up peeling can only utilize intra-iteration parallelism and require heavy synchronization, leading to poor scalability. In this paper, we propose a novel Parallel Bipartite Network peelinG (PBNG) framework which adopts a two-phased peeling approach to relax the order of peeling, and in turn, dramatically reduce synchronization. The î€›rst phase divides the decomposition hierarchy into few partitions, and requires little synchronization to compute such partitioning. The second phase concurrently processes all of these partitions to generate individual levels in the î€›nal decomposition hierarchy, and requires no global synchronization. Eî€ectively, both phases of PBNG parallelize computation across multiple levels of decomposition hierarchy, which is not possible with bottom-up peeling. The two-phased peeling further enables batching optimizations that dramatically improve the computational eî€œciency of PBNG. The proposed approach represents a non-trivial generalization of our prior work on a two-phased vertex peeling algorithm [30], and its adoption for both tip and wing decomposition. We empirically evaluate PBNG using several real-world bipartite graphs and demonstrate radical improvements over the existing approaches. On a shared-memory 36 core server, PBNG achieves up to 19 art parallel framework Pî¡î²Bîµî´î´î¥î²î¦î¬î¹, PBNG reduces synchronization by up to 15260 it achieves up to 38 decomposition results of some of the largest public real-world datasets, which PBNG can peel in few minutes/hours, but algorithms in current practice fail to process even in several days. Our source code is made available at https://github.com/kartiklakhotia/RECEIPT. Additional Key Words and Phrases: Graph Algorithms, Parallel Graph Analytics, Dense Graph Mining, Bipartite Graphs A bipartite graph ğ‘‰ (ğº)such that any edge systems naturally exhibit bipartite relationships, such as consumer-product purchase network of an e-commerce website [26 group memberships in a social network [ mining of dense structures in bipartite graphs has become a popular research topic [30, 51, 54, 66, 67, 72]. .5Ã—speedup over state-of-the-art algorithms speciî€›cally tuned for wing decomposition. We also present the î€›rst ğº (ğ‘Š = (ğ‘ˆ,ğ‘‰ ), ğ¸)is a special graph whose vertices can be partitioned into two disjoint setsğ‘ˆ (ğº)and ], user-ratings data in a recommendation system [23,34], author-paper network of a scientiî€›c î€›eld [41], Nucleus decomposition is commonly used to mine hierarchical dense subgraphs where minimum clique participation of an edge in a subgraph determines its level in the hierarchy [53]. Truss decomposition is arguably the most popular case of nucleus decomposition which uses triangles (3-cliques) to measure subgraph density [5,18,46,50,63,70]. However, truss decomposition is not directly applicable for bipartite graphs as they do not have triangles. One way to circumvent this issue is to compute unipartite projection of a bipartite graphğºwhich contains an edge between each pair of vertices with common neighbor(s) inğº. But this approach suî€ers from (a) information loss which can impact quality of results, and (b) explosion in dataset size which can restrict its scalability [51]. Butterî€y (2,2âˆ’biclique/quadrangle) is the smallest cohesive motif in bipartite graphs. Butterî€ies can be used to directly analyze bipartite graphs and have drawn signiî€›cant research interest in the recent years [24,48,49,51,54,64â€“ 66]. Sariyuce and Pinar [51] use butterî€ies as a density indicator to deî€›ne the notion ofğ‘˜âˆ’wings andğ‘˜âˆ’tips, as maximal bipartite subgraphs where each edge and vertex, respectively, is involved in at leastğ‘˜butterî€ies. For example, the graph shown in î€›g.1a is a 1âˆ’wing since each edge participates in at least one butterî€y. Analogous toğ‘˜âˆ’trusses [8], ğ‘˜âˆ’wings (ğ‘˜âˆ’tips) represent hierarchical dense structures in the sense that a(ğ‘˜ +1)âˆ’wing ((ğ‘˜ +1)âˆ’tip) is a subgraph of a ğ‘˜âˆ’wing (ğ‘˜âˆ’tip). In this paper, we explore parallel algorithms for wingand tip decomposition analytics, that construct the entire hierarchy ofğ‘˜âˆ’wings andğ‘˜âˆ’tips in a bipartite graph, respectively. For space-eî€œcient representation of the hierarchy, these analytics output wing number of each edgeğ‘’or tip number of each vertexğ‘¢, which represent the densest level of hierarchy that containsğ‘’orğ‘¢, respectively. Wing and tip decomposition have several real-world applications such as: â€¢Link prediction in recommendation systems or e-commerce websites that contain communities of users with common preferences or purchase history [12, 24, 32, 40]. â€¢Mining nested communities in social networks or discussion forums, where users aî€œliate with broad groups and more speciî€›c sub-groups based on their interests. [24]. â€¢ Detecting spam reviewers that collectively rate selected items in rating networks [15, 34, 38]. â€¢ Document clustering by mining co-occurring keywords and groups of documents containing them [10]. â€¢ Finding nested groups of researchers from author-paper networks [51] with varying degree of collaboration. Existing algorithms for decomposing bipartite graphs typically employ an iterative bottom-up peeling approach [51, 54], wherein entities (edges and vertices for wing and tip decomposition, respectively) with the minimum support (butterî€y count) are peeled in each iteration. Peeling an entityğ‘™involves deleting it from the graph and updating the support of other entities that share butterî€ies withğ‘™. However, the huge number of butterî€ies in bipartite graphs makes bottom-up peeling computationally demanding and renders large graphs intractable for decomposing by sequential algorithms. For example, trackers â€“ a bipartite network of internet domains and the trackers contained in them, has 140 million edges but more than 20 trillion butterî€ies. Parallel computing is widely used to scale such high complexity analytics to large datasets [33,42,57]. However, the bottom-up peeling approach used in existing parallel frameworks [54] severely restricts parallelism by peeling entities in a strictly increasing order of their entity numbers (wing or tip numbers). Consequently, it takes a very large number of iterations to peel an entire graph, for example, it takes>31 million iterations to peel all edges of the trackers dataset using bottom-up peeling. Moreover, each peeling iteration is sequentially dependent on support updates in all prior iterations, thus mandating synchronization of parallel threads before each iteration. Hence, the conventional Fig. 1. (a) Bipartite graph approach of parallelizing workload within each iteration [ parallel scalability. In this paper, we propose a novel two-phased peeling approach for generalized bipartite graph decomposition. Both phases in the proposed approach exploit parallelism across multiple levels of the decomposition hierarchy to drastically reduce the number of parallel peeling iterations and in turn, the amount of thread synchronization. The î€›rst phase creates a coarse hierarchy which divides the set of entity numbers into few non-overlapping ranges. It accordingly partitions the entities by iteratively peeling the ones with support in the lowest range. A major implication of range-based partitioning is that each iteration peels a large number of entities corresponding to a wide range of entity numbers. This results in large parallel workload per iteration and little synchronization. The second phase concurrently processes multiple partitions to compute the exact entity numbers. Absence of overlap between corresponding entity number ranges enables every partition to be peeled independently of others. By assigning each partition exclusively to a single thread, this phase achieves parallelism with no global synchronization. We implement the two-phased peeling as a part of our Parallel Bipartite Network peelinG (PBNG) framework which adapts this approach for both wing and tip decomposition. PBNG further encapsulates novel workload optimizations that exploit batched peeling of numerous entities in the î€›rst phase to dramatically improve computational eî€œciency of decomposition. Overall, our contributions can be summarized as follows: (1)We propose a novel two-phased peeling approach for bipartite graph decomposition, that parallelizes workload across diî€erent levels of decomposition hierarchy. The proposed methodology is implemented in our PBNG framework which generalizes it for both vertex and edge peeling. To the best of our knowledge, this is the î€›rst approach to utilize parallelism across the levels of both wing and tip decomposition hierarchies. (2)Using the proposed two-phased peeling, we achieve a dramatic reduction in the number of parallel peeling iterations and in turn, the thread synchronization. As an example, wing decomposition of trackers dataset in PBNG requires only 2034 parallel peeling iterations, which is four orders of magnitude less than existing parallel algorithms. (3)We develop novel optimizations that are highly eî€ective for the two-phased peeling approach and dramatically reduce the work done by PBNG. As a result, PBNG traverses only 3.3 trillion wedges during tip decomposition of internet domains in trackers dataset, compared to 211.1 trillion wedges traversed by the state-of-the-art. We empirically evaluate PBNG on several real-world bipartite graphs and demonstrate its superior scalability compared to state-of-the-art. We show that PBNG signiî€›cantly expands the limits of current practice by decomposing some of the largest publicly available datasets in few minutes/hours, that existing algorithms cannot decompose in multiple days. In a previous work [30], we developed a two-phased algorithm for tip decomposition (vertex peeling). This paper generalizes the two-phased approach for peeling any set of entities within a bipartite graph. We further present non-trivial techniques to adopt the two-phased peeling for wing decomposition (edge peeling), which is known to reveal better quality dense subgraphs than tip decomposition [51]. 2 BACKGROUND In this section, we formally deî€›ne the problem statement and review existing methods for butterî€y counting and bipartite graph decomposition. Note that counting is used to initialize support (running count of butterî€ies) of each vertex or edge before peeling, and also inspires some optimizations to improve eî€œciency of decomposition. Table 1 lists some notations used in this paper. For description of a general approach, we use the term entity to denote a vertex (for tip decomposition) or an edge (for wing decomposition), and entity number to denote tip or wing number (sec.2.2), respectively. Correspondingly, notationsâŠ²âŠ³andğœƒdenote the support and entity number of entityğ‘™. ğº (ğ‘Š = (ğ‘ˆ , ğ‘‰ ), ğ¸) bipartite graph ğº with disjoint vertex sets ğ‘ˆ (ğº) and ğ‘‰ (ğº), and edges ğ¸(ğº) ğœƒ/ğœƒmaximum tip number of vertices in ğ‘ˆ (ğº) / maximum wing number of edges in ğ¸(ğº) 2.1 Buî€erfly counting A butterî€y (2,2-bicliques/quadrangle) can be viewed as a combination of two wedges with common endpoints. For example, in î€›g.1a, both wedges butterî€ies is to explore all wedges and combine the ones with common end points. However, this is computationally ineî€œcient with complexity O Chiba and Nishizeki [ from each vertexî€Ã a cache-eî€œcient version of this algorithm that traverses wedges such that the degree of the last vertex is greater than the that of the start and middle vertices (alg.1, line 10). Thus, wedge explorations frequently end at a small set of high degree vertices that can be cached. The vertex-priority algorithm can be easily parallelized by concurrently processing multiple start vertices [ PBNG, we use the per-vertex and per-edge counting variants of the parallel algorithm [ avoid conî€icts, each thread is provided an individual and butterî€y counts of entities are incremented using atomic operations. Algorithm 1 Counting per-vertex and per-edge butterî€ies (pveBcnt) Input: Bipartite Graph ğº (ğ‘Š = (ğ‘ˆ , ğ‘‰ ), ğ¸) Output: Butterî€y counts â€“ âŠ²âŠ³ â† 0 for each ğ‘¢ âˆˆ ğ‘Š (ğº); âŠ²âŠ³ 2.2 Bipartite Graph Decomposition Sariyuce et al.[ They are formally deî€›ned as follows: ğ‘¢, only those wedges are expanded whereğ‘¢has the highest degree. It has a theoretical complexity ofî€‘ min (ğ‘‘, ğ‘‘)= O(ğ›¼ Â· ğ‘š), which is state-of-the-art for butterî€y counting. Wang et al.[66] further propose in increasing order of new labels â† âŠ²âŠ³+ ğ‘ğ‘ğ‘›ğ‘¡; âŠ²âŠ³â† âŠ²âŠ³+ ğ‘ğ‘ğ‘›ğ‘¡ and ğ‘’denote edges (ğ‘ ğ‘¡ğ‘ğ‘Ÿğ‘¡,ğ‘šğ‘–ğ‘‘) and (ğ‘šğ‘–ğ‘‘, ğ‘™ğ‘ğ‘ ğ‘¡), respectively â† âŠ²âŠ³+ (ğ‘¤ğ‘’ğ‘‘ğ‘”ğ‘’_ğ‘ğ‘œğ‘¢ğ‘›ğ‘¡ [ğ‘™ğ‘ğ‘ ğ‘¡] âˆ’ 1); âŠ²âŠ³â† âŠ²âŠ³+ (ğ‘¤ğ‘’ğ‘‘ğ‘”ğ‘’_ğ‘ğ‘œğ‘¢ğ‘›ğ‘¡ [ğ‘™ğ‘ğ‘ ğ‘¡] âˆ’ 1) 51] introducedğ‘˜âˆ’tips andğ‘˜âˆ’wings as a butterî€y dense vertex and edge-induced subgraphs, respectively. Dî¥î¦î©î®î©î´î©î¯î® 1. A bipartite subgraph ğ» âŠ† ğº, induce d on edges ğ¸(ğ» ) âŠ† ğ¸(ğº), is a k-wing iî€ â€¢ each edge ğ‘’ âˆˆ ğ¸(ğ» ) is contained in at least k butterî€ies, â€¢ any two edges (ğ‘’, ğ‘’) âˆˆ ğ¸is connected by a series of butterî€ies, â€¢ ğ» is maximal i.e. no other ğ‘˜âˆ’wing in ğº subsumes ğ». Dî¥î¦î©î®î©î´î©î¯î® 2. A bipartite subgraph ğ» âŠ† ğº, induce d on vertex sets ğ‘ˆ (ğ» ) âŠ† ğ‘ˆ (ğº) and ğ‘‰ (ğ») = ğ‘‰ (ğº), is a k-tip iî€ â€¢ each vertex ğ‘¢ âˆˆ ğ‘ˆ (ğ» ) is containe d in at least k butterî€ies, â€¢ any two vertices {ğ‘¢, ğ‘¢} âˆˆ ğ‘ˆ (ğ» ) are connected by a series of butterî€ies, â€¢ ğ» is maximal i.e. no other ğ‘˜âˆ’tip in ğº subsumes ğ». Bothğ‘˜âˆ’wings andğ‘˜âˆ’tips are hierarchical as ağ‘˜âˆ’wing/ğ‘˜âˆ’tip completely overlaps with ağ‘˜âˆ’wing/ğ‘˜âˆ’tip for all ğ‘˜â‰¤ ğ‘˜. Therefore, instead of storing allğ‘˜âˆ’wings, a wing numberğœƒof an edgeğ‘’is deî€›ned as the maximumğ‘˜for whichğ‘’is present in ağ‘˜âˆ’wing. Similarly, tip numberğœƒof a vertexğ‘¢is the maximumğ‘˜for whichğ‘¢is present in a ğ‘˜âˆ’tip. Wing and tip numbers act as a space-eî€œcient indexing from which any level of theğ‘˜âˆ’wing andğ‘˜âˆ’tip hierarchy, respectively, can be quickly retrieved [51]. In this paper, we study the problem of î€›nding wing and tip numbers, also known as wing and tip decomposition, respectively. Bottom-Up Peeling (BUP) is a commonly employed technique to compute wing decomposition (alg.2). It initializes the support of each edge using per-edge butterî€y counting (alg.2, line 1), and then iteratively peels the edges with minimum support until no edge remains. When an edgeğ‘’ âˆˆ ğ¸is peeled, its support in that iteration is recorded as its wing number (alg.2, line 4). Further, for every edgeğ‘’that shares butterî€ies withğ‘’, the supportâŠ²âŠ³is decreased corresponding to the removal of those butterî€ies. Thus, edges are peeled in a non-decreasing order of wing numbers. Bottom-up peeling for tip decomposition utilizes a similar procedure for peeling vertices. A crucial distinction here is that in tip decomposition, vertices in only one of the setsğ‘ˆ (ğº)orğ‘‰ (ğº)are peeled as ağ‘˜âˆ’tip consists of all vertices from the other set (defn.2). For clarity of description, we assume thatğ‘ˆ (ğº)is the vertex set to peel. As we will see later in sec.3.2, this distinction renders the two-phased approach of PBNG highly suitable for decomposition. Runtime of bottom-up peeling is dominated by wedge traversal required to î€›nd butterî€ies that contain the en-î€ÃÃî€‘ tities being peeled (alg.2, lines 7-9). The overall complexity for wing decomposition isOğ‘‘=î€î€‘î€î€‘î€î€‘ OÃÃğ‘‘ğ‘‘. Relatively, tip decomposition has a lower complexity ofOÃÃğ‘‘= OÃğ‘‘, which is still quadratic in vertex degrees and very high in absolute terms. 2.3 Bloom-Edge-Index Chiba and Nishizeki [7] proposed storing wedges derived from the computational patterns of their butterî€y counting algorithm, as a space-eî€œcient representation of all butterî€ies. Wang et al.[67] used a similar representation termed Bloom-Edge-Index (BE-Index) for quick retrieval of butterî€ies containing peeled edges during wing decomposition. We extensively utilize BE-Index not just for computational eî€œciency, but also for enabling parallelism in wing decomposition. In this subsection, we give a brief overview of some key concepts in this regard. The butterî€y counting algorithm assigns priorities (labels) to all vertices in a decreasing order of their degree (alg.1, line 2). Based on these priorities, a structure called maximal priorityğ‘˜âˆ’bloom, which is the basic building block of BE-Index, is deî€›ned as follows [67]: Dî¥î¦î©î®î©î´î©î¯î® 3. A maximal priorityğ‘˜âˆ’bloomğµ(ğ‘Š = (ğ‘ˆ , ğ‘‰ ), ğ¸)is a(2, ğ‘˜)âˆ’biclique (eitherğ‘ˆ (ğµ)orğ‘‰ (ğµ)has exactly two vertices, each connected to all ğ‘˜ vertices in ğ‘‰ (ğµ) or ğ‘ˆ (ğµ), respectively) that satisî€›es the following conditions: Algorithm 2 Wing decomposition using bottom-up peeling (BUP) Input: Bipartite graph ğº (ğ‘Š = (ğ‘ˆ , ğ‘‰ ), ğ¸) (1) The highest priority vertex in ğ‘Š (ğµ) belongs to the set (ğ‘ˆ (ğµ) or ğ‘‰ (ğµ)) which has exactly two vertices, and (2) ğµ is maximal i.e. there exists no (2, ğ‘˜)âˆ’biclique ğµ Maximal Priority Bloom Notations dominant set of be twins of each other in bloom is a maximal priority 2 The twin of an edge is called the bloom number of ğµ. Wang et al.[67] further prove the following properties of maximal priority blooms: Pî²î¯î°î¥î²î´î¹ 2. A butterî€y in ğº must be contained in exactly one maximal priority ğ‘˜âˆ’bloom. Note that the butterî€ies containing an edge all blooms that contain ğ‘’. For quick access to blooms of an edge and vice-versa, BE-Index is deî€›ned as follows: Dî¥î¦î©î®î©î´î©î¯î® 4. BE-Index of a graph priority blooms in ğº to the respective edges within the blooms. â€¢ W(I) â€“ Each vertex ğµ âˆˆ ğ‘ˆ (ğ¼ ) also stores the bloom number ğ‘˜ â€¢ E(I) â€“ Each edge (ğ‘’, ğµ) âˆˆ ğ¸ (ğ¼) is labeled with ğ‘¡ğ‘¤ğ‘–ğ‘›(ğ‘’, ğµ). BE-Index Notations notationğµ ğµ âˆˆ ğ‘ˆ (ğ¼ ) by ğ‘˜(ğ¼ ). Note that ğ‘˜ â† âŠ²âŠ³, ğ¸(ğº) â† ğ¸ (ğº) \ {ğ‘’} denote edge (ğ‘¢, ğ‘£) â† maxğœƒ, âŠ²âŠ³âˆ’1; âŠ²âŠ³â† maxğœƒ, âŠ²âŠ³âˆ’1; âŠ²âŠ³â† maxğœƒ, âŠ²âŠ³âˆ’1âŠ² Update support ğµ. Note that each vertex in the non-dominant set has exactly two incident edges inğ¸(ğµ), that are said to ğ‘˜âˆ’bloomğµ(ğ‘Š = (ğ‘ˆ , ğ‘‰ ), ğ¸)consists of exactlyî€€î€=butterî€ies. Each edgeğ‘’ âˆˆ ğ¸(ğµ)is contained ğ‘˜ âˆ’1 butterî€ies inğµ. Further, edgeğ‘’shares allğ‘˜ âˆ’1 butterî€ies withğ‘¡ğ‘¤ğ‘–ğ‘›(ğ‘’, ğµ), and one butterî€y each with all âˆˆ ğ¸(ğµ) \ {ğ‘¡ğ‘¤ğ‘–ğ‘›(ğ‘’, ğµ)}. Vertices inğ‘ˆ (ğ¼ )andğ‘‰ (ğ¼)uniquely represent all maximal priority blooms inğºand edges inğ¸(ğº), respectively. There exists an edge(ğ‘’, ğµ) âˆˆ ğ¸(ğ¼ )if and only if the corresponding bloomğµ âŠ† ğºcontains the edgeğ‘’ âˆˆ ğ¸(ğº). (orğ‘’) to denote both a bloom (or edge) and its representative vertex in BE-Index. Neighborhood of a vertex andğ‘’ âˆˆ ğ‘‰ (ğ¼ )is denoted byğ‘(ğ¼ )andğ‘(ğ¼ ), respectively. The bloom number ofğµin BE-Indexğ¼is denoted Fig.2 depicts a graphğº(subgraph ofğºfrom î€›g.1) and its BE-Index.ğºconsists of two maximal priority blooms: (a)ğµwith dominant setğ‘‰ (ğµ) = {ğ‘£, ğ‘£}andğ‘˜(ğ¼ ) =2, and (b)ğµwith dominant vertex setğ‘‰ (ğµ) = {ğ‘£, ğ‘£}and ğ‘˜(ğ¼ ) =3. As an example, edgeğ‘’is a part of 1 butterî€y inğµshared with twinğ‘’, and 2 butterî€ies inğµshared with twin ğ‘’. With all other edges in ğµand ğµ, it shares one butterî€y each. Construction of BE-Index: Index construction can be easily embedded within the counting procedure (alg.1). Each pair of endpoint vertices{ğ‘ ğ‘¡ğ‘ğ‘Ÿğ‘¡, ğ‘™ğ‘ğ‘ ğ‘¡ }of wedges explored during counting, represents the dominating set of a bloom (with ğ‘™ğ‘ğ‘ ğ‘¡as the highest priority vertex) containing the edges{ğ‘ ğ‘¡ğ‘ğ‘Ÿğ‘¡,ğ‘šğ‘–ğ‘‘}and{ğ‘šğ‘–ğ‘‘, ğ‘™ğ‘ğ‘ ğ‘¡ }for all midpointsğ‘šğ‘–ğ‘‘. Lastly, for a given vertexğ‘šğ‘–ğ‘‘, edges{ğ‘ ğ‘¡ğ‘ğ‘Ÿğ‘¡,ğ‘šğ‘–ğ‘‘}and{ğ‘šğ‘–ğ‘‘, ğ‘™ğ‘ğ‘ ğ‘¡ }are twins of each other. Thus, the space and computational complexities of BE-Index construction are bounded by the the wedges explored during counting which is O(ğ›¼ Â· ğ‘š). Wing Decomposition with BE-Index: Alg.3 depicts the procedure to peel an edgeğ‘’using BE-Indexğ¼. Instead of traversing wedges inğºto î€›nd butterî€ies ofğ‘’, edges that share butterî€ies withğ‘’are found by exploring 2-hop neighborhood ofğ‘’inğ¼(alg.3, line 7). Number of butterî€ies shared with these edges in each bloom is also obtained analytically using property 1 (alg.3, lines 4 and 8). Remarkably, peeling an edgeğ‘’using alg.3 requires at mostâŠ²âŠ³î€Ãî€‘ traversal in BE-Index [67]. Thus, it reduces the computational complexity of wing decomposition toOâŠ²âŠ³. However, it is still proportional to the number of butterî€ies which can be enormous for large graphs. Algorithm 3 Support update during edge peeling, using BE-Index 2.4 Challenges Bipartite graph decomposition is computationally very expensive and parallel computing is widely used to accelerate such workloads. However, state-of-the-art parallel framework Pî¡î²Bîµî´î´î¥î²î¦î¬î¹ [11,54] is based on bottom-up peeling and only utilizes parallelism within each peeling iteration. This restricted parallelism is due to the following sequential dependency between iterations â€“ support updates in an iteration guide the choice of entities to peel in the subsequent iterations. Hence, even though Pî¡î²Bîµî´î´î¥î²î¦î¬î¹ is work-eî€œcient [54], its scalability is limited because: (1)It incurs large number of iterations and low parallel workload per iteration. Due to the resulting synchronization and load imbalance, intra-iteration parallelism is insuî€œcient for substantial acceleration. Objective 1 synchronization and exposes large amount of parallel workload. (2)It traverses an enormous amount of wedges (or bloom-edge links in BE-Index) to retrieve butterî€ies removed by peeling. This is computationally expensive and can be infeasible on large datasets, even for a parallel algorithm. Objective 2 is therefore, to reduce the amount of traversal in practice. 3 PARALLEL BIPARTITE NETWORK PEELING (PBNG) In this section, we describe a generic parallelism friendly two-phased peeling approach for bipartite graph decomposition (targeting objective 1, sec.2.4). We further demonstrate how this approach is adopted individually for tip and wing decomposition in our Parallel Bipartite Network peelinG (PBNG) framework. 3.1 Two-phased Peeling The fundamental observation underlining our approach is that entity number number of butterî€ies shared between ğº (ğ‘Š = (ğ‘ˆ , ğ‘‰ ), ğ¸) and per-entity butterî€y counts in ğº (obtained from counting), only the cumulative eî€ect of peeling all entities with entity number strictly smaller than decomposition hierarchy. Due to commutativity of addition, the order of peeling these entities has no impact on This insight allows us to eliminate the constraint of deleting only minimum support entities in each iteration, which bottlenecks the available parallelism. To î€›nd concurrently, providing suî€œcient parallel workload. However, for every possible number will be computationally very ineî€œcient. To avoid this ineî€œciency, we develop a novel two-phased approach. 3.1.1 Coarse-grained Decomposition. The î€›rst phase divides the spectrum of all possible entity numbers intoğ‘ƒsmaller non-overlapping ranges user-speciî€›ed parameter. A range allğ‘— â‰  ğ‘–. These ranges are computed using a heuristic described in sec.3.1.3. Corresponding to each range also computes the partition entity number Coarse-grained Decomposition (PBNG CD). The absence of overlap between the ranges allows each subset to be peeled independently of others in the second phase, for exact entity number computation. Entity partitions are computed by iteratively peeling entities whose support lie in the minimum range (alg.4,lines 5-13). For each partition, the î€›rst peeling iteration in PBNG CD scans all entities to î€›nd the peeling set, denoted as ğ‘ğ‘ğ‘¡ğ‘–ğ‘£ğ‘’ğ‘†ğ‘’ğ‘¡ up peeling, PBNG CD does not require a priority queue data structure which makes support updates relatively cheaper. PBNG CD can be visualized as a generalization of bottom-up peeling (alg.2). In each iteration, the latter peels entities with minimum support ( is therefore, to design a parallelism aware peeling methodology for bipartite graphs that reduces ğœƒof an entityğ‘™, the î€›rst phase of PBNG computes bounds onğœƒ. Therefore, we refer to this phase as (alg.4, line 9). In subsequent iterations,ğ‘ğ‘ğ‘¡ğ‘–ğ‘£ğ‘’ğ‘†ğ‘’ğ‘¡is computed jointly with support updates. Thus, unlike bottom- Fig. 3. Graphical illustration of PBNGâ€™s two-phased peeling for wing decomposition of the graph ğº from fig.1. The coarse-grained decomposition divides ğ¸ (ğº) into ğ‘ƒ = 2 partitions using parallel peeling iterations. The fine-grained decomposition peels each For example, in î€›g.3, PBNG CD divides edgesğ¸(ğº)into two partitions corresponding to rangesğ‘…= [0,2]andğ‘…= [3,5], whereas bottom-up peeling will create 4 partitions corresponding to every individual level in the decomposition hierarchy (ğœƒ = {1,2,3,4}). Settingğ‘ƒ â‰ª ğœƒensures a large number of entities peeled per iteration (suî€œcient parallel workload) and signiî€›cantly fewer iterations (dramatically less synchronization) compared to bottom-up peeling. In addition to the ranges and partitions, PBNG CD also computes a support initialization vectorâŠ²âŠ³. For an entity ğ‘™ âˆˆ ğ¿,âŠ²âŠ³is the number of butterî€ies thatğ‘™shares only with entities in partitionsğ¿such thatğ‘— â‰¥ ğ‘–. In other words, it represents the aggregate eî€ect of peeling entities with entity number in ranges lower thanğ‘…. During iteative peeling in PBNG CD, this number is inherently generated after the last peeling iteration ofğ‘…and copied intoâŠ²âŠ³(ğ‘™)(alg.4, lines 6-7). For example, in î€›g.3, support of ğ‘’after peeling ğ¸= {ğ‘’, ğ‘’, ğ‘’, ğ‘’, ğ‘’} is 3, which is recorded in âŠ²âŠ³. 3.1.2 Fine-grained Decomposition. The second phase computes exact entity numbers and is called Fine-grained Decomposition (PBNG FD). The key idea behind PBNG FD is that if we have the knowledge of all butterî€ies that each entity ğ‘™ âˆˆ ğ¿shares only with entities in partitionsğ¿such thatğ‘— â‰¥ ğ‘–,ğ¿can be peeled independently of all other partitions. TheâŠ²âŠ³vector computed in PBNG CD precisely indicates the count of such butterî€ies (sec.3.1.1) and hence, is used to initialize support values in PBNG FD. PBNG FD exploits the resulting independence among partitions to concurrently process multiple partitions using sequential bottom up peeling. Settingğ‘ƒ â‰« ğ‘‡ensures that PBNG FD can be eî€œciently Algorithm 4 PBNG Coarse-grained Decomposition (PBNG CD) for wing decomposition Input: Bipartite graph ğº (ğ‘Š = (ğ‘ˆ , ğ‘‰ ), ğ¸), # partitions ğ‘ƒ Output: Ranges {ğœƒ (1), ğœƒ (2) . . . ğœƒ (ğ‘ƒ + 1)}, Edge Partitions {ğ¸ â† {ğœ™} âˆ€ ğ‘– âˆˆ {1, 2 . . . ğ‘ƒ } parallelized across partitions on between diî€erent levels of decomposition hierarchy to eî€œciently parallelize the peeling process. The two-phased approach can potentially double the computation required for peeling. However, we note that since partitions are peeled independently in PBNG FD, support updates are not communicated across the partitions. Therefore, to improve computational eî€œciency, PBNG FD operates on a smaller representative subgraph each partitions ğ¿ â† arg min(ğœƒ)such that ğ‘¤ğ‘œğ‘Ÿğ‘˜ [ğœƒ] â‰¥ ğ‘¡ğ‘”ğ‘¡ + 1 â† ğ‘¡ğ‘¤ğ‘–ğ‘›(ğ‘’, ğµ), ğ‘˜(ğ¼ ) â† bloom number of ğµ in ğ¼î€€î€ (ğ‘’âˆ‰ ğ‘ğ‘ğ‘¡ğ‘–ğ‘£ğ‘’ğ‘†ğ‘’ğ‘¡)orğ‘’ğ‘‘ğ‘”ğ‘’ğ¼ ğ· (ğ‘’) < ğ‘’ğ‘‘ğ‘”ğ‘’ğ¼ğ· (ğ‘’)thenî€€î€ . Speciî€›cally, ğºpreserves a butterî€y âŠ²âŠ³ iî€ it satisî€›es both of the following conditions: (2) âŠ²âŠ³only contains entities from partitionsğ¿such thatğ‘— â‰¥ ğ‘–. IfâŠ²âŠ³contains an entity from lower ranged partitions, then it does not exist inğœƒ (ğ‘–)-level of decomposition hierarchy (lowest entity number inğ¿). Moreover, the impact of removing âŠ²âŠ³ on the support of entities in ğ¿, is already accounted for in âŠ²âŠ³(sec.3.1.1). For example, in î€›g.3,ğºcontains the butterî€yâŠ²âŠ³ =(ğ‘¢, ğ‘£, ğ‘¢, ğ‘£)because (a) it contains multiple edges{ğ‘’, ğ‘’} âˆˆ ğ¿ and satisî€›es condition 1, and (b) all edges in âŠ²âŠ³ are from ğ¿or ğ¿and hence, it satisî€›es condition 2. However, ğºdoes not contain this butterî€y because two if its edges are in ğ¿and hence, it does not satisfy condition 2 for ğº. 3.1.3 Range Partitioning. In PBNG CD, the î€›rst step for computing a partitionğ¿is to î€›nd the rangeğ‘…= [ğœƒ (ğ‘–), ğœƒ (ğ‘– + 1))(alg.4, line 8). For load balancing,ğœƒ (ğ‘– +1)should be computedsuch that the all partitionsğ¿pose uniform workload in PBNG FD. However, the representative subgraphs and the corresponding workloads are not known prior to actual partitioning. Furthermore, exact entity numbers are not known either and hence, we cannot determine beforehand, exactly which entities will lie inğ¿for diî€erent values ofğœƒ (ğ‘– +1). Considering these challenges, PBNG uses two proxies for range determination: (1) Proxy 1 â†’ current support âŠ²âŠ³of an entity ğ‘™ is used as a proxy for its entity number. (2)Proxy 2â†’complexity of peeling individual entities inğºis used as a proxy to estimate peeling workload in representative subgraphs. Now, the problem is to computeğœƒ (ğ‘– +1)such that estimated workload ofğ¿as per proxies, is close to the average workload per partition denoted asğ‘¡ğ‘”ğ‘¡. To this purpose, PBNG CD creates a bin for each support value, and computes the aggregate workload of entities in that bin. For a givenğœƒ (ğ‘– +1), estimated workload of peelingğ¿is the sum of workload of all bins corresponding to support less thanğœƒ (ğ‘– +1). Thus, the workload ofğ¿as a function ofğœƒ (ğ‘– +1)can be computed by a preî€›x scan of individual bin workloads (alg.4, lines 17-18). Using this function, the upper bound is chosen such that the estimated workload of ğ¿is close to but no less than ğ‘¡ğ‘”ğ‘¡ (alg.4, line 19). Adaptive Range Computation: Since range determination uses current support as a proxy for entity numbers, the target workload for each partitionğ¿is covered by the entities added toğ¿in its very î€›rst peeling iteration in PBNG CD. After the support updates in this iteration, more entities may be added toğ¿and î€›nal workload estimate ofğ¿may signiî€›cantly exceedğ‘¡ğ‘”ğ‘¡. This can result in signiî€›cant load imbalance among the partitions and potentially, PBNG CD could î€›nish in much fewer thanğ‘ƒpartitions. To avoid this scenario, we implement the following two-way adaptive range determination: (1)Instead of statically computing an average target, we dynamically updateğ‘¡ğ‘”ğ‘¡for every partition based on the remaining workload and the number of partitions to create. If a partition gets too much workload, the target for subsequent partitions is automatically reduced, thereby preventing a situation where all entities get peeled in â‰ª ğ‘ƒ partitions. (2)A partitionğ¿likely covers many more entities than the initial estimate based on proxy 1. The second adaptation scales down the dynamic target for ğ¿in an attempt to bring the actual workload close to the intended value. It assumes predictive local behavior i.e.ğ¿will overshoot the target similar toğ¿. Therefore, the scaling factor is computed as the ratio of initial workload estimate ofğ¿duringğœƒ (ğ‘–)computation, and î€›nal estimate based on all entities inğ¿. 3.1.4 Partition scheduling in PBNG FD. While adaptive range determination(sec.3.1.3) tries to create partitions with uniform estimated workload, the actual workload per partition in PBNG FD depends on the the representative subgraphs ğºand can still have signiî€›cant variance. Therefore, to improve load balance across threads, we use scheduling strategies inspired from Longest Processing Time (LPT) scheduling rule which is a well known We use the workload of ğ¿ â€¢Dynamic task allocation from the queue and processes the corresponding partition. Thus, all threads are busy until every partition is scheduled. â€¢Workload-aware Scheduling partitions with highest workload get scheduled î€›rst and the threads processing them naturally receive fewer tasks in the future. Fig.4 shows how workload-aware scheduling can improve the eî€œciency of dynamic allocation. Fig. 4. Benefits of Workload-aware Scheduling (WaS) in a 3-thread (ğ‘‡ estimated time to peel them in PBNG FD. Dynamic allocation without WaS finishes in 28 units of time compared to 20 units with WaS. 3.2 Tip Decomposition In this section, we give a brief overview of PBNGâ€™s two-phased peeling (sec.3.1) applied for tip decomposition. A detailed description of the same is provided in our previous work [30]. For tip decomposition, PBNG CD divides the vertex set ğ‘¢ âˆˆ ğ‘ˆ (ğº) uses wedge count of vertices in one of the vertex sets of support updates to a vertex to support âŠ²âŠ³ PBNG FD also utilizes the fact that any butterî€y peeled (sec.2.2). If are satisî€›ed only when ğ‘Š= (ğ‘ˆ,ğ‘‰ (ğº)) FD (sec.3.1.4), we use the total wedges in ğº requires traversal of all wedges withğ‘¢as one of the endpoints. Therefore, range determination in PBNG CD can be simply computed by atomically aggregating the updates from individual vertices in ğ‘ğ‘ğ‘¡ğ‘–ğ‘£ğ‘’ğ‘†ğ‘’ğ‘¡. ğ‘¢ âˆˆ ğ‘ˆandğ‘¢âˆˆ ğ‘ˆ, the two conditions for preservingâŠ²âŠ³in either representative graphsğºorğº . Clearly,ğºpreserves every butterî€yğ‘¢, ğ‘£, ğ‘¢, ğ‘£where{ğ‘¢, ğ‘¢} âˆˆ ğ‘ˆ. For task scheduling in PBNG Given the bipartite nature of graphğº, any edge(ğ‘¢, ğ‘£) âˆˆ ğ¸(ğº)exists in exactly one of the subgraphsğºand thus, the collective space requirement of all induced subgraphs is bounded by ğ‘‚ (ğ‘š). Moreover, by the design of representative (induced) subgraphs, PBNG FD for tip decomposition traverses only those wedges for which both the endpoints are in the same partition. This dramatically reduces the amount of work done in PBNG FD compared to bottom-up peeling and PBNG CD. Note that we do not use BE-Index for tip decomposition due to the following reasons: â€¢Butterî€ies between two vertices are quadratic in the number of wedges between them, and wedge traversal (not butterî€y count) determines the work done in tip decomposition. Since BE-Index facilitates per-edge butterî€y retrieval, peeling a vertex using BE-Index will require processing each of its edge individually and can result in increasedÃÃ computation ifğ‘‘â‰ªâŠ²âŠ³(sec.2.3).î€î€‘ â€¢BE-Index has a high space complexity ofOÃmin(ğ‘‘, ğ‘‘)compared to justO(ğ‘š)space needed to store ğºand all induced subgraphsğº. This can make BE-Index based peeling infeasible even on machines with large amount of main memory. For example, BE-Index of a user-group dataset Orkut (327 million edges) has 26 billion blooms, 150 billion bloom-edge links and consumes 2.6 TB memory. 3.3 Wing Decomposition 3.3.1 Challenges. Each butterî€y consists of 4 edges inğ¸(ğº)which is the entity set to decompose in wing decomposition. This is unlike tip decomposition where each butterî€y has only 2 vertices from the decomposition setğ‘ˆ (ğº), and results in the following issues: (1)When a butterî€yâŠ²âŠ³is removed due to peeling, the support of unpeeled edge(s) inâŠ²âŠ³should be reduced by exactly 1 corresponding to this removal. However, when multiple (but not all) edges inâŠ²âŠ³are concurrently peeled in the same iteration of PBNG CD, multiple updates with aggregate value > 1 may be generated to unpeeled edges in âŠ²âŠ³. (2)It is possible that a butterî€yâŠ²âŠ³contains multiple but not all edges from a partition. Thus,âŠ²âŠ³may need to be preserved in the representative subgraph of a partition, but will not be present in its edge-induced subgraph. Due to these reasons, a trivial extension of tip decomposition algorithm (sec.3.2) is not suitable for wing decomposition. In this section, we explore novel BE-Index based strategies to enable two-phased peeling for wing decomposition. 3.3.2 PBNG CD. This phase divides the edgesğ¸(ğº)intoğ‘ƒpartitions â€“{ğ¸, ğ¸, . . . , ğ¸}, as shown in alg.4. Not only do we utilize BE-Index for computationally eî€œcient support update computation in PBNG CD, we also utilize it to avoid conî€icts in parallel peeling iterations of PBNG CD. Since a butterî€y is contained in exactly one maximal priority bloom (sec.2.3, property 2), correctness of support updates within each bloomğµimplies overall correctness of support updates in an iteration. To avoid conî€icts, we therefore employ the following resolution mechanism for each bloom ğµ: (1)If an edgeğ‘’and its twinğ‘’= ğ‘¡ğ‘¤ğ‘–ğ‘›(ğ‘’, ğµ)are both peeled in the same iteration, then only the edge with highest index amongğ‘’andğ‘’updates (a) the support of other edges inğµ, and (b) the bloom numberğ‘˜(ğ¼ )(alg.4, lines 26-31). This is because all butterî€ies in ğµ that contain ğ‘’ also contain ğ‘’(sec.2.3, property1). (2)If in an iteration, an edgeğ‘’ âˆˆ ğ‘ğ‘ğ‘¡ğ‘–ğ‘£ğ‘’ğ‘†ğ‘’ğ‘¡butğ‘’= ğ‘¡ğ‘¤ğ‘–ğ‘›(ğ‘’, ğµ) âˆ‰ ğ‘ğ‘ğ‘¡ğ‘–ğ‘£ğ‘’ğ‘†ğ‘’ğ‘¡, then the supportâŠ²âŠ³is decreased by exactly ğ‘˜(ğ¼ ) âˆ’ 1whenğ‘’is peeled. Other edges inğ‘ğ‘ğ‘¡ğ‘–ğ‘£ğ‘’ğ‘†ğ‘’ğ‘¡do not propagate any updates toâŠ²âŠ³via bloomğµ(alg.4, lines 26-30). This is becauseğ‘’is contained in exactlyğ‘˜(ğ¼ ) âˆ’ 1butterî€ies inğµ, all of which are removed whenğ‘’is peeled. To ensure thatğ‘˜(ğ¼ )correctly represents the butterî€ies shared between twin edges, support updates from all peeled edges are computed prior to updating ğ‘˜(ğ¼ ). Peeling an edge uses edge support as a proxy to estimate the workload of peeling each partition ğ¸ Algorithm 5 PBNG Fine-grained Decomposition (PBNG FD) for wing decomposition Input: Graph ğº (ğ‘Š = (ğ‘ˆ , ğ‘‰ ), ğ¸), BE-Index ğ¼ (ğ‘Š = (ğ‘ˆ,ğ‘‰ ), ğ¸), edge partitions {ğ¸ 3.3.3 PBNG FD. The î€›rst step for peeling a partition its representative subgraph to construct ğ¼ â€¢Computing expensive. Additionally, the overhead of index construction even for a few hundred partitions can be signiî€›cantly large. â€¢Any edge ğºrequires O (ğ‘šğ‘ƒ) memory space. To avoid these drawbacks, we directly compute ğº(alg.5, lines 12-25). Our partitioning mechanism ensures that all butterî€ies satisfying the two preservation conditions (sec.3.1.2) for a partition ğ¸ ğ‘’ âˆˆ ğ¸(ğº)requiresO(âŠ²âŠ³)traversal in the BE-Index. Therefore, range determination in PBNG CD Support initialization vector âŠ²âŠ³ for all ğ‘’ âˆˆ ğ¸âŠ² Initialize Support , . . . , ğ¼ â† âŠ²âŠ³, ğ¸â† ğ¸\ {ğ‘’} ) â† ğ¸, ğ‘ˆ (ğ¼) â† {ğœ™}, ğ¸(ğ¼) â† {ğœ™} âˆ€ ğ‘– âˆˆ {1, 2 . . . ğ‘ƒ } â† ğ‘¡ğ‘¤ğ‘–ğ‘›(ğ‘’, ğµ) (ğ¼) â†ğ‘¤ğ‘’ğ‘‘ğ‘”ğ‘’_ğ‘ğ‘œğ‘¢ğ‘›ğ‘¡ (ğ¼ , ğ¼, . . . , ğ¼} . However, this approach has the following drawbacks: ğºrequires mining all edges inğ¸(ğº)that share butterî€ies with edgesğ‘’ âˆˆ ğ¸, which can be computationally ğ‘’ âˆˆ ğ¸can potentially exist in all subgraphsğºsuch thatğ‘— â‰¤ ğ‘–. Therefore, creating and storing all subgraphs Firstly, for an edgeğ‘’ âˆˆ ğ¸, its link(ğ‘’, ğµ)with a bloomğµis preserved inğ¼if and only if the twinğ‘’= ğ‘¡ğ‘¤ğ‘–ğ‘›(ğ‘’, ğµ) âˆˆ ğ¸ such thatğ‘— â‰¥ ğ‘–(alg.5, lines 19-20). Since all butterî€ies inğµthat containğ‘’also containğ‘’(sec.2.3, property 1), none of them need to be preserved inğ¼ifğ‘— < ğ‘–. Moreover, if{ğ‘’, ğ‘’} âˆˆ ğ¸, their contribution to the bloom numberğ‘˜(ğ¼)is counted only once (alg.5, lines -22).î€€î€ Secondly, for a space-eî€œcient representation,ğ¼does not store a linkğ‘’, ğµifğ‘’âˆ‰ ğ¸. However, while such an edge ğ‘’will not participate in peeling ofğ¸, it may be a part of a butterî€y inğµthat satisî€›es both preservation conditions for ğ¼(sec.3.1.2). For example, î€›g.2 shows the representative subgraphğºand BE-Index for the partitionğ¸generated by PBNG CD in î€›g.3. For space eî€œciency, we do not store the links{(ğ‘’, ğµ), (ğ‘’, ğµ), (ğ‘’, ğµ), (ğ‘’, ğµ)}inğ¼. However, the two butterî€ies inğµâ€“(ğ‘’, ğ‘’, ğ‘’, ğ‘’)and(ğ‘’, ğ‘’, ğ‘’, ğ‘’), satisfy both preservation conditions forğ¼, and may be needed when peelingğ‘’orğ‘’. In order to account for such butterî€ies, we adjust the bloom numberğ‘˜(ğ¼)to correctly represent the number of butterî€ies inğµthat only contain edges from all partitionsğ¸such thatğ‘— â‰¥ ğ‘–(alg.5, lines 23-24).î€Œî€Œ For example, in î€›g.2b, we initialize the bloom number ofğµtoğ‘˜(ğ¼) =3 even thoughî€Œğ‘(ğ¼)î€Œ=2. Thus,ğ‘˜(ğ¼)î€€î€ correctly represents the= 3 butterî€ies in ğµ, that contain edges only from âˆª{ğ¸}. After the BE-Indices for partitions are computed, PBNG FD dynamically schedules partitions on threads, where they are processed using sequential bottom-up peeling. Here, the aggregate initial support of a partitionâ€™s edges (given by âŠ²âŠ³vector) is used as an indicator of its workload (alg.5, line 4) for LPT scheduling (sec.3.1.2). 4 ANALYSIS 4.1 Correctness of Decomposition Output In this section, we prove the correctness of wing numbers and tip numbers computed by PBNG. We will exploit comparisons with sequential BUP (alg.2) and hence, î€›rst establish the follwing lemmas: Lî¥î­î­î¡ 1. InBUP, the supportâŠ²âŠ³of an edgeğ‘’at any timeğ‘¡before the î€›rst edge with wing numberâ‰¥ ğœƒis peeled, depends on the cumulative eî€ect of all edges peeled till ğ‘¡ and is independent of the order in which they are peeled. Pî²î¯î¯î¦.LetâŠ²âŠ³denote the number of butterî€ies inğºthat containğ‘’,ğ‘†be the set of vertices peeled till timeğ‘¡and âŠ²âŠ³denote a butterî€y containing ğ‘’ and other edges {ğ‘’, ğ‘’, ğ‘’} such that ğ‘ > ğ‘ > ğ‘ (for uniqueness of representation). Ifğ‘’,ğ‘’orğ‘’are peeled tillğ‘¡, corresponding to the removal ofâŠ²âŠ³, only one of them (the î€›rst edge to be peeled) reduces the supportâŠ²âŠ³by a unit. SinceBUPpeels edges in a non-decreasing order of their wing numbers,ğœƒ< ğœƒÃ for allğ‘’âˆˆ ğ‘†. Hence, current support (alg.2, line 11) ofğ‘’is given byâŠ²âŠ³= âŠ²âŠ³âˆ’1(ğ‘’âˆˆ ğ‘† or ğ‘’âˆˆ ğ‘† or ğ‘’âˆˆ ğ‘†). The î€›rst term of RHS is constant for a givenğº, and by commutativity of addition, the second term is independent of the order in which contribution of individual butterî€ies are added. Therefore,âŠ²âŠ³is independent of the order of peeling inğ‘†.â–¡ Lî¥î­î­î¡ 2. Given a setğ‘†of edges peeled in an iteration, the parallel peeling in PBNG CD (alg.4, lines 21-33) correctly updates the support of remaining edges in ğ¸(ğº). Pî²î¯î¯î¦.Parallel updates are correct if for an edgeğ‘’not yet assigned to any partition,âŠ²âŠ³decreases by exactly 1 for each butterî€y ofğ‘’deleted in a peeling iteration. By property 2 (sec.2.3), parallel updates are correct if this holds true for butterî€ies deleted within each bloom. Consider a bloomğµ(ğ‘Š = (ğ‘ˆ , ğ‘‰ ), ğ¸)and letâŠ²âŠ³âŠ† ğµbe a butterî€y containing edges{ğ‘’, ğ‘’, ğ‘’, ğ‘’}, where ğ‘’= ğ‘¡ğ‘¤ğ‘–ğ‘›(ğ‘’, ğµ)andğ‘’= ğ‘¡ğ‘¤ğ‘–ğ‘›(ğ‘’, ğµ)(property 1, sec.2.3), such thatâŠ²âŠ³is deleted in theğ‘—peeling iteration of PBNG CD. Clearly, neither of âŠ²âŠ³corresponding to the deletion of butterî€y deleted if and only if either of the following is true: (1) ğ‘’ âˆˆ ğ‘† â†’ (2) ğ‘’ âˆ‰ ğ‘†but in ğµ that contains ğ‘’ (property 1, sec.2.3). No updates from other edges are propagated to âŠ²âŠ³ (3) {ğ‘’, ğ‘’} âˆ‰ ğ‘† is decreased by exactly 1 when the highest indexed edge among (ğ‘’, ğµ) not generate support updates corresponding to âŠ²âŠ³ Lemmas 1 and 2 together show that whether we peel a set any order in PBNG CD, the support of edges with wing numbers higher than all edges in peelingğ‘†. Next, we show that PBNG CD correctly computes the edge partitions corresponding to wing number ranges and î€›nally prove that PBNG FD outputs correct wing numbers for all edges. For ease of explanation, we use denote the support of a edge ğ‘’ after ğ‘— Consider an edge the number of butterî€ies containing butterî€ies that contain which is a contradiction. Thus, no such Pî²î¯î¯î¦. edges not peeled till this iteration. Clearly, be peeled in or before the butterî€ies that contain edges only from wing number, ğœƒ Tî¨î¥î¯î²î¥î­ 1. PBNG CD (alg.4) correctly computes the edge partitions corresponding to every wing number range. Tî¨î¥î¯î²î¥î­ 2. PBNG correctly computes the wing numbers for all ğ‘’ âˆˆ ğ¸ (ğº). In this case,ğ‘’is already assigned to a partition and updates toâŠ²âŠ³have no impact on the output of PBNG. ğ‘’âˆˆ ğ‘† â†’ âŠ²âŠ³is reduced by exactly(ğ‘˜âˆ’1)via bloomğµ, which amounts to unit reduction per each butterî€y butğ‘’âˆˆ ğ‘†orğ‘’âˆˆ ğ‘† â†’ âŠ²âŠ³is decreased by exactly 1 whenğ‘’/ğ‘’is peeled. If both{ğ‘’, ğ‘’} âˆˆ ğ‘†, thenâŠ²âŠ³ and(ğ‘’, ğµ)are deleted and bloom numberğ‘˜is decreased by 1. Hence, subsequent peeling of any edges will Letğ‘—be the î€›rst iteration in PBNG CD that wrongly peels a set of edgesğ‘†, and assigns them toğ¸even â‰¥ ğœƒ (ğ‘– +1) âˆ€ ğ‘’ âˆˆ ğ‘†. Letğ‘†âŠ‡ ğ‘†be the set of all edges with wing numbersâ‰¥ ğœƒ (ğ‘– +1)andğ‘†be the set of âŠ† ğ¸(ğº) \ ğ‘†. Letğ‘…be the smallest range for which there exists an edgeğ‘’such thatğœƒ (ğ‘–) â‰¤ ğœƒ< ğœƒ (ğ‘– +1), butğ‘’ âˆˆ ğ¸for . Letğ‘—be the last peeling iteration in PBNG CD that assigns edges toğ¸, andğ‘†= âˆªğ¸denote the set of Pî²î¯î¯î¦.From theorem 1,ğœƒ (ğ‘–) â‰¤ ğœƒ< ğœƒ (ğ‘– +1)for each edgeğ‘’ âˆˆ ğ¸. Consider an edge partitionğ¸and Let ğ‘†= ğ¸âˆª ğ¸. . . ğ¸denote the set of edges peeled beforeğ¸in PBNG CD. From theorem 1,ğœƒâ‰¥ ğœƒ (ğ‘–)for all edges ğ‘’ âˆˆ ğ¸, andğœƒ< ğœƒ (ğ‘–)for all edgesğ‘’ âˆˆ ğ‘†. Hence,ğ‘†will be peeled beforeğ¸inBUPas well. Similarly, any edge in ğ‘†= ğ¸âˆª ğ¸Â· Â· Â· âˆª ğ¸will be peeled afterğ¸inBUP. Hence, support updates to any edgeğ‘’ âˆˆ ğ‘†have no impact on wing numbers computed for edges in ğ¸. For each edgeğ‘’ âˆˆ ğ¸, PBNG FD initializesâŠ²âŠ³usingâŠ²âŠ³, which is the support ofğ‘’in PBNG CD just afterğ‘†is peeled. From lemma 2, this is equal to the support of ğ‘’ in BUP just after ğ‘†is peeled. Note that both PBNG FD andBUPemploy same algorithm (sequential bottom-up peeling) to peel edges inğ¸. Hence, to prove the correctness of wing numbers generated by PBNG FD, it suî€œces to show that when an edge inğ¸is peeled, support updates propagated to other edges in ğ¸via each bloom ğµ, are the same in PBNG FD and BUP. (1)Firstly, every bloom-edge link(ğ‘’, ğµ)whereğ‘’ âˆˆ ğ¸andğ‘¡ğ‘¤ğ‘–ğ‘›(ğ‘’, ğµ) âˆˆ ğ¸âˆª ğ‘†, is preserved in the partitionâ€™s BE-Index ğ¼. Thus, when an edgeğ‘’ âˆˆ ğ¸is peeled, the set of aî€ected edges inğ¸are correctly retrieved fromğ¼(same as the set retrieved from BE-Index ğ¼ in BUP). (2)Secondly, by construction (alg.5, lines 21-22 and 23-24), the initial bloom number ofğµinğ¼is equal to the number of those twin edge pairs inğµ, for which both edges are inğ¸or higher ranged partitions (not necessarily in same partition). Thus,ğ‘˜(ğ¼) =, which in turn is the bloom numberğ‘˜(ğ¼ )inBUPjust before ğ¸is peeled. Since both PBNG FD andBUPhave identical support values just before peelingğ¸, the updates computed for edges inğ¸ and the order of edges peeled inğ¸will be the same as well. Hence, the î€›nal wing numbers computed by PBNG FD will The correctness of tip decomposition in PBNG can be proven in a similar fashion. A detailed derivation for the same is given in theorem 2 of [30], 4.2 Computation and Space Complexity To feasibly decompose large datasets, it is important for an algorithm to be eî€œcient in terms of computation and memory requirements. The following theorems show that for a reasonable upper bound on partitionsğ‘ƒ, PBNG is at least as computationally eî€œcient as the best sequential decomposition algorithm BUP. Tî¨î¥î¯î²î¥î­ 3. Forğ‘ƒ = Opartitions, wing decomposition in PBNG is work-eî€œcient with computational complexity of Oğ›¼ Â· ğ‘š +ÃâŠ²âŠ³, where âŠ²âŠ³is the number of butterî€ies in ğº that contain ğ‘’. Pî²î¯î¯î¦. PBNG CD initializes the edge support using butterî€y counting algorithm with O(ğ›¼ Â· ğ‘š)complexity. Since ğœƒâ‰¤ ğ‘š, binning for range computation of each partition can be done using anO(ğ‘š)-element array, such thatğ‘– element in the array corresponds to workload of edges with supportğ‘–(alg.4, lines 16-19). A preî€›x scan of the array gives the range workload as a function of the upper bound. Parallel implementations of binning and preî€›x scan perform O(ğ‘š)computations per partition, amounting toO(ğ‘ƒ Â· ğ‘š)computations in entire PBNG CD. Constructingğ‘ğ‘ğ‘¡ğ‘–ğ‘£ğ‘’ğ‘†ğ‘’ğ‘¡ for î€›rst peeling iteration of each partition requires anO(ğ‘š)complexity parallel î€›lter on remaining edges. Subsequent iterations constructğ‘ğ‘ğ‘¡ğ‘–ğ‘£ğ‘’ğ‘†ğ‘’ğ‘¡by tracking support updates doingO(1)work per update. Further, peeling an edgeğ‘’ generatesO(âŠ²âŠ³)updates, each of which can be applied in constant time using BE-Index (sec.2.3). Therefore, totalî€Ãî€‘ complexity of PBNG CD is OâŠ²âŠ³+ (ğ‘ƒ + ğ›¼) Â· ğ‘š. PBNG FD partitions BE-Index requires constant number of traversals of entire set is represented in at most one partitionâ€™s BE-Index. Therefore, PBNG FD will also generate updates. Hence, the work complexity of PBNG FD is O Pî²î¯î¯î¦. number can be cubic in the size of the vertex set. Therefore, range determination uses a hashmap with support values as the keys. The aggregate workloads of the bins need to be sorted on keys before computing the preî€›x scan. Hence, total complexity of range determination for tip decomposition in PBNG CD is Next, we prove that PBNGâ€™s space consumption is almost similar to the best known sequential algorithms. Tî¨î¥î¯î²î¥î­ 5. Wing decomposition in PBNG parallelized over ğ‘‡ threads consumes O Pî²î¯î¯î¦. O(ğ‘› Â· ğ‘‡ ) space consumption [66]. For peeling: (1) PBNG CD uses the BE-Index ğ¼ (ğ‘Š = (ğ‘ˆ , ğ‘‰ ), ğ¸) whose space complexity is O (2)PBNG FD uses individual BE-Indices for each partition. Any bloom-edge link partitionâ€™s BE-Index. Therefore, cumulative space required to store all partitionsâ€™ BE-Indices is O Thus, overall space complexity of PBNGâ€™s wing decomposition is O Tî¨î¥î¯î²î¥î­ 6. Tip decomposition in PBNG parallelized over ğ‘‡ threads consumes O Pî²î¯î¯î¦. counts, resulting in at most one partition (because partitions of induced subgraphs, resulting in overall O 5 OPTIMIZATIONS Despite the use of parallel computing resources, PBNG may consume a lot of time to decompose large graphs such as the trackers dataset, that contain several trillion wedges (for tip decomposition) or butterî€ies (for wedge decomposition). In this section, we propose novel optimization techniques based on the two-phased peeling of PBNG, that dramatically improve computational eî€œciency and make it feasible to decompose datasets like trackers in few minutes. 5.1 Batch Processing Due to the broad range of entity numbers peeled in each iteration of PBNG CD (sec.3.1.1), some iterations may peel a large number of entities. Peeling individual entities in such iterations requires a large amount of traversal in ğ‘ƒ = Opartitions, tip decomposition in PBNG is work-eî€œcient with computational The proof is simliar to that of theorem 3. The key diî€erence from wing decomposition is that maximum tip For butterî€y counting, each thread uses a privateO(ğ‘›)array to accumulate wedge counts, resulting to For butterî€y counting and peeling in PBNG, each thread uses a privateO(ğ‘›)array to accumulate wedge BE-Indexğ¼. However, visualizing such iterations as peeling a single large set of entities can enable batch optimizations that drastically reduce the required computation. Tip Decomposition. Here, we exploit the fact that (per-vertex) butterî€y counting is computationally eî€œcient and parallelizble (sec.2.1). Given a vertex setğ‘ğ‘ğ‘¡ğ‘–ğ‘£ğ‘’ğ‘†ğ‘’ğ‘¡, the number of wedges traversed for peelingğ‘ğ‘ğ‘¡ğ‘–ğ‘£ğ‘’ğ‘†ğ‘’ğ‘¡is givenÃÃ byâˆ§(ğ‘ğ‘ğ‘¡ğ‘–ğ‘£ğ‘’ğ‘†ğ‘’ğ‘¡) =ğ‘‘. However, number of wedges traversed for re-counting butterî€ies forÃ remaining vertices is upper bounded byâˆ§=min(ğ‘‘, ğ‘‘), which is constant for a givenğº(sec.2.1). If âˆ§(ğ‘ğ‘ğ‘¡ğ‘–ğ‘£ğ‘’ğ‘†ğ‘’ğ‘¡) > âˆ§, we re-compute butterî€ies for all remaining vertices inğ‘ˆinstead of peelingğ‘ğ‘ğ‘¡ğ‘–ğ‘£ğ‘’ğ‘†ğ‘’ğ‘¡. Thus, computational complexity of a peeling iteration in PBNG tip decomposition is O(ğ›¼ Â· ğ‘š). Algorithm 6 Batch computation of support updates from peeling a set of edges ğ‘ğ‘ğ‘¡ğ‘–ğ‘£ğ‘’ğ‘†ğ‘’ğ‘¡ Wing Decomposition. For peeling a large set of edgesğ‘ğ‘ğ‘¡ğ‘–ğ‘£ğ‘’ğ‘†ğ‘’ğ‘¡, we use the batch processing proposed in [67]. The key idea is that when an edgeğ‘’is peeled, the aî€ected edges are discovered by exploring the neighborhood of blooms in ğ‘(ğ¼ )(alg.3). Therefore, the support updates from all edges inğ‘ğ‘ğ‘¡ğ‘–ğ‘£ğ‘’ğ‘†ğ‘’ğ‘¡can be aggregated at the blooms (alg.6, line 8), and then applied via a single traversal of their neighborhoods (alg.6, lines 10-13). Thus, computational complexity of a peeling iteration in PBNG wing decomposition is bounded by the size of BE-Index which isO(ğ›¼ Â· ğ‘š). While batch processing using BE-Index was proposed in [67], we note that it is signiî€›cantly more beneî€›cial for PBNG CD compared to bottom-up peeling, due to the large number of edges peeled per iteration. 5.2 Dynamic Graph Updates After a vertexğ‘¢(or an edgeğ‘’) is peeled in PBNG, it is excluded from future computation in the respective phase. However, due to the undirected nature of the graph, the adjacency list data structure forğº(or BE-Indexğ¼) still contains edges ofğ‘¢(or bloom-edge links ofğ‘’) that are interleaved with other edges. Consequently, wedges incident onğ‘¢(or bloom-edge links ofğ‘’), though not used in computation, are still explored even afterğ‘¢(orğ‘’) is peeled. To prevent such wasteful exploration, we update the data structures to remove edges incident on peeled vertices (or bloom-edge links of peeled edges). These updates can be performed jointly with the traversal required for peeling. In tip decomposition, updating vertex support requires traversing adjacencies of the neighbors of peeled vertices. Edges to peeled vertices can be removed while traversing neighborsâ€™ adjacency lists. In wing decomposition, updating edge support requires iterating over the aî€ected blooms (alg.6, lines 10-13) and their neighborhoods their twins can be removed from ğ‘ 6 EXPERIMENTS In this section, we present detailed experimental results of PBNG for both tip and wing decomposition. In sec.6.1, we list the datasets and describe the baselines used for comparison. Secondly, in sec.6.2, we provide a thorough evaluation of wing decomposition in PBNG. We (a) compare PBNG against the baselines on several metrics, (b) report empirical beneî€›ts of optimizations proposed in sec.5, (c) compare workload and execution time of coarse and î€›ne decomposition phases, and (d) evaluate parallel scalability of PBNG. Lastly, in sec.6.3, we report a similar evaluation of tip decomposition. 6.1 Setup We conduct the experiments on a 36 core dual-socket linux server with two Intel Xeon E5-2695 v4 processors@ 2.1GHz and 1TB DRAM. All algorithms are implemented in C++-14 and are compiled using G++ 9.1.0 with the -O3 optimization î€ag, and OpenMP v4.5 for multithreading. Datasets: We use twelve unweighted bipartite graphs obtained from the KOBLENZ collection [ Repository [ publicly available real-world bipartite datasets. Table 2. Bipartite graphs with the corresponding number of buî€erflies ( Baselines: We compare the performance of PBNG against the following baselines: â€¢ BUPâ†’ sequential bottom-up peeling (alg.2) that does not use BE-Index. â€¢ ParBâ†’ iteration of BUP using a parallel bucketing structure [11]. â€¢ BE_Batch dynamic deletion of bloom-edge links (sec.5). â€¢ BE_PC(for wing decomposition only) in [67]. It generates candidate subgraphs top-down in the hierarchy to avoid support updates from peeling edges in lower subgraphs (small candidate subgraphs is set to ğœ = 0.02, as speciî€›ed in [67]. 44], whose characteristics are shown in table 2. To the best of our knowledge, these are some of the largest Pî¡î²Bîµî´î´î¥î²î¦î¬î¹ frameworkwith the best performing BatchS aggregation method [54]. It parallelizes each (for wing decomposition only)â†’BE-Index assisted peeling with batch processing optimization [67], and Furthermore, to evaluate the eî€ect of optimizations (sec.5), we create two variants of PBNG: â€¢ PBNG- â†’ PBNG without dynamic graph updates (sec.5.2). â€¢ PBNG-- â†’ PBNG without dynamic graph updates (sec.5.2) and batch processing optimization (sec.5.1). Parameter Setting: The only user-speciî€›ed parameter in PBNG is the no. of partitionsğ‘ƒ. For tip decomposition, we useğ‘ƒ =150 which was empirically determined in [30]. For wing decomposition, we measure the runtime of PBNG as a function ofğ‘ƒas shown in î€›g.5. Performance of PBNG CD improves with a decrease inğ‘ƒbecause of reduced peeling iterations and larger peeling set (batch size) per iteration. However, for PBNG FD, a small value ofğ‘ƒreduces parallelism and increases the workload. Thus,ğ‘ƒrepresents a trade-oî€ between the two phases of PBNG. Based on our our observations, we setğ‘ƒ =400 for graphs with<100 M edges, andğ‘ƒ =1000 for graphs withâ‰¥100 M edges. We also note that the performance of PBNG is robust (within 2Ã—of the optimal) in a wide range ofğ‘ƒfor both small and large datasets. 6.2 Results: Wing Decomposition 6.2.1 Comparison with Baselines. Table 3 shows a detailed comparison of PBNG and baseline wing decomposition algorithms. To compare the workload of diî€erent algorithms, we measure the number of support updates applied in each algorithm [67]. Note that this may under-represent the workload ofBUPandParB, as they cannot retrieve aî€ected edges during peeling in constant time. However, it is a useful metric to compare BE-Index based approaches [67] as support updates represent bulk of the computation performed by during decomposition. Amongst the baseline algorithms,BE_PCdemonstrates state-of-the-art execution time and lowest computational workload, represented by the number of support updates, due to its top-down subgraph construction approach. However, with the two-phased peeling and batch optimizations, support updates in PBNG are at par or even lower thanBE_PC in some cases. Moreover, most updates in PBNG are applied to a simple array and are relatively cheaper compared to updates applied to priority queue data structure in all baselines (includingBE_PC). Furthermore, by utilizing parallel computational resources, PBNG achieves up to 38.5Ã—speedup overBE_PC, with especially high speedup on large datasets. Compared to the parallel frameworkParB, PBNG is two orders of magnitude or more (up to 295Ã—) faster. This is becauseParBdoes not use BE-Index for eî€œcient peeling, does not utilize batch optimizations to reduce computations, and requires large amount of parallel peeling iterations (ğœŒ). The number of threads synchronizations is directly proportional toğœŒ, and PBNG achieves up to 15260Ã—reduction inğœŒcompared toParB. This is primarily because PBNG CD peels Table 3. Comparing execution time (t), number of support updates and thread synchronization (or parallel peeling iterations ğœŒ) for PBNG and baseline algorithms. Missing entries denote that execution did not finish in 2 days. ParB will generate same number of support updates as BUP, and parallel variants of all baselines will have same amount of synchronization (ğœŒ) as ParB. vertices with a broad range of support in every iteration, and PBNG FD does not require a global thread synchronization at alll. This drastic reduction in ğœŒ is the primary contributor to PBNGâ€™s parallel eî€œciency. Quite remarkably, PBNG is the only algorithm to successfully wing decompose Gtr and De-ut datasets in few hours, whereas all of the baselines fail to decompose them in two days workload, execution time and synchronization compared to all previously existing algorithms. 6.2.2 Eî€›ect of Optimizations. Since dynamic BE-Index updates do not aî€ect the updates generated during peeling, PBNG and PBNG- exhibit the same number of support updates. Hence, to highlight the beneî€›ts of BE-Index updates (sec.5.2), we also measure the number of bloom-edge links traversed in PBNG with and without the optimizations. Fig.6 shows the eî€ect of optimizations on the performance of PBNG. Normalized performance of PBNG- (î€›g.6) shows that deletion of bloom-edge links (corresponding to peeled edges) from BE-Index reduces traversal by an average of 1 relatively inexpensive compared to support updates as the latter involve atomic computations on array elements (PBNG CD) or on a priority queue (PBNG FD). Fig.6 also clearly shows a direct correlation between the execution time of PBNG-- and the number of support updates. Consequently, the performance is drastically impacted by batch processing, without which large datasets of PBNG-- shows that both optimizations cumulatively enable an average reduction of 9 support updates and execution time of wing decomposition, respectively. This shows that the two-phased approach of PBNG is highly suitable for batch optimization as it peels large number of edges per parallel iteration. 6.2.3 Comparison of Diî€›erent Phases. Fig.7 shows a breakdown of the support updates and execution time of PBNG across diî€erent steps, namely initial butterî€y counting and BE-Index Construction, peeling in PBNG CD, BE-Index partitioning more than 60% of the support updates for most graphs. In some datasets such as Tr and Gtr, the batch optimizations drastically reduce the workload of PBNG CD, rendering PBNG FD as the dominant phase. The trends in execution time are largely similar to those of support updates. However, due to diî€erences in parallel scalability of diî€erent steps, contribution of PBNG FD to execution time of several datasets is slightly higher than its corresponding contribution and peeling in PBNG FD. For most datasets, PBNG CD dominates the overall workload, contributing PBNG- (PBNG without dynamic BE-Index updates) PBNG-- (PBNG- without batch processing) Fig. 6. Eî€›ect of optimizations (sec.5) on wing decomposition in PBNG. All quantities are normalized with respective measurements for PBNG with all optimizations enabled. With batch processing disabled (PBNG--), Gtr, Tr and De-ut did not finish within 2 days. Fig. 7. Contribution of diî€›erent steps to the overall support updates and the execution time of wing decomposition in PBNG to support updates. We also observe that peeling in PBNG CD and PBNG FD is much more expensive compared to BE-Index construction and partitioning. Fig. 8. Strong scaling of wing decomposition in PBNG. Datasets shown on the leî€œ were decomposed in less than a minute, and on 6.2.4 Scalability. Fig.8 demonstrates the parallel speedup of PBNG over sequential execution an average 8 generally higher for large datasets (up to 11 average 2.6Ã— speedup over sequential BUP, due to the large amount of synchronization. We also observe that PBNG consistently accelerates decomposition up to 18 threads (single socket), providing average 7.2Ã—parallel speedup. However, scaling to two sockets (increasing threads from 18 to 36) only fetches 1 on average. This could be due to NUMA eî€ects which increases the cost of memory accesses and atomics. This can signiî€›cantly impact the performance as PBNGâ€™s workload is dominated by traversal of the large BE-Index and atomic support updates. Further, edges contained in a large number of butterî€ies may receive numerous support updates, which increases coherency traî€œc and reduces scalability. 6.3 Results: Tip Decomposition To evaluate tip decomposition in PBNG, we select 6 of the largest datasets from table 2 and individually decompose both vertex sets in them. Without loss of generality, we label the vertex set with higher peeling complexity as the other as ğ‘‰ . Corresponding to the set being decomposed, we suî€œx the dataset name with ğ‘ˆ or ğ‘‰ . Table 4. Comparing execution time ( and baseline algorithms for tip decomposition. ParB traverses the same # wedges as BUP and has missing entries due to 6.3.1 Comparison with Baselines. Table 4 shows a detailed comparison of various tip decomposition algorithms. To compare the workload of tip decomposition algorithms, we measure the number of wedges traversed in traversal is required to compute butterî€ies between vertex pairs during counting/peeling, and represents bulk of the computation performed in tip decomposition . With up to 80 for all datasets. Contrarily, speedups are typically higher for large datasets that oî€er large amount of computation to parallelize and beneî€›t more from batch optimization (sec.5.1). Optimization beneî€›ts are also evident in the wedge traversal of PBNG wedges than the baselines, achieving up to 64 1105Ã—reduction in synchronization ( .7Ã—parallel speedup with 36 threads, which is signiî€›cantly better thanParB. Furthermore, the speedup is .8Ã—and 64.7Ã—speedup overBUPandParB, respectively, PBNG is dramatically faster than the baselines, parallel eî€œciency and workload optimizations enable PBNG to decompose large datasets like EnU in few minutes, unlike baselines that take few days for the same. Quite remarkably, PBNG is the only algorithm to successfully tip decompose TrU dataset within an hour, whereas the baselines fail to decompose it in two days. We also note PBNG can decompose both vertex sets ofOrdataset in approximately half an hour, even though none of the algorithms could feasibly wing decompose theOrdataset (sec.6.2). Thus, tip decomposition is advantageous over wing decomposition, in terms of eî€œciency and feasibility. PBNG- (PBNG without dynamic graph updates)PBNG-- (PBNG- without batch processing) Fig. 9. Eî€›ect of optimizations (sec.5) on tip decomposition in PBNG. All quantities are normalized with the respective measurements 6.3.2 Optimizations. Fig.9 shows the eî€ect of workload optimizations on tip decomposition in PBNG. Clearly, the execution time closely follows the variations in number of wedges traversed. Dynamic deletion of edges (corresponding to peeled vertices) from adjacency lists can potentially half the wedge workload since each wedge has two endpoints in peeling set. Normalized performance of PBNG- (î€›g.6) shows that it achieves 1.41Ã— and 1.29Ã— average reduction in wedges and execution time, respectively. Similar to wing decomposition, the batch optimization provides dramatic improvement in workload and execution time. This is especially true for datasets with a large ratio of total wedges with endpoints in peeling set to the wedges traversed during counting (for example, for LjU, EnU and TrU, this ratio is>1000). For instance, in TrU, both optimizations cumulatively enable 68.8Ã—and 47.7Ã—reduction in wedge traversal and execution time, respectively. Contrarily, in datasets with small value of this ratio such as DeV, OrV, LjV and EnV, none of the peeling iterations in PBNG CD utilize re-counting. Consequently, performance of PBNG- and PBNG-- is similar for these datasets. 6.3.3 Comparison of phases. Fig.7 shows a breakdown of the wedge traversal and execution time of PBNG across diî€erent steps, namely initial butterî€y counting, peeling in PBNG CD and PBNG FD. As expected, PBNG FD only contributes less than 15% of the total wedge traversal in tip decomposition. This is because it operates on small subgraphs that preserve very few wedges ofğº. When peeling the large workloadğ‘ˆvertex set, more than 80% of the wedge traversal and 70% of the execution time is spent in PBNG CD. 6.3.4 Scalability. Fig.11 demonstrates the parallel speedup of PBNG over sequential execution. When peeling the large workload vertex setğ‘ˆ, PBNG achieves almost linear scalability with 14.4Ã—average parallel speedup on 36 threads, and up to 19.7Ã—speedup forğºğ‘¡ğ‘Ÿğ‘ˆdataset. Contrarily,ParBachieves an average 1.54Ã—speedup over sequentialBUP, and up to 2.3Ã— speedup for ğ‘‡ğ‘Ÿğ‘‰ dataset. Fig. 10. Contribution of diî€›erent steps to the overall wedge traversal and the execution time of tip decomposition in PBNG Typically, datasets with small amount of wedges (LjV, EnV ) exhibit lower speedup, because they provide lower workload per synchronization round on average. For example, LjV traverses 86 scalability of PBNG CD, which is the highest workload step in PBNG (î€›g.10). Similar to wing decomposition, NUMA eî€ects on scalability to multiple sockets (36 threads) can be seen in tip decomposition of some datasets such as andTrU. However, we still observe 1 threads. This is possibly because most of the workload in tip decomposition is comprised of wedge traversal which only reads the graph data structure. It incurs much fewer support updates, and in turn atomic writes, compared to wing decomposition. 7 RELATED WORK Discovering dense subgraphs and communities in networks is a key operation in several applications [ containing an entity (vertex or an edge) acts as an indicator of its local density. Consequently, several recent works have focused on eî€œciently î€›nding such motifs in the graphs [1, 16, 22, 25, 35, 54, 56, 66]. fewer synchronizations. This increases the relative overheads of parallelization and restricts the parallel 59]. Motif-based techniques are widely used to reveal dense regions in graphs [3,4,14,17,19,27,31,36,50â€“ 63,63,65,69]. Motifs like triangles represent a quantum of cohesion in graphs and the number of motifs Nucleus decomposition is a clique based technique for discovering hierarchical dense regions in unipartite graphs. Instead of per-entity clique count in the entire graph, it considers the minimum clique count of a subgraphâ€™s entities as an indicator of that subgraphâ€™s density [2]. This allows mining denser subgraphs compared to counting alone [2,53]. Truss decomposition is a special and one of the most popular cases of nucleus decomposition that uses triangle clique. It is a part of the GraphChallenge [47] initiative, that has resulted in highly scalable parallel decomposition algorithms [9,21,57,62]. However, nucleus decomposition is not applicable on bipartite graphs as they do not have cliques. The simplest non-trivial motif in a bipartite graph is a Butterî€y (2,2-biclique). Several algorithms for butterî€y counting have been developed: in-memory or external memory [64,66], exact or approximate counting [48,49] and parallel counting on various platforms [54,64,66]. The most eî€œcient approaches are based on Chiba and Nishizekiâ€™s [7] vertex-priority butterî€y counting algorithm. Wang et al.[66] propose a cache optimized variant of this algorithm and use shared-memory parallelism for acceleration. Independently, Shi et al.[54] develop provably eî€œcient shared-memory parallel implementations of this algorithm. Notably, their algorithms are able to extract parallelism at the granularity of wedges explored. Such î€›ne-grained parallelism can also be explored for improving parallel scalability of PBNG. Inspired byğ‘˜-truss, Sariyuce et al.[51] deî€›nedğ‘˜-tips andğ‘˜-wings as subgraphs with minimumğ‘˜butterî€ies incident on every vertex and edge, respectively. Similar to nucleus decomposition algorithms, they designed bottom-up peeling algorithms to î€›nd hierarchies ofğ‘˜-tips andğ‘˜-wings. Independently, Zou [72] deî€›ned the notion of bitruss similar to ğ‘˜-wing. Shi et al.[54] propose the ğ‘ƒî¡î²ğµîµî´î´î¥î²î¦î¬î¹ framework that parallelizes individual peeling iterations. Chiba and Nishizeki [7] proposed that wedges traversed in butterî€y counting algorithm can act as a space-eî€œcient representation of all butterî€ies in the graph. Wang et al.[67] propose a butterî€y representation called BE-Index (also derived from the counting algorithm) for eî€œcient support updates during edge peeling. Based on BE-Index, they develop several peeling algorithms for wing decomposition that achieve state-of-the-art computational eî€œciency and are used as baselines in this paper. Very recently, Wang et al.[68] also proposed parallel versions of BE-Index based wing decomposition algorithms. Although the code is not publicly available, authors report the performance on few graphs. Based on the reported results, PBNG signiî€›cantly outperforms their parallel algorithms as well. Secondly, these algorithms parallelize individual peeling iterations and will incur heavy synchronization similar toğ‘ƒî¡î²ğµîµî´î´î¥î²î¦î¬î¹(table 3). Lastly, they are only designed for wing decomposition, whereas PBNG comprehensively targets both wing and tip decomposition. This is important because tip decomposition in PBNG (a) is typically faster than wing decomposition, and (b) can process large datasets like Orkut in few minutes, that none of the existing tip or wing decomposition algorithms can process in several days. 8 CONCLUSION AND FUTURE WORK In this paper, we studied the problem of bipartite graph decomposition which is a computationally demanding analytic for which the existing algorithms were not amenable to eî€œcient parallelization. We proposed a novel parallelism friendly two-phased peeling framework called PBNG, that is the î€›rst to exploit parallelism across the levels of decomposition hierarchy. The proposed approach further enabled novel optimizations that drastically reduce computational workload, allowing bipartite decomposition to scale beyond the limits of current practice. We presented a comprehensive empirical evaluation of PBNG on a shared-memory multicore server and showed that it can process some of the largest publicly available bipartite datasets two orders of magnitude faster than the state-of-the-art. PBNG also achieved a dramatic reduction in thread synchronization, allowing up to 19.7Ã—self-relative parallel speedup on 36 threads. There are several directions for future research in the context of this work. The proposed two-phased peeling can open up avenues for distributed-memory parallel bipartite decomposition on HPC clusters. Clusters allow scaling of both computational and memory resources, which is crucial for decomposing large graphs. To further improve the performance of PBNG, we will also explore î€›ne-grained parallelism, and techniques to avoid atomics and enhance memory access locality. Such system optimizations have been shown to be highly eî€ective in conventional graph processing frameworks [ unipartite graphs, which is an interesting direction to explore. Acknowledgement Contract Number FA8750-17-C-0086, and National Science Foundation (NSF) under Grant Numbers CNS-2009057 and OAC-1911229. Any opinions, î€›ndings and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reî€ect the views of DARPA or NSF. The U.S. Government is authorized to reproduce and distribute reprints for Government purposes notwithstanding any copyright notation here on. . This material is based on work supported by the Defense Advanced Research Projects Agency (DARPA) under
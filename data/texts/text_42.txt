Session-based recommendation targets next-item prediction by exploiting user behaviors within a short time period. Compared with other recommendation paradigms, session-based recommendation suî€ers more from the problem of data sparsity due to the very limited short-term interactions. Self-supervised learning, which can discover ground-truth samples from the raw data, holds vast potentials to tackle this problem. However, existing self-supervised recommendation models mainly rely on item/segment dropout to augment data, which are not î€›t for session-based recommendation because the dropout leads to sparser data, creating unserviceable self-supervision signals. In this paper, for informative sessionbased data augmentation, we combine self-supervised learning with co-training, and then develop a framework to enhance sessionbased recommendation. Technically, we î€›rst exploit the sessionbased graph to augment two views that exhibit the internal and external connectivities of sessions, and then we build two distinct graph encoders over the two views, which recursively leverage the diî€erent connectivity information to generate ground-truth samples to supervise each other by contrastive learning. In contrast to the dropout strategy, the proposed self-supervised graph co-training preserves the complete session information and fulî€›lls genuine data augmentation. Extensive experiments on multiple benchmark datasets show that, session-based recommendation can be remarkably enhanced under the regime of self-supervised graph co-training, achieving the state-of-the-art performance. â€¢ Information systems â†’ Recommender systems;â€¢ Theory of computation â†’ Semi-supervised learning. Self-Supervised Learning, Contrastive Learning, Session-based Recommendation, Co-Training ACM Reference Format: Xin Xia, Hongzhi Yin, Junliang Yu, Yingxia Shao, and Lizhen Cui. 2021. Self-Supervised Graph Co-Training for Session-based Recommendation. In Proceedings of the 30th ACM International Conference on Information and Knowledge Management (CIKM â€™21), November 1â€“5, 2021, Virtual Event, QLD, Australia. ACM, New York, NY, USA, 11 pages. https://doi.org/10.1145/ 3459637.3482388 Recommender systems (RS) now have been pervasive and become an indispensable tool to facilitate online shopping and information delivery. Most traditional recommendation approaches share a common assumption that user behaviors are constantly recorded and available for access [50,52]. However, in some situations, recording long-term user proî€›les may be infeasible. For example, guests who do not log in, or users who keep personal information private do not have an accessible user proî€›le. Session-based recommendation emerges to tackle this challenge [36], aiming at predicting the next item only with short-term user interaction data generated in a session. Owing to its promising prospect, in the past few years, session-based recommendation has received considerable attention, and a number of models have been successively developed [18, 20, 28, 29]. Early eî€ort in this î€›eld brought Markov Chain into sessionbased scenarios to capture the temporal information [28,29]. Afterwards, deep learning exhibited overwhelming advantage of modeling sequential data[56], and recurrent neural networks (RNNs) became the dominant paradigm in this line of research [12,13]. Recently, graph neural networks (GNNs) [42] have sparked heated discussions across multiple î€›elds for its unprecedented eî€ectiveness in solving graph-based tasks. As session-based data can also be modeled as sequence-like graphs, there also have been a proliferation of GNNs-based session-based recommendation models [24,27,41,43,47], which outperform RNNs-based models and show decent improvements. Despite the achievements, however, these approaches are still compromised by the same issue - data sparsity. Due to the inaccessibility of the long-term user behavior data, session-based recommenders can only leverage very limited useritem interactions generated within a short session to reî€›ne the corresponding user/session representations. In most cases, these data is too few to induce an accurate user preference, leading to sub-optimal recommendation performance. Self-supervised learning (SSL) [21], as an emerging learning paradigm which can discover ground-truth samples from the raw data, is considered to be an antidote to the data sparsity issue. Inspired by its great success in the areas of graph and visual representation learning [11,17], recent advances seek to harness SSL for improving recommendation [43,44,53,57]. The typical idea of applying SSL to recommendation is conducting stochastic data augmentations by randomly dropping some items/segments from the raw user-item interaction graph/sequence to create supervisory signals, which is analogous to the strategy used in masked language models like BERT [7]. Following this line of thought, Bert4Rec [30] drives a cloze objective for sequential recommendation by predicting the random masked items in the sequence with their left and right contexts.ğ‘†-Rec [57] designs four types of pretexts to derive supervision signals from the segments, items and attributes of sequential data and then utilizes mutual information maximization to reî€›ne item representations. Similarly, CL4SRec [44] adopts item cropping, masking and reordering to construct diî€erent data augmentations based on sequences for contrastive learning. With such random dropout strategies, SSL is compatible with sequential recommendation. However, when it comes to session-based recommendation, the same idea may not be practicable. It should be noted that, the user interaction data generated in a session is much less than a long-term user proî€›le in sequential recommenders. Accordingly, conducting dropout on session-based data would create sparser sequences, which could be unserviceable for improving recommendation performance. To address this problem, in this paper, we propose a novel framework which combines SSL with semisupervised learning to create more informative self-supervision signals to enhance session-based recommendation. Co-training [3], as a classical semi-supervised learning paradigm, exploits unlabeled data to improve classiî€›ers. The basic idea of co-training is to train two classiî€›ers over two diî€erent data views, and then predict pseudo-labels of unlabeled instances to supervise each other in an iterative way. In our framework, we î€›rst exploit the session-item graph to construct two views (item view and session view) that exhibit the internal and external connections of sessions. Then two asymmetric graph encoders (i.e. graph convolutional networks) are built over these two views and trained under the scheme of co-training. One of them (main encoder) is for recommendation and the other acts as the auxiliary encoder to boost the former. Speciî€›cally, given a session, we regard the items as unlabeled data. In each time, one encoder predicts its possible next items and delivers them to the other encoder, respectively. By doing so, both encoders can acquire complementary information from each other. And then a contrastive objective is optimized towards reî€›ning the encoders and item representations. Meanwhile, to prevent the mode collapse (i.e. two encoders become very similar and suggest the same item), we exploit adversarial examples to encourage divergence between the two views. As this co-training regime is built upon the graph views derived from the same data source for data augmentation, and is with a contrastive objective, we name it self-supervised graph co-training. By iterating this process, the beneî€›ts can be two-fold: (1). with the co-training proceeding, the generated item samples become more informative (a.k.a. hard examples), which can bring more useful information to each encoder compared with the dropout strategy that is only for self-discrimination; (2). the complete data of a session is preserved and two diî€erent aspects of connectivity information are exploited, generating more practicable self-supervision signals. Finally, the main encoder is signiî€›cantly improved for recommendation. Overall, the contributions of this paper are summarized as follows: â€¢We propose a novel self-supervised framework for session-based recommendation which can generate more informative and practicable self-supervision signals. â€¢The proposed framework is model-agnostic. Ideally, the architectures of the two used encoders can be diverse, which generalizes the framework to adapt to more scenarios. â€¢Extensive experiments show that the proposed framework has overwhelming superiority over the state-of-the-art baselines and achieves statistically signiî€›cant improvements on benchmark datasets. We release the code at https://github.com/xiaxin1998/ COTREC. The rest of this paper is organized as follows. Section 2 summarizes the related work of session-based recommendation and selfsupervised learning. Section 3 presents the proposed framework. The experimental results are reported in Section 4. Finally, Section 5 concludes this paper. Early studies on session-based recommendation focused on exploiting temporal information from session data with Markov chain [28,29,49,58]. Zimdars et al. [58] investigated the order of temporal data based on Markov chain and used a probability decision-tree to model sequential patterns between items. Shan et al. [29] developed a novel recommender system based on an Markov Decision Process model with appropriate initialization and generated recommendations based upon the transition probabilities between items. With the boom of deep learning, recurrent neural networks (RNNs) [15] have been applied to session-based recommendation models to capture sequential order between items and achieved great success [19,55]. Hidasi et al. [13] was the î€›rst that applied RNNs to model the whole session and introduced several modiî€›cations to vanilla RNNs such as a ranking loss function and session-parallel mini-batch training to generate more accurate recommendations. As a follow-up study [33], Tan et al. enhanced RNNs by utilizing the technique of data augmentation and handling the temporal shifts of session data. Besides, NARM [18], a neural attentive recommendation algorithm, employs a hybrid encoder with attention mechanism to model the userâ€™s sequential behavior and capture the userâ€™s main purpose in the current session. In [20], a short-term attention priority model is developed to capture both local and global user interests with simple multilayer perceptrons (MLPs) networks and attention mechanism. Graph Neural Networks (GNNs) [42] are recently introduced to session-based recommendation and exhibit great performance [24,27,32,37,41]. Unlike RNN-based approaches, graph structure is an essential factor in graph-based methods, aiming to learn item transitions over session graphs. For example, SR-GNN [41] is the î€›rst to model session sequences in session graphs and applies a gated GNN model to aggregate information between items into session representations. MGNN-SPred [37] builds a multi-relational item graph based on all session clicks to learn global item associations and uses a gated mechanism to adaptively predict the next item. GC-SAN [47] dynamically constructs session-educed graphs and employs self-attention networks on the graphs to capture item dependencies via graph information aggregation. FGNN [27] rethinks the sequence order of items to exploit usersâ€™ intrinsic intents using GNNs. GCE-GNN [38] aggregates item information from both item-level and session-level through graph convolution and self-attention mechanism. LESSR [5] proposes an edge-order preserving aggregation scheme based on GRU and a shortcut graph attention layer to address the lossy session encoding problem and eî€ectively capture long-range dependencies, respectively. Although these graph-based methods outperform RNN-based methods, they all suî€er data sparsity problem due to the limited short-term proî€›les in session-based scenarios. Recently, self-supervised learning (SSL) [14], as a novel machine learning paradigm which mines free labels from unlabeled data and supervises models using the generated labels, is under the spotlight. The information or intermediate representation learned from self-supervised learning are expected to carry good semantic or structural meanings and can be beneî€›cial to a variety of downstream tasks. SSL was initially applied in the î€›elds of visual representation learning and language modeling [2,7], where it augments the raw data through image rotation/clipping and sentence masking. Recent advances of SSL start to focus on graphs, and have received considerable attention [16,35,40]. DGI [35] maximizes mutual information between the local patch and the global graph to reî€›ne node representations, making them as the ground-truth of each other. In InfoGraph [31], graph-level representations encode diî€erent aspects of data by encouraging agreement between the representations of substructures with diî€erent scales (e.g., nodes, edges, triangles). Hassani et al. [10] contrasted multiple views of graphs and nodes to learn their representations. Qiu [26] et al. designed a self-supervised graph neural network pre-training framework to capture the structural representations of graphs by leveraging instance discrimination and contrastive learning. Inspired by the success of SSL in other areas, there are also some studies that integrate self-supervised learning into sequential recommendation [22,45,57]. Bert4Rec [30] transfers the cloze objective from language modeling to sequential recommendation by predicting the random masked items in the sequence with the surrounding contexts.ğ‘†-Rec [57] utilizes the intrinsic data correlations among attribute, item, subsequence and sequence to generate self-supervision signals and enhance the data representations via pre-training. Xie et al. [44] proposed three data augmentation strategies to construct self-supervision signals from the original user behavior sequences, extracting more meaningful user patterns and encoding eî€ective user representation. Ma et al. [22] proposed a sequence-to-sequence training strategy based on latent self-supervision and disentanglement of user intention behind behavior sequences. Besides, SSL is also applied to other recommendation paradigms such as general recommendation [48] and social recommendation [51,53]. Although these self-supervised methods have achieved decent improvements in recommendation performance, they are not suitable for session-based recommendation for the reason that the random dropout strategy used in these models would lead to sparser session data and unserviceable self-supervision signals. The most relevant work to ours is ğ‘†-DHCN [43] which conducts contrastive learning between representations learned over diî€erent hypergraphs by employing selfdiscrimination without random dropout. But it cannot learn invariant representations against the data variance for its î€›xed groundtruths, leading to merely slight improvements. Besides, Yu et al. [51] recently proposed a self-supervised tri-training framework that leverages diî€erent aspects of social information to generate complementary self-supervision signals to boost recommendation. As the î€›rst work to combine SSL with multi-view semi-supervised learning for recommendation, it gives us clues about applying cotraining to session-based recommendation. 3.1.1 Notations. Letğ» = {ğ‘–, ğ‘–, ğ‘–, ...,ğ‘–}denote the set of items, whereğ‘is the number of items. Each session is represented as a sequenceğ‘  = [ğ‘–, ğ‘–, ğ‘–, ...,ğ‘–]ordered by timestamps and ğ‘–âˆˆ ğ» (1â‰¤ ğ‘˜ â‰¤ ğ‘š)represents an interacted item of an anonymous user within the sessionğ‘ . For learning presentations, we embed each itemğ‘– âˆˆ ğ¼into the same space and letxâˆˆ R denote the representation of itemğ‘–of dimensionğ‘‘in theğ‘™-th layer of a deep neural network. The representation of the whole item set is denoted asXâˆˆ R, andğ‘¿is randomly initialized with uniform distribution. Each sessionğ‘ is represented by a vectors. The task of session-based recommendation is to predict the next item, namelyğ‘–, for any given sessionğ‘ . Givenğ¼andğ‘ , the output of session-based recommendation model is a ranked list ğ‘¦ = [ğ‘¦, ğ‘¦, ğ‘¦, ...,ğ‘¦]whereğ‘¦(1â‰¤ ğ‘– â‰¤ ğ‘ )is the corresponding predicted probability of itemğ‘–. The top-K items(1â‰¤ ğ¾ â‰¤ ğ‘ )with highest probabilities inğ‘¦will be selected as the recommendations. 3.1.2 Co-Training. Co-Training is a classical semi-supervised learning paradigm to exploit unlabeled data [3,6,9]. Under this regime, two classiî€›ers are separately trained on two views and then exchange conî€›dent pseudo labels of unlabeled instances to construct additional labeled training data for each other. Typically, the two views are two disjoint sets of features and can provide complementary information to each other. Blum et al. [3] î€›rst proved that co-training can bring signiî€›cant beneî€›ts when the two views are suî€œcient and conditionally independent. However, the required conditional dependence of two views is hard to be satisî€›ed in many cases. To relax this assumption, Abney et al. [1] found that weak dependence can also enable co-training success, which lifts the dependence restriction and makes co-training easily applied. Furthermore, co-training can also be applied when there is only single data representation if the data is processed by independent prediction models, such as two diî€erent classiî€›ers [46]. It should be mentioned that there have been several attempts that combine cotraining and recommendation [6,54]. However, these methods are all based on shallow or KNN-based models, leaving much space to be explored by the graph neural models coupled with SSL. In this section, the proposed self-supervised graphCO-Training framework for session-basedRECommendation (COTREC) is presented. The overview of COTREC is illustrated in Figure 1. 3.2.1 View Augmentation. To conduct co-training, we î€›rst derive two diî€erent views from the session data, i.e. item view and session view, by exploiting the intra- and inter-connectivity patterns of sessions. The item-view captures the item-level connectivity information while the session view encodes the session-level structural patterns. Concretely, the item view is educed by aligning all sessions. In other words, any two items (ğ‘–andğ‘–) which are connected in a session also get connected as nodes in the item view with a weighted directed edgeğ¸, counting how many times they are adjacent in diî€erent sessions in the form of [ğ‘–, ğ‘–]. As for the session view, two sessions (ğ‘ andğ‘ ) are connected as nodes with a weighted undirected edgeğ¸obtained by using the number of shared items to divide the number of total items in the two sessions (shown in the left part of Figure 1). These two views are able to provide complementary information for each other while keeping independent and exhibiting divergence to some degree, which are subject to the weak dependence constraint in [1]. To make an analogy, if we intuitively consider the session data presented in the left side of Fig.1 as the complete information, which is analogous to the whole picture in the task of image recognition, then constructing these two views corresponds to the patch clipping in visual self-supervised learning [4]. The augmented parts diî€er but inherit essential information from the original data, which can help learn more generalizable representations through a self-supervised task. 3.2.2 Learning Graph Encoders over Augmented Views. After the view construction, we have two types of graphs. Although we aim to devise a model-agnostic framework that can drive a multitude of session-based neural graph recommendation models, for a concrete architecture than can fulî€›ll the capability of the proposed self-supervised graph co-training, we construct two diî€erent graph encoders with graph convolutions over the views as the base. However, the technical details can be modiî€›ed to adapt to more scenarios. Item View Encoding.The item encoder with a simpliî€›ed graph convolution layer for the item view is deî€›ned as: whereË†A= A+ IandIis the identity matrix,Ë†D=ÃË†A andAare the degree matrix and the adjacency matrix,XandW represent theğ‘™-th layerâ€™s item embeddings and parameter matrix of the item view, respectively. Here we do not use the non-linear function since it has been proved redundant in recommendation [39,53]. After passingXthroughğ¿graph convolution layers, we average the item embeddings obtained from each layer to beÃ the î€›nal learned item embeddingsX=X. Although the graph convolution can perfectly capture item connections, it cannot encode the order of items in a speciî€›c session. Following [38], we concatenate the reversed position embeddings with the learned item representations by a learnable position matrixP= [p, p, p, ..., p], whereğ‘šis the length of the current session and pâˆˆ Rrepresents the vector of positionğ‘š. The embedding of ğ‘¡-th item in session ğ‘  = [ğ‘–, ğ‘–, ğ‘–, ...,ğ‘–] is: where Wâˆˆ R, and ğ‘ âˆˆ Rare learnable parameters. Session embeddings can be obtained by aggregating representations of items contained in that session. A soft-attention mechanism is often used in session-based recommendation methods where different items should have diî€erent priorities when learning session embeddings. We follow the strategy used in GCE-GNN [38] to reî€›ne the embedding of session ğ‘  = [ğ‘–, ğ‘–, ğ‘–, ...,ğ‘–]: wherexis the embedding of sessionğ‘ and here it is obtained by averaging the embeddings of items within the sessionğ‘ , i.e.Ã x=x. Session representationğœƒis represented by aggregating item embeddings considering their corresponding importance.f, c âˆˆ R,Wâˆˆ RandWâˆˆ Rare attention parameters used to learn the item weight ğ›¼. Session View Encoding.The session view depicts item and session relations from the other perspective. Similarly, the session encoder conducts graph convolution on the session graph. As there are no items involved in the session graph, we î€›rst initialize the session embeddingsğš¯by averaging the corresponding embeddings of items of each session inX. And the graph convolution on session graph is deî€›ned as followed: whereË†A= A+ I,Ais the adjacency matrix, andË†Dis the corresponding degree matrix,Î˜andWrepresent theğ‘™-th layerâ€™s session embeddings and the parameter matrix, respectively. Similarly, we pass initialized session embeddings intoğ¿graph convolution layers to learn session-level information. The î€›nal session representations are obtained by averagingğ¿embeddings learnedÃ at diî€erent layers, which is formulated as Î˜=Î˜. 3.2.3 Mining Self-Supervision Signals with Graph Co-Training. In this section, we show how graph co-training mines informative self-supervision signals to enhance session-based recommendation. Recall that, in the last two subsections, we build two graph encoders over two diî€erent views that can provide complementary information to each other. Therefore, it is natural to reî€›ne each encoder by exploiting the information from the other view. This can be achieved by following the regime of co-training. Given a sessionğ‘in the session view, we predict its positive and negative next-item samples using its representation learned over the item whereğœƒis the representation of sessionğ‘in the item view, and yâˆˆ Rdenotes the predicted probability of each item being recommended to sessionğ‘in the item view.ğœƒcan be seen as a linear classiî€›er, and Xis seen as the unlabeled sample set. With the computed probabilities, we can select items with the top-K highest conî€›dence as the positive samples which act as the augmented ground-truths to supervise the session encoder. Formally, the positive sample selection is as follows: As for the way to select negative samples, a straightforward idea is to take the items with the lowest scores. However, such a way can only choose easy samples which contribute little. Instead, we randomly selectğ¾negative samples from the items ranked in top 10% inyexcluding the positives to constructğ‘. These items can be seen as hard negatives which can contribute enough information, and meanwhile are less likely to fall into the set of false negatives which would mislead the learning. Analogously, we use the similar way to select informative samples for the item encoder,î€î€‘ where the main diî€erence is that when selecting the top-ğ‘˜item samples,ğ‘¿is used rather thanğ‘¿because the session encoder does not output convolved item embeddings. In each training batch, the positive and negative pseudo-labels for each session in each view are iteratively reconstructed and then are delivered to the other view as the possible next item for reî€›ning session and item representations. The intuition behind this process is that, the item samples, which receive high conî€›dence to be the next-item in one view, should also be valuable in the other view. Iterating this process is expected to generate more informative examples (a.k.a. harder examples). In turn, the encoders evolve under the supervision of informative examples as well, which will recursively distill harder examples. 3.2.4 Contrastive Learning. With the generated pseudo-labels, the self-supervised task used to reî€›ne encoders can be conducted through a contrastive objective. In session-based scenarios, we assume that the last clicked item in a session is the most related to the next item. Therefore, we can maximize (minimize) the agreement between the representations of the last-clicked item and the predicted items samples, accompanied with the given session representation as the session context. Formally, given a sessionğ‘and the predicted ground-truths, we follow InfoNCE [23], which can maximize the lower bound of mutual information between the item pairs, as our learning objective: wherexis the embedding of the last-clicked item of the given temperature to amplify the eî€ect of discrimination (we empirically use 0.2 in our experiments), andğ‘“ (Â·):RÃ—Râ†¦âˆ’â†’ Ris the discriminator function that takes two vectors as the input and then scores the agreement between them. We simply implement the discriminator by applying the cosine operation. Through the contrastive learning between the positive and negative pairs, the two views can exchange information and the last-clicked item representation can learn to infer related items with a session context, and thus item and session representations are reî€›ned. In the vanilla co-training, the generated pseudo-labels are reused in subsequent training as training labels. However, that way will make our framework less eî€œcient because adding pseudo-labels will lead to adjacency matrix reconstruction in each iteration. Also, it may misguide the training from then on when the pseudo-labels introduce false information because the added pseudo-labels would not be removed. Therefore, in our model, we decide not to add pseudo-labels into training set in view of the above considerations. Besides, compared with the dropout based SSL methods [44,57] which leverage the fragmentary sequences as self-supervision signals, our idea has the advantage of preserving the complete session information and fulî€›lling genuine label augmentation, and hence it is more suitable for session-based scenarios. 3.2.5 Divergence Constraint in Co-Training. In our framework, the two data views for co-training are derived from the same data source by exploiting structural information in diî€erent aspects. On the one hand, this augmentation does not require two suî€œcient and independent data sources, which is the advantage. But on the other hand, it somehow might lead to the mode collapse problem, i.e., two encoders become similar and generated the same ground-truths when given the same session after a number of learning iterations. Therefore, it is necessary to make the two encoders diî€er to some degree. Following [25], we impose the divergence constraint on the self-supervised graph co-training regime by integrating adversarial examples into the training. Theoretically, the adversarial examples targeting one encoder [8] would mislead it to generate wrong predictions. However, if the two encoders are trained to be resistant to the adversarial examples generated by each other and still output the correct predictions, we can manage to achieve the goal of keeping them diî€erent. We deî€›ne the divergence constraint as follows: whereğ‘ƒğ‘Ÿğ‘œğ‘(Â·)andğ‘ƒğ‘Ÿğ‘œğ‘(Â·)represent the probabilities of each item to be recommended to a given sessionğ‘, which are computed by two encoders:ğ‘ƒğ‘Ÿğ‘œğ‘(X) = Softmax(ğ‘¿ğœ½), andğ‘ƒğ‘Ÿğ‘œğ‘(X) = Softmax(ğ‘¿ğœ½),Î”andÎ”represent the adversarial perturbations on the item embeddings with regard toğœ½andğœ½, respectively, andğ¾ğ¿(Â·)denotes the KL divergence. To make it clear,î€î€‘ ğ‘ƒğ‘Ÿğ‘œğ‘X+ Î”is the probability distribution produced by the session encoder whenğ‘¿is perturbed byÎ”. If the session encoder is immune toÎ”that is destructive to the item encoder, it will output a probability distribution similar toğ‘ƒğ‘Ÿğ‘œğ‘(X)due to shared information, resulting in a smaller loss of Eq. (9), otherwise not. To create adversarial examples, we adopt the FGSM method proposed in [8], which adds adversarial perturbations on model parameters through fast gradient computation. In our paper, we add adversarial perturbations on item embeddings. The perturbations Î” are updated as: Î”= ğœ–Î“âˆ¥Î“ âˆ¥where Î“ =ğœ•ğ‘™(Ë†ğ‘¦ | x + Î”)ğœ•Î” ğ‘™(Ë†ğ‘¦)is the loss of aversarial examples andğœ–is the control parameter (ğœ–is 0.5 on Diginetica and 0.2 on Tmall and RetailRocket in our experiments). 3.2.6 Model Optimization. Based on the learned representations, the score of each candidate itemğ‘– âˆˆ ğ¼to be recommended for a session ğ‘  is computed by doing inner product: Since the item view can reî€ect the item connectivity in a î€›nergrained granularity, we use the encoder over the item view as the main encoder to predict the î€›nal candidate items for recommendation. After that, a softmax function is applied: Input: Sessions S, node embeddings ğ‘¿ ; Output: Recommendation lists We then use cross entropy loss function to be the learning objective: yis the one-hot encoding vector of the ground truth. For simplicity, we leave out theğ¿regularization terms. Finally, we unify the recommendation task with the auxiliary SSL task. The total lossğ¿ is deî€›ned as: whereğ›¼, ğ›½are hyperparameters to control the scale of the selfsupervised graph co-training and view diî€erence constraint. It should be noted that, we jointly optimize the three throughout the training. Finally, the whole procedure of COTREC is summarized in Algorithm 1. 4.1.1 Datasets. We evaluate our model on three real-world benchmark datasets: Tmall, RetailRocketand Diginetica, which are often used in session-based recommendation methods. Tmall dataset comes from IJCAI-15 competition, which contains anonymized userâ€™s shopping logs on Tmall online shopping platform. RetailRocket is a dataset on a Kaggle contest published by an e-commerce company, which contains the userâ€™s browsing activity within six months. Diginetica dataset describes the music listening behavior of users, and Diginetica comes from CIKM Cup 2016. For convenience of comparing, we follow the experiment environment in [38,41]. Speciî€›cally, we î€›lter out all sessions whose length is 1 and items appearing less than 5 times. Latest data (such as, the data of last week) is set to be test set and previous data is used as training set. Then, we augment and label the training and test datasets by using a sequence splitting method, which generates multiple labeled sequences with the corresponding labels ([ğ‘–], ğ‘–), ([ğ‘–, ğ‘–], ğ‘–), ..., ([ğ‘–, ğ‘–, ...,ğ‘–], ğ‘–)for every sessionğ‘  = [ğ‘–, ğ‘–, ğ‘–, ...,ğ‘–]. Note that the label of each sequence is the last click item in it. The statistics of the datasets are presented in Table 1. 4.1.2 Baseline Methods. We compare COTREC with the following representative methods: â€¢ FPMC[28] is a sequential method based on Markov Chain. In order to adapt it to session-based recommendation, we do not consider the user latent representations when computing recommendation scores. â€¢ GRU4REC[13] utilizes a session-parallel mini-batch training process and adopts ranking-based loss functions to model user sequences. â€¢ NARM[18]: is a RNN-based state-of-the-art model which employs attention mechanism to capture userâ€™s main purpose and combines it with the sequential behavior to generate the recommendations. â€¢ STAMP[20]: adopts attention layers to replace all RNN encoders in the previous work and employs the self-attention mechanism[34] to enhance the session-based recommendation performance. â€¢ SR-GNN[41]: applies a gated graph convolutional layer to obtain item embeddings and also employs a soft-attention mechanism to compute the session embeddings. â€¢ GCE-GNN[38]: constructs two types of session-educed graphs to capture local and global information in diî€erent levels. â€¢ S-DHCN[43]: constructs two types of hypergraphs to learn inter- and intra-session information and uses self-supervised learning to enhance session-based recommendation. 4.1.3 Evaluation Metrics. Following [38,41], we use P@K (Precision) and MRR@K (Mean Reciprocal Rank) to evaluate the recommendation results where K is 10 or 20. 4.1.4 Hyper-parameters Seî€ings. Following previous works, we set the embedding size to 100, the batch size for mini-batch to 100, and theğ¿regularization to 10. In our model, all parameters are initialized with the Gaussian DistributionN (0, 0.1). We use Adam with the learning rate of 0.001 to optimize our model. For the number of layers of graph convolution on the three datasets, a three-layer setting achieves the best performance. For the baseline models, we refer to their best parameter setups reported in the original papers and directly report their results if available, since we use the same datasets and evaluation settings. 4.2.1 Overall Performance. The experimental results of overall performance are reported in Table 2, where we highlight the best results of each column in boldface. From the results, we can draw some conclusions: â€¢Recent methods that consider temporal information (such as, GRU4REC, NARM, STAMP, SR-GNN) outperform traditional methods (FPMC) that do not, demonstrating the importance of capturing sequential dependency between items in session-based recommendation. Besides, among the methods based on RNNslike units (RNN, LSTM, GRU), NRAM and STAMP achieve better performance than GRU4REC. This is because NRAM and STAMP not only utilize recurrent neural networks to model sequential behavior, but also utilize an attention mechanism to learn importance of each item when learning session representations. GRU4REC which only uses GRU cannot handle the shift of user preference. â€¢Graph-based baseline methods all outperform RNN-based methods, showing the great capacity of graph neural networks in modeling session data. Among them, GCE-GNN obtains higher accuracy than SR-GNN. This proves that capturing diî€erent levels of information (inter- and intra-session information) helps accurately predict user intent in session-based recommendation. ğ‘†-DHCN also utilize both inter- and intra-session information in hypergraph modeling and achieves promising performance. However, compared to GCE-GNN,ğ‘†-DHCN has lower results on Tmall and Diginetica, showing that self-discrimination based SSL method is not so successful in improving session-based recommendation performance, which is in line with our motivation. â€¢Our proposed COTREC almost outperforms all the baselines on all the datasets. Particularly, it beats other models by a large margin on Tmall, showing the eî€ectiveness of the self-supervised grpah co-training when applied to real e-commerce data. Compared with the other self-supervised modelğ‘†-DHCN, the advantage is also obvious. Considering thatğ‘†-DHCN and COTREC both have a two-branch architecture, we think that the improvements mainly derive from the multi-instance contrastive learning in Eq. (8) whileğ‘†-DHCN only conducts self-discrimination contrastive learning. Compared with another strong baseline GCE-GNN, COTREC is competitive in terms of both performance and eî€œciency. Although GCE-GNN can achieve comparable results on Diginetica, its more complex structure makes it suî€er from the out-of-memory problem when performing on RetailRocket on our RTX 2080 Ti GPU. Besides, its performance is much lower than that of COTREC on Tmall. 4.2.2 Ablation Study. In this section, to investigate the contribution of each component in our model, we develop four variant versions of COTREC:COTREC-base,base-NP,base-NA,COTRECND, and we compare the four variants with the complete COTREC model on Tmall and Diginetica. InCOTREC-base, we only use the item view to model session data, removing the session view and the self-supervised graph co-training. Inbase-NP, we remove the reversed position embeddings.base-NAmeans that we remove the soft-attention mechanism and replace it with averaging item representations as the representation of each session. InCOTREC-ND, we only use self-supervised co-training without the divergence constraint. We show the results of these four variants in Figure 2. From Figure 2, we can observe that each component consistently contributes on both datasets. The self-supervised co-training improves the base model the most, serving as the driving force of the performance improvement. When removing the self-supervised co-training, we can observe a remarkable performance drop on both the two metrics. Besides, the divergence constraint is eî€ective to prevent mode collapse in co-training process. Without this module, the performance of COTREC is even worse than that of the base on Diginetica. Note that on Tmall, base-NP outperforms COTREC-base, proving that a strict temporal order of items may negatively inî€uence the performance in some cases, which is in line with the our previous observation inğ‘†-DHCN. According to the results of base-NA, it is shown that learning diî€erent item importance across sessions is better than directly averaging representations of contained items for learning session representations in session-based recommendation. Table 3: Comparisons of Diî€erent SSL Methods. 4.2.3 Comparison with Diî€›erent SSL Methods. To further investigate the eî€ectiveness of the proposed self-supervised graph cotraining, we also compare it with other diî€erent SSL methods that are based on self-discrimination and random dropout to generate self-supervision signals on Tmall and Diginetica. The î€›rst is the method proposed inğ‘†-DHCN. DHCN proposes to capture item-level and session-level information and maximize mutual information between the session representations learned at the two levels. Positive examples are two types of session representation of the same session, whereas negative pairs are representations of diî€erent sessions. The second compared SSL method is based on the item mask, which is an often used strategy where some items are randomly dropped in each session. The generated new session can be the positive example and other sessions can be negative samples. For a fair comparison, we employ these SSL strategies on the base model of COTREC. So we name the three as base-COTREC, base-DHCN,base-MASK. Besides, these SSL methods are used to establish auxiliary tasks in the model optimization and we use a hyperparameter to control the magnitude of SSL. Finally, we use grid-search to adjust the parameter to ensure the best performances of them, and the best results are shown in Table 3. From Table 3, we can see that, only the self-supervised graph co-training can boost the recommendation performance on both datasets and it also achieves the best performance, while the other two methods can only take eî€ect on Tmall, demonstrating that selfsupervised graph co-training is more eî€ective than self-discrimination and dropout-based methods. We also î€›nd that the strategy of item mask is the least eî€ective in most cases, proving that masked subsequences can only generate sub-optimal self-supervision signals in the scenario of session-based recommendation due to the very limited behaviors. 4.2.4 Handling Diî€›erent Session Lengths. In real world situations, sessions with various lengths are common, so it is interesting to know how stable our COTREC as well as the baseline models are when dealing with them, and it is also a critical indicator for production environments. To evaluate this, we follow [20, 41] to split the sessions of Tmall and Diginetica into two groups with diî€erent lengths and name them asShortandLong. Short contains sessions whose lengths are less than or equal to 5, while Long contains sessions whose lengths are larger than 5. Then, we compare the performance of COTREC with some representative baselines, i.e., STAMP, SR-GNN, GCE-GNN andğ‘†-DHCN in terms of Prec@20 Figure 3: P@20 results on Long and Short. Figure 5: The impacts of the number of layer. on Short and Long. Results in Figure 3 show that COTREC almost outperforms all the baseline models on both datasets with diî€erent session lengths. It demonstrates the adaptability of COTREC in real-world session-based recommendation. Besides, it is shown that the performance on the short sessions is better than that on the long sessions. 4.2.5 The Impact of Hyperparameters. In COTREC, we have two hyperparameters to control the magnitude of the SSL taks and the eî€ect of the divergence constraint, i.e.ğ›½andğ›¼. To investigate the inî€uence of them, we report the performance with a set of representativeğ›½values in { 0.001, 0.005, 0.01, 0.05, 0.1, 0.2, 0.5, 1} and ğ›¼values in {0, 0.001, 0.005, 0.01, 0.05, 0.1, 0.2, 0.5} on Tmall and Diginetica. We î€›x the other parameter as 0.005 when investigating ğ›½orğ›¼. According to the results in Figure 4, our model achieves the best performance when jointly trained with the SSL taks and the divergence constraint. On both Tmall and Diginetica, the best setting isğ›½ =0.05 andğ›¼ =0.005. When using largeğ›¼, a huge performance drop is observed, demonstrating that when there is large divergence between two encoder, it is hard for them to supervise each other. 4.2.6 The impact of the number of layers. To investigate the impact of the number of layers in graph convolution network, we range the number of layers in {1, 2, 3, 4, 5}. According to the results in Figure 5, we can see that for both Tmall and Diginetica, a three-layer setting achieves the best performance. When the number becomes larger, performance will drop due to the over-smoothing issue. Besides, an obvious performance î€uctuation is observed on Diginetica. Self-supervised learning is an emerging machine learning paradigm which exploits unlabeled data by generating ground-truth labels from the raw data itself and recently has been utilized in many î€›elds to enhance deep learning models. Existing SSL-based recommendation methods usually adopt random dropout-based self-discrimination to generate self-supervision signals. However, we argue that it cannot adapt to session-based recommendation because it would create sparser data and cannot leverage informative self-supervision signals from other entities. In this paper, we design a self-supervised graph co-training framework to address this issue. In our framework, co-training can iteratively selects evolving pseudo-labels as informative self-supervision examples for each view to improve the session-based recommendation. Extensive experiments and empirical studies demonstrate the eî€ectiveness of our framework and show its superiority over other recent baselines. This work was supported by ARC Discovery Project (Grant No. DP190101985),ARC Future Fellowship (FT210100624), National Natural Science Foundation of China (No. U1936104), CCF- Baidu Open Fund, and The Fundamental Research Funds for the Central Universities 2020RC25.
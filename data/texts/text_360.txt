South China University of TechnologyJD Finance America Corporation cslianghao.xia@mail.scut.edu.cnchaohuang75@gmail.com Capturing users‚Äô precise preferences is of great importance in various recommender systems (e.g., e-commerce platforms and online advertising sites), which is the basis of how to present personalized interesting product lists to individual users. In spite of signiÓÄõcant progress has been made to consider relations between users and items, most of existing recommendation techniques solely focus on singular type of user-item interactions. However, user-item interactive behavior is often exhibited with multi-type (e.g., page view, add-to-favorite and purchase) and inter-dependent in nature. The overlook of multiplex behavior relations can hardly recognize the multi-modal contextual signals across diÓÄùerent types of interactions, which limit the feasibility of current recommendation methods. To tackle the above challenge, this work proposes aMemory-AugmentedTransformerNetworks (MATN), to enable the recommendation with multiplex behavioral relational information, and joint modeling of type-speciÓÄõc behavioral context and type-wise behavior inter-dependencies, in a fully automatic manner. In our MATN framework, we ÓÄõrst develop a transformer-based multi-behavior relation encoder, to make the learned interaction representations be reÓÄûective of the cross-type behavior relations. Furthermore, a memory attention network is proposed to supercharge MATN capturing the contextual signals of diÓÄùerent types of behavior into the category-speciÓÄõc latent embedding space. Finally, a cross-behavior aggregation component is introduced to promote the comprehensive collaboration across type-aware interaction behavior representations, and discriminate their inherent contributions in assisting recommendations. Extensive experiments on two benchmark datasets and a real-world e-commence user behavior data demonstrate signiÓÄõcant improvements obtained by MATN over baselines. Codes are available at: https://github.com/akaxlh/MATN. ‚Ä¢ Information systems ‚Üí Re commender systems. Collaborative Filtering; Recommendation; Multi-Behavior Learning; Transformer Network; Deep Neural Networks ACM Reference Format: Lianghao Xia, Chao Huang, Yong Xu, Peng Dai, Bo Zhang, and Liefeng Bo. 2020. Multiplex Behavioral Relation Learning for Recommendation via Memory Augmented Transformer Network. In Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR ‚Äô20), July 25‚Äì30, 2020, Virtual Event, China. ACM, Xi‚Äôan, China, 10 pages. https://doi.org/10.1145/3397271.3401445 Recommender system, which facilitates the information-seeking process of users and meet their personalized interests, have played a critical role in various online services, such as e-commerce systems [13,38], online review platforms [1,44] and advertising [39]. At its core is to learn low-dimensional representations of user-item interaction while capturing the user preference and the underlying intrinsic characteristics [19]. Early methods towards this goal, have made signiÓÄõcant eÓÄùorts on transforming user-item interactions through vectorized representations based on the conventional Collaborative Filtering (CF) techniques (e.g., matrix factorization scheme [15, 22] and its variations [12, 26]). Inspired by the advancement of deep learning techniques, various neural network-based collaborative ÓÄõltering frameworks have been developed to model the relationships between users and items. These methods aim to map sparse input interaction features into low-dimensional user/item embedding vectors and then project them into ÓÄõxed-length representations in a group-wise manner [16,54]. For example, neural collaborative ÓÄõltering models replace the inner product function in the matrix factorization consider non-linearities with multilayer perceptron [11] and metric learning scheme [33]. In addition, auto-encoder architecture has served as an eÓÄùective solution to learn a mapping function between the explicit interaction and latent representation through the reconstructionbased encoder-decoder framework. To capture the rich graph-based neighborhood contextual signals, various graph neural encoders have been proposed to aggregate information over the user-item interaction graph, with the graph convolutional network [49] or message-passing mechanism [41]. Despite the prevalence of the above recommendation solutions, they has thus far focused on user preference representation learning with the consideration of singular type of user-item interactive behavior. However, in many practical recommendation scenarios, user-item interactions are multiplex and exhibited with relationship diversity in nature. Let‚Äôs consider the e-commerce system as an example, there exist multiple types of behavior (e.g., page view, add-to-favourite, add-to-cart and purchase) between users and items [8], which are mutually inter-dependent. For instance, add-to-cart behavior is more likely to co-occur with purchase than the add-to-favorite behavior. The page view and add-to-favourite behavior can also provide useful signals for making purchase decisions. In such cases, the ignorance of such multi-modal relations across diÓÄùerent types of user-item interaction behavior, makes existing recommendation methods insuÓÄúcient to distill eÓÄùective collaborative signals from the collective users behavior. The recommendation framework with multiplex interactive behavior pose two key challenges: First, the dependencies across diÓÄùerent types of user-item interactions can be arbitrary since any pair of type-speciÓÄõc behavior could potentially be correlated due to various factors [42]. For example, users often have correlated online behaviors and exhibit diÓÄùerent dependencies in choosing items of diÓÄùerent categories due to his/her specialty. Such interdependencies between diÓÄùerent types of interaction behavior may vary by users and items. While a handful of studies attempt to learn user preference from multi-behavior [7,8], they merely consider the singular dimensional cascading correlations between multi-type interactions, and cannot comprehensively capture the arbitrary dependencies between diÓÄùerent types of interaction over diÓÄùerent items. Hence, to build eÓÄùective recommendation model with the complex behavior dependencies remains a signiÓÄõcant challenge. Second, when modeling the relationships across diÓÄùerent types of behavior, it is also important to capture the context and semantics of individual type of user-item interactions, e.g., users‚Äô page view are more frequent than their purchases, and add-to-favorite behavior is more likely to happen over users‚Äô interested items but may postpone their buying decision. In addition, type-speciÓÄõc behavioral patterns interweave with each other in complex way (e.g., support or mutually exclusive relations) and are diÓÄúcult to be captured. During the behavioral pattern integration, as the importance of various types of behavior can be diÓÄùerent, their relevance in assisting the forecasting task on the target behavior need to be carefully decided. Motivated by the aforementioned challenges, this work proposes a general and ÓÄûexible multi-behavior relation learning framework‚Äì Memory-AugmentedTransformerNetworks (MATN). SpeciÓÄõcally, this work ÓÄõrst proposes a multi-behavior transformer network to learn type-speciÓÄõc behavioral representations with the incorporation of inter-dependencies across diÓÄùerent types of user-item interactions. By integrating the transformer network with a memoryaugmented attention mechanism, we endow the MATN framework with the capability of incorporating type-speciÓÄõc behavior contextual signals. to collectively model the implicit relevance across multi-type behavioral patterns and perform comprehensive learning for making recommendations, we design a behavior type-wise gating mechanism which promotes the collaboration of diÓÄùerent types of interactions. In the pattern aggregation layer, MATN could learn cross-type representations in the latent feature spaces by automatically adjusting the contribution of each behavior view point in the behavior predictive model. The contributions of this paper are highlighted as follows: ‚Ä¢We propose MATN, a new recommendation framework with multiplex behavioral relation learning. MATN explicitly encodes multi-behavior relational structures by preserving both the crosstype behavior collaborative signals and type-speciÓÄõc behavior contextual information. ‚Ä¢We ÓÄõrst develop a multi-behavior dependency encoder with a transformer architecture, to inject collaborative signals across diÓÄùerent types of user-item interactions into the embedding process. Furthermore, we augment the multi-behavior transformer network with a memory attention mechanism, which is capable of uncovering type-speciÓÄõc behavior semantics during the customized representation recalibration phase. ‚Ä¢Finally, a type-wise pattern aggregation layer with gating mechanism is developed to promote the collaboration of diÓÄùerent behavior views for robust representations on user preferences. ‚Ä¢Our extensive experiments on two benchmark datasets and a user behavior data from a major e-commence platform, demonstrate that MATN outperforms 12 baselines from various research lines in yielding better recommendation performance. We further perform case studies with qualitative examples to better understand the interpretation ability of MATN framework, and study the model eÓÄúciency under diÓÄùerent recommendation scenarios. In the recommendation scenario, we ÓÄõrst deÓÄõne the behavior (e.g., purchase) which we aim to predict as target behavior, other relevant user-item interactive behavior (e.g., click, add-to-cart and add-to-favorite) is termed as source behavior. In this work, we aim to explore the latent relational structures between diÓÄùerent types of user behavior (e.g., purchases and click) for making predictions on the target behavior of users in recommender systems. Definition 1.Multi-Behavior Tensor X. We deÓÄõne a threedimensional multi-behavior tensorX ‚àà Rto represent theùêø (indexed byùëô) types of behavior fromùêº(indexed byùëñ) users overùêΩ(indexed byùëó) items. Without loss of generality, we focus on the implicit user feedback which is more common in practical recommendation scenarios [25,40]. Particularly, in tensorX, each entryùë•=1 if userùë¢is interacted with itemùë°given theùëô-th behavior type. For example, if userùë¢purchases itemùë°, the corresponding elementùë• will be set as 1 in the purchase behavior matrix X. Problem Statement. Based on the aforementioned deÓÄõnitions, the recommendation task with multiplex behavior learning is formulated as follows:Input: the user-item interaction data represented with multi-behavior tensorX(including both the target and source behavior).Output: A predictive model to eÓÄùectively infer the unknown user-item interactions in X with the target behavior ùëô. In this section, we present the technical details of MATN framework, the architecture of which is illustrated in Figure 1. MATN is a hierarchical neural architecture with three key modules in MATN: (i) cross-behavior embedding layers that learn the representations by exploring the inter-dependencies across diÓÄùerent types of interactions; (ii) a customized representation recalibration network that reÓÄõnes the latent embeddings, with the preservation of individual behavioral contextual information; (iii) a forecasting layer that aggregates the reÓÄõned behavior type-speciÓÄõc embeddings and outputs a predicted likelihood of a user-item interaction pair. As discussed before, diÓÄùerent types of user behaviors are correlated with each other, which brings in new challenges to the recommendation framework. To model the inter-dependencies across diÓÄùerent types of behavior, we design a multi-behavior transformer network to promote the collaboration of diÓÄùerent behavioral views. To achieve this goal, we learns a robust representation for useritem interactive patterns of each individual categorical behavior ùëô, which integrates the relevant information from other behavior views ùëô‚àà [1, ..., ùêø]&ùëô‚â† ùëô. 3.1.1Initialized Embedding Layer.Firstly, a projection layer is introduced to map the original multi-behavior user-item interaction data into initial latent representations. We denote the interaction vector ofùëô-th behavior type andùëñ-th user (ùë¢) over all items (ùë°,1‚â§ ùëó ‚â§ ùêΩ) asX‚àà R. The projection operation forXis formally deÓÄõned asÀúX= V ¬∑ X, whereV ‚àà Randùëëdenotes learned projection matrix and hidden state dimensionality, respectively. Note thatVis shared across behavior categories to model the common semantics of diÓÄùerent interactions. The projectedÀúX serves as an initial parameterized state for user-item interactions X, to be optimized with the following modules. 3.1.2Multi-Head Self-Attentive Mechanism.Inspired by the promising potential of self-attention mechanism in data correlation learning [50], we build our multi-behavior dependency learning module upon the architecture of multi-head self-attention network, which allows the learned behavior type-speciÓÄõc representations to interact with each other and identify the most informative correlated signals across diÓÄùerent types of interaction behavior. Furthermore, considering the fact that diÓÄùerent types of interaction behavior (e.g., add-to-cart and purchase) can be mutually correlated in a complex way (due to personalized factors) [2], the multi-head learning strategy enable our behavior dependency encoder with the capability of jointly attending to information from diÓÄùerent representation subspaces [48]. In our transformer network, we adopts the scaled dot-product attention for each‚Ñé-th head with the deÓÄõnitions of query, key and value transformation matricesQ‚àà R, K‚àà RandV‚àà R. Then, the weightÀÜùõºassigned to each input value is determined by the dot-product of the query with all the keys as follows: whereùõºis the intermediate variable fed into the softmax operation to generate the ÓÄõnal relevance scoreÀÜùõºbetween theùëô-th and ùëô-th type of behavior. Based on the learned head-speciÓÄõc attention weights, our dependency encoding module aims to learns a crosshead relevance score for each behavior type-speciÓÄõc representation ÀúXwith the following multi-head learning operations: To alleviate the gradient vanishing issue, the residual connection [9] is employed in the deep neural network structures. Additionally, we element-wisely add the learned dependency-aware behavior type-speciÓÄõc interaction representationYwith the projected feature embeddingÀúXofùëô-th behavior, so as to jointly preserve the behavior type-speciÓÄõc interaction features and the underlying interdependent signals across various types of user behavior. Formally, such operation is given as:ÀúY=ÀúX+ Y. In addition to the implicit multi-behavior dependency encoded by the above introduced transformer network, each type of behavior may have its own characteristics. For instance, users‚Äô page view behavior are more frequent than their purchases and add-to-cart behavior is more likely to be followed by a purchase than the addto-favorite behavior. While the cross-behavior inter-correlation structure can be modeled by our transformer module, the behavior type-speciÓÄõc semantic diversity has been overlooked. Hence, we propose to augment our MATN framework with the capability of capturing the semantic signals of each individual type of interaction behavior. Motivated by the recent advancements of augmented neural architecture and attention mechanism [21,33], we perform a customized representation recalibration process on behavior typespeciÓÄõc context with a memory-augmented attention network. In our memory-based behavior context learning module, we provide a customized transformations for each type of user behavior representationÀúYby stacking a set of memory blocks. By doing so, we endow MATN with the power of distilling the underlying semantics from the speciÓÄõc contextual user-item interaction scenario (e.g., page view, interested in, want to buy, or purchase). In speciÓÄõc, our customized embedding recalibration module aims to learnùëÄ(indexed byùëö) transformation matrices (individual is referred asU‚àà R) as the corresponding augmented memory, in order to project the general behavior embeddingÀúYinto a type-aware latent learning space. By applying diÓÄùerent memory transformations over diÓÄùerent types of behavior, each type of behavioral features are reÓÄõned with respect to its own contexts with the designed memory, and a customized behavioral representations are generated through this type-speciÓÄõc transformation procedure. Furthermore, in order to alleviate the overÓÄõtting phenomenon of type-speciÓÄõc memory augmented neural network architecture [53], Figure 1: The model architecture of the proposed MATN framework. The initialized embedding layer shares parameters across diÓÄùerent b ehavior types. The transformer-based behavior dependency encoder takes all kinds of behavioral interaction data for dependency modeling. DiÓÄùerent types of behaviors are individually transformed by the customized context learning with√ã shared key and memory slots.is the dot-product between the embeddings and transformation weight matrix. we employ an attention network to learn the relations betweenùêø behavior types andùëÄmemory matrices in an explicit way, and generate a behavior type-speciÓÄõc transformations with weighted summation. Formally, the reÓÄõned representation with customized behavioral context for the ùëô-th interaction type is whereK ‚àà R, b ‚àà Rare the transformation and bias for calculating attention weights. Instead of using Softmax, we use ReLU to relieve the gradient vanishing issue and mke it easier to train the attentive weight calculating. The memory transformation matricesUand calculating attention weightsùúîare jointly trained with other components of MATN. Next, we build upon a behavior type-wise gating mechanism to aggregate the learned latent representations from the memoryaugmented transformer network, with the exploration of their contributions in capturing user‚Äôs preference and assisting making predictions on the target behavior. Considering the distinct eÓÄùects of diÓÄùerent types of behavior in characterizing user‚Äôs interest, e.g. user‚Äôs historical purchases may be more relevant to his future purchases as compared to his page view activities, the type-speciÓÄõc importance is learned in our gated mechanism in an adaptive manner. Formally, the applied weighted aggregation gate outputs a ùëë-dimensional uniÓÄõed representation for ùë¢as follows: where w ‚àà Ris the parametric weights for aggregation, the Softmax activation function is used to normalize the weights. By applying the weighted aggregation gate, MATN learns the contributions of diÓÄùerent behavior types and thus can enable the adaptive aggregation in modeling the cross-type behavior relations. After obtaining the aggregated user behavior representation, the MATN adopts a two-layer feed-forward network with non-linear activation, to capture the complex feature interactions in the latent embeddings. Formally the deeply-extracted user representations are learned with the following operation: Œõ= ùëì (W¬∑ Œ®+ b) + Œ®; Œì= ùëì (W¬∑ Œõ+ b) + Œõ(6) whereW‚àà Randb‚àà Rare transformation and bias vectors of the neural network,ùëìis element-wisely applying non-linear activation functions, and residual connections are also employed. Œì‚àà Ris the ÓÄõnal user representation. Given the user behavior representation aggregated from diÓÄùerent views (i.e., behavior type-speciÓÄõc semantics and cross-type behavior dependencies), MATN could make predictions on user‚Äôs preference over items for the targetùëô-th type of behavior. In particular, the prediction process is performed through a dot product operation Pr(X) = P¬∑ Œì, whereP‚àà Ris from a parametric embedding table for all items, and the resultPr(X)is a scalar score representingùë¢‚Äôs tendency of interacting withùë°under behaviorùëô. Inspired by the settings of learning process on top-N recommendation tasks [23,51], we leverage the pair-wise loss to model the relative position in ranking-based recommendation scenarios. For each training step for userùë¢, we sample a positive interaction set {ùë°, ùë°, ...ùë°}composed of interacted items withùë¢for the target ùëô-th type of behavior. Here.ùë†is deÓÄõned as the number of the positive samples. Correspondingly, the same number of items that have no interactions withùë¢in the training set are randomly sampled to form the negative interaction set{ùë°, ùë°, ..., ùë°}. Based on the above descriptions, we formally deÓÄõne our loss function over all the samples of all users as below: Loss =max(0, 1 ‚àí Pr(X) + Pr(X)) + ùúÜ‚à•Œò‚à•(7) where the ÓÄõrst term is the pair-wise loss for a positive-negative pair. It expands the signed diÓÄùerence between two predictions, until it Output: trained parameters in Œò reaches a big enough scale. The latter term is a weight decay regularization term to prevent over-ÓÄõtting, andùúÜis the regularization weight. The learning process is elaborated in Algorithm 1. In this section, we perform experiments on diÓÄùerent datasets to demonstrate the eÓÄùectiveness of our MATN. We aim to answer the following research questions: ‚Ä¢ RQ1: Compared to state-of-the-art models, does MATN achieve better performance in various recommendation applications? ‚Ä¢ RQ2: What is the impact of the designed modules in MATN ? Are the proposed cross-behavior transformer network and attention memory module necessary for improving performance? ‚Ä¢ RQ3: How is the MATN ‚Äôs recommendation accuracy w.r.t the integration of diÓÄùerent types of behavior? ‚Ä¢ RQ4: What is the inÓÄûuence of hyperparameter settings in MATN for the recommendation performance? ‚Ä¢ RQ5: What behavior relational patterns does the proposed MATN model capture for the ÓÄõnal recommendation decision? ‚Ä¢ RQ6: How is the scalability of the MATN framework? 4.1.1Data Description.We evaluate the model performance on three diÓÄùerent types of datasets: (i) MovieLens: a benchmark dataset for movie recommendations; (ii) Yelp: another benchmark dataset for location-based venue recommendations from the online review Table 1: Statistics of experimented datasets platform Yelp; (iii) E-Commerce: a user behavior data from a realworld e-commence platform. Table 1 summarizes the data statistics and we present the data details as below: MovieLens Data. It is a widely-used dataset for performance validation of various recommendation methods. Following the partition strategy in [18,24], we diÓÄùerentiate the explicit user-item interactive behavior into three types in terms of user rating scores (i.e., ranging from 1 (worst) to 5 (best) stars with 0.5 star as increment): the original rating score‚â§2,>2 and<4,‚â•4 corresponds to the dislike, neutral and like user behavior, respectively. In the MovieLens dataset, we regard the like interaction as the target behavior and other interactions (dislike and neutral) as source behavior, because the positive interactions between users and items may be more useful for capturing user‚Äôs preferences in recommendations [20]. Yelp Data. This is another recommendation benchmark dataset collected from Yelp. We use the same multi-behavior diÓÄùerentiation strategy as the MovieLens data and partition the 5-star range rating behavior into dislike, neutral and like user behavior. In addition to the user rating behavior, this data includes an additional tip behavior to indicate that user writes a tip on his/her visited venues. Similar to the MovieLens data, the target behavior in Yelp data is also set as the like interaction and others are set as source behavior. E-Commerce Data. Besides the two benchmark datasets for movie and location-based venue recommendations, we also evaluate our MATN framework in a real-world recommendation scenario with explicit multiple user behavior data from a major online retailing platform. SpeciÓÄõcally, this data contains four types of interaction behavior, i.e., page view, add-to-favorite, add-to-cart and purchase. We consider the purchase behavior as the target one, since the purchase is directly related with the conversion rate of recommendation in real-life E-commerce sites [8]. 4.1.2Evaluation Settings and Metrics.In our experiments, we utilize the leave-one-out evaluation strategy which has been widely utilized in recommendation literature [11,12]. Following their evaluation settings, we regard the latest interaction of each user as the test set and use the rest of data for training. For eÓÄúcient and fair evaluation, we follow the common strategy in [14,32] to associate each ground truth item with 99 randomly sampled negative instances which have not interacted with the corresponding user. We leverage two widely-used ranking metrics: Hit Ratio (HR@ùëò) and Normalized Discounted Cumulative Gain (NDCG@ùëò) [4,41], to investigate the ranking performance (top-ùëòranked recommended items) of all compared methods. Note that higher HR and NDCG scores reÓÄûect better recommendation results. In our experiments, we also evaluate the model performance by varying the ùëò value. 4.1.3Competitive Baselines.To perform a comprehensive performance validation, we compare our MATN with 12 baselines from six research lines, which are elaborated as follows: Conventional Matrix Factorization-based Recommendation: ‚Ä¢ BiasMF[15]: This method is built upon the matrix factorization architecture with the incorporation of user and item biases. Neural Collaborative Filtering Models for Recommendation: ‚Ä¢ DMF[47]: It is a deep matrix factorization model which takes both the explicit and implicit feedback as the input. ‚Ä¢ NCF [10]: NCF aims to supercharge collaborative ÓÄõltering with non-linear neural networks. We consider three variants of NCF w.r.t user-item interaction encoders: i.e., Multilayer perceptron (i.e., NCF-M), concatenated element-wise-product branch (i.e., NCF-N) and the ÓÄõxed element-wise product (i.e., NCF-G). Collaborative Filtering with Auto-Encoder: ‚Ä¢ AutoRec[27]: It leverages a three-layer autoencoder to map user-item interactions into latent representations. ‚Ä¢ CDAE[45]: In this autoencoder CF, an adaptive loss is incorporated into the embedding projection process for users/items. Neural Auto-regressive Recommendation Models: ‚Ä¢ CF-NADE[53]: It enhances the autoregressive collaborative ÓÄõltering with the parameter sharing between diÓÄùerent ratings. ‚Ä¢ CF-UIcA[5]: It is a neural co-autoregressive framework to consider the structural correlation for both users and items. Graph Neural Network Recommendation Models: ‚Ä¢ ST-GCN[49]: It stacks encoder-decoder blocks using graph convolutional networks to learn embeddings of users and items. ‚Ä¢ NGCF[41]: This approach explore the structural knowledge with the message-passing mechanism to capture the high-order connections in the user-item interaction graph. Recommendation with Multi-Behavior Learning: ‚Ä¢ NMTR[7]: It is a multi-task recommendation model which considers the behavior correlations in a cascaded manner. ‚Ä¢ DIPN[8]: This model utilizes bi-directional recurrent network and attention mechanism to consider the correlations between the buying or browsing activities. 4.1.4Parameter Settings.In the latent learning space of MATN framework, we set the hidden state dimensionalityùëëas 16. In the multi-behavior transformer module, we set the number of attention heads for multi-dimensional learning as 2. Furthermore, the number of memory transformations is set as 8 in our customized behavior-speciÓÄõc context encoding. We implement our MATN with TensorFlow and use Adam optimizer for model optimization with the learning rate and batch size of 1ùëíand 32, respectively. The decay rate of 0.96 is applied for each epoch during the training phase. To reduce the overÓÄõtting eÓÄùect, we adopt set weight decay as the regularization strategy with the selection from {0.05, 0.01, 0.005, 0.001, 0}. The depth of our feature extraction module is set as 3. For the baselines (i.e., NCF and NMTR) which employ the point-wise loss, we set the sampling ratio for positive and negative instances from the range of 1 : 1 to 1 : 4. Table 2: Prediction performance on Yelp (like behavior), MovieLens (like behavior) and E-Commerce (purchase behavior) data, in terms of HR@ùëò and NDCG@ùëò (ùëò = 10). 4.2.1Performance on Target Behavior.In the evaluation, we ÓÄõrst perform experiments to separately make recommendations on venue, movie and online retailing products with three types of datasets and the results are shown in Table 2 (‚ÄúImp‚Äù indicates the relatively improvement ratio). We observe the remarkable performance improvement achieved by our MATN in predicting diÓÄùerent types of behaviors. We attribute such improvements to exploration of the cross-type behavior dependencies which are neglected by most existing methods, although they attempt to model complex user-item interactive relations with various deep neural encoders (e.g., autoencoder, graph neural network, attention mechanism). Additionally, by jointly analyzing the results among the three datasets, we ÓÄõnd that the improvement of MATN on the E-Commerce data is the most signiÓÄõcant with the largest data scale. This may be caused by the behavior diversity: the multiple behaviors from the E-Commerce site are constructed with four diÓÄùerent types of behavior which may show strong ordinal relations between the target (purchase) and source behaviors (e.g., page view‚Üíadd-to-cart‚Üí purchase) in the real-world online retailing systems. The consistent improvement across datasets with diÓÄùerent user-item interaction densities, suggests the robustness of MATN in accurately learning user preference under diÓÄùerent sparsity degrees. Lastly, it is worth mentioning that although the correlations between behavior has been considered in recent recommendation solutions (i.e., NMTR and DIPN), they merely model the singular dimensional cascading correlations between multi-type interactions, and cannot comprehensively capture the arbitrary dependencies between diÓÄùerent types of interaction with diÓÄùerent items. Therefore, such oversimpliÓÄõcation on the behavior dependency leads to suboptimal recommendation results. 4.2.2Overall Prediction Click Behavior.We also conduct experiments to evaluate the recommendation performance of all compared methods by forecasting the overall user-item interaction (i.e., click behavior), since the accurate predictions on overall interactive behavior (e.g., including all page view, add-to-cart and purchase behavior) could also provide useful insights for recommendation scenarios which focus on optimizing the click rate. As shown in Table 3, our MATN still achieves the best performance on all datasets as compared to various types of baselines. This validation shows Table 3: Overall recommendation performance in forecasting click behavior in terms of HR@ùëò and NDCG@ùëò (ùëò = 10). E-Commerce the potential of the overall prediction performance of MATN by jointly considering multi-type behavior of users. 4.2.3Ranking Performance v.s. Top-ùêæ Value.We also evaluate the model ranking performance by varying theùêævalue in terms of HR@ùêæand NDCG@ùêæ. We compare MATN with the best performed method of each baseline categories (see Section 4.1.3 for baseline description), and report the results of predicting the click and like behavior on Yelp data in Table 4. We can observe that MATN consistently outperforms other representative baselines with diÓÄùerent settings of ùêæ . Table 4: Ranking performance evaluation on Yelp dataset with varying Top-K value in terms of HR@K and NDCG@K Furthermore, we conduct ablation experiments over a several key components of MATN to better understand the component-speciÓÄõc eÓÄùects. Particularly, we introduce the following model variants: ‚Ä¢ EÓÄùect of Multi-Behavior Transformer Network: MATN -T. We do not utilize the multi-behavior transformer network to capture mutual relations between diÓÄùerent types of behavior. ‚Ä¢ EÓÄùect of Memory Attention Mechanism: MATN -M. We remove the memory-augmented attention network in the joint MATN model to encode behavior type-speciÓÄõc semantics. ‚Ä¢ EÓÄùect of Gating Mechanism: MATN -G. We replace the designed gating mechanism with the simpliÓÄõed average pooling operation over all behavior type-speciÓÄõc representations in the behavioral pattern aggregation layer. Figure 2 presents the model ablation study results. We summary the following ÓÄõndings (MATN is the default model version). (1) The incorporation of mutual dependencies between diÓÄùerent types of interaction behavior over all items, is capable of boosting the performance substantially. It demonstrates the rationality of our multi-head self-attention architecture in learning explicit pair-wise relations between diÓÄùerent behavior types. (2) MATN is consistently superior to MATN -M, which hence illustrates the importance of considering context and semantics of individual type of behavior in proÓÄõling user preferences. (3) The replacement of our gating mechanism (MATN) with average pooling operation (MATN-G), degrades the model‚Äôs performance. It make sense since MATN -G fails to model the diÓÄùerent importance across diÓÄùerent types of behavior in making ÓÄõnal recommendations. To investigate whether exploiting multi-type interaction behavior helps to achieve better performance, we further perform ablation experiments for the purchase prediction task on E-Commerce data, to show the eÓÄùect of incorporating diÓÄùerent types of user-item interactions in our MATN with four model variants: MATN‚Äìwithout the add-to-favorite behavior; MATN‚Äìwithout the add-to-cart behavior; and MATN‚Äìwithout the page view behavior. Furthermore, we design another variant by removing all other types of interactions and only contain the purchase behavior MATN. Figure 3 shows the evaluation results of diÓÄùerent variants under varying top-k settings. We summarize the following ÓÄõndings: (1) MATN using all types of interaction behaviors consistently outperforms other variants with varying top-k settings, except for one exception on top-1 prediction with minor performance defect. The results validate that our MATN improve purchase forecasting through integrating multi-behavior relations. (2) MATNusing only purchase data yields worst performance, which shows the positive contribution of the three additional behavior types (i.e. page view, add-to-favorite and add-to-cart) in helping with user modeling in the e-commerce scenario. (3) Among the three variants that utilize two additional behavior types (i.e. MATN, MATN, MATN), MATNclearly shows more severe performance degradation compared to the other two. This sheds light on the higher importance and eÓÄùectiveness of utilizing page view data in MATN and online shopping recommendation. In our experiments, we also investigate the impact of diÓÄùerent hyperparameter settings in our developed MATN framework. Specifically, we evaluate the model recommendation performance by varying the values of several key hyperparameters, including the hidden state dimensionalityùëë, the memory dimensionùëÄin our memory attention network, and the number of neural network layersùëÅin our deep feature extraction module. The evaluation Figure 2: Model ablation study of MATN on Yelp, MovieLens and E-Commerce data in terms of HR@ùêæ and NDCG@ùêæ. Figure 3: Impact study of multi-behavior relation integration on purchase prediction of E-Commerce dataset. results on the Yelp data in predicting both click and like behavior are shown in Figure 4. The major ÓÄõndings are summarized as below: ‚Ä¢ Hidden State Dimensionality ùëë. We can observe that when we increaseùëëfrom 4 to 16, the recommendation performance becomes better, but the further increase theùëëvalue (‚â•32) may not be helpful for the model prediction accuracy. The potential reason for this observation is that the large number of latent units could bring a stronger representation capability. ‚Ä¢ Memory Dimension ùëÄ. Our memory attention network enables the behavior type-speciÓÄõc semantics learning could be performed fromùëÄdiÓÄùerent dimensions. The parameter study results on memory dimensionùëÄindicates that performing the transformation with more latent learning sub-spaces will beneÓÄõt the recommendation at the early stage, but the continuous increase of ùëÄ will lead to the overÓÄõtting issue. ‚Ä¢ Feature Extraction Network Depth ùëÅ. We further examine whether designing a deep feature extraction network is beneÓÄõcial to the recommendation task. As we can see, stacking two hidden layers is beneÓÄõcial to the performance, which is attributed to the high non-linearities brought by more non-linear layers. However, the overÓÄõtting phenomenon can be observe when we perform more transformation-based feature interaction operation with more hidden layers (‚â• 3). In this subsection, we perform qualitative analyses to show the model interpretation of MATN in comprehending user behavior relationships and generate more convincing recommendation. To be speciÓÄõc, we visualize the learned quantitative weights learned by our multi-head self-attention mechanism, memory-augmented attention network and multiplex relation aggregation layer. Four typical cases (i.e., samp,...,samp) are sampled from the prediction of overall click behavior and purchase behavior on the E-Commerce dataset. From the visualization results, we have the following observations: (1) page view and purchase behavior could provide more informative signals in predicting the click and purchase, respectively. This make sense since the same type of behavior may share closer relationships than other behavior types. (2) In the head-speciÓÄõc self-attention layer, the 4√ó4 behavior relevance matrix indicates across four types of user behavior. An interesting observation is that: add-to-favorite activity is more like to be correlated with page view and purchase, than add-to-favorite. Similar results can be observed for add-to-cart. It might indicate that add-to-favorite has a high co-occurrence probability than others in the real-world ecommerce platform. (3) The memory attention could learn weights in an adaptive way which corresponds to the importance score generated by our gating mechanism. The reason lies in the utilization of ReLU activation in the attention calculation instead of the mandatory restriction with Softmax function. Overall, all above observations demonstrate the model interpretation power of MATN in capturing complex behavior relations from diÓÄùerent perspective. In addition to recommendation accuracy, the model eÓÄúciency is also an important factor to investigate. In this subsection, we evaluate the computation time cost of our MATN as compared to other baselines. In Table 5, we report the running time of each epoch during the training phase of each compared approach. We can observe that our MATN model could achieve comparable performance when competing with most baselines, especially in dealing with the large-scale user-item interaction data. Although we lose in the cases when comparing with some of the competitive baselines‚Äìlearning user-item interaction representations with simple relation encoders (e.g., Multilayer Perceptron, vanilla autoencoder), our MATN still exhibits competitive model scalability due to the comparable time complexity. However, MATN can show obvious performance superiority over these techniques. In addition, the performance gap (measured by running time) between MATN and graph neural network recommendation methods (i.e., ST-GCN and NGCF), may stem from the high computational cost of graph convolution operation when performing information aggregation and propagation. Deep Collaborative Filtering Techniques. Deep learning have been revolutionizing collaborative ÓÄõltering techniques and achieve promising results in many recommendation scenarios. For example, Figure 5: Case study of the learned quantitative weights from key modules in MATN. Pair-wise relations between four types of behavior (e.g., ùëÉ, ùêπ , ùê∂ and ùêµ) are represented with a4√ó4weight matrix in the multi-head self-attention layer. ùúî,...,ùúîindicate the learned weights across 8 memory dimensions in the memory attention network. The four relevance scores encoded by gating mechanism corresponds to four behavior types. Tuples (e.g., <50,12,39,50>) are numbers of behaviors in the order of (P, F, C, B). Table 5: Computational time cost (seconds) investigation. Multi-layer Perceptron has been integrated into the collaborative ÓÄõltering architecture to handle non-linear feature interactions [11,47]. Several work attempts to utilize encoder-decoder network to map explicit user-item interactions into latent representations, using autoencoder [27] and its variants [29]. In addition, another research line lie in leveraging graph neural network to incorporate useritem graph signals into the recommendation framework, such as NGCF [41], STAR-GCN [49] and Multi-GCCF [31]. The major difference between these methods and ours is that MATN explores the cross-behavior interactive knowledge to assist recommendation. Relation-aware Recommender Systems. Prior work has made signiÓÄõcant advances to develop recommender systems with the consideration of various relations between users and items. For example, the social-aware recommender systems aim to boost recommendation performance by exploring user‚Äôs social relations based on the information dissemination [3,6]. Furthermore, knowledge graph has become another information source from item side to help recommendation models capture relationships between items [37,40]. In addition to the relation of collaborative similarity, there exist work aiming to consider multiple item relationships (e.g., shared director or categories) to learn ÓÄõne-grained item knowledge [46]. DiÓÄùerent from these methods which focus on using the exogenous information from either user or item side, this work explores the multiplicity of pairwise user-item interactions and carefully learns their underlying inter-dependencies. Attention Network for Recommendations. Attention mechanism has been proven to be eÓÄùective in diÓÄùerentiating various relations for recommendations [34], such as item transitions [17], user connections [28] and customer group dynamics [36]. To address the limitation of recurrent neural architectures in capturing long-range dependencies without the rigid order assumption, selfattention mechanism has been introduced to model correlations from any pair of positions of input data points [35]. For example, Sun et al. [30] proposed a bidirectional self-attention framework for sequential recommendation. Additionally, multi-head self-attentive model is introduced to recommended news to users [43]. Our MATN framework is motivated by the multi-head self-attentive learning architecture in a sense that a memory augmented transformer is designed to model multiplex behavior relation dynamics from different types of user-item interactions. In this work, we propose MATN, a novel memory augmented transformer neural architecture which incorporates multiple types of user behavior relationships into a cross-behavior collaborative ÓÄõltering framework. We argue that these diÓÄùerent types of user-item interactions are usually neglected in conventional methods. MATN demonstrates the state-of-the-art performance on two benchmark datasets and a large-scale user behavior data from a major online retailing platform. In addition, via the qualitative analysis of the attentive weights, we discover that the implicit cross-type behavioral dependencies are encoded within the MATN framework. Notwithstanding the interesting problem and promising results, some directions exist for future work. We will next incorporate rich auxiliary data source (e.g., user review text information or item description [52]) to further enhance the current recommendation framework. Additionally, another time dimension of the problem deserves more investigation. When multi-type user-item interaction data arrives in a timely manner, how to best account for it in the current MATN framework? One possible direction is adapting MATN to a time-sensitive model by analyzing the trade-oÓÄù between accuracy and complexity. We thank the anonymous reviewers for their constructive feedback. This work was supported by National Nature Science Foundation of China (61672241, U1611461), Major Project of National Social Science Foundation of China (18ZDA062), Natural Science Foundation of Guangdong Province (2016A030308013), Science and Technology Program of Guangdong Province (2019A050510010), and Fundamental Research Funds for the Central Universities (x2js-D2192830).
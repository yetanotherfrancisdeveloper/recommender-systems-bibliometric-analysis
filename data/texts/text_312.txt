Search and recommendation are the two most common approaches used by people to obtain information. They share the same goal â€“ satisfying the userâ€™s information need at the right time. There are already a lot of Internet platforms and Apps providing both search and recommendation services, showing us the demand and opportunity to simultaneously handle both tasks. However, most platforms consider these two tasks independently â€“ they tend to train separate search model and recommendation model, without exploiting the relatedness and dependency between them. In this paper, we argue that jointly modeling these two tasks will beneî€›t both of them and î€›nally improve overall user satisfaction. We investigate the interactions between these two tasks in the speciî€›c information content service domain. We propose î€›rst integrating the userâ€™s behaviors in search and recommendation into a heterogeneous behavior sequence, then utilizing a joint model for handling both tasks based on the uniî€›ed sequence. More speciî€›cally, we design theUniî€›ed InformationSEarch andRecommendation model (USER), which mines user interests from the integrated sequence and accomplish the two tasks in a uniî€›ed way. Experiments on a dataset from a real-world information content service platform verify that our model outperforms separate search and recommendation baselines. â€¢ Information systems â†’ Web search engines;Personalization; Recommender systems. personalized search; recommendation; uniî€›ed model ACM Reference Format: Jing Yao, Zhicheng Dou, Ruobing Xie, Yanxiong Lu, Zhiping Wang, and JiRong Wen. 2021. USER: A Uniî€›ed Information Search and Recommendation Model based on Integrated Behavior Sequence. In Proceedings of the 30th ACM International Conference on Information and Knowledge Management (CIKM â€™21), November 1â€“5, 2021, Virtual Event, QLD, Australia. ACM, New York, NY, USA, 10 pages. https://doi.org/10.1145/3459637.3482489 Figure 1: Illustration of an information content service platform with both search and recommendation services. On Internet platforms, search and recommendation are two major approaches to help users obtain the required knowledge. In this paper, we mainly focus on the domain of information content service which aims to deliver news feeds, tweets, or web articles to users. In order to improve usersâ€™ satisfaction with search and recommendation results, a lot of personalized search models and recommendation models have been proposed [5,10,13,14,20,36,37]. These models aim to mine user preferences from their historical behaviors to infer their current intents and generate a personalized document ranking list that can satisfy the current user interest. Typically, many deep learning based personalized search models learn a representation of user interests from her search history to re-rank the candidate documents[13,20,21,43,44,48]. Recommendation models also present document ranking lists according to the userâ€™s browsing history [14,36,37,39,41]. However, most existing studies concentrate on only one single task, namely either search or recommendation. They devise a speciî€›c model applicable for one task, but rarely consider their combination. Currently, there are more and more mobile Apps and websites where both information search and recommendation services are available. For the example of Toutiaoplatform shown in Figure 1, users can not only actively issue queries to seek information, but also browse the recommended articles. Indeed, some early attempts of combining the two services have already been applied. For example, some articles are recommended along with the clicked search results. Queries may also be suggested at the end of a recommended news article.Therefore, how to eî€ectively aggregate the two tasks together is an essential and valuable problem. Actually, some early studies [2] have discussed the similarity between search and recommendation. The two tasks share the same target â€“ helping people get the information they require at the right time. Zamani and Croft[46]propose a vanilla joint learning framework to handle both tasks at the same time. They train two separate models for the two tasks through a joint loss, but neglect the essential relatedness between them in human information-seeking behaviors. Actually, users usually switch between the two services when they are obtaining information from the Web. Let us take the example in Figure 1 for illustration. When a user browses the article list generated by the recommendation system, she is attracted by the article titled â€œNew energy vehicle: Weilai ...?â€. After reading this article, she switches to the search engine and issues a query to seek more knowledge about â€œNew energy vehicleâ€. Then, she browses the search results and articles recommended along with the clicked document to know more. Such an information-seeking pattern which mixes behaviors made in proactive searches and passive recommendations is common in our surî€›ng process. From the example, we î€›nd that the user may switch between the search service and recommender system for a single target, both the search behaviors and browsing behaviors reî€ect her personalized information need. Therefore, jointly modeling the entire user behavior sequence is expected to discover real user intents more precisely. Besides, some close associations may exist between the two kinds of behaviors that browsing could stimulate search and search might impact browsing in the future. Richer interaction and training data is available. Motivated by this scenario,we pay attention to jointly modeling both tasks of personalized search and recommendation in the information content domain, exploring the potential relatedness between their corresponding user behaviors to promote each other. To begin with, we integrate the userâ€™s historical search and browsing behaviors in chronological order, getting a simpliî€›ed heterogeneous behavior sequence shown in Figure 2.ğµrepresents browsed articles,ğ‘„indicates queries issued by the user, andğ·is documents clicked under the corresponding query. Then, we propose aUniî€›ed InformationSEarch andRecommendation model (USER) to encode the heterogeneous sequence and solve the two tasks in a uniî€›ed way. We think recommendation and personalized search share the same paradigm: recommendation can be treated as personalized search taking anEMPTYquery. Hence we design the USER model in a personalized ranking style, to rank candidate documents based on the input query (using empty for recommendation) and the user preferences contained in the integrated behavior sequence. This model has several advantages.First, we aggregate the userâ€™s search and recommendation logs, alleviating the problem of data sparsity faced by a single task.Second, based on the merged behavior sequence, more comprehensive and accurate user proî€›les can be constructed, improving personalization performance.Third, the potential relatedness between search and recommendation can be captured to essentially promote each other. Speciî€›cally, ourUSERmodel is composed of four modules.First, a text encoder is used to learn the representation for the documents and queries.Second, the session encoder models the integrated behavior sequence in the current session, captures relatedness between the search and browsing behaviors, and clariî€›es the userâ€™s current intention. As for a search behavior including a query and clicked documents with strong relevance, we employ a co-attention structure [25] to fuse their representations. Then, a transformer layer is constructed to capture the associations between the search and browsing behaviors in the session and fuse the context into the current intention.Third, the history encoder learns information from the long-term heterogeneous history sequence as an enhancement.Finally, we build a uniî€›ed task framework to complete the two tasks in a uniî€›ed way. We î€›rst pre-train the uniî€›ed model with the training data from both tasks, alleviating data sparsity. Then, we make a copy for each task and î€›netune it with the corresponding task data to î€›t the individual data distribution. We experiment on a dataset comprised of search and browsing behaviors constructed from a real-world information content service platform with both search and recommendation engines. The results verify that our model outperforms separate baselines and alleviates data sparsity. Our main contributions are summarized as follows: (1) We pay attention to both tasks of personalized search and recommendation. For the î€›rst time, we integrate separate behaviors of the two tasks into a heterogeneous behavior sequence. (2) We model the relatedness between a userâ€™s search and browsing behaviors to promote both personalized search and recommendation. (3) We propose a uniî€›ed search and recommendation model (USER) that accomplishes the two tasks in a uniî€›ed way with an encoder for the integrated behavior sequence and a uniî€›ed task framework. Personalized Search. Personalized search customizes search results for each user by inferring her personal intents. Early studies relied on features and heuristic methods to analyze user interests. Focusing on click features, Dou et al. [12] proposed P-Click to re-rank documents with their historical click counts. Topic-based features were applied to build user proî€›les [4,9,17,26,30,31,35]. The Open Directory Project (ODP) [26], learned or latent topic models [6] were used to obtain the topic-based information of a web page. Besides, the userâ€™s reading level and location are applied for personalization [3,11]. Multiple features were combined with a learning to rank method [7, 8] to compute a personalized score [5, 29]. Recently, deep learning was applied to capture potential user preferences. Song et al. [27] leveraged personal data to adapt a general ranking model. Ge et al. [13] devised a hierarchical RNN with query-aware attention to dynamically mine preference information. Lu et at. [20] employed GAN [15] to enhance the training data. Yao et al. [44] adopted reinforcement learning to learn user interests. Zhou et al. [49] explored re-î€›nding behaviors with a memory network. The latest studies were committed to disambiguating the query by introducing entities [21], training personal word embeddings [43], or involving search history as the context [48]. All these models are specially designed for the personalized search task. Information Recommendation Models. Personalized content recommendation is critical to help users alleviate information overload and î€›nd something interesting. Traditional recommendation systems mainly depended on collaborative î€›ltering (CF) [24] and factorization machine (FM) [23]. With the emergence of deep learning, Figure 2: Illustration of the integrated behavior sequence. The target behavior is personalized search with a query ğ‘„ or recommendation with an empty query. many models combined both low- and high-order feature interactions, such as Wide & Deep [10] and DeepFM [16]. Specially, representation based models have been studied for the recommendation of news articles that have abundant textual information. These models include two modules: a text encoder to obtain article representations and a user encoder to learn user representation from her browsing history. Then, articles are ranked based on their relevance with the user. Okura et al [22] devised an auto-encoder to learn news representations, and used an RNN to generate user representations. Wu et al. [36] learned article vectors from titles, bodies and topic categories. User representation was a weighted sum of the browsed news vectors. Wu et al. [37] set user embeddings to generate personalized attention to calculate the article and user representations. They also exploited multi-head self-attention [28] to capture contextual information [39]. LSTUR [1] kept both shortterm and long-term user proî€›les. To enhance text representations, entities in the article and their neighbors in the knowledge graph are considered [19,32,33]. The GNN structure [40] was also adopted to model high-order relatedness between users and articles [14,18]. In these models, only the recommendation task is discussed. Joint Search and Recommendation. Some studies considered both the search and recommendation tasks. In e-commerce, an early work [34] built a uniî€›ed recommendation and search system by merging their features. Zamani et al. [46] proposed a joint learning framework that simultaneously trains a search model and a recommendation model by optimizing a joint loss. For the situation with only recommendation data but not search logs, a multi-task framework was trained on browsing interactions [47]. These joint methods simply combined the two tasks and train two separate models through multi-task learning or joint loss, without exploring more essential dependency between them. Search history was also used to help generate recommendations for the users with little browsing history [38,45]. This model just targeted one single task with data from the other task as complementary information. In this paper, we propose a uniî€›ed model to solve the two tasks at the same time, mining the relatedness between their corresponding user behaviors to promote each other. Search and recommendation are two main approaches to help people obtain information. Many separate personalized search models and recommendation models have been proposed. As analyzed in Section 1, people usually achieve their information targets through a mixture of proactive searches and passive recommendation, which is popular on information content service platforms with both search and recommendation engines. Both kinds of behaviors reî€ect the userâ€™s information need and preferences. Thus, compared to existing separate approaches, jointly modeling the two tasks and exploiting the relatedness between them might have the potential to promote each other. In this paper, we integrate the userâ€™s search and browsing behaviors into a sequence to discover more accurate user interests, then design a uniî€›ed model to solve the two tasks in a uniî€›ed way. Next, we deî€›ne the new problem to be handled. Recall that we focus on the information content domain, let us formulate a userâ€™s behaviors with notations. On an information content service platform with both search engine and recommendation engine, the userğ‘¢could browse articlesğµin the recommendation system, issue queriesğ‘„to seek for information and click satisî€›ed documentsğ·in the search engine. All these behaviors are sequential, so we integrate them into a heterogeneous behavior sequence in chronological order. Referring to existing session segmentation methods [13,20], we divide the userâ€™s whole behavior sequence into severalsessionswith 30 minutes of inactivity as the interval. Past behaviors in the current session are viewed as theshort-termhistory. The other previous sessions constitute the long-termhistory. Speciî€›cally, we denote the userâ€™s history sequence asğ» = {ğ», ğ»} = {{ğ‘†, . . . , ğ‘†}, ğ‘†}, whereğ‘is the number of sessions. Each sessionğ‘†corresponds to a sub-sequence with both behaviors, such as {ğµ, ğµ, (ğ‘„, ğ·, ğ·), . . . , }. We illustrate the whole behavior sequence in Figure 2. The horizontal edges indicate the sequential relationship between two consecutive actions, while the slanted edges point to the documents clicked under the corresponding query. The blue vertical lines separate sessions. For example, in the current Sessionğ‘, the user î€›rst browses two articles in the recommendation system. Then, she enters a query in the search engine and clicks a document under this query. At the current momentğ‘¡, the user would perform a target behavior, either search with an issued queryğ‘„or browsing. For both tasks, we are supposed to infer the userâ€™s intent and return a personalized document list. Due to the same paradigm, we regard the recommendation task as personalized search with an empty query, and complete the two tasks in a uniî€›ed personalized ranking style. Facingğ‘„or an empty query, the model is required to return a personalized document list based on the query and the user interests learned from the userâ€™s integrated behavior sequence. The architecture of our USER model is shown in Figure 3. First, the text encoder is used to learn representations for documents and queries. Second, the session encoder models the userâ€™s integrated behavior sequence within the current session to clarify her information need. Then, the history encoder enhances the userâ€™s intent representation by mining information from the long-term history. Finally, we design a uniî€›ed task framework to complete personalized search and recommendation in a uniî€›ed way. We present the details of each module in the remaining parts of this section. For each queryğ‘„, clicked documentğ·and browsed articleğµ, we apply the text encoder to learn their semantic representations. Taking the calculation of a browsed articleğµas an example,ğµ = [ğ‘¤, ğ‘¤, . . . , ğ‘¤]whereğ‘€is the number of words in the article, the complete text encoder can be divided into three sub-layers. The î€›rst Figure 3: The architecture of our USER model. There are four major comp onents: the text encoder to learn representations for queries and documents; the session encoder to model integrated behaviors in the current session; the history encoder to mine information from the long-term behavior sequence; the uniî€›ed task framework to complete both tasks in a uniî€›ed way. is the word embedding layer that converts the word sequence into a matrix with word vectors, i.e.Emb= [ğ‘£, ğ‘£, . . . , ğ‘£] âˆˆ ğ‘…. ğ‘£corresponds to the low-dimensional word vector ofğ‘¤. In addition, contexts within the article are also helpful for users to î€›gure out the true meaning of a word. For example, the diî€erent meanings of â€œAppleâ€ in â€œApple fruitâ€ and â€œApple companyâ€ can be distinguished based on the diî€erent contextual words â€œfruitâ€ and â€œcompanyâ€. Therefore, we set a word-level transformer [28] as the second sub-layer to obtain the context-aware word representations ğ¶âˆˆ ğ‘…by capturing interactions between words. The details about transformer can be referred to [28]. The last sub-layer is a word-level attention layer. In a piece of text, diî€erent words contribute diî€erent informativeness for expressing the semantics of this text. For instance, in the sequence â€˜symptoms of novel coronavirus pneumoniaâ€™, the word â€˜symptomsâ€™ is very informative for learning the text representation, while â€˜ofâ€™ has little information. To highlight important words in a text sequence, we exploit a word-level attention mechanism to give them larger weights. We set a trainable vectorğ‘as the query in the attention mechanism. The weights ğ›¼ âˆˆ ğ‘…for all words are computed as: whereğ‘Šandğ‘are parameters. The î€›nal contextual representation of the browsed documentğ‘Ÿâˆˆ ğ‘…is the weighted sum ofÃ all the word vectors, i.e. ğ‘Ÿ=ğ›¼ğ¶. Contextual representations of the queryğ‘Ÿand clicked document ğ‘Ÿare computed in the same way. At the current timeğ‘¡, the userğ‘¢has a target action, either search or browsing. We represent her intention with a vectorğ¼. If the user issues a queryğ‘„for search, the intentionğ¼is initialized with the text representation of this queryğ‘Ÿcomputed by the text encoder. Otherwise, we use the corresponding trainable user embedding Embas initialization. This step is realized by a select gate, as: ğ¼=ğ‘Ÿif the target behavior is searchEmbif the target behavior is browsing(3) Then, we mine information from the userâ€™s history comprised of search and browsing behaviors to clarify her personal intent ğ¼. According to existing studies [13,48], it is thought that behaviors within a session show consistency in the userâ€™s information need. Thus, the userâ€™s past behaviors during the current session could provide rich contextual information for deducing her current intention. In the uniî€›ed search & recommendation scenario we study, there are both search and browsing actions in a session, as shown in Figure 2. We analyze that several possible relationships exist between the behaviors in the heterogeneous sequence: (1) For a document clicked under a query, we think this document satisî€›es the userâ€™s information need to be expressed by this query. It shows strong relevance between the query and the document. (2) After the user browses a series of recommended articles, she might be triggered to seek for more related information through proactive searches. (3) Queries are actively issued by the user, explicitly showing her preferences. With these queries and clicked documents, we can î€›gure out the points of interest the user focuses on when browsing articles. We design a session encoder to capture these associations in the current session and employ the session context to enhance the intent representation. First, for a historical query and the corresponding clicked documents, we are supposed to learn the strong relevance between them. Clicked documents indicate the userâ€™s intention contained in the query keywords, and the query highlights the important words in the documents. Thus, we suggest adopting the co-attention structure [25] to calculate their representation vectors by fusing their interactive information, instead of the vanilla word-attention mechanism. Taking a queryğ‘„and the clicked documentsğ·, ğ·, . . .as an example, the detailed computing process is as follows. At the î€›rst step, we obtain the contextual vector matricesğ¶andğ¶for the query and each document through the word embedding layer and the word-level transformer of our text encoder. Vectors of all clicked documents are concatenated together asğ¶= [ğ¶;ğ¶;. . .]. Then, we compute an aî€œnity matrix ğ´ between ğ¶and ğ¶. whereğ‘Šâˆˆ ğ‘…is a weight matrix to be learned. The attention weights for the query and documents are calculated based on the interactive features in the aî€œnity matrix, as: ğ»= tanh(ğ‘Šğ¶+ (ğ‘Šğ¶)ğ´), ğ‘= softmax(ğ‘Šğ»), (5) ğ»= tanh(ğ‘Šğ¶+ (ğ‘Šğ¶)ğ´), ğ‘= softmax(ğ‘Šğ»). (6) ğ‘Š,ğ‘Š,ğ‘Š,ğ‘Šare parameters.ğ‘andğ‘are the attention weights for query keywords and document terms respectively. We calculate the attended representation for the query and documents as the weighted sum of the contextual vectors ğ¶and ğ¶. The two vectors are concatenated to generate the representation of a historical search behaviorğ‘Ÿthrough an MLP layer, i.e.ğ‘Ÿ= MLP([ğ‘Ÿ;ğ‘Ÿ]). For a browsing behavior made in recommendation, it corresponds to only a browsed articleğµ. Thus, its representation is just the article representation ğ‘Ÿcalculated by the text encoder. With the representation of all past behaviors in the current session calculated,ğ»= {ğ‘Ÿ, ğ‘Ÿ, . . .}, we could capture the relationships between the search and browsing behaviors, and fuse the session context into the userâ€™s current intention. We combine ğ»with the target intentionğ¼and pass them through a sessionlevel transformer for interaction. On account of the behaviors are sequential and heterogeneous, we add the position and type information of each behavior for clariî€›cation. The action type includes search (S) and browsing (B). Finally, the output of the last position ğ¼represents the userâ€™s current intention fusing the session context. ğ¼= Transformer([ğ», ğ¼] + [ğ», ğ¼]+ [ğ», ğ¼] [ğ», ğ¼],[ğ», ğ¼]are the position embedding and type embedding. Transformer(Â·) means taking the output of the last position. With the session encoder described above, we clarify the userâ€™s current information need under the help of the short-term history, obtainingğ¼. But for the situation with little session history, it is still ambiguous due to the lack of session context. The userâ€™s long-term behavior history often reî€ects relatively stable interests, which also provides some assistant information. Thus, we further model the long-term history to enhance the userâ€™s intent representation based onğ¼. At î€›rst, we process each historical session with the session encoder to capture the connections between search and browsing behaviors, getting the contextual representation for all historical behaviors,ğ»= [{ğ‘Ÿ, ğ‘Ÿ, . . .}, {ğ‘Ÿ, . . .}, . . .]. We concatenate all session sub-sequences as a long behavior sequence and combine it with the target action as[ğ», ğ¼]. Then, a history-level transformer module is conducted on the long-term heterogeneous sequence to fuse the history information into the current intention. To preserve the sequential information between actions, we involve the position of each behavior{1,2, . . . ğ‘¡ }. In the î€›nal, we take the output of the last position as the userâ€™s intent representation enhanced by the long-term behavior history, denoted as ğ¼. where [ğ», ğ¼]is the position embedding. Motivated by some news recommendation models [37,39], the userâ€™s attention to a document is also impacted by her interests. Besides, the user might intend to î€›nd a speciî€›c document that appeared in the history, as analyzed in [49]. Thus, for the candidate documentğ·, we can use the long-term history to enhance its representationğ‘Ÿcalculated by the text encoder in the same way as the target intent, getting ğ‘Ÿ ğ‘Ÿ= Transformer([ğ», ğ‘Ÿ] + [ğ», ğ‘Ÿ] We will useğ‘Ÿtogether withğ‘Ÿto calculate the personalized ranking score for the candidate document in the uniî€›ed task framework that will be introduced in the next part. As for the personalized search and recommendation tasks in the information content domain, the main diî€erence between them is whether there is an issued query. In the problem deî€›nition, we claim to unify the two diî€erent tasks as a uniî€›ed problem by regarding the recommendation task as personalized search with an empty query. We represent the userâ€™s current intention asğ¼that is initialized with the issued queryğ‘„for search or the user embeddingEmbfor recommendation. The uniî€›ed problem is to rank the candidate documentğ·based on the personalized relevance that is calculated with the current intentionğ¼, the queryğ‘„(empty for recommendation) and the user historyğ». The personalized relevance is denoted as ğ‘(ğ·|ğ¼, ğ‘„, ğ» ). Through the text encoder, session encoder and history encoder, we get the representations of the userâ€™s current intention and candidate document, i.e.ğ¼,ğ¼,ğ‘Ÿandğ‘Ÿ. We calculate the relevance between each pair of them by cosine similaritysim(Â·, Â·). Moreover, for the personalized search task, the correlation between the candidate document and the query keywords is also critical. Thus, we additionally pay attention to the interactive features between the context-aware representations of the query and document, i.e.ğ¶ andğ¶. We exploit the interaction-based component KNRM [42] to calculate the interactive scoreinter(ğ¶, ğ¶). The detailed calculation process can be found in [42]. Besides, following [13,20], we also extract several relevance-based features ğ¹for personalized search. When calculating the relevance for articles in recommendation, the interaction score and features are all empty. Finally, the score for the candidate document is calculated by aggregating all these scores and features with an MLP layer, as: ğ‘“= [sim(ğ¼, ğ‘Ÿ), sim(ğ¼, ğ‘Ÿ), sim(ğ¼, ğ‘Ÿ), ğ‘(ğ·|ğ¼, ğ‘„, ğ» ) = Î¦(ğ‘“ Î¦()represents an MLP layer without an activation function. Whether for the search or recommendation task, we generate personalized document list by calculating relevance scores in this way. We adopt a pairwise manner to train our USER model. For both personalized search and recommendation tasks, we construct each training sample as a document group comprised of a positive document andğ¾negative documents presented in the same impression, represented as{ğ·, (ğ·, . . . , ğ·)}. For each document group, we aim to maximize the score of the positive document and minimize that of those negative documents. The lossLis computed as the negative log-likelihood of the positive sample. We have: L = âˆ’ log(exp(ğ‘(ğ·))Ã). (13) whereğ‘(Â·)is the abbreviation ofğ‘(Â·|ğ¼, ğ‘„, ğ» ). We minimize the loss with the Adam optimizer. In the uniî€›ed scenario, we have access to both search and recommendation data. Thus, we can train one USER model with data from the two tasks and apply the trained model to both of them. However, there may be a problem that some gaps exist between the data distributions of the search task and recommendation task. The only uniî€›ed model trained on the data from the two tasks is diî€œcult to achieve the best performance on both of them. Therefore, we propose an alternative training method. We î€›rst pre-train a uniî€›ed model with both task data. Then, we make a copy for each task and î€›netune it with the corresponding task data to î€›t the individual data distribution. In this case, the model not only beneî€›ts from more training data but also adapts to the speciî€›c task. DatasetThere is no public dataset with both search and recommendation logs of a shared set of users in the information content domain. To evaluate our uniî€›ed model, we construct a dataset comprised of usersâ€™ search and browsing behaviors from a popular information service platform that has both search and recommendation engines. We randomly sample 100,000 users. Then, we obtain their search logs in its search engine and browsed articles recommended by the recommendation system for three months. The whole log is preprocessed via data masking to protect user privacy. Each piece of search data includes an anonymous user ID, the action time, a query, top 20 returned documents, click tags and click dwelling time. As for each recommendation record, only a browsed article is kept, without other presented but unclicked documents. We generate pseudo unclicked documents for each browsed article for model training. We rank all documents in the recommendation log based on a weighted score of the popularity measured by the click count and the topic similarity with the browsed article calculated by cosine similarity. Nine negative documents ranked at the top are sampled for each browsed article. The original recommendation list is randomly shuî€Ÿed. All search and browsing behaviors of each user are merged into a sequence in chronological order. We separate a userâ€™s whole behavior sequence into sessions with 30 minutes of inactivity as the interval [13,20]. Usersâ€™ browsing behaviors are usually more frequent than search behaviors, which leads to an unbalance in the dataset. Since we intend to explore the relatedness between the search and browsing behaviors, we sample sessions containing both actions and three sessions before and after these sessions. To guarantee each user has enough history for building user proî€›le, we treat the log data of the î€›rst eight weeks as the historical set and the other î€›ve weeks log as the experimental data. The experimental data is used for training, validation and testing with 4:1:1 ratio. The statistics are shown in Table 1. MetricsReferring to existing works [37,39], the recommendation task is also to re-rank the candidate documents. For both tasks, we take the sat-clicked documents with more than 30 seconds of dwelling time as relevant and the others as irrelevant. We choose common ranking metrics to evaluate our model and baselines, including MAP, MRR, P@1, Avg.C (average position of the clicked documents), NDCG@5 and NDCG@10. For recommendation, we also adopt AUC to measure the click-through rate. The original search results are returned by the search engine. The original recommendation lists are randomly shuî€Ÿed. Besides, we compare our model with state-of-the-art personalized search models, news recommendation models and the joint framework [46]. HRNN[13]: A hierarchical RNN model with query-aware attention to dynamically mine relevant history information. RPMN[49]: This model captures complex re-î€›nding patterns of previous queries or documents with the memory network. PEPS[43]: Yao et al. claim that diî€erent users have diî€erent understandings of the same word due to their knowledge. They learn personal word embeddings to clarify the query keywords. HTPS[48]: It encodes the userâ€™s history as the context information to disambiguate the current query. We adapt it to the uniî€›ed scenario by adding the userâ€™s browsed articles into her history. NPA[37]: The model sets user embeddings to compute personalized word- and news-level attention. It highlights important words and articles to generate informative news and user representations. Table 2: Overall performance in various scenarios: personalized search with only search data, recommend with browsing data, uniî€›ed search & recommend with both data. The relative percentages are computed based on the original rankings. The best results in each scenario are shown with underlines. The overall best results are in bold. "â€ " indicates signiî€›cant improvements over all corresponding baselines, with paired t-test at p < 0.05 level. MRR is used for search and AUC for recommendation. Personalized+1.66%.6962+1.50%.5795 +0.50% 3.642 Search+1.71%.6979+1.75%.5811 +0.78% 3.626 Recommend+65.33%.7131+42.79%.2767+67.42%.7124+42.65%.2794 Uniî€›ed Search+3.49%.7074+3.13%.5892 & RecommendRecommendation Task NRMS[39]: This model utilizes multi-head self-attention to learn news and user representations by capturing the relatedness between words and browsed articles. By adding documents clicked in the search history, we adapt it into the uniî€›ed scenario. LSTUR[1]: It includes the short-term user interests modeled from the recent clicked articles with GRU and the long-term proî€›le corresponding to a trainable user embedding. GERL[14]: It applies transformer on the userâ€™s interaction graph to capture high-order associations between users and news. JSR[46]: This is a general joint framework that trains a separate search model and a recommendation model by optimizing a joint loss. We select HRNN for search and NRMS for recommendation. USER: This is the uniî€›ed model proposed in this paper.USER-S andUSER-Rare the variants used in independent search and recommendation scenarios respectively. They share the same structure as USER but have access to only the data of that single task. We conduct multiple sets of experiments to decide the model parameters as follows. The size of word embeddings, pretrained by word2vec on all logs, and user embeddings is 100. Due to usersâ€™ click decisions are usually made based on titles, we use titles in our experiment, instead of complete articles. For each query or document title, the max sequence length is 30. In the history sequence, we maintain up to 20 sessions and the maximum number of user behaviors in a session is 5. The number of heads in the transformer is 8 and the hidden dimension is 50. The numberğ¾of negative samples in each document group is 4. The learning rate is 1ğ‘’ âˆ’ 3. +170.9%3.489+36.48%.5306+79.74%.6037+32.89% +179.8%3.564+35.12%.5268+78.46%.6075+33.72% +182.5%3.584+34.75%.5263+78.29%.6128+34.89% +144.4%3.499+36.30%.5253+77.95%.5885+29.54% +185.6%3.381+38.45%.5386+82.45%.6204+36.56% +2.19% 3.479+10.75%.7001+4.18%.7422+3.83% +187.9%3.496+36.35%.5361+81.61%.6147+35.31% +179.6%3.386+38.36%.5432+84.01%.6143+35.22% +194.2%3.258+40.69%.5514+86.79%.6222+36.96% We compare all models in various scenarios: pure personalized search with only search data, pure recommendation with only recommendation data and uniî€›ed scenario with both data. The results are shown in Table 2. We have several î€›ndings: (1) The comparison of the same model trained with the independent task dataset and the uniî€›ed dataset.For HTPS, NRMS and USER, their performance on the uniî€›ed dataset is better than that on the indep endent task data.For example, the personalized search model HTPS trained on the uniî€›ed history promotes 0.6% in MAP based on that trained with pure search data. The recommendation model NRMS has 1.6% improvement in MAP with the uniî€›ed data. Consistently, our USER model in the uniî€›ed scenario also shows improvements over USER-S and USER-R on all metrics. Compared to the independent task data, the uniî€›ed dataset is comprised of both search and browsing behaviors, from which we analyze the userâ€™s preferences. The results demonstrate that a more precise user interest proî€›le can be constructed based on the integrated behavior sequence to improve ranking qualities. (2) The comparison of our USER model and the separate personalized search or recommendation baselines.The USER-S and USER-R variants achieve better results than the corresponding baselines on independent scenarios. Greater improvements are observed on the complete USER model in the uniî€›ed case with both data, with paired t-test at p<0.05 level.Specifically, on the pure personalized search, USER-S outperforms the Table 3: Performance of USER variants. The relative percentages are calculated based on the complete USER model. Variants w/o Session Encoder.6760 -1.24% .6934 -0.96% .7343 -1.06% .3963 -21.29% .4504 -18.32% .5393 -13.32% w/o History Encoder w/o Uniî€›ed Pre-train HTPS. In recommendation, USER-R promotes NRMS on all evaluation metrics. This proves that our history encoders can eî€ectively learn user interests to improve personalized rankings. Furthermore, the complete USER model promotes HTPS more greatly in the uniî€›ed scenario. We analyze it may because the USER model is pretrained by both search and recommendation tasks on the uniî€›ed dataset, which beneî€›ts from more training data. (3) The comparison of our uniî€›ed model USER and the general joint framework JSR.Compared to JSR, USER improves the corresponding separate variants (USER-S and USER-R) much better by training with the uniî€›ed data.The HRNN and NRMS combined in JSR show similar performance to the original HRNN and NRMS. However, the USER model achieves 1.14% improvements in MAP over the USER-S and 1.20% in MAP over the USER-R. JSR simply combines a personalized search model and a recommendation model through optimizing a joint loss, without exploiting any interactions between them. In the USER model, we integrate the two kinds of behaviors into a heterogeneous sequence and complete both tasks based on this sequence. The results suggest that USER provides a better approach to aggregate the two tasks and capture the associations between them to promote each other. To conclude,with the uniî€›ed data comprised of the userâ€™s search and browsing logs, a more comprehensive user proî€›le and more training samples can be obtained for personalization. Besides, the USER model is promising to capture the relatedness between the two tasks to promote each other. To analyze how the major modules in our model impact the eî€ects, we conduct several ablation studies. The variants are as follows. USER w/o Session Encoder: We discard the short-term history and the session encoder for clariî€›cation. USER w/o History Encoder: In this variant, we remove the long-term history and the history-level transformer. USER w/o Uniî€›ed Pre-train: We skip pre-training one uniî€›ed model with the training data from both tasks, but train two separate models from scratch, with integrated history sequences. USER w/o Uniî€›ed Data: With only separate task data not the uniî€›ed dataset, USER degrades to USER-S and USER-R respectively. From the results shown in Table 3, we can observe that: (1) Removing the session encoder or history encoder and the corresponding behavior history causes a decline in all evaluation metrics for both personalized search and recommendation tasks. This proves that both encoders mine information from the userâ€™s history to help personalization. The session encoder captures the Figure 4: Performance on diî€erent data subsets. (a), (c): the î€›rst search/recommend behavior of each user; (b), (d): sessions with both search & recommendation. userâ€™s consistent intention in the current session. The history encoder learns stable user interests in the long-term history. The two parts help clarify the userâ€™s current information need together. (2) There is a decrease in the ranking results when skipping the uniî€›ed pre-training, especially for the personalized search task. This conî€›rms the beneî€›ts of more training samples constructed from both task data in our uniî€›ed model. It has few impacts on the recommendation task. A possible reason is that the browsing behaviors in recommendation are usually far more frequent than search behaviors, thus the recommendation task has enough training samples. Discarding the uniî€›ed data leads to a greater decline in both tasks. On a separate task dataset, only one kind of user behavior is available whether in history or training. This decline demonstrates that the integrated behavior sequence is more informative. We further test our model and baselines on diî€erent subsets: the î€›rst search/recommend behavior of each user, and sessions with search & recommendation. The results are shown in Figure 4, using the improvement of MAP over the original ranking as the metric. First Search/Recommend Behavior.We claim that USER is promising to alleviate data sparsity by merging the userâ€™s search and recommendation logs. To verify this eî€ectiveness of USER, we sample each userâ€™s î€›rst search record and recommendation record in the testing data to construct a subset. In this subset, there is little search history for each piece of search data, and little browsing history for each recommendation record. It is a cold-start case for separate personalized search and recommendation tasks. From Figure 4 (a) and (c), we î€›nd that USER trained on the uniî€›ed dataset Figure 5: Illustration of the heterogeneous behavior sequence in a session and the attention weights of the current action over historical behaviors in diî€erent models. A darker area indicates a larger weight. outperforms the corresponding baselines with only separate search or recommendation data. In the uniî€›ed situation, for the userâ€™s î€›rst search behavior with little search history, the browsing history can be a supplement for mining the userâ€™s preferences. As for the î€›rst recommendation sample, the search history can also be used as auxiliary information. Thus, we think that combining the two tasks as well as the corresponding behaviors indeed eliminates the problem of user data sparsity and the cold-start challenge. Sessions with Search & Recommendation.In this paper, we intend to explore the relatedness between the userâ€™s search and browsing behaviors to promote the two tasks. Therefore, we sample a subset comprised of sessions with both behaviors. We select several independent baselines and JSR for comparison. From Figure 4 (b) and (d), we î€›nd that USER achieves the best on both tasks. The other joint model JSR that consists of HRNN and NRMS shows similar performance to the separate models. In USER model, we deduce the userâ€™s intent based on the integrated behavior sequence. Thus, the potential relatedness between the two kinds of behaviors can be captured to promote personalization, especially for these sessions with both behaviors. However, JSR trains two separate models through a joint loss, which might have diî€œculty learning the interactions between the two tasks. These results also suggest that USER copes with the uniî€›ed scenario better than JSR. In this paper, we focus on the situation with both search and recommendation services in the information content domain. We design a uniî€›ed model (USER) to jointly handle the two tasks. To illustrate the advantages of our model more intuitively, we conduct a case study to analyze the userâ€™s mixed behaviors within a session. Moreover, we discuss the impacts of the userâ€™s historical behaviors on the current action in USER, HTPS and NRMS. The impacts are indicated by the attention weights. The results are in Figure 5. Observing the userâ€™s behaviors in the session, we î€›nd the userâ€™s preferences reî€ected by the search behaviors and browsing behaviors are consistent, probably about sushi, small muscle î€›sh and Japanese jack mackerel. Besides, there is some relatedness between the two kinds of behaviors. For example, the user browses the article titled â€œThe story of Japanese jack mackerelâ€ in recommendation, followed by a query â€œJapanese jack mackerelâ€ to seek more relevant information. Thus, integrating the two tasks together has the potential to promote each other. With the aggregated behaviors, we can mine more precise information about the userâ€™s interests to help the current ranking. Let us take the last search query â€œJapanese jack mackerelâ€ as an example. Obviously, this query is strongly relevant to both the historical query â€œJapanese jack mackerelâ€ and the browsed article â€œThe story of Japanese jack mackerelâ€. USER pays high attention to both the two strongly relevant behaviors. However, HTPS, which is proposed for the independent search case, can only attend to the historical queries, without any information about the browsing actions. With regard to the last recommendation, the historical query â€œsmall muscle î€›shâ€ also reî€ects relevant user interests, which will be highlighted in USER.This case study fully proves the value of aggregating the two separate tasks together and our proposal of the uniî€›ed model. In this paper, we focus on the connections between the personalized search and recommendation in the information content domain, and explore an eî€ective approach to jointly model them together. We integrate the userâ€™s search and browsing behaviors into a heterogeneous behavior sequence. Then, we propose the uniî€›ed model USER. It includes encoders to mine information from the heterogeneous behavior sequence for personalization and a uniî€›ed task framework to solve both tasks in a uniî€›ed ranking style. We experiment with a dataset comprised of both behaviors constructed from a real-world commercial platform. The results conî€›rm that our model outperforms the state-of-the-art separate baselines on both tasks. In the future, we will combine the two tasks better. Zhicheng Dou is the corresponding author. This work was supported by National Natural Science Foundation of China No. 61872370 and No. 61832017, Beijing Outstanding Young Scientist Program NO. BJJWZYJH012019100020098, Shandong Provincial Natural Science Foundation under Grant ZR2019ZD06, and Intelligent Social Governance Platform, Major Innovation & Planning Interdisciplinary Platform for the â€œDouble-First Classâ€ Initiative, Renmin University of China. I also wish to acknowledge the support provided and contribution made by Public Policy and Decision-making Research Lab of Renmin University of China.
Department of Computer ScienceDepartment of Computer Science Department of Statistics and AppliedDepartment of Computer Science mengyang@pstat.ucsb.edu The Internet has become indispensable to daily activities, such as work, education and health care. Many of these activities require Internet access data rates t hat support real-time video conferencing. However, digital inequality persists across the United States, not only in who has access but in the quality of that access. Spee dtest by Ookla allows users to run network diagnostic tests to bett er understand the current perfor mance of their network. In this work, we leverage an Internet performance dataset from Ookla, together with an ESRI demographic dataset, to conduct a comprehensive analysis t hat characterizes performance diï¬€erences between Speedtest users across the U.S. Our analysis shows that median download speeds for Speedtest users can diï¬€er by over 150 Mbps between states. Further, there are important distinctions between user categories. For instance, all bu t one state showed statistically signiï¬cant diï¬€erences in performance between Sp eedtest users in urban and rural areas. The diï¬€erence also exists in urban areas between high and low income users in 27 states. Our analysis reveals that states that d emonstrate this disparity in Speedtest results are geographically bigger, more populous and have a wider dispersion of median household income. We conclude by highlighting several challenges to the complex p roblem space of digital inequality c haracterization and provide recommendations fo r furthering research on this topic. The terms â€œInternet inequityâ€ or â€œdigital inequality" refer to the gap in Internet access, access quality, and aï¬€ordability that exists within and between geographic areas and communities or individuals of varying demographic attributes [6]. While the problem of Internet inequity in the U.S. has long existed [41], the Covid19 p andemic has intensiï¬ed its impact [7 ]. The lack of high quality, aï¬€ordable Internet access severely impacts the out comes of remote education, work from home, and telehealth, among others [9, 11, 12, 14â€“17]. Addressing this problem is critical; however, it is important to ï¬rst more deeply understand the challenges so that the right solutions can be applied to those communities most in need. A full characterization of Internet inequity requires combining Internet access and quality data, at ï¬ne-grained geographic resolution, with demographic datasets. Ideally, t his data should be available at the granularity of census blocks (smallest demographic unit), or even smaller. While the Federal Communications Commission (FCC) and U.S. Census Bureau release related information at this granularity, the quality of this publicly available information is low. Through Form 477 [26], the FCC documents Internet coverage and theoretical maximum download speed from diï¬€erent Internet service providers at the granularity of census blocks. However, this dataset is known to inaccurately report and overstate Internet coverage, particularly in rural areas [27, 57]. More importantly, this dataset does not report the actu al Internet performance experienced by the end users. This information is cr itical to characterize the regional quality of the Internet service. Recently, Ookla [35] released an aggregated Internet performance dataset of Speedtest by Ookla measurements through the Open Data Initiative. This dat aset overcomes a major l imitation of Form 477 because it measures the Internet performance experienced by the end users at much ï¬ner spatial granularity. Additionally, Speedtest by Ookla is a po pular Internet quality assessment solution, thereby facilitating a more ï¬ne-grained characterizatio n of Internet inequity amongst its users in the U.S. While the scope of this dataset is limited to people who opt to take a Speedtest, it remains one of the largest end-user Internet performance measurement datasets, w ith high spatial ï¬delity, that is openly available to the public. In this work, we combine this Ookla dataset with geographic information from the U.S. Census Bureau and demographic information provided by the Economic and Social Research Institute (ESRI) [39] to explore multiple dimensions of Internet inequity in the U.S. amongst Speedtest takers. Our analysis shows the me dian download speed between two states in the U.S. could diï¬€er by as much as 150 Mbps. We employ statistical techniques to quantify the extent of digital inequality between populations of diï¬€erent geographic loc ations (urban/rural) and income demographic variables (high/low income) within a state. Prior studies [2, 4, 21] undertook similar analysis using user survey data collec ted at the coarser geographic levels of census tract and county. Our analysis, however is conducted at the ï¬ner geographic granularity of census block group using actual network performance data. Conï¬rming ï¬ndings of [2, 4], our analysis shows that, for more than 45 states, the quality of Internet for Speedtest users in ru ral areas lags behind that of urban areas. Further, we observe and quantify this divide in access quality between populations of urban areas; our analysis reveals a statistically signiï¬cant diï¬€erence in Internet quality between low income and high income block groups in 27 states. States that exhibit this divide between the urban Speedtest user groups tend to be bigger, with greater population and higher dispersion of household income compared to other states. Our ï¬ndings demonstrate and quantify inequality of Internet access for Speedtest users and highlight the need for thorough analysis of Internet performance experienced by diï¬€erent communities. In summary, our contributions are as follows: â€¢ We aggregate and analyze an 18-month Internet performance dataset from Ookla Speedtest users from the 50 U.S. states, ESRI demographic data, and U.S. Census data to identify and quantify key Internet performance inequities between user groups in the U.S. based on geographic region and income. â€¢ Using stat istical techniques, we identify over 45 states where rural users receive statisticall y worse Internet performance than urban users over the 18-month period. â€¢ We further make novel observation and detect performance inequity between high income and l ow income urban Speedtest users in 27 stat es. â€¢ Through our analysis, we identify potential sources of bias in crowdsourced internet p erformance datasets such as Spe edtest data. Based on these ï¬ndings, we conclude with speciï¬c recommendations for furthering research o n Internet access inequality. In this section, we describe the publicly available datasets that we use for our analysis. Our analysis is based on data available throughout 2020 and the ï¬rst half of 2021. This d ata is aggregated at the time-granularity of quarters by Ookla, as described below. The quality of user experience for web-based activities is dictated by available upload and download speed and latency to the remote server. For example, the user experience for video streaming applications depends mostly on available download speed , video conferencing applications depends on both the upload and download speeds, and web browsing depends mostly on latency. T he Ookla Speedtest allows users to assess the quality of their Internet connection using either the web-based portal or native mob ile application [35]. Ookla relies on volunteer users to co nduct a speed test that measures Internet download and uplo ad speed and latency at the current connection point. For each request, Ooklaâ€™s controller uses the clientâ€™s location to select a set of measurement servers that are geographically closest to the client. It then chooses the one with minimum round-trip time (RTT) as an endpo int for the test. Ookla dynamically scales each measurement with multiple parall el connections to satu rate the bottleneck link. To ensure high quality and ï¬delity dat a is obtained, Ookla operates a network of tens of thousands of measurement servers, and periodically eliminates servers that perform poorl y [37]. The results of a single test oï¬€er an instantaneous snapshot of Internet performance at the current location, to the current point of attachment, and subject to the current competing traï¬ƒc on the path to the selected server. Together, the aggregation of many of these measurements can paint a picture of connectivity within a given geographic area that is broadly diverse both in time, exact physical location, and network traï¬ƒc load. While access quality can change greatly within a small spatial area based on subscribed plan, residential vs. business connectivity, etc., measurement aggregation can still oï¬€er broad insight into general performance trends for a region, as we will demonstrate through our analysis. Through the Open Data Initiative, Ookla has released an aggregated version of the data it collects to the public every quarter, beginning in January 2019 [10]. In this dataset, geographic areas are grouped into quad tiles [36]. The size of these quad tiles depends on their geographic location. For example, quad tiles measure approximately 600 by 600 sq. meters at the equator, and roughly 500 by 500 sq. meters in Los Angeles. The dataset reports the average of all measurement values for each quarter of the year for each tile. Ookla divides the data into two groups, each with measurements from users connected to the Internet via a (1) ï¬xed broadband network (e.g., Cox, Xï¬nity, etc.); and (2) mobile network (e.g., T-Mobile, US Cellular, etc.). Ookla only includes the measurements from mobile devices with in-built GPS. This ï¬lter ensures higher accuracy in mapping Speedtest measurements to geographic locations (or tiles). Given our focus on the U.S., we ï¬lter the t il es from Ooklaâ€™s dataset to include only those that are completely within the geographic boundary of the U.S. The total number of tiles with measurements of ï¬xed networks are 1.70 million (M), 1.74 M, 1.72 M and 1.51 M in each of the respective four quart ers of 20 20. In the ï¬rst and second quart er of 2021, approximately 1.53 M tiles are present in the dataset. The number of tiles in the mobile network group was approximately 600 k in each quarter of 2020 and 2021. The number of measurements from each tile depends on multiple factors, such as population density, popularity of the spee d test application, etc. Because the number of tiles for the mobile network group is very small, we focus our analysis on the ï¬xed broadband network. Critique. The potential shortcomings of crowdsourced Internet measurements using tools such as Ooklaâ€™s Speedtest are st udied in the literature [48, 51]. Essentially, these crowdsourced measurements may introduce bias in terms of locations where the tests originate and network conditions under w hich they are conducted. However, in the absence of true underlying distributions, the eï¬€ect and magnitude of this bias is diï¬ƒcult to quantify. While Ookla does not have any research data on the speciï¬c demographic attributes of their user population, they do have general information about Speedtest usage. According to their data, people tend to use Speedtest in a variety of circumstances, including when they are having Internet issues, immediately after sett ing up a new device, and when they arrive at a new location (i.e. hotel, public space, or even other side of the house). Wit h the shift to education and work-from-home due to the Covid-19 pandemic, an increased number of users tested home Internet connections, to discern both the number and types of applications that could be concurrently sup ported, as well as the locations in the house that oï¬€ered the best connectivity. Hence, while it is impossible to say that Ookla data does not have bias t owards certain types of events or points of attachment, the aggregated data, grouped over both space and time, oï¬€ers a broad swath of usage scenarios. Our goal is to study the network performance, as represented by Ookla Speedtest results, during those scenarios, and to attempt to correlate performance with demographic data to the extent possible. Because of potential bias, we cannot d eï¬nitively characterize Internet connectivity in a given quad tile; however, we hope that our work is a step forward in t hat directio n and can point to where additional data and analysis is needed. To st udy the relationship between Internet performance, geographic region, and u ser demographic attributes, we leverage the demography data provided by ESRIâ€™s Updated Demographics [39]. ESRI curates this dataset using multiple sources that provide currentyear estimates and 5-year projections of a variety of demographic attributes. This dataset is a critical combination of the most recent demography data available that is also highly accurate [3]. Most demographic information is aggregated and released at the granularity o f census bl ock groups [8]. For our analysis, we choose the demographic attribute of median household income; prior work [9, 16] has shown income to play an important role in Internet access availability to diï¬€erent user groups. Using the ESRI dataset [24], we obtain the median household income at the granularity of the census block group in the U.S. At this granularity, the ESRI dataset is comprehensive and covers 98.6% (214K out of 217K) of all block groups in the U.S. In addition to median household income, we also obtain the popu lation of each census block group in the U.S. using [24]. To the median household income data, we also include the type of geographic area (urban/rural); again, prior studies have shown that the region type has an impact on Internet access availability and quality [57]. In contrast to median household income, the distinction between rural and ur ban area types are made at the level of census blocks. On average, there are 39 blocks present in a census block group [19]. We utilize data from the 2010 U.S. Census [1] to ï¬rst obtain each census blockâ€™s designation. Subsequently, we aggregate all census blocks wit hin a census block group to classify the area type of the census block group based of the area type of a simple majority of the blocks within that group. Our aggregation allocates 22.7% of the total U.S. popul ation o f 330M to rural block groups. This percentage of rural population is consistent with the number reported by the Census [33, 34]. To understand the eï¬€ect of diï¬€erent location types and demographic attributes on Internet performance, we ï¬rst need to assign each tile in the Ookla dataset into the much larger areas of census block Figure 2: CDF of Ookla Speedtests across states in the U.S. in Q2-2021. groups b ecause demographic information is only available at the granularity o f block group. Because the Ookla data provides the geographic coordinates of each tile, we are able to all ocate tiles to the po lygon boundaries of the census bl ock groups. Post allocation, analysis shows these tiles are present in roughly 94% of all c ensus block groups in the U.S. in each quarter of 2020 and the ï¬r st two quarters of 2021. To determine the Internet performance of a particular block group, we take the average of each network metric for all the til es that belong to that block group, and we weight by the number of tests that originated from each tile. With this level of aggregation, we are able to quantify the Internet performance of census blo c k groups within a state, placing higher weights to tiles that have more number of tests. Prior work [52, 56] has demonstrated t hat , due to the Covid-19 pandemic, Internet traï¬ƒc patterns changed signiï¬cantly through 2020; traï¬ƒc volume increased, and signiï¬cant capacity upgrades were made by service providers to meet the rising demand. This change in Internet traï¬ƒc dynamics is also captured in our high level analysis of our aggregate d dat aset. Table 1 presents the median download speed, upload speed and latency (along with the inter-quartile range (IQR)) recorded across all the tiles within the bo undary of the U.S. over the six quarters. Both the median download speed and upload speed increase during our studied time period. The recorded med ian latency also improves, decreaseing from 18ms from the ï¬rst three quarters of 2020 and remaining at 16 ms from Q4-2020 to Q2-2021. Figure 1 shows the d istribution of download speed in every state in the U.S. in Q2-2021. New Jersey, Delaware, Maryland, Rhode Island and Massachusetts recorded t he best median download speeds during Q2-2021. During the same quarter, Wyoming emerged as with the lowest download speed along with Arkansas, Montana, Idaho and New Mexico. The median diï¬€erence in download speed is 149.40 Mbps between New Jersey and Wyoming during Q2-2021. Upload (Mbps) Latency (ms) The median download speed of New Jersey and Delaware remained within the top ï¬ve during Q1-2021 and all of 2020. Wyoming and New Mexico, on the other hand, recorded the lowest median download speed our studied time period. New Jersey, Delaware, Rhode Island and Maryland also had the highest median upload speeds during Q2-2021 , w hile New Mexico and Wyoming continued to have the lowest. The best and worst performing states by median upl oad speed diï¬€ered by 27.63Mbps in Q2-2021 . As observed in the case of download spe ed, the best and worst performing states remained consistent dur ing other the quarters of 2020 and 2021. Similar trends were observed for latency. Another critical diï¬€erence in state-by-state data is the number of tests that originate from each st ate as shown in Figure 2. There were 2 .8M Ookla Speedtests conduct ed in California in Q2-2021, and 1 .9M and 1. 6M tests conducted in Texas and Florida, respectively, representing the greatest number of tests by volume in the nation. Once the number of tests are normalized by the population of the respective states, there are 0.07 tests conducted per person (pp) from each of these st ates. These same three states also recorded the greatest number of tests during 2020 and Q1-2021. North Dakota had the fewest tests (25K or 0.03 pp) followed by South Dakota (26K or 0.03 pp) and Alaska (34K or 0.04 pp) in Q22021. These states also produced the fewest tests in the other quarters analysed in this work. To understand the relationship between Internet performance, region type, and median income within a state, we need to compare the Internet performance received by diï¬€erent user groups in the Speedtest dataset. Ideally, controlled experiments would be conducted to explore this relationship. However, as pointed out in [45], Speedtest users are not r andomly selected, thereby rendering controlled experiments infeasible in this scenario. To overcome this limitation, similar to the methodology followed in the diverse ï¬elds of epidemiology, sociology and economics, we util iz e natural experiments to conduct our analysis. By employing natural ex periments, we are able to pair two user groups who both conducted Speedtests while diï¬€ering in terms of the location or median household income. This pairing imitates randomness and allows us the oppo rtunity to explore the relationship between these factors and Internet performance of Speedtest user groups [32, 45] . For every factor we consider in our natural experiments, we set a null hypothesis, ğ», pose a hypothesis (ğ») and compare the average Internet perfor mance of two diï¬€erent types of block groups in a state. These block groups can diï¬€er in terms of location type (urban/rural) or me dian household income (high/low income). This approach allows us identify Internet inequity in the dimensions of location and income within every U.S. st ate. Table 2 presents the ğ»and ğ» for the factors of location and income. Locationban and ru ral Inter-mance is better than ru- Table 2: Null and alternative hypotheses in natural exp eriments for detecting statistically signiï¬cant diï¬€erence in performance between u s er groups. To compare and detect a statistically signiï¬cant diï¬€erence in Internet performance between Speedtest user groups, we employ two methodologies: i) one-tailed Komolgorov-Smirnov (K-S) 2 sample test [29] and ii) one-sided Mannâ€“Whitney U (M-W U) test [30]. We employ these two separate tests to reduce the number of false positives in detecting statistically signiï¬cant diï¬€erences in performance between two user groups. These tests are non-parametric and, therefore, can be used for non-normal distributions. The KS test captures the diï¬€erence between two samples by evaluating the maximum distance between the two distributions for a conï¬dence interval, ğ›¼. However, the K-S test is less sensitive to the difference in median between two distributions. T he M-W U test, on the other hand, detects the discrepancy between the mean ranks of the two groups being compared and hence is mo re capable of detecting a change in median values between the groups. To further ascertain statistical signiï¬cance and reduce Type-I errors [38] while employing these two tests, we employ the Bonferroni correction technique [18] for multiple testing. For the K-S test, we only consider two distributions to be statistically diï¬€erent when the ğ‘âˆ’ğ‘£ğ‘ğ‘™ğ‘¢ğ‘’ is below 0.05, and the test st atistic (also known as ğ· âˆ’ğ‘ ğ‘¡ğ‘ğ‘¡ğ‘–ğ‘ ğ‘¡ğ‘–ğ‘) is greater than the corrected threshold value for each experiment. Similarly, in the case of the M-W U test, we consider a test statistic signiï¬cant if the ğ‘ âˆ’ ğ‘£ğ‘ğ‘™ğ‘¢ğ‘’ is below 0.05. For each test we conduct between two distributions, we analyze whether there is a presence of strict/strong or weak conformance to our expected hypothesis. We co nsider two distributions to be strictly diï¬€erent if one distribution remains statistically diï¬€erent from the other over the entire distribution. Suppose a distribution leads another for some part while lagging otherwise, both with statistical signiï¬cance. In that case, we consider such a crossover case to be weak. The one-tailed nature of the two tests allows for the evaluation of ğ‘¡ğ‘’ğ‘ ğ‘¡ âˆ’ğ‘ ğ‘¡ğ‘ğ‘¡ğ‘–ğ‘ ğ‘¡ğ‘–ğ‘ (ğ· in the case of K-S test) and ğ‘ âˆ’ğ‘£ğ‘ğ‘™ğ‘¢ğ‘’ (ğ‘ for bo th the K-S test and M-W U test) for both our hypothesis and the null hypothesis. By so doing, we are able to quantify the extent to which we failed to reject the null hypothesis and accept our hypothesis for each test we conduct . Suppose there is no statistical diï¬€erence between the distributions of Internet performance of t wo diï¬€erent groups in a state. In that case, we conclude that the association between region type or Figure 3: Q1-2020 CDFs of download speeds, disaggregated by ru r al and urban block groups, in four example states. demographic at tribute and Internet performance metric is not statistically signiï¬cant in that state. We employ these two tests across all the states in the country. In this sectio n, we analyze how Internet performance varies between diï¬€erent population groups of Speedtest users within U.S. states using the methodology described in Section 3. We present our ï¬ndings and highlight spe ciï¬c states where this perfor mance diï¬€erence is detected across location type (Section 4.1) and median household income (Section 4.2). We ï¬rst employ our methodology to show the impact of location type on Internet perfor mance. Using the datasets described in Section 2 and l ocation hypotheses stated in Table 2, we quantify the diï¬€erence in p erformance between urban and rural block groups within every U.S. state. We evaluate the block group level distribu tions o f the network metrics for urban and rural areas across all states. For the K-S test, we compare the distribution for each state per network metric and either accept or reject ğ»based on the ğ· and ğ‘ values obtained from each comparison. Similarly, for the M-W U test, we accept or reject ğ»based on the resulting ğ‘ value obtained by conduct ing the one-sided test. We conduct this analysis on every quarter to understand the change in performance over the course of 2020 and the ï¬rst two quar ters of 2021. We begin our analysis with Q1-2020. For bo th tests we obser ve a statistically signiï¬cant diï¬€erence (strict) in distributions of urban and rural block group download speeds in favor of o ur hypothesis, ğ» , in 47 states in the country. The states that did not show a diï¬€erence were Rhode Island, Delaware, and Connecticut . Figures 3(a) and (b) present two examples of states (Gerogia (GA) and Louisiana (LA)) where the rural block groups recorded statistically poorer performance than their urban counterparts across the studied time period (CDFs of Q1-2020 are shown as examples). In the case of Rhode Island (RI) and Delaware (DE), as illustrated in Figures 3(c) and (d), the performance in the urban block groups was not statistically better than that of rur al block groups (for RI in Q1 and DE in both Q1 and Q4). Subsequent analysis of the remaining quarters using both tests revealed 48, 49 and 49 states conforming to our hypothesis in Q2, Q3 and Q4 of 2020, respectively. The number of conforming states remained 49 for the ï¬rst two quarters of 2021. We repeat the analysis to detect statistically signiï¬cant diï¬€erences in upload speeds between rural and urban block groups. Results show the urban block groups within 47 stat es outperform their rural counterparts in Q1-2020. Similar to the case of download speed, RI did not show any diï¬€erence in upload speed between these two groups. However, unlike in the case of download speed, New Hampshire and North Dakota rural block groups outperformed urb an block groups. Q3-2020 recorded 49 conforming states. Q2 and Q4 of 2020, as well Q1- and Q2-2021, recorded 47 states that strictly conformed with our hypothesis. When analyzing latency, 47 and 46 states conformed to our hypothesis in Q1and Q2-2020, with the number reducing to 45 in both Q3- and Q42020. The number of conforming states increased to 46 and 47 for Q1- and Q2-2021, respect ively. We next evaluate our location hypothesis on the number of Ookla Speedtests per person that originate from the two types of block groups. We set ğ»as the number of Speedtests per person originating from rural block groups is not less than the number of Speedtests per person conducted in urban block groups. We po se the hypothesis (ğ» ) that the number of Ookla Speedtests that are conducted per person in urban block groups will be greater than that originating from rur al block groups. About 20 states conformed to this hypothesis in each quarter of 2020 and 2021. The remaining 30 states did not demonstrat e any statistically discernible diï¬€erence in the normalized Speedtest counts between these two location types. Takeaways. Our analysis of Internet performance for Speedtest users shows a clear divide between rural and urban regions in nearly every state in the country. In total, 49 diï¬€erent states conformed with our hypothesis and demonstrated a stat istically signiï¬cant diï¬€erence (in favor of urban areas) in perfor mance in at least one of the six quarters we analyzed. Rhode Island, the smallest state in the U.S. by land mass [42], remained the sole exception, where a st atistically signiï¬cant diï¬€erence in performance was not found in any quarter. Its smaller size could translate into ease in establishing network infrastructu re throughout the state, as oppose d to bigger states with larger, and in part more diï¬ƒcult, terrains. Further, while overall performance improved during the studied time perio d, the rural block groups continued to fare worse than the urban block groups in a vast majority of the states. However, the average K-S t est ğ· âˆ’ğ‘ ğ‘¡ğ‘ğ‘¡ğ‘–ğ‘ ğ‘¡ğ‘–ğ‘ value between urban and rural block groups across all the states reduced from 0.45 in Q1-2020 to 0.40 in Q2-2021 , representing a small narrowing of the divide between these location types. Finally, and surprisingly, our results indicate that, once normalized by the total population, the majority of states do not exhibit a bias towards the urban areas in the number of t ests per person. We next explore the relationship between an important demographic variable, median household income, and Internet access quality. Prior work [5] indicates that rural areas tend to have higher poverty and l ower median household income. Given the presence of this relationship between locatio n type and income, we analyse the impact of median household income on Internet quality in u rban census block groups. To do so, we divide the urban block groups within every state into two categories. Based on the median block group level hou sehold income obtained from the ESRI dataset, we calculate the average state household income for every state in our dataset. With this average state income, we classify the block groups w hose median income lay below the st ate income as â€œLow Income" block groups and those with income greater than or equal to the state income as â€œHigh Incomeâ€ block groups. Our null hypothesis ğ»and alternative hypothesis ğ» for income are presented in Table 2. Similar to our location related analysis, we begin our exploration on the Ookla data from Q1-2020 . Table 3 presents the number of states where a statistically signiï¬cant diï¬€erence in download speed was detected by the K-S test and M -W U test between high income and low income census blo ck groups. Figures 4(a) and (b) present examples of states, Ge orgia and Louisiana, that strictl y conform with ou r hyp othesis in both tests across all quarters. Arkansas, Alabama, and New Mexico are examples of other states that demonstrated similar trends. The M-W U test detected an additional nine states with statistically signiï¬cant diï¬€erences in download speed compared to the K-S test. Texas, Alaska and California were amongst the nine st ates that only weakly passed the K-S test; i.e., for some download speed range, the low income neighborhoods outperform the high income neighborhoods. Examples of states where the higher income block groups recorded statistically worse download speed compared to the lower income block groups in bot h tests are RI and New Jersey (NJ) as observed from Figures 4(c) and (d). This observation is captured through the ğ· value of 0.14 (0.15 in RI) with the ğ‘ value of 1.04 Ã— 10(1.84 Ã— 10in RI) in favor of ğ»while using K-S test. Other states that exhibit a similar pattern include Delaware and Massachusetts. In the next two of quarters of 2020, the number of st ates that conformed with our hypothesis remained fairly similar to Q1-2020. Q4-2020 (as well as ï¬rst two quarters of 2021) witnessed a rise in the number of conforming states for both tests. Across these six quarters, 14 states co nformed to our hypothesis in every quarter for K-S test. This number increases to 27 states for the case of MW U test. This indicates the presence of a large number of states where the median d ownload speed of high income block groups remained statistically better than the low income block groups over the course of 18 months. We now turn to upload speed, in which the number of states where higher income block groups achieve better performance than lower income block groups is 31 (K-S test) and 35 (M-W U test) in Q1- and Q2-2020. Examples of st ates where our hypothesis is strictly held include Louisiana, Arkansas and Virginia. While there are a number of states where the low income block groups do not exhibit statistically worse uplo ad speed than the high income block groups, the converse does not hold for any state. A similar trend is observed during the rest of 2020 and ï¬rst two quarters of 2021. In the case of latency, the number of conforming states remained fairly similar for the K-S test. The M-W U test, however, had more conforming states than to the K-S test except for Q2-2021. Finally, we investigate whether there exists a statistical diï¬€erence in the number of Ookla Speedtests conducted in l ow and high income bl ock groups. The ğ»is the number of Speedtests (pp) in low income block groups is not less than that of high income block groups in a given state. We then pose ğ» as the number of Speedtests(pp)in a high income block group is greater than the number of tests that originate from the low income block groups. Results show a lar ge number of states reject the null hypo thesis across all quarters (45, 48, 48, 46, 45, and 47 states in Q1-Q4 of 2020 and Q1-Q2 of 2021, respectively). This indicates that users from high income block groups tend to conduct a greater number of Speedtest measurements compared to t he low income block groups. Takeaways. Our analysis of the relationship between income and Internet performance produces some key results. First, there exists multiple states, such as Georgia and Louisiana, where we detect statistically better Internet performance in favor of Speedtest users from high income block groups. This points towards a likely gap in Internet access quality between these two types of income areas in these states. In a parallel work, we have analyzed the pricing structure for Internet services oï¬€ered by the major Internet service providers around the country. Our preliminary results show that cost of Internet access remains largely invariant of locatio n and income across the country. As a result, the higher tiers of Internet service likely remain ou t o f reach for l ower income populations. On the other hand, states such as New Jersey and Rhode Island do not reveal a relationship between income and Internet quality during our study period. This likely indicates the pervasiveness o f quality Internet access across these states. Finally, our analysis on the number of Speedtests demonstrates one source of bias that exists in crowdsourced active measurement platforms where the Internet performance of lower income users may be under-represented. As discovered in Section 4, a gap in Internet quality is present for users of Speedtest across many states in the d imensions of location and income. Both the K-S and M-W U tests revealed that a vast majority of states d emonstrat e this divide across urban and rural locations. H owever, in terms of income, 23 states did not reveal the presence of digital inequality in any of the six quarters analysed. In this se c tion, we spe c iï¬cally examine t he characteristics of the states that conformed with our income hypothesis to determine whether and how they diï¬€er from those of the non-conforming states. Figure 5(a) shows the distribution of the geographic area of the conforming and non-conforming states. The largest conforming Figure 4: Q1-2020 CDFs of download speeds, disaggregated by low and high income block groups, in four example states. state is Alaska, with an area of roughly 700K square miles (mi). Other l arger conforming states include Texas and California. On the other hand, the largest non-conforming stat e (states that failed to conform in any of the six quarters) is Montana, with an area of 150K mi. Excluding Alaska, Texas and California, the average size of a conforming state is 60 K mi; when including these three large states, the average size jumps to 9 3K mi. In both cases, this is larger than the average size of all non-conforming states (46K mi). Smaller state size could potentially ease the challenge and cost of network infrastructure deployment, and subsequently make it easier to provide higher Internet quality to all populations within a state. The population distributions of conforming and non-conforming states are demonstrated in Figure 5(b). California, wit h a population of 40M, is the most populous conforming state. In the nonconforming category, Ohio possesses the largest pop ulation of 12M. On average, non-conforming states show much lower populat io ns (3.2M ) compared to conforming states (8.2M). The greater populations of the conforming states, coupled with greater geographic size, could cause challenges in network infrastructure deployment, resulting in disparities in physical equipment lo cation and sub sequent inequality of access across diï¬€erent population groups. To represent the income inequality w ithin a given state, we compute the ratio of the 9 0percentile (P90) and 10percentile (P10) block group level median household income of each state. A higher ğ‘ƒ90/ğ‘ƒ10 ratio indicates a higher dispersion of income within the state. As can seen from Figure 5(c), conforming states tend to have higher ratio compared to non-conforming states. This is further illustrated by the higher average ratio of 3 .4 for conforming states compared to 3 for the non-conforming states. States with higher income dispersion could potentially have a gap in purchasing power that can impact a low income subscriberâ€™s ability to purchase higher cost su bscription plans, which are typically associated with better Internet quality (download and upload speeds). In this section, we discuss the signiï¬cant challenges asso ciated with research in the general space of digital inequality. Base d on the experience of aggregating the presented data, we also provide recommendations that we hope could lead to additional research in assessing and bridging digital inequity. 6.1.1 Lack of Granular Internet Measurement Data. Many publicly available Internet measurement datasets, such as the FCCâ€™s Measuring Broadband America (MBA) project [31], lack both expansive and ï¬ne-grained geographic coverage. This is in part because of the diï¬ƒculty in collecting access measurement data with strong spatial and temporal ï¬delity due to challenges of privacy-preserving data collection from user homes. This lack o f ï¬ne-grained, spatiallydiverse Internet measurement data across varied demographic variables presents signiï¬cant challenges to detailed analysis of Internet quality and aï¬€ordability [47]. The magnitude of this challenge is highlighted by the recent FCC initiative [28]. Through this initiative, the FCC has asked researchers and stakeholders to propose methodologies and techniques to gather high-ï¬delity, ï¬ne-grained data to create more comprehensive and accurate maps of Internet availability and quality. 6.1.2 Lack of Understanding User Context. A dataset such as the one from Ookla provides information on network quality of service from diï¬€erent vantage points. However, the metrics collected during these tests do not shed light on critical user related information such as the sub scr ibed tier of service and the actual quality of experience for diï¬€erent application genres. Witho ut knowing the ISP and tier of subscription, it is diï¬ƒcult to understand the fundamental reasons behind poor quality of service. Similarly, without information abo ut user quality of experience, it is diï¬ƒcult to determine the usability of diï¬€erent ap plications. Collection of this data in a secure and privacy preserving manner remains an open research problem. 6.1.3 Lack of Broadband Pricing Data. Through the FCCâ€™s Urban Rate Survey [40], aggregated information related to the price and Figure 5: Characteristic distributions for states with an Internet quality gap between high and low income populations. speed oï¬€ered by ISPs is reported at the granularity of county, not individual homes. The U.S. broadband industry suï¬€ers from a severe shortage of publicly available datasets that contain information about Internet access plan speeds and pr icing. Practices employed by ISPs are d iï¬ƒcult to st udy and analyse in the absence of such information. We hope that our work draws further attention to this research space so that issues related to broadband availability and cost, that in turn ad versely aï¬€ect the penetration of high speed Internet connectivity, can b e more deeply studied. 6.2.1 Publicly Available Data. Given the complex nature of digital inequality, the integration of diï¬€erent data types is needed to better characterize and ameliorate its manifestations. However, the overhead associated with some data collection eï¬€orts can be signiï¬cant. For instance, the FCCâ€™s Measuring Broadband A merica (MBA) project [31] requires measurement-capable routers to be shipped to volunteers. Hence it may make sense of incentivize or mandate ISPs to periodically report access quality measurements to/from their subscribers. Placement of such measurement datasets in the public sphere would signiï¬cantly aid research that characterizes and pinpoints the speciï¬c locations of digital inequities, particularly across diverse user groups. 6.2.2 Examination of ISP Practices. While our work did not study the Internet service pricing structure and its impact on diï¬€erent popu lation groups, prio r work [59] has indicated the presence of certain ISP monopolies across diï¬€erent areas of the U.S. Due to the market monopoly, ISPs could potentially exert Internet pricing that leaves certain customer groups paying for more than what they would otherw ise in a market with multiple competing ISPs. These ï¬ndings point towards a need to conduct an in-depth and extensive examination of ISP competition across states. Careful analysis is also needed to better understand Internet access pricing st ructures and the role the cost of access plays in digital inequal ity. 6.2.3 Adjusted Cost of Internet Access. Our results indicate that Speedtest performance in lower income areas lags behind that of higher income areas. One p otential cause could be the cost of access to high quality Internet service. Pricing structures that do not vary based on median income can have the eï¬€ect of marginalizing some communities and reducing their ability to access higher tiers of Internet service. The Emergency Broadband Beneï¬t initiative by the FCC [23] subsidises the cost of high speed Internet for low income households and highlights the need to suppo rt certain communities and individuals in their ability to purchase high quality Internet. While an extremely positive step, there have b een indications that some ISPs may be forcing cu stomers into mo re expensive plans in order to take advantage of these subsidies [22, 43]. As subsequent assistance plans are rolled out, it is important to monitor usage and impact on the populations they are meant to assist. Every year, the Census, through the American Community Survey (ACS) One Year estimates, compiles a list of cities with the worst Internet connectivity in the country [20]. However, this estimate is only done for cities with population greater t han 65, 000, leaving other regions unassessed. Critically, it is these smaller co mmunities that are more likely to have sub-par Internet access. Similar to our work, [13] analysed the relationship between income and download speed at t he ge ographic granularity of zip codes in the U.S. The work utilized income data (grouped into ï¬ve income bins) obtained from 2017 tax returns ï¬led with the Internal Revenue Service. The study demonstrated a positive correlation between zip code income and download speed. In [47], the autho rs conducted an analysis similar t o ours using the Ookla Open data [10] and demonstrated the variability of important Internet quality metrics between co mmunities. Our work goes a step further in that we conduct a comprehensive analysis at ï¬ner geographic granularity to understand several dimensions (location, income and cost of access) of Internet access variability. The work conducted in [57] demonstrated that the FCC significantly overestimates coverage and highlighted the lack of coverage in rural and marginalized communities. The work in [44] showed moderate correlation between reliability of Internet service (packet loss) and type of area (urban/rural). Through our analysis, we show that the quality of Internet between diï¬€erent states and diï¬€erent communities within these states also varies. Other studies have shown the shortcomings of FCCâ€™s Form 477 [26]. In a recent study conducted by Microsoft [41], it was estimated that 162.8 million Americans did not have access to high-speed broadband, a number far greater than the FCCâ€™s estimate. A similar study [25] estimated 4 2 million (6.5% more than FCC estimates) Americans do not have access to broadband Internet. In [ 58, 60, 61, 64], demographic factors such as location, race and/or income are all shown to impact Internet access. We advance this body of work and demonstrate that while areas may have Internet access, the quality of that access may diï¬€er widely by location and income. Similar to our work, the authors of [48] used crowdsourced measurements to benchmark Internet performance across multiple metropolitan areas. In [49], cable and DSL performance in residential areas of North America and Europe was characterized. In [46, 54, 55, 63], additional work related to understanding Internet performance of diï¬€erent user groups was conducted. While relevant, these prior studies did not attempt to understand how the Internet performance varies between users of diï¬€erent locations (urban/rural) or income levels. Finally, cost eï¬€ective depl oyment sol utions were proposed to increase coverage in unserved or under-served areas in [50, 53, 62]. Internet inequality continues to persist across the U.S. Our work integrates data on Internet performance with location and income to explore multiple dimensions in which this divide manifests amongst users of the popular Ookla Speedtest application. Our ï¬ndings point towards the need to develop more accur ate Internet coverage, affordability and quality measurement to ols to facilitate more ï¬negrained analysis of the quality of experience of user groups. Additionally, given the lack of information that currently exists in the broadband market, our work highlights the need for increasing visibility in this segment to better understand the root causes behind Internet access quality diï¬€erentials between users. It is our hope that our ï¬ndings can help guide the eï¬€orts of policymakers and researchers in narrowing this persistent digital gap.
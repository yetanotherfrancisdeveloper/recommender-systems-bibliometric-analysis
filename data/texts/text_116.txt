As recommendation systems become increasingly standard for online platforms, simulations provide an avenue for understanding the impacts of these systems on individuals and society. When constructing a recommendation system simulation, there are two key challenges: ï¬rst, deï¬ning a model for users selecting or engaging with recommended items and second, de ï¬ning a mechanism for users encountering items that are not recommended to the user directly b y the platform, such as by a friend sharing speciï¬c content. This paper will delve into both of these challenges , reviewing simulation assumptions from existing research and proposing alternative assumptions. We also include a broader discussion of the limitations of simulations and outline of open questions in this area. Key Words and Phrases: Recommendation systems; consumer choice models; simulations. Reference Format: Allison J.B. Chaney. 2021. Recommendation System Simulations: A Discussion of Two Key Challenges. In SimuRec: Workshop on Synthetic Data and Simulation Methods for Recommender Systems Research 2021 (at ACM RecSys â€™21), Amsterdam, Netherlands. 1 INTRODUCTION With over 4.6 billion active internet user worldwide [ precedented rates. Major online platforms typically provide personalized reco mmendations for their usersâ€”these system tailor search results, suggest products to purchase, customize front pages for news and opinions sites, curate social media posts, reco mmended movies, and generate music playlists. Basic recommendation systems are relatively straightforward to build; Googleâ€™s free recommendation systems course to complete (given prerequisite skills). Because of the ease of implementing a basic system, algorithmic recommendations are proliï¬c online, deployed by business large and small to impact millions of people each day. Recently, there has been increasing interest in understanding t he impact of personalized recommendation systems from perspectives that ï¬rms have historically not considered, such as: how mu ch do these systems co ntribute to polarization? Do they homogenize users? Are they fair to all users or do they disadvantage portions of users? These qu estions are diï¬ƒcult to answer from observational data and it may be risky, or even unethical, for ï¬rms to explore these ideas with A/B tests. Simulations provide an alternative approach to u nderstand the impacts of recommendation systems; this is an increasingly popular approach to evaluating these systems and broad simulation tools are being developed [ ally, some recommendation methods, such as reinforcement learning techniques, require more sophisticated approaches to oï¬„ine evaluation prior to moving to A/B testing; simulations are similarly appropriate in this and other contexts. When constructing a recommendation system simulation, there are two key challenges. The ï¬rst is deï¬ning a model of user choice. There are a variety of well-established consumer choice models from economics and marketing, which will be described in more detail in consumer decision-making is likely more complicated and heterogeneous than deï¬ned by these choice models. That said, these models of choice oï¬€er us hope: if machine learning models can capture behavior patterns under these simpliï¬ed assumptions, we have a chance of recovering and understanding usersâ€™ true preferences in a more nuanced world. This would allow us to to begin describing the limitations of machine learning recommendation systems (e.g., by answering the previously posed questions about their impact) and therefore use them more judiciously in practice. The other key chall enge is deï¬ning how users encounter items that are not recommended, including in the counterfactual world in which they do not receive algorithmic recommendations at all. In the real world, consumers encounter content in a wide variety of ways (and sometimes even using a variety of similar platforms): search, promotions, lists of new content or content b y t heme, and recommendations from friends or experts are a few alternative me c hanisms. A simulation that does not include the notion of users accessing items in alternate ways will overestimate the eï¬€ects of algorithmic recommendations on user behavior. This second challenge is not wholly disentangled from the ï¬rst one of deï¬ning a model of user choice, but we will address it distinctly in Section 3. While there are undoub tedly a variety of other challenges associated with b uilding a recommendation system simulator, this position paper will delve into both of these key chall enges, reviewing simulation assumptions for existing research in this context, as well as prop osing alternative assumptions worth further exploration. We will conclude with a broader discussion limitations of simulations and an outline o f open questions in this area (Section 4). 2 MODELS OF CONSUMER CHOICE In order for users to select items from among the recommendations, a simulator must include so me model of user choice; this is our ï¬rst key challenge. Existing work in recommendation system simulations typically represents both user p references and items attributes in some relatively low-dimensional space, not unlike the very recommendation systems they seek to evaluate. For example, the general purpose T-RECS tool [11] uses vector representations for each item and user, with the â€œscoreâ€ of an item for a user being either the inner product between the user preferences and item attributes, or the cosine similarity between the two representations. E ven within this construction, however, t here are a wide variety of assumptions abo ut how users make their choices. Some simulations assume that users are uncertain of their preferences. Aridor et al. [1] model users as considering items sequentially, updating their beliefs as they go; under this paradigm, recommendations amount to adjusting the values which users rely on fo r decisions. Other work frames the utility of an item for a user as being comprised of two parts: known and unknown to the user; a user then acts based on a function of the recommended rank of an item and their known utility for that item [2]. Still other simulations forgo the individual element, assuming a universal qualit y value for each item with items being selecte d based on a function of eitehr rank (popularity) or quality based on a popularity bias parameter [3]. Sometimes users are represented as points in a low-dimensional attitude space with items being selecte d based on distance metrics [6]. Yao and Huang [19] use stochastic block models to generate data: u sers probabilistically belong to groups and users within a group probabilistically like it ems. Unfortunately, some work does not make the exact choice model clear, spe cifying only that u sers select a subset of recommended items and provide feedback on this set [9]; the mechanism for selection is unspeciï¬ed. In other cases, simulations assume that users act on every single recommendation, rating each according to their preferences [18]. Regardless of the choice model used, researchers need to be explicit about these assumptions as it is impo rtant for replicability; simple alterations in assumptions may drastically alter results. In addition, it would be beneï¬cial to work towards a set of standard choice models. In doing so, I encourage us to look to consumer cho ice models from economics and marketing. Relying on these existing models confers multiple beneï¬ts to researchers and analysts: these models have been critiqued extensively, theoretically vetted, used to analyze real-world behaviors in multiple contexts, and bring with them established terminology; we need not reinvent the wheel. While no choice model will perfectly capture all the nuances in user behavior, it stands to reason that we should draw on and integrate with existing consumer choice models in deï¬ning how simulated users behave when interacting with recommendation systems. To aid in this eï¬€ort, we will discuss a few co nsumer choice models, adapting them to the context of recommendation systems. A fundamental premise shared among consumer choice mo dels is that consumers, or users, make choices based on the utility of diï¬€erent actions. The utility ğ‘ˆ it) at choice instance ğ‘¡ is typically comprised of two parts: a deterministic function ğ‘“ of the attributes of the item (a= {ğ‘ overall ut ility ğ‘ˆ where ğ‘¢ deterministic utility of co nsuming an item is a linear combination of the utility weights of each of the itemâ€™s attributes, or This linear construction of utility has par allels with many of the simulation assumptions already used in recommendation system simulations, which draw from the matrix factorization model for recommendation [ seminal work of Guadagni and Little [ random component ğœ– is assumed to be drawn from a standard Gumbel distribution. As an alternative to this multinomial logit model, the multinomial probit model assumes a diï¬€erent distribution of the random component o f the utility ğœ–; speciï¬cally, it assumes ğœ– both cases, consumers maximize their utility in expectation with the probability of choosing an item being a function of all the item alternatives available I to generate data rather than to describe observed behaviors, so to use this model in simulating choices we nee d only draw the collection of random components ğ from the appropriate distributions; each user ğ‘¢ then selects the item ğ‘– that maximizes their ut il ity ğ‘ˆ user utility weights u there will be no randomness in consumer behavior, but if it is too small, user behavior will be exclusively random. Personalized recommendation systems are only used in domains where users select multiple items, meaning the models of choice we consider must accommodate multiple selection. The linear multinomial logit and probit model just described easily integrate this constraint but allow for the same item to be selected multiple times. In some contexts, however, this may not be a desirable property. For these cases, we may modify the models to exclude items previously selected by the userğ‘› from consideration, giving us a user-speciï¬c set item alternatives I represent extreme ends of a spectrum: repeated consumption of the same item could yield identical utility in expec tation or zero utility after the ï¬rst instance of consumption. In many domains, the reality for consumers would be a hybrid of the two: d iminishing utility for repeat consumption. For simplicity, one could consider only the two extremes and argue that a diminishing utilit y model would perform somewhere in between the two. When consumers can easily consider al l items, the model assumptions discussed thus far se em appropriate. Unfortunately, recommendation systems are deployed in exactly the context in which users cannot consider all items. Because of this context, the order in which users consider items matters, which brings us to the notion of â€œsat isï¬cingâ€ choice [ This gives us a choice model wherein a consumer picks ï¬rst item to meet a minimum threshold. Under a the model , . . . ğ‘} for ğ½ attributes) and a random component ğœ– speciï¬c to the choice instance ğ‘¡. In computing a given , the utility of a given attribute can be unique for each user, giving us is the utility weight of attribute ğ‘— for user ğ‘›. The deterministic function ğ‘“ is usually (but not always) linear: the proposed by StÃ¼ttgen et al. [17], users have an â€œaspiration levelâ€ for each item attribute: this is the point at which the item would be considered satisfactory; for an item ğ‘– to be satisfactory overall, each attribute ğ‘— needs to be satisfactory. With a large number of attributes, however, it is unrealistic for consumers to consider each attribute individually. Instead, we have user ğ‘› accept the ï¬rst item ğ‘– with utility ğ‘ˆ(Equation (1)) greater than or equal to a user-speciï¬c threshold, or overall aspiration level ğ›¼. These aspiration levels may be ï¬x ed or learned by the user as a function of their experiences on the platform. Anecdotally, this may be the best model for simulating consumer choice in the recommendation system context due to it s simplicity. However, like with determining the magnitude of utility weights u, care must be taken in choosing the aspiration thresholds ğ›¼; too large thresholds yield minimal user interactions and overemphasize deterministic preferences whereas too small thresholds generate a large number of highly random user interactions. In addition to the utilities of the items themselves, we can incorporate the cost of thinking [14] or search costs [16] into our choice models. This leads to another family of models based on consideration sets [8, 12]. In the words of Hauser and Wernerfelt [8], these models capture the â€œtrade-oï¬€s between decision costs and the incremental beneï¬ts of choosing from a l ar ger set.â€ Given a consideration set of items C, a consumer ğ‘› must choose b etween evaluating the items in the consideration set to select one, or searching for a new item to consider, with search cost ğ‘ . If they choose to search and discover a new item, they must determine if it is worth the decision cost ğ‘‘to add the item to the consideration set. Items may also be dropped from a consideration set if their contributions to the expected utilit y of the ï¬nal choice do not outweigh the decision cost ğ‘‘of including them in the set. One could assume that each user ğ‘› has their own decision costs ğ‘‘and search costs ğ‘ that are co nstant. Under this model, each user ğ‘› starts with an empty consideration set C and selects items using the following procedure, based on Hauser and Wernerfelt [8] for a given choice instance ğ‘¡. â€¢ Drop any item ğ‘– from the consideration set Cif its expected contribution to utility is not worth the d ecision cost,î€‚î€ƒî€‚î€ƒ â€¢ If the expected marginal utility of considering a new item with the associated decision costs is less than theî€‚î€ƒî€‚î€ƒ search cost, or Emaxğ‘ˆâˆ’ Emaxğ‘ˆ+ ğ‘‘< ğ‘ , search for a new item ğ‘– âˆˆ Iand continue. Otherw ise, return to the start of the procedure after choosing the highest utility item from C, ğ‘¦= arg maxğ‘ˆ, and then removing ğ‘¦from C. â€¢ Add item ğ‘– to the consideration set Cif the expected marginal ut ility of adding the item is greater than theî€‚î€ƒî€‚î€ƒ decision cost, Emaxğ‘ˆâˆ’ Emaxğ‘ˆ> ğ‘‘. In practice, this model requires extensive co mputation to estimate all the user-speciï¬c expected contributions and marginal utilities. Once these challenges are overcome, this could be a potentially powerful model for simulating user choices. In all of the consumer choice models discussed here, we have assumed that deterministic consumer preferences are static except for small random variations ğœ–; these deterministic preferences do not evolve systematically in any way. The satisfying model includes some notion of adapting preference if we allow the aspirational thresholds ğœ¶ to be learnt; the search model similarly includes evolving preferences based on expected marginal ut il ities, which are dynamic based on the usersâ€™ experiences. However, there is more room to explore the d ynamics of evolving consumer preferences in the recommendation systems context; for example, it is established that consumers can l earn their own preference weights uas they search, complicating the process of recommendation [5]. These and similar complex dynamics have been explored in economics and marketing, providing recommendation system researchers a plethora of mod els from which to draw inspiration for their simulation assumptions regarding user choices. 3 ALTERNATIVES TO RECOMMENDATIONS We now turn to an even broader challenge: in the real world, users interact with items through a combination of online and oï¬„ine mechanisms, including, but not limited to, algorithm recommendation. For example, a consumer may receive a book recommendation from a friend in conversation and then use a search engine to ï¬nd it later. Users will always have alternatives to using a recommendation system, including leaving the plat form entirely if it does not meet their needs. Excluding this general concept from the simulation setting will vastly overemphasize the impact of any given recommendation system on user behavior. To date, recommendation system simulations address this in simple ways, if at all. Some work oï¬€ers no alternatives to recommendations, focusing o nly on generating data with bias and the corresponding implications [ mendations based on overall popularity, matrix factorization, and recommendations under ideal or oracle conditions [ 9]. Along this vein, Geschke et al. [6] compares recommending close content to distant content, but also includes social dynamics in their simulations. Even more simply, some simulations interleave random items among recommended ones [ Many researchers dismiss the need for alternatives to recommended content or re-frame their questions to avoid this diï¬ƒcult issue. While this is an understandable starting point, we need to move past it. An o bservational study of Bing search and Amazon data estimated that at least 75% of Amazon product browsing activity would likely occur in the absence of recommendations [ and platform features, this example underscores the importance of alternate ways o f accessing content. This second challenge is connected to the ï¬rst one of deï¬ning a model of user choice: users consider not only which items to select, but the sources from which they select them. On some level, then, there are easy solutions. For example, a satisï¬cing model presents users with an ordered list of items; in this context, we can extend the concept of interleaving random items to probabilistically selecting items for consideration from diï¬€erent sources. Items may be algorithmically recommended, but they may also be new items, items returned by search, etc. Ideally, these probabilities would change as a function of the learned relevancy for each source, not unlike a multi-armed bandit model. The consideration set model previously discussed can similarly draw on multiple sources with distinct search costs for each source. The true diï¬ƒculty is that each of these al ternate mechanisms, or sources, needs a corresponding model with its own assumptions. Again, we need standards for alternate mechanisms for accessing content in simulations, including the associated assumptions with each mechanism. This may involve observational research to understand the breadth of how users access content and to characterize the nature of their interactions with these alternate sources. 4 DISCUSSION As simulation methods become more popular for understanding the impact of recommendation systems, we must be critical of the assumptions we use and work toward establishing standards base d on real-world consumer behaviors. This includes clear deï¬nitions of our user choice models ( alternatives to algorithmic recommendations ( need to deï¬ne what the comparison is, or what can realistically be changed in the world. Firms cannot deploy an oracle recommendation system, though they undoubte dly wish they could . Instead, the data that they have is biased by their existing recommendation system or platform design choices; they need to make the best choices they c an within those constraints. Our work should focus on realistic comparisons that lead to actionable results for ï¬rms. This includes how to handle new items and users (the â€œcold-startâ€ problem), understating the beneï¬ts and consequences of bias reduction strategies, how t o best comb ine historic and recent data, and comparing pipeline choices such as oï¬„ine evaluation and 18, 19]. Others compare diï¬€erent recommendation systems such as random recommendations, recom- A/B t esting metrics, as well as the frequency of retraining or updating the system. We also need standards on the scale of simulations; real-world platforms are large with thousands if not millions of users. What size of simulations are needed to generate compelling results? How does the required scale vary based on the simulation assumptions? While these challenges may seem d aunting, they are part of a larger, enduring task. As our society continues to integrate with technical systems like recommendation engines, we must do our best to understand the impacts of these systems through simulations and other methods so we may use these technologies wisely. ACKNOWLEDGMENTS Thank you to Brandon Stewart, Ryan Dew, Sam Levy, the marketing faculty at both Chicago Booth and Duke Fuqua, and my fellow organizers of the SimuRec workshop for their discussions broadly related to this work.
<title>Graph Neural Networks for Recommender Systems: Challenges, Methods, and Directions</title> CHEN GAO* , YU ZHENG* , NIAN LI , YINFENG LI , YINGRONG QIN , JINGHUA PIAO , YUHAN QUAN , JIANXIN CHANG , DEPENG JIN , XIANGNAN HE , YONG LI* <title>arXiv:2109.12843v1  [cs.IR]  27 Sep 2021</title> information to users, which improves the user experience and promotes business proî€›t. As one of 2 Gao et al. neural networks for recommender systems. In this survey, by contrast, we provide a comprehensive understanding of why GNN can be and should be used in recommender system, which can help readers to understand the position and value of this new research î€›eld. Third, it does not explain the critical challenges of applying graph neural networks to recommendation and how to address them, which are fully discussed in this survey. Last, since this area is increasingly popular, our survey also introduces a lot of recently published papers not covered by [168]. The structure of this survey is organized as follows. We î€›rst introduce the background of recommender systems, from four kinds of perspectives (stage, scenario, objective, application), and the background of graph neural networks, in Section 2. We then discuss the challenges of applying graph neural networks to recommender systems from four aspects, in Section 3. Then we elaborate on the representative methods of graph nerual network-based recommendation in Section 4 by following the taxonomy in the above section. We discuss the most critical open problems in this area and provide ideas of the future directions in Section 5 and conclude this survey in Section 6. 2.1.1 Overview . In this section, we present the background of recommender systems from four perspectives: stages, scenarios, objectives, and applications. Speciî€›cally, in industrial applications, due to the real-world requirements on system engineering, the recommender systems are always split into three stages, matching, ranking, and re-ranking, forming a standard pipeline. Each stage has diî€erent characteristics on data input, output, model design, etc. Besides the standard stages, there are many speciî€›c recommendation scenarios with a special deî€›nition. For example, in the last twenty years, social recommendation has been attracting attention, deî€›ned as improving recommender system based on social relations. Last, diî€erent recommender systems have diî€erent objectives, of which accuracy is always the most important one as it directly determines the systemâ€™s utility. Recently, recommender systems have been assigned other requirements such as recommending diversiî€›ed items to avoid boring user experience, making sure the system treats all users fairly, protecting user privacy from attack, etc. As for the applications, GNN models can 4 Gao et al. be widely deployed in e-commerce recommendation, point-of-interest recommendation, news recommendation, movie recommendation, music recommendation, etc. 2.1.2 Stages . The item pool, i.e. all the items available for recommender systems, is usually large and can include millions of items. Thus, common recommender systems follow a multi-stage architecture, î€›ltering items stage by stage from the large-scale item pool to the î€›nal recommendations exposed to users, tens of items. [ 29 158 ]. Generally, a modern recommender system is composed of the following three stages. â€¢ Matching. This î€›rst stage generates hundreds of candidate items from the extremely large item pool (million-level or even billion-level), which signiî€›cantly reduces the scale. Considering the large scale of data input in this stage, and due to the strict latency restrictions of online serving, complicated algorithms cannot be adopted, such as very deep neural networks [ 29 70 ]. In other words, models in this stage are usually concise. That is, the core task of this stage is to retrieve potentially relevant items with high eî€œciency and attain coarse-grained modeling of user interests. It is worth noting that a recommender system in the real world usually contains multiple matching channels with multiple models, such as embedding matching, geographical matching, popularity matching, social matching, etc. â€¢ Ranking. After the matching stage, multiple sources of candidate items from diî€erent channels are merged into one list and then scored by a single ranking model. Speciî€›cally, the ranking model ranks these items according to the scores, and the top dozens of items are selected. Since the amount of input items in this stage is relatively small, the system can aî€ord much more complicated algorithms to achieve higher recommendation accuracy [69, 89, 133]. For example, rich features including user proî€›les and item attributes can be taken into consideration, and advanced techniques such as self-attention [ 69 ] can be utilized. Since a lot of features are involved, the key challenge in this stage is to design appropriate models for capturing complicated feature interactions. â€¢ Re-ranking. Although the obtained item list after the ranking stage is optimized with respect to relevance, it may not meet other important requirements, such as freshness, diversity, fairness, etc. [ 120 ] Therefore, a re-ranking stage is necessary, which usually removes certain items or changes the order of the list in order to fulî€›ll additional criteria and also satisfy business needs. The main concern in this stage is to consider multiple relationships among the top-scored items 217 ]. For example, similar or substitutable items can lead to information redundancy when they are displayed closely in the recommendations. Fig. 2 illustrates the typical pipeline of a recommender system, as well as the comparisons of the three stages above. 2.1.3 Scenarios. In the following, we will elaborate on the diî€erent scenarios of recommender systems, including social recommendation, sequential recommendation, session recommendation, bundle recommendation, cross-domain recommendation, and multi-behavior recommendation. â€¢ Social Recommendation. In the past few years, social platforms have dramatically changed usersâ€™ daily life. With the ability to interact with other users, individual behaviors are driven by both personal and social factors. Speciî€›cally, usersâ€™ behavior may be inî€uenced by what their friends might do or think, which is known as social inî€uence [ 28 ]. For example, users in WeChat Video platform may like some videos only because of their WeChat friendsâ€™ like behaviors. At the same time, social homophily is another popular phenomenon in many social platforms, i.e., people tend to build social relations with others who have similar preferences with them [ 107 ]. Taking social e-commerce as an example, users from a common family possibly share similar product preferences, such as food, clothes, daily necessities, and so on. Hence, social relations are often integrated into recommender systems to enhance the î€›nal performance, which is called social recommendation. Fig. 3 illustrates the data input of social recommendation, of which user interactions are determined by both his/her own preferences and social factors (social inî€uence and social homophily). â€¢ Sequential Recommendation. In recommender systems, users will produce a large number of interaction behaviors over time. The sequential recommendation method extracts information from these behavioral sequences and predicts the userâ€™s next interaction item, as shown in Fig. 4. To symbolize this problem, for the sequence of items {ğ‘¥ , ğ‘¥ , ..., ğ‘¥ that the user has 6 Gao et al. sets on Amazon, and the furniture suites on IKEA. It is worth mentioning that bundle recommendations are also used to solve interesting and meaningful problems such as fashion outî€›ts [ 83 and drug packages [209]. â€¢ Cross-Domain Recommendation. As an increasing number of users interact with multi-modal information across multiple domains, cross-domain recommendation (CDR) has been proven to be a promising method to alleviate cold start and data sparsity problems [ 41 43 60 68 104 112 203 ]. CDR methods can be roughly divided into two categories, single-target CDR (STCDR) and dualtarget CDR (DTCDR) [ 30 ]. CDR methods transfer the information from the source domain to the target domain in one direction; DTCDR emphasizes the mutual utilization of information from both source domain and target domain, which can be extended to multiple-target CDR (MTCDR). Since utilizing information from multiple domains can improve performance, cross-domain recommendation has become an important scenario in recommender systems. â€¢ Multi-behavior Recommendation. Users interact with recommender systems under multiple types of behaviors instead of only one type of behavior. For example, when the user clicks on the video, he/she may also perform behaviors such as collecting or comment. In an e-commerce website, users often click, add into shopping carts, share, or collect a product before purchasing it, as shown in Fig. 8. Although the ultimate goal of the recommender system is to recommend products that users will purchase, the purchase behavior is very sparse compared to the userâ€™s click, sharing, and other behaviors. To symbolize this problem, For each user and item suppose there are diî€erent types of behaviors {ğ‘¦ , ğ‘¦ , ...,ğ‘¦ . For the -th behavior, if the user has a observed behavior, then 1, otherwise 1. The goal of the recommender system is to improve the prediction accuracy of a certain type of target behavior ğ‘¦ 8 Gao et al. For multi-behavior recommendation, generally speaking, there are two main challenges. Firstly, diî€erent behaviors have diî€erent inî€uences on the target behavior. Some behaviors may be strong signals, and some may be weak signals [ 173 174 ]. At the same time, this inî€uence is diî€erent for each user. Itâ€™s challenging to model the inî€uence of these diî€erent behaviors on the target behavior accurately. Secondly, it is challenging to learn comprehensive representations from diî€erent types of behaviors for items. Diî€erent behaviors reî€ect usersâ€™ diî€erent preferences for items; in other words, diî€erent behaviors have diî€erent meanings. In order to obtain a better representation, the meaning of diî€erent behaviors needs to be integrated into the representation learning. 2.1.4 Objectives. The most important objective of recommender systems, of course, is accuracy. In the following, we elaborate on the three other important objectives, including diversity, explainability, and fairness. sometimes called long-tail recommendation. Fig. 9 brieî€y illustrates the two types of diversity and their diî€erences. For both individual-level and system-level diversity, there are two main challenges. First, the signal strength of diî€erent items varies greatly. For each user, there exist dominant topics and disadvantaged topics, e.g. a userâ€™s interaction records with electronics might be much more frequent than with clothes. Similarly, the signal strength of long-tail items is also far weaker than popular items. Therefore, it is challenging to recommend relevant content with such weak supervision from either disadvantaged topics or long-tail items for individual-level and system-level diversity, respectively. Second, diversity may sometimes contradict recommendation accuracy, resulting in the accuracy-diversity dilemma; thus it is challenging to balance between the two aspects. â€¢ Explainability. As current recommender systems mostly adopt a deep learning paradigm, they can arouse urgent needs on the explainability of recommendation [ 201 ]. The focus of explainable recommender systems is not only to produce accurate recommendation results but to generate persuasive explanations for how and why the item is recommended to a speciî€›c user [ 201 ]. Increasing the explainability of recommender systems can enhance usersâ€™ perceived transparency [ 131 ], persuasiveness [ 142 ] and trustworthiness [ 75 ], and facilitate practitioners to debug and reî€›ne the system [ 201 ]. This survey mainly focuses on improving explainability with machine learning techniques. Speciî€›cally, past research adopts two diî€erent approaches [ 201 ]: one makes eî€orts to design intrinsic explainable models, ensuring the explainability of recommendation results by designing models with transparent logic (rather than merely â€œblack boxâ€), e.g., Explicit Factor Models [ 202 ], Hidden Factor and Topic Model [ 106 ], and TriRank [ 54 ]. The others compromise slightly: they design post-hoc separate models to explain the results generated by â€œblack boxâ€ recommender systems, e.g., Explanation Mining [ 119 ]. Currently, there are two challenges. First, representing explainable information requires graph-structural item attributes, which are diî€œcult to model without the power of GNN. Second, reasoning recommendations depend on external knowledge in the knowledge graph, which also poses challenges on the task. â€¢ Fairness. As a typical data-driven system, recommender systems could be biased by data and the algorithm, arousing increasing concerns on the fairness [ 86 108 ]. Speciî€›cally, according to the involved stakeholders, fairness in recommender systems can be divided into two categories [ 86 108 ]: user fairness, which attempts to ensure no algorithmic bias among speciî€›c users or demographic groups [ 78 84 ], and item fairness, which indicates fair exposures of diî€erent items, or no popularity bias among diî€erent items [ 86 108 ]. Here, we focus on the user fairness, and leave item fairness in the section of diversity for their close connection in terms of interpretations and solutions [ 105 ]. Speciî€›cally, researchers adopt two methods to enhance fairness: One is directly debiasing recommendation results in the training process [ 216 ], while the other endeavors to rank items to alleviate the unfairness in a post-processing method [ 46 130 ]. Indeed, increasing evidence shows that the utilization of graph data, e.g., user-user, could intensify concerns on fairness [ 31 124 162 ]. Thus, it is challenging to debias unfairness in recommendation in the context of rich graph data. Furthermore, it is even harder to boost user fairness in recommendation from the perspective of graph. 2.1.5 Applications. Recommender systems widely existing in todayâ€™s information services, with various kinds of applications, of which the representative ones are as follows. Product recommendation, also known as E-commerce recommendation, is one the most famous applications of recommender systems. For recommendation models in the e-commerce scenario, the business value is highly concerned. Therefore, it is crucial to handle multiple types of behaviors closely relevant to the platform proî€›t, including adding to cart or purchase. Some works [ 102 propose to optimize the click-through rate and conversion rate at the same time. In addition, in 10 Gao et al. e-commerce platform, products may have rich attributes, such as price [ 207 ], category [ 210 ], etc., based on which heterogeneous graphs can be constructed [ 99 ]. Representative benchmark datasets for product recommendation includes Amazon , Tmall POI (Point-of-interest) recommendation, is also a popular application that aims to recommend new locations/point-of-interests for usersâ€™ next visitation. In Point-of-interest recommendation, there are two important factors, spatial factor and temporal factor. The spatial factor refers to naturally-existed geographical attributes of POIs, i.e., the geographic location. In addition, the usersâ€™ visitations are also largely limited by their geographical activity areas since the user cannot visit POIs as easily as browsing/purchasing products on e-commerce websites. Besides, the temporal factor is also of great importance since usersâ€™ visitation/check-in behaviors always form a sequence. This motivates the problem of next-POI or successive POI recommendation[ 37 90 179 ]. Representative benchmark datasets for news recommendation includes Yelp , Gowalla , etc. News recommendation helps users î€›nd preferred news, which is also another typical application. Diî€erent from other recommendation applications, news recommendation requires proper modeling of the texts of news. Therefore, methods of natural language processing can be combined with recommendation models for extracting news features better [ 114 ]. Besides, users are always interested in up-to-date news and may refuse out-of-date ones. Thus, it is also critical but challenging to fast and accurately î€›lter news from the fast-changing candidate pools. As for news recommendation, MIND dataset [159] is the recently-released representative benchmark dataset. Movie recommendation is one of the earliest recommender systems. Precisely, Netî€ixâ€™s movie recommendation competition [ ] motivated many pioneer recommendation researches [ 73 ]. The earlier setting of movie recommendation is to estimate the usersâ€™ rating scores on movies, from one to î€›ve, which is named explicit feedback. Recently, the binary implicit feedback has become more popular setting [56, 126]. There are also other types of recommendation applications, such as video recommendation [ 32 93 ], music recommendation [ 143 156 ], job recommendation [ 117 ], food recommendation [ 111 ], etc. convolutional neural network (CNN) and graph representation learning (GRL) [ 171 212 ]. When applied to regular Euclidean data such as images or texts, CNN is extremely eî€ective in extracting localized features. However, for non-Euclidean data like graphs, CNN requires generalization to handle the situations where operation objects (e.g., pixels in images or nodes on graphs) are nonî€›xed in size. In terms of GRL, it aims to generate low-dimensional vectors for graph nodes, edges, or subgraphs, which represent complex connection structures of graphs. For example, a pioneering work DeepWalk [ 121 ] learns node representations by using SkipGram [ 110 ] on a generated path with random walks on graphs. Combining CNN and GRL, various GNNs are developed to distill structural information and learn high-level representations. In later parts, we will introduce several general and primary stages for designing a GNN model to accomplish tasks on graphs, illustrated in Fig. 10. Speciî€›cally, section 2.2.1, 2.2.2 and 2.2.3 elaborate how to construct graphs, design specialized and eî€ective graph neural networks and optimize models, respectively. â€¢ Homogeneous graph , of which each edge connects only two nodes, and there is only one type of nodes and edges. â€¢ Heterogeneous graph , of which each edge connects only two nodes, and there are multiple types of nodes or edges. â€¢ Hypergraph, of which each edge joins more than two nodes. In many information services nowadays, relational data is naturally represented in the form of graphs. For example, implicit social media relationships can be considered as a uniî€›ed graph, with nodes representing individuals and edges connecting people who follow each other. However, since non-structured data such as images and texts do not explicitly contain graphs, it is necessary to deî€›ne nodes and edges manually for building graphs. Taking text data used in Natural Language Processsing (NLP) as an example, words/documents are described as nodes, and edges among them are constructed according to Term Frequency-Inverse Document Frequency (IF-ITF) [ 186 ]. Additionally, an emerging research direction in representation learning on graphs is knowledge graph (KG), which is a representative instance of the heterogeneous graph. KG integrates multiple data attributes and relationships, in which nodes and edges are redeî€›ned as entities and relations, respectively. Speciî€›cally, the entities in KG can cover a wide range of elements, including persons, movies, books, and so on. The relations are utilized to describe how entities associate with each other. For example, a movie can relate to persons (e.g., actors or directors), countries, languages, etc. Except for ordinary graphs, the hypergraph is also explored recently to handle more complex 12 Gao et al. data (e.g., beyond pairwise relations and multiple modals) î€exibly [ 38 ], in which each edge can connect more than two nodes. In summary, constructing graphs necessitates either pre-existing graph data or abstracting the concept of graph nodes and edges from non-structured data. where F denotes the graph Fourier transform. In contrast, spatial models conduct the convolution on graph structures directly to extract localized features via weighted aggregation like CNNs. Despite the fact that these two types of models start from diî€erent places, they fall into the same principle of collecting neighborhood information iteratively to capture high-order correlations among graph nodes and edges. Here â€œinformationâ€ is represented as embeddings, i.e., low-dimensional vectors. To this end, the primary and pivotal operation of GNN is to propagate embeddings on graphs following structural connections, including aggregating neighborhood embeddings and fusing them with the target (a node or an edge) embedding, to update graph embeddings layer by layer. In the following, we will introduce several groundbreaking GNN models to elaborate how neural networks are implemented on graphs. The frequently used notations are explained in Table 1. â€¢ GCN 72 ]. This is a typical spectral model that combines graph convolution and neural networks to achieve the graph task of semi-supervised classiî€›cation. In detail, GCN approximates the î€›lter in convolution by the î€›rst order following [ 53 ]. Then the node embeddings are updated as follows, = ğ›¿ ( ), (2) of which the derivation can refer to [ 171 ]. âˆˆ R is the embedding matrix of graph nodes in the -th layer of convolution, where is the embedding dimension. Besides, A âˆˆ R is the adjacency matrix of the graph with self-loop, of which each entry 1 if the node connects with ğ‘— or ğ‘– = ğ‘—; otherwise = 0, and â€¢ GraphSAGE 52 ]. This is a pioneered spatial GNN model that samples neighbors of the target node, aggregates their embeddings, and merges with the target embedding to update. where is the propagation weight from node to node and is the neighborhood set of node , including itself. As shown in the second equation, the attention mechanism is implemented via a fully-connected layer parameterized by a learnable vector , followed by the softmax function. â€¢ HetGNN 195 ]. This is a spatial GNN tailored for heterogeneous graphs. Considering the heterogeneous graph consists of multiple types of nodes and edges, HetGNN î€›rst divides neighbors into subsets according to their types. Hereafter, an aggregator function is conducted for each type of neighbor to gather localized information, combining LSTM and MEAN operations. Furthermore, diî€erent types of neighborhood information are aggregated based on the attention mechanism. Detailed formulas are omitted since the implementation is following the above works. â€¢ HGNN 38 ]. This is a spectral model implementing GNN on the hypergraph. The convolution is deî€›ned as follows, = D ED , (5) where each entry of E âˆˆ R denotes whether the hyperedge contains the node , each diagonal entry of âˆˆ R denotes how many hyperedges the node is included in and each diagonal entry of âˆˆ R denotes how many nodes the hyperedge includes. Generally, this convolution operation can be considered as two stages of propagating neighborhood embeddings: 1) propagation from nodes to the hyperedge connecting them, and 2) propagation from hyperedges to the node they meet. The commonality and diî€erence among typical GNN models above is illustrated in Fig. 11. In order to further capture high-order structural information on the graph, the convolution or embedding propagation mentioned above will be performed for times. In most cases, ğ¿ â‰¤ 4 since GNNs are suî€ered from the over-smoothing problem that the updated embeddings will be in small î€uctuations when the number of propagation layers becomes larger. Relevant studies focusing on developing deep and eî€ective GNN models will be introduced in section 5.1. 2.2.3 Model Optimization. After the processing of the designed network in section 2.2.2, overall embeddings of nodes or edges encoding feature semantics as well as graph structures are produced. To perform the downstream graph learning tasks, these embeddings will be further transformed to targets (e.g., the probability that a node belongs to a class) by general neural networks (e.g., MLP). There are mainly classiî€›cation, prediction and regression tasks on graphs, including three levels: node, edge, and subgraph. Despite the disparity of various tasks, there is a standard procedure for model optimization. Speciî€›cally, relevant embeddings will be mapped and come with labels to formulate the loss function, and then existing optimizers are utilized for model learning. Following this process, there are several types of mapping functions (e.g., MLP, inner product) and loss functions (e.g., pair-wise, point-wise) to choose for speciî€›c tasks. For pair-wise loss function, the discrimination between positive and negative samples is encouraged, and a typical formulation 14 Gao et al. where ğœ (Â·) is the sigmoid function. and denote positive and negative samples respectively, and ğ‘  (Â·) is for measuring the samples. For point-wise loss function, it includes mean square error (MSE) loss, cross-entropy loss and so on. For a better understanding, we take link prediction and node classiî€›cation tasks as examples to elaborate on how the GNN model is optimized. For link prediction, the likelihood that whether an edge exists between two nodes requires deî€›nition. Technically, it is usually calculated based on similarity with node embeddings in each layer of propagation: In terms of node classiî€›cation, node embedding will be transformed to a probability distribution representing which class it belongs to, shown as follows, In short, optimization in GNN-based models treats representations generalized by GNNs as input and graph structures (e.g., edges, node classes) as labels, and loss functions are deî€›ned for training. Over the past decade, recommender systems have evolved rapidly from traditional factorization approaches to advanced deep neural networks based models. Particularly, GNN based recommenders have achieved the state-of-the-art in many aspects, including diî€erent recommendaiton stages, scenarios, objectives, applications. The success of GNN based recommenders can be explained from the following three perspectives: (1) structural data; (2) high-order connectivity; (3) supervision signal. Structural data. Data collected from online platforms comes in many forms, including user-item interaction (rating, click, purchase, etc.), user proî€›le (gender, age, income, etc.), item attribute (brand, category, price, etc.), and so on. Traditional recommender systems are not capable of leveraging those multiple forms of data, and they usually focus on one or a few speciî€›c data sources, which leads to sub-optimal performance since much information is ignored. By expressing all the data as nodes and edges on a graph, GNN provides a uniî€›ed way to utilize available data. Meanwhile, GNN shows strong power in learning representations, and thus, high-quality embeddings for users, items, and other features can be obtained, which is critical to the recommendation performance. High-order connectivity. Recommendation accuracy relies on capturing similarity between users and items, and such similarity is supposed to be reî€ected in the learned embedding space. Speciî€›cally, the learned embedding for a user is similar to embeddings of items that are interacted by the user. Furthermore, those items that are interacted by other users with similar preferences are also relevant to the user, which is known as the collaborative î€›ltering eî€ect, and it is of great importance for recommendation accuracy. In traditional approaches, the collaborative î€›ltering eî€ect is only implicitly captured since the training data is mainly interaction records that only contain directly connected items. In other words, only î€›rst-order connectivity is taken into consideration. The absence of high-order connectivity can largely damage recommendation performance. In contrast, GNN based models can eî€ectively capture high-order connectivity. Speciî€›cally, the collaborative î€›ltering eî€ect can be naturally expressed as multi-hop neighbors on the graph, and it is incorporated in the learned representations through embedding propagation and aggregation. Supervision signal. Supervision signals are usually sparse in the collected data, while GNN based model can leverage semi-supervised signals in the representation learning process to alleviate this problem. Take the E-Commerce platform as an example; the target behavior, purchase, is pretty sparse compared to other behaviors. Therefore, recommender systems that only use the target behavior may achieve poor performance. GNN based models can eî€ectively incorporate multiple non-target behaviors, such as search and add to cart, by encoding semi-supervised signals over the graph, which can signiî€›cantly improve recommendation performance [ 67 ]. Meanwhile, self-supervised signals can also be utilized by designing auxiliary tasks on the graph, which further improves recommendation performance. 16 Gao et al. Although it is well motivated to apply graph neural networks in recommender systems, there exist four parts of critical challenges. â€¢ How to construct appropriate graphs for speciî€›c tasks? â€¢ How to design the mechanism of information propagation and aggregation? â€¢ How to optimize the model? â€¢ How to ensure the eî€œciency of model training and inference? In the following, we will elaborate on the four challenges one by one. Obviously, the î€›rst step of applying graph neural networks is to construct graphs. This is in two folds: constructing the data input as graph-structured data; reorganize the recommendation goal as a task on the graph. Taking the task of standard collaborative î€›ltering as an example, the data input is the observed user-item interaction data, and the output is predictions of the missing user-item interactions. Therefore, a bipartite graph with users/items as nodes and interactions as edges can be constructed. Besides, the CF task turns to the user-item link prediction on the graph. However, it is challenging to construct graphs that can well handle the task properly. It should be carefully implemented with the consideration of the following aspects. â€¢ Nodes. One of the main goals of learning with graph neural networks is to assign nodes the representations. This results in that the deî€›nition of nodes largely determines the scale of the GNN models, of which the majority of parameters are occupied by the layer-0 node embeddings. Note that edge embeddings are usually either not considered or computed based on node embeddings. On the other hand, it is also a challenging problem to determine whether to distinguish diî€erent types of nodes. For example, in the collaborative î€›ltering task, user nodes and item nodes can be modeling diî€erently or considered as the same kind of nodes. Another challenging point is to handle concrete input such as some numerical features like item prices, which are always continuous numbers. To represent these features in the graph, one possible solution is to discretize them to categorical ones, which can be then represented as nodes [207]. â€¢ Edges. The deî€›nition of edges highly aî€ects the graphâ€™s quality in further propagation and aggregation, along with the model optimization. In some trivial tasks, the data input of the recommender system can be considered as a kind of relational data such as user-item interactions or user-user social relations. In some complex tasks, other relations can also be represented as edges. For example, in bundle recommendation, a bundle consists of several items. Then the edge connecting the bundle and item can reî€ect the relation of aî€œliation. Good designs of edges when constructing a graph should fully consider the graph density. A too-dense graph means there are nodes with extremely high degrees. This will make the embedding propagation conducted by a very large number of neighbors. It will further make the propagated embedding non-distinguished and useless. To handle too dense edges, sampling, î€›ltering, or pruning on graphs are promising solutions. A too-sparse graph will also, of course, results in the poor utility of embedding propagation since the propagation will be conducted on only a small fraction of nodes. user-item interaction graph, it captures the item-based CF eî€ect. The weights refer to the diî€erent importance of historically interacted items. In the propagation, there are also various choices of aggregation functions, including mean pooling, LSTM, max, min, etc. Since there is no single choice that can perform the best among all recommendation tasks or diî€erent datasets, it is vital to design a speciî€›c and proper one. Besides, the diî€erent choices of propagation/aggregation highly aî€ect the computation eî€œciency. For example, mean pooling is widely used in GNN-based recommendation models since it can be computed eî€œciently, especially for the graph containing high-degree nodes, such as very popular items (which can connect a large number of users). Also, the propagation/aggregation layers can be stacked to help nodes access higher-hops neighbors. Too shallow layers make the high-order graph structure cannot be well modeled, and too deep ones make the node embedding over-smoothed. Either one of the two cases will lead to poor recommendation performance. To optimize the graph neural network-based recommendation models, the traditional loss functions in recommender system always turn to graph learning losses. For example, the logloss in the optimization can be regarded as the point-wise link prediction loss. Similarly, BPR loss [ 126 ] is usually adopted in the link prediction task on graphs. Another aspect is data sampling. In GNNbased recommendation, to sample positive or negative items, the sampling manner can highly depend on the graph structure. For example, in social recommendation, performing random walk on the graph can generate weak positive items (such as items interacted by friends). In addition, sometimes, GNN-based recommendation may involve multiple tasks, such as the link prediction tasks on diî€erent types of edges. Then in such a case, how to balance each task and make them enhance each other is challenging. In the real world, recommender systems should be trained/inferred eî€œciently. Therefore, to ensure the application value of GNN-based recommendation models, its computation eî€œciency should be seriously considered. Compared with traditional non-GNN recommendation methods such as NCF or FM, GNN modelsâ€™ computation cost is far higher. Especially for the spectral GNN models such as GCN, complex matrix operations are involved in each GCN layer. With multi-layer stacking of GCN layers, the computation cost further increases. Therefore, spatial GNN models such as PinSage can be easier to be implemented in large-scale industrial applications. With sampling among neighbors or pruned graph structure, eî€œciency can always be kept as long as we can bear the drop of recommendation performance. In recent years, GNN has been applied to a wide range of recommendation tasks. Here we deî€›ne the taxonomy in terms of recommendation stages, scenarios, objectives, and applications, respectively. To be more speciî€›c, recommendation stages indicate the overall procedure that a recommender system is implemented in the real-world platform. The procedure includes matching for item candidates selection, ranking for capturing user preferences, and re-ranking for other criteria beyond accuracy. The recommendation scenarios including social recommendation, sequential recommendation, cross-domain recommendation, etc. The recommendation objectives incorporate accuracy, diversity, explainability, fairness, and so on, in which accuracy is of the most concern. The recommendation application refers to speciî€›c industrial applications. Table 2, 3, and 4 show 18 Gao et al. representative researches of GNN-based recommendation published in top-tier venues for diî€erent recommendation stages, recommendation scenarios, and recommendation objectives, respectively. 4.2.1 GNN in Matching. In the matching stage, eî€œciency is an essential problem because of the high computation complexity for candidates selection. Speciî€›cally, only hundreds of items will be selected from the item pool of million magnitudes for the following ranking stage, based on coarse-grained user preferences. Therefore, proposed models in this stage barely leverage user-item interactions as data input for modeling user preferences, without introducing additional features such as user ages, item price, browsing time on the application, etc. GNN-based models in the matching stage can be regarded as embedding matching, usually designing specialized GNN architecture on the user-item bipartite graph [ 137 153 154 161 ]. Berg et al. [ ] proposed to pass neighborhood messages by summing and assign weight-sharing transformation channels for diî€erent relational edges (i.e., user-item ratings). Wang et al. [ 153 proposed a spatial GNN in recommendation and obtain superior performance compared with conventional CF methods like MF [ 74 ] or NCF [ 56 ]. Sun et al. [ 137 ] argued that simple aggregation mechanisms like sum, mean, or max, cannot model relational information among neighbors and proposed a neighbor interaction-aware convolution to address the issue. Wang et al. [ 154 ] developed disentangled GNN to capture independent user intentions, which extends the set of candidate items in matching and guarantees the accuracy simultaneously. Wu et al. [ 161 ] leverage the stability of graph structure to incorporate a contrastive learning framework to assist representation learning. These GNN-based models are capable of capturing high-order similarity among users and items as well as structural connectivity. In this way, the semantics that users with similar interactions will have similar preferences are extended through multiple times of information propagation. On the other hand, the training complexity of GNN-based models were demonstrated [ 153 154 ] acceptable and comparable with non-graph models, especially when the transformation matrix is removed [ 55 ]. Besides, [ 188 ] showed that GNN-based model could be applied to web-scale recommender system in real-world platforms eî€œciently and eî€ectively, which combines random walk and GraphSAGE [ 52 for embedding learning on a large-scale item-item graph. Table 5 shows the commonality and diî€erence among the GNN models in matching. In a nutshell, GNN can be applied to recommendation tasks eî€ectively, which balances the accuracy and eî€œciency of generating candidates from the item pool. embedding vectors. These feature embeddings are directly concatenated and fed into DNN [ 26 48 or speciî€›cally designed models [ 56 125 133 ] in an unstructured way to estimate the ranking score. The main challenge of utilizing GNN for ranking is designing proper structures to capture feature interactions. Speciî€›cally, GNN-based ranking models usually consist of two components, encoder and predictor, which address feature interaction from diî€erent directions. On the one hand, special graph structures can be designed in the encoder to capture the desired feature interactions. On the 20 Gao et al. other hand, feature interaction can be taken into consideration in the predictor, where the ranking score is estimated by integrating diî€erent feature embeddings from the GNN encoder. Li et al. [ 87 ] propose Feature Interaction Graph Neural Networks (Fi-GNN), which constructs a weighted fully connected graph of all the input features. The encoder in Fi-GNN is composed of a GAT and a GRU, and the predictor is achieved with attention networks. Zheng et al. [ 206 207 investigate the inî€uence of price feature in ranking and propose a model called Price-aware User Preference modeling (PUP). They design an encoder with GCN on a pre-deî€›ned heterogeneous graph to capture price awareness, and a two-branch factorization machine is utilized as the predictor. Since not all feature interactions are useful, -SIGN [ 135 ] automatically detects beneî€›cial feature interactions and only reserves those edges, resulting in a learned graph which is further fed into a graph classiî€›cation model to estimate the ranking score. In addition, Guo et al. [ 50 ] propose DG-ENN with a dual graph of an attribute graph and a collaborative graph, which integrates the information of diî€erent î€›elds to reî€›ne the embedding for ranking. Furthermore, SHCF [ 79 and GCM [ 160 ] utilize extra nodes and edge attributes to represent item attributes and context information, respectively. Classical interaction predictors are adopted, such as inner product and FM. Table 6 illustrates the diî€erences of the above GNN based ranking models in terms of the designs of encoder and predictor. 4.2.3 GNN in Re-ranking. After obtaining the scores of recommended items, top items are further re-ranked with pre-deî€›ned rules or functions to improve the recommendation quality. Speciî€›cally, two key factors need to be considered in re-ranking. First, diî€erent items can have mutual inî€uence by certain relationships such as substitutability and complementarity. Second, diî€erent users tend to have distinct preferences, and thus re-ranking can also be personalized. GNN provides a uniî€›ed way to encode both item relationships and user preferences. Liu et al. [ 94 ] propose a model called IRGPR to accomplish personalized re-ranking with the help of GNN. They propose a heterogeneous graph to fuse the two information sources, one item relation graph to capture multiple item relationships, and one user-item scoring graph to include the initial ranking scores. User and item embeddings are obtained after multiple message propagation layers, including global item relation propagation and personalized intent propagation. The î€›nal order of re-ranked items is generated with a feed-forward network. 4.3.1 GNN in Social Recommendation. In social recommendation, we have social networks that contain the social relations of each user, and the goal is to utilize the local neighborsâ€™ preferences for each user in social networks to enhance the user modeling [ 17 138 165 166 ]. From the perspective of representation learning with GNN, there are two key considerations in social recommendation: 1) how to capture the social factor; 2) how to combine the social factor from friends and user preference from his/her interaction behaviors. Here, we î€›rst summarize how the existing works capture the social factors from two perspectives, i.e., graph construction, and information propagation. 22 Gao et al. recursively propagate embeddings along the social network for reî€ecting the inî€uence of highorder neighbors in the user representations. To further improve the recommendation performance, some works [ 63 134 182 196 ] introduce side information when constructing the graph. RecoGCN [ 182 ] uniî€›es users, items, and selling agents into a heterogeneous graph to capture the complex relations in social E-commerce. GBGCN [ 196 ] constructs a graph for organizing user behaviors of two views in group-buying recommendation, of which the initiator view contains those initiator-item interactions and the participant view contains those participant-item interactions. DGRec [ 134 ] and TGRec [ ] introduce temporal information of user behaviors into social recommendation. KCGN [ 63 ] proposes to capture both user-user and item-item relations with the developed knowledge-aware coupled graph. â€¢ Information propagation. As for the propagation on the constructed graph for social recommendation, there are two main propagation mechanisms, i.e., average-pooling (GCN) and attention mechanism (GAT). The methods with average-pooling mechanism [ 51 63 71 132 164 184 191 193 196 ] conduct average-pooling propagation (GCN) on social graph and treats the social inî€uence of friends equally. RecoGCN [ 182 ] conducts meta-path based GCN propagation on the constructed graph to capture both the social impact and user preference. HOSR [ 96 aggregates the information from neighbors with GCN to capture the high-order relations in social graph. MHCN [ 193 ] performs propagation with GCN on constructed hypergraph to obtain the high-order social relations. The methods with attention mechanism [ 35 98 113 134 163 167 192 ], such as GraphRec [ 35 ] and Diî€Net++ [ 163 ], assume that the social inî€uences from diî€erent neighbors on the social graph are diî€erent and assign diî€erent weights to the social inî€uences from diî€erent friends. In social recommendation, user representations are learned from two distinct perspectives, i.e. social inî€uence and user interactions. To combine the user representations from the above two perspectives, there are two strategies, 1) separately learn user representations from the social graph and user-item bipartite graph and 2) jointly learn user representations from the uniî€›ed graph that consists of social graph and user-item bipartite graph. The methods with the î€›rst strategy, such as Diî€Net [ 164 ], GraphRec [ 35 ] and MHCN [ 193 ], î€›rst separately learn user representations from social graph and user-item graph, and then combines the representations with sum-pooling [ 164 193 ], concatenation [ 35 ], MLP [ 113 ] or attention mechanism [ 71 96 ]. Diî€Net++ [ 163 ], a typical method with the second strategy, î€›rst aggregates the information in the user-item sub-graph and social sub-graph with the GAT mechanism and then combines the representations with the designed multilevel attention network at each layer. Table 7 shows the diî€erences among the above approaches for social recommendation. To sum up, the development of social recommendation with GNN can be summarized in Fig. 12. Early eî€orts in Social Recommendation only model the social network with GNN, such as Diî€Net [ 164 ]. Then, the methods [ 35 51 71 98 113 132 163 164 167 184 191 192 ] that model both social network and user interactions with GNNs become the mainstream in GNN-based social recommendation. Moreover, some studies, such as MHCN [ 193 ] and HOSR [ 96 ], attempt to enhance the recommendation by modeling the high-order relations in social networks more suî€œciently. Also, there exist some works [ 63 134 182 196 ] that introduce additional information to further enhance the social recommendation. 4.3.2 GNN in Sequential Recommendation. For sequential recommendation, in order to improve the recommendation performance, it is necessary to extract as much eî€ective information as possible from the sequence, and to learn the userâ€™s interest in the sequence, including short-term interest, long-term interest, dynamic interest, etc., so as to accurately predict the next item that the user may be interested in. Some tools for sequence modeling have been used, such as Markov chains [ 25 ] or recurrent neural networks [ 69 ]. For graph neural networks, it can be well leveraged for short-term, dynamic interest modeling or representation learning in by converting the data to graph. A general pattern for sequential modeling with GNN is shown in î€›gure 13. SURGE [ 14 ] transforms the sequence of each user into an item-item graph and adaptively learns the weights of edges through metric learning, with only the stronger edges retained by dynamic graph pooling. The retained graph is converted to a sequence by position î€atten and î€›nally be used to predict the next item. Ma et al. [ 100 ] considers the short-term interest modeling in the sequence to build an item-item graph. For each item, it only builds edges with other items close to it in the sequence. This enables it to learn short-term user interests in the sequence while still 24 Gao et al. the items before and after the target item in diî€erent sequences, the representation of the item is enhanced. GPR [ 12 ] and GME [ 179 ] constructs edges between items by considering the frequency of consecutive occurrences or occurrences in the same sequence to enhance the representation. Some works are more complicated. For example, RetaGNN [ 59 ] considers the attributes of the items when constructing the graph, while STP-UDGAT [ 90 ] considers the geographic location, timestamp, and frequency in the POI recommendation. Table 8 summarizes the above works. 4.3.3 GNN in Session-based Recommendation . In session-based recommendation, the session data may contain both user interersts and noisy signals. Suppose a session for a certain user, iPhone iPad milk AirPods. Obviously, milk is likely clicked by mistake and then becomes a noise, as the session reî€ects the userâ€™s preference for electronic products. Hence, the two main considerations in session-based recommendation are 1) how to model the item transition pattern in session data, 26 Gao et al. and 2) how to activate userâ€™s core interests from noisy data. From the perspective of graph learning, the item transitions can be modeled as graph, and the information propagation on the graph can activate userâ€™s actual interests. â€¢ Graph construction. In session-based recommendation, most existing works [ 122 157 169 181 190 ] model the session data with a directed graph to capture the item transition pattern. Distinct from sequential recommendation, the session sequence in session-based recommendation is short and the user behaviors are limited, i.e., the average length of sequences in Tmall is only 6.69 [ 157 176 ]. Hence, a session graph constructed from a single session may only contain limited nodes and edges. To address the above challenge and suî€œciently capture the possible relations among items, there are two strategies, 1) straightforwardly capturing relations from other sessions, and 2) add the additional edges of the session graph. For the î€›rst strategy, APGNN [ 170 ], DGTN [ 208 ], and GAG [ 123 ] propose to enhance relations of the current session graph with related sessions, and GCE-GNN [ 157 ] leverages the global context by constructing another global graph to assist the transition patterns in the current session. DHCN [ 176 ] regards each session as a hyperedge and represents all sessions in a hypergraph to model the high-order item relations. SERec [ 24 ] enhances the global information for each session with a knowledge graph. CAGE [ 128 ] learns the representations of semantic-level entities by leveraging the open knowledge graph to improve the session-based news recommendation. MKM-SR [ 109 ] enhances the information in the given session by incorporating user micro-behaviors and item knowledge graph. COTREC [ 175 ] uniî€›es all sessions into a global item graph from item view and captures the relations among sessions by line graph from session view. DAT-MID [ 15 ] follows GCE-GNN [ 157 to construct both session graph and global graph and then learns item embeddings from diî€erent domains. TASRec [ 211 ] constructs a graph for each day to model the relations among items and enhance the information in each session. As for the second strategy, SGNN-HN [ 116 ] constructs star graph with a "star" node to gain extra knowledge in session data. SHARE [ 148 ] expands the hyperedge connections by sliding the contextual window on the session sequence. LESSR [ 23 proposes to î€›rst construct an edge-order preserving multigraph and then construct a shortcut graph for each session for enriching edge links. â€¢ Information propagation. As for the information propagation on the constructed graph, there are four propagation mechanisms that are used in session-based recommendation, e.g. gated GNN, GCN, GAT, and GraphSAGE. SR-GNN [ 169 ] and its related works [ 24 109 116 170 181 190 ] combine the gated recurrent units in the propagation (gated GNN) on the session graph. GAG [ 123 ], DCTN [ 208 ] conduct graph convolution on the constructed directed graph. DHCN [ 176 ] proposes to perform graph convolution on both hypergraph and line graph to obtain session representations from two diî€erent perspectives. Similar to DHCN [ 176 ], COTREC [ 175 performs GCN on item graph and line graph to obtain information from item and session views, respectively. CAGE [ 128 ] conducts GCN on article-level graph and TASRec [ 211 ] performs graph convolution on the dynamic graph to capture the item relations. FGNN [ 122 ] conducts GAT on a directed session graph to assign diî€erent weights on diî€erent items. SHARE [ 148 performs GAT on session hypergraphs to capture the high-order contextual relations among items. GCE-GNN [ 157 ] and DAT-MID [ 15 ] perform GAT on both session graph and global graph to capture the local and global information, respectively. MGNN-SPred [ 150 ] adopts GraphSAGE on multi-relational item graph to capture the information from diî€erent types of neighbors. SR-GNN [ 169 ], GC-SAN [ 181 ], TA-GNN [ 190 ], and FGNN [ 122 ]. Then, some methods attempt to enrich the relation and information in the session graph with other sessions or additional links. The methods in [ 15 24 109 123 128 150 157 170 175 176 208 211 ] combine the information from other sessions to capture more information from similar sessions or all sessions. Moreover, the methods with additional links, such as SGNN-HN [ 116 ], SHARE [ 148 ] and LESSR [ 23 ], attempt to introduce additional edges to the given session to capture the complex relations and information in session data. Furthermore, some studies, such as DHCN [ 176 ] and SHARE [ 148 ], attempt to enhance the recommendation by modeling the high-order relations in session data more suî€œciently. 4.3.4 GNN in Bundle Recommendation. The three challenges of bundle recommendation are 1) usersâ€™ decisions towards bundles are determined by the items the bundles contain (the aî€œliation relation), 2) learning bundle representations with the sparse user-bundle interactions, and 3) highorder relations. The earlier works approach the problem of bundle recommendation by learning from user-item interaction and user-bundle interaction together, with parameter sharing or joint loss function [ 22 118 ]. For the î€›rst time, Chang et al. [ 13 ] propose a GNN-based model that uniî€›es both two parts of interactions and the bundle-item aî€œliation-relations into one graph. Then the item can serve as the bridge for embedding propagation between user-bundle and bundle-bundle. Besides, a specially designed sampling manner for î€›nding hard-negative samples is further proposed for training. Deng et al. [ 33 ] construct a similar tripartite graph with the transformation parameters to well extract bundle representations from included itemsâ€™ representations. Zheng et al. [ 209 ] consider the bundle recommendation in the drug package dataset and propose to initialize a graph with auxiliary data and represent the interaction as scalar weights and vectors. GNN layers are proposed for obtaining the drug package embeddings. Li et al. [ 83 ] consider the problem of personalized outî€›t recommendation, which can also be regarded as a kind of bundle recommendation. The authors construct a hierarchical graph, of which the users, items, and outî€›ts are contained. GNN 28 Gao et al. layers are deployed for obtaining the representations of users and outî€›ts. The learning of the GNN model follows a multi-task manner. In summary, the data input of bundle recommendation can be well represented as graph-structural data, especially for the bundles, which have been represented as a kind of new nodes. 4.3.5 GNN in Cross-Domain Recommendation. Beneî€›t from the powerful capabilities, GNN-based recommendation model has gradually emerged in the î€›eld of cross-domain recommendation. Zhao et al. [ 204 ] construct the cross-domain graph with shared users and items from multiple domains. The proposed PPGNâ€™s embedding propagation layers can well learn the usersâ€™ preferences on multiple domainsâ€™ items under a multi-task learning framework. Liu et al. [ 92 ] propose the bidirectional knowledge transfer by regarding the shared users as the bridge. GNN layers are adopted to leverage the high-order connectivity in the user-item interaction graph for better preference learning with the user features, fuses from common features, and domain-speciî€›c features. Guo et al. [ 49 ] construct the graph for each domain and deploy domain-speciî€›c GCN layers for learning user-speciî€›c embeddings. The authors combine it with the attention mechanisms for adoptively choose important neighbors during the embedding propagation. Wang et al. [ 146 propose an encoder-decoder framework where the encoder is implemented by graph convolutional networks. Speciî€›cally, the GCNs are deployed on the user-item interaction graphs. Cui et al. [ 30 proposes to construct a heterogeneous graph, where multiple domainsâ€™ users and items can be well included. The GNN-based embedding propagation is deployed on multiple domains, where a user/item can directly absorb the information of diî€erent domains, where recurrent attention networks are used for distinguishing important neighbors. 4.3.6 GNN in Multi-behavior Recommendation. Multiple types of behaviors can provide a large amount of information to the recommender system, which helps the recommender system to learn the userâ€™s intentions better, thereby improving the recommendation performance. For recommender systems based on graph neural networks, on the basis of common user-item bipartite graphs, the multiple types of behaviors between users and items can naturally be modeled as diî€erent types of edges between nodes. Therefore, most of the multi-behavior recommendation methods based on graph neural networks are based on heterogeneous graphs. However, the focus of multi-behavior recommendation is 1) how to model the relationship between multiple behaviors and target behavior, and 2) how to model the semantics of the item through behavior, which is shown in Fig. 17. In order to model the eî€ect of auxiliary behaviors on target behaviors, the simplest method is to directly model all types of behaviors without considering the diî€erences between behaviors. Zhang et al. [ 200 ] constructs all user behaviors in one graph and performs graph convolution operations. Wang [ 150 151 ] extracts each behavior from the graph to construct a subgraph, then learns from the subgraph, and î€›nally aggregates through the gating mechanism. Chen et al. [ 16 ] proposed a intuitive method which assigns a representation to users, items, and behaviors. In the process of propagation, the representations of edges and neighbor nodes need to be composited î€›rst to obtain a new node representation, and then it can be applied to the GNN method. Through the composition operation, the representation of the node is fused with diî€erent types of behaviors. Xia et al. [ 172 also redesign the aggregation mechanism on the graph convolutional network to explicitly model 30 Gao et al. the impact of diî€erent types of behavior. Jin et al. [ 67 ] assign diî€erent learnable weights to diî€erent edges to model the importance of the behaviors. In addition, in order to capture complex multibehavior relationships, there are also some works that rely on knowledge. For example, Xia et al. [ 173 ] learns the representations in diî€erent behavior spaces, and then inject temporal contextual information into the representations to model the userâ€™s behavior dynamics, and î€›nally, through the attention mechanism, discriminate the most important relationships and behaviors for the predicted target. Xia et al. [ 174 ] uses meta-graph networks to learn meta knowledge for diî€erent behaviors and then transfer the learned meta-knowledge between diî€erent types of behaviors. In addition to modeling the inî€uence of diî€erent types of behaviors, diî€erent behaviors may contain diî€erent meanings or semantics. For example, for items added to a shopping cart, users may have similar preferences for them, or these items have a complementary relationship and generally need to be purchased at the same time. If these items are connected through a graph, the representation of the item can be enhanced. In order to get better item representation, Yu et al. [ 189 not only connects related items in the graph, but also constructs a new graph of the category that the items belong to, which is used to enhance the representation of the item. It needs to construct the item graph separately, and there are also some works that do not construct the graph separately and directly in the user-item heterogeneous graph, by using for meta-path or second-order neighbors, where similar items are aggregated to enhance their representation [ 67 173 ]. These worksâ€™ details are presented in Table 12. stacked, which propagates well-trained embeddings of frequent items to undertrained embeddings of long-tail items. In this way, long-tail item embeddings of higher quality are obtained since they share the information from frequent items; thus system-level diversity is improved with more recommendation on long-tail items. In addition, a few studies [ 66 180 ] utilize GNN to improve both individual-level and system-level diversity. Speciî€›cally, Xie et al. [ 180 ] propose FH-GAT, which addresses the challenge of weak signals by constructing a heterogeneous interaction graph to express diverse user preferences. A neighbor similarity-based loss is conducted on the heterogeneous graph to balance between accuracy and diversity. Isuî€› et al. [ 66 ] propose two GCN on the nearest neighbor (NN) graph and the furthest neighbor (FN) graph, where NN guarantees accuracy and FN enhances the weak signals of diverse items. Meanwhile, the two GCN are jointly optimized with a hyper-parameter to achieves a trade-oî€ between accuracy and diversity. Table 13 shows the diî€erences among the above approaches. 4.4.2 GNN for Explainablility. With the proliferation of GNN, researchers also make endeavors to improve the explainability of recommender systems with GNNâ€™s power of modeling logical relations. He et al. [ 54 ] construct a heterogeneous graph with three kinds of nodes, including the user, the item, and the aspect (the speciî€›c item property extracted from textual reviews). Therefore, they cast the recommendation task into a ternary relation ranking task, and propose TriRank with a high degree of explainability by explicitly modeling aspects in reviews. Inspired by this work, the following research further explores rich information in dimensions of users and items, generally organized in a form of knowledge graph, in order to enhance the explainability [ 201 ]. Ai et al. [ ] construct a knowledge graph with entities, i.e., users and items, and relations, e.g., â€œUser A purchased Item B belonging to Category Câ€. Moreover, they embed each entity for recommendation and adopt the shortest relation path between a user and an item in the 32 Gao et al. knowledge, Ma et al. [ 101 ] jointly combine the discovery of inductive rules (meta-paths) from the item-centric knowledge graph, which equips the framework with explainability and the learning of a rule-guided recommendation model. Moreover, to overcome the computational diî€œculties of enumerating all potential meta-paths, Xian et al. [ 177 ] replace the enumeration method with the reinforcement reasoning approach to identify proper meta-paths for scalability. Besides meta-path-based solutions, Wang et al. [ 152 ] propose a new method named Knowledge Graph Attention Network (KGAT), where the attention mechanism can oî€er explainability to some extent. Yang et al. [ 185 ] develop a hierarchical attention graph convolutional network to model higher-order relations in the heterogeneous knowledge graph, where the explainability is also dependent on the attention mechanism. 4.4.3 GNN for Fairness. Despite the power of graph data in recommendation, it might inherit or even amplify discrimination and the societal bias in recommendation [ 31 124 162 ]. Past research has proven that compared with models that only adopt node attributes, the user unfairness is magniî€›ed due to the utilization of graph structures [31]. To curb the fairness issue in recommendation, some researchers propose to learn fair graph embeddings [ 10 124 162 ]. Rahman et al. [ 124 ] extends the well-known graph embedding method, node2vec [ 47 ], to a more fair version, Fairwalk, which can generate more diverse network neighborhood representation for social recommendations by sampling the next node based on its sensitive attributes. Thus, all nodesâ€™ sensitive attributes are indispensable. Bose et al. [ 10 ] proposes an adversarial framework to minimize the sensitive information in graph embeddings with a discriminator enforcing the fairness constraints. Moreover, considering the evaluations of fairness can be varying, fairness constraints are î€exible according to the task. However, similar to Fairwalk [ 124 ], all nodesâ€™ sensitive attributes are required. Wu et al. [ 162 ] learn fair embeddings for recommendation from a graph-based perspective. They propose FairGo, which adopts a graph-based adversarial learning 34 Gao et al. method to map embeddings from any recommendation models into a sensitive-information-î€›ltered space, therefore eliminating potential leakage of sensitive information from both original recommendation embeddings and user-centric graph structures. Indeed, except for learning fair embeddings, Dai et al. [ 31 ] propose FairGNN, which learns fair GNN classiî€›ers with limited known sensitive attributes in an adversarial learning paradigm with fairness constraints. Diî€erent from fair graph embeddings, fair GNN classiî€›ers are to ensure node classiî€›cation task (rather than graph embeddings) independent with sensitive data. Moreover, they develop GNN-based sensitive data estimators to overcome the issue of missing sensitive data in the real world. Graph neural networks are also widely used to handle the speciî€›c challenges in diî€erent applications of recommender systems. As for e-commerce/product recommendation, most of the existing works have been introduced in the above sections. Li et al. [ 88 ] propose to stack multiple GNN modules and use a deterministic clustering algorithm to help improve the eî€œciency of GNN in large-scale e-commerce applications. Liu et al. [ 95 ] propose to leverage the topology of item-relations for building graph neural networks in e-commerce recommendation. As for the Point-of-Interest recommendation, GGLR [ 12 ] uses the sequence of POIs a user visited to construct the POI-POI graph, where the edges between POIs denote the frequency of users consecutively visiting two POIs. Zhang et al. [ 197 ] propose to combine social networks and user-item interactions together, which deploys embedding aggregation on both social-connected users and interacted POIs. As for news recommendation, Hu et al. [ 61 ] propose to introduce the preference disentanglement into the user-news embedding propagation. There are a lot of papers for speciî€›c applications, but they can be well categorized into and covered by the corresponding stages, scenarios, and objectives, and thus we omit them here. Due to the over-smoothing problem, more and more studies focus on properly increasing GNNâ€™s layers to capture higher-order connectivity correlations on graphs as well as improve modelsâ€™ performance [ 19 76 127 213 ]. Despite these advancements, there is still no universal solution for constructing very deep GNN like CNN, and relevant works propose diî€erent strategies. Lai et al. [ 76 develops a meta-policy to adaptively select the number of propagation for each graph node through training with reinforcement learning (RL). The experiment results show that partial nodes require more than three layers of propagation to boost model performance. Rong et al. [ 127 ] alleviates the over-smoothing problem by randomly removing graph edges, which acts as a message-passing reducer. Claudio et al. [ 42 ] considers GNN as a dynamic system, and learned representations are the systemâ€™s î€›xed points. Following this assumption, the transformation matrix in propagation is î€›rst î€›xed under stability conditions. Furthermore, only embeddings are updated in the learning procedure, leaving the matrix untrained. In this way, GNN can be trained faster as well as go deeper. Li et al. [ 80 ] transfer the concepts of residual/dense connections and dilated convolutions from CNNs to assist deeper GNNs. As for future works, the performance leap compared with current shallow GNNs should be an essential problem in developing very deep GNNs, like groundbreaking works in the area of CNN [ 64 141 ]. At the same time, the computation and time complexity must also be acceptable. Existing GNN-based recommendation models are almost based on the static graph, as mentioned above, while there is plenty of dynamics in recommender systems. For example, in the sequential recommendation or session-based recommendation, the usersâ€™ data is collected in a dynamic manner, naturally. In addition, modeling the dynamic user preferences is one of the most critical challenges in these recommendation scenarios. In addition, the platform may dynamically involve new users, new products, new features, etc., which poses challenges to static graph neural networks. Recently, dynamic graph neural networks [ 81 103 ] have attracted attention, which deploys graph neural networks-based models on dynamically constructed graphs. Given the time-evolving property of recommender systems, the dynamic graph neural network-based recommendation model will be a promising research direction, with broad applications in the real world. Recent research has demonstrated the power of KG in recommendation by enriching the user-item bipartite graph with knowledge [ 44 ]. Speciî€›cally, the utilization of knowledge graph with GNN signiî€›cantly addresses some practical issues in recommender systems [ 44 ], for example, cold start problem [ 34 198 ], scalability [ 183 ], and dynamicity [ 140 ]. Moreover, knowledge graph also oî€ers a novel solution to some scenarios in recommendations, e.g., sequential recommendation [ 65 155 ], and objectives, e.g., explainability [ 152 185 ]. Currently, the majority of research î€›rst uses GNN to learn embeddings of knowledge graphs and then incorporate these embeddings into the recommendation model, so that an end-to-end model can be trained [ 145 ]. Therefore, we point out the utilization of KG in recommendation with GNN can be further enhanced from perspectives of data, scenario, and model. Speciî€›cally, the incorporated KG mostly records the rich item-item relations, e.g., Movie A belongs to Category B [ 44 ], but user-user knowledge is lacking in formal and plausible deî€›nition and thus substantially overlooked. Future work can consider creating user-centric KG on the foundation of abundant knowledge in sociology. Moreover, considering its success in scenarios, such as sequential recommendation [ 65 155 ], it is promising that the leverage of KG could further enhance recommendation quality from the aspects that require more external knowledge, such as diversity and fairness. Further, existing methods on leveraging KG in recommendation cannot fully model complex relations between a user and a speciî€›c item or its attributes. Thus, designing a better framework to carve out these complex relations is another future direction. Early works on GNN follow the full-batch gradient descent algorithm, where the whole adjacency matrix is multiplied on the node embeddings during each inference step, which can not handle real-world recommender systems since the number of nodes and edges can reach a million-level scale. Hamilton et al. propose GraphSAGE [ 52 ] which performs neighbor sampling and only updates the related sub-graph instead of the whole graph during each inference step. The sampling strategy is also adopted in a few other works [ 21 27 ] which reduce the computation complexity of GNN and improve the scalability. Ying et al. [ 188 ] successfully apply GraphSAGE to web-scale recommender systems, which can eî€œciently compute embeddings for billions of items. In addition, a few opensource tools have been released which can accelerate the research and development of GNN-based recommendation, such as PyG [ 39 ], DGL [ 149 ] and AliGraph [ 214 ]. We refer to another survey [ for details on computing and accelerating GNN. Despite these existing approaches, how to achieve large-scale GNN based recommendation is still a challenging task, especially in the ranking stage 36 Gao et al. where thousands of features are involved, which results in a large and complicated heterogeneous graph. The direct supervision from interaction data is relatively sparse compared with the scale of the graph. Therefore, it is necessary to include more supervision signals from the graph structure itself or the recommendation task. For example, Yu et al. [ 194 ] and Wu et al. [ 161 ] attempt to enhance GNN-based recommendation by designing auxiliary tasks from the graph structure with self-supervision. Data augmentations such as node dropout are utilized to generate sample pairs for contrastive training. We believe that it is a promising future direction to leverage extra selfsupervised tasks to learn meaningful and robust representations for GNN-based recommender systems. In existing recommender systems, there may exist the issue of information asymmetry that the system can only estimate usersâ€™ preferences based on their historically collected behavior data. To address it, recently, conversational (interactive) recommendation researches [ 77 139 ], propose the new paradigm the user can interact with the system in conversations, and then new data can be dynamically collected. Speciî€›cally, users can chat with the system to explicitly convey their consumption demands or oî€er positive/negative feedback on the recommended items. As future work, the advances of representation learning with graph neural networks can be combined with preference learning in the conversational recommendation. Recommendation scenarios are diverse and largely diî€erent from each other; thus, there exists no silver bullet GNN model that can generalize across all scenarios. Recently, AutoML (Automated Machine Learning) [ 187 ] is proposed, which can automatically design appropriate models for speciî€›c tasks. With respect to GNN-based recommendation, the search space is quite large, which includes multiple options for the neighbor sampler, aggregator, interaction function, and so on. As a consequence, AutoML can, to a great extent, reduce human eî€ort in discovering advanced model structures. A few works [ 45 62 ] have been proposed which search to combine GNN layers and aggregate neighbors. However, designing AutoML algorithms to search for GNN based recommender systems is a largely unexplored yet promising future direction. There is a rapid development of graph neural networks models in the research î€›eld of recommender systems. This paper provides an extensive survey systematically presenting the challenges, methods, and future directions in this area. Not only the history of development and also the most recent advances are well covered and introduced. We hope this survey can well help both junior and experienced researchers in the relative areas. 38 Gao et al. 40 Gao et al. 42 Gao et al. 44 Gao et al. 46 Gao et al.
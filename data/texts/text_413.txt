{shuyuan.xu,juntao.tan}@rutgers.edu,{shelby.heinecke,jia.li}@salesforce.com,yongfeng.zhang@rutgers.edu Recommender systems may be confounded by various types of confounding factors (also called confounders) that may lead to inaccurate recommendations and sacriî€›ced recommendation performance. Current approaches to solving the problem usually design each speciî€›c model for each speciî€›c confounder. However, realworld systems may include a huge number of confounders and thus designing each speciî€›c model for each speciî€›c confounder is unrealistic. More importantly, except for those â€œexplicit confoundersâ€ that researchers can manually identify and process such as itemâ€™s position in the ranking list, there are also many â€œlatent confoundersâ€ that are beyond the imagination of researchers. For example, usersâ€™ rating on a song may depend on their current mood or the current weather, and usersâ€™ preference on ice creams may depend on the air temperature. Such latent confounders may be unobservable in the recorded training data. To solve the problem, we propose a deconfounded causal collaborative î€›ltering model. We î€›rst frame user behaviors with unobserved confounders into a causal graph, and then we design a front-door adjustment model carefully fused with machine learning to deconfound the inî€uence of unobserved confounders. The proposed model is able to handle both global confounders and personalized confounders. Experiments on real-world datasets show that our method is able to deconfound unobserved confounders to achieve better recommendation performance. Recommender Systems; Deconfounded Recommendation; Causal Analysis Recommender systems occupy an expanding role in daily decision making, such as e-commerce, video streaming and social media. Most of the existing recommendation models learn from the collective historical interactions to achieve good recommendation performance. However, the collected data may be confounded by various types of confounders that aî€ect both treatment assignment (which item is exposed) and outcome (whether the user likes the item). As a result, the collected data may not represent the accurate preference of users. Recommendation algorithms that are trained with confounded data may result in inaccurate recommendations and sacriî€›ced performance. The existence of confounders naturally leads to a question: can we develop models to eliminate the inî€uence of confounders so as to estimate more accurate user-item preferences? Current approaches to answering this question usually identify a speciî€›c confounder based on researchersâ€™ expertise and design a speciî€›c model to tackle this confounder. For instance, many models are proposed to handle the popularity confounders [13,35,40â€“43], click Figure 1: Examples of global and personal confounders. confounders [28,30,31], exposure confounders [1,9,27,38], etc. Existing eî€orts have performed well on combating these manually identiî€›ed confounders. However, real-world systems may involve a huge number of confounders, which makes it unrealistic to design each speciî€›c model for each speciî€›c confounder. Moreover, the confounders are not limited to the â€œexplicit confoundersâ€ that can be manually identiî€›ed by experts based on their knowledge, but also include many â€œlatent confoundersâ€ that can be hardly identiî€›ed or measured. For example, a userâ€™s interaction and rating with music recommendations can be aî€ected by his/her current mood or spirit, however, the mood or spirit cannot be quantitatively measured or logged in the training data. The large number of confounders and the existence of latent confounders make it important to develop â€œuniversalâ€ deconfounded recommendation models that are agnostic to certain types or certain numbers of confounders. Broadly speaking, the confounders can be classiî€›ed into global confounders and personal confounders, as shown in Figure 1. Global confounders are those that inî€uence user preferences in a consistent way, while personal confounders are those that aî€ect diî€erent users diî€erently. For example, the air temperature can be a global confounder for usersâ€™ preferences on ice creamsâ€”during normal times, some users tend to like ice creams while others tend to dislike ice creams, however, an extremely high temperature may increase both groupsâ€™ likeness on ice creams. On the other hand, the weather can be a personal confounder for usersâ€™ preferences on household PlayStations such as Xbox. For example, some users like sunny days and they choose to take outdoor activities, as a result, their preferences on playstations decrease when sunny while increase when rainy since they have to stay at home. However, some other users may dislike sunny days due to skin protection reasons and thus they choose to stay at home when sunny with an increased preference on playstations, while their preference on playstation decreases when rainy since they choose to go out when the UV exposure is low. This complex nature of confounders makes it challenging to design deconfounded recommendation models. Fortunately, causal inference techniquesâ€”especially front-door adjusted modelsâ€”make it possible to design a uniî€›ed deconfounding model for both global and personal confounders. In particular, the user, item, and preference can be formulated into a causal graph, while unobserved global or personal confounders present possible connections to the user, item and preference nodes (Figure 1). Technically, we identify a mediatorğ‘€between item and preference that is independent from the inî€uence of confounders (Figure 3, more details later). Based on mediator analysis, we are able to estimate the deconfounded user-item preferenceğ‘ƒ (ğ‘¦|ğ‘¢, ğ‘‘ğ‘œ(ğ‘£))based on front-door adjustments rooted in causal theory, whereğ‘¢, ğ‘£is a pair of user and item, andğ‘¦is the preference score between them. In the experiments, we compare our model with both state-ofthe-art deconfounded recommendation algorithms and traditional association-based recommendation models. The results show that our deconfounded algorithm achieves better recommendation performance than all of the baselines. In summary, we list our key contributions as following: â€¢We design a causal graph to represent the eî€ects of unobserved confounders in the recommendation scenario. â€¢To mitigate the eî€ects of unobserved confounders which are not directly measurable, we adapt the front-door adjustment into the proposed deconfounded causal collaborative î€›ltering. â€¢We design a sample-based approach integrated with exposure models to make the front-door adjustment calculable despite the large item space. â€¢Experiments on two real-world datasets show that our deconfounded model outperforms existing deconfounded recommendation models and traditional association-based models. The remainder of this paper is organized as follows. We discuss the related works in Section 2. In Section 3, we introduce some notations, basic concepts and theorems to help readers gain a better understanding of the fundamentals. We introduce our proposed model in Section 4. In Section 5, we experiment on real-world datasets and make discussions. Finally, we conclude the work and discuss future directions in Section 6. Deconfounded recommender systems aim to remove or reduce the unwanted eî€ect of confounders, which is important to the accurate estimation of user preferences. Among the large number of methods mitigating the confounding eî€ects, causal technique plays an important role. Inverse Propensity Score (IPS) based method is an important approach for deconfounding. The basic idea is to re-weight the observations with inverse propensity scores so as to mitigate the inî€uence of selection bias [28,31], exposure bias [27,38], position bias [3,8,11,29], etc. IPS-based methods are well used approaches for deconfounded learning with observational data, but they still suî€er from some known issues. For example, the performance of IPS-based methods highly depends on the accurate estimation of propensity scores [26] and usually suî€ers from the high variance of the propensity scores [5]. Besides IPS, leveraging causal graph is a powerful approach to deconfounded recommendation. Many existing methods construct a speciî€›c causal graph based on certain assumptions to incorporate speciî€›c confounders into the data generation process, and then apply causal inference techniques to mitigate the confounding bias. Just to name a few as examples, Zhang et al. [40] assume that item popularity aî€ects the item exposure and user interaction, and constructed a causal graph incorporated with item popularity to estimate the user-item preferences; Qiu et al. [22] observed visual bias in visual-aware recommendation and that usersâ€™ attention to visual features does not always reî€ect the real preference, and thus developed a causal graph to remove the eî€ect of visual confounders. Li et al. [14] noticed that usersâ€™ sensitive features may lead to unfair recommendations and thus developed causal graphs to deconfound the inî€uence of sensitive features in recommendation; Wang et al. [30] identiî€›ed that user clicks may be inî€uenced by item popularity and proposed a deconfounding method to alleviate the ampliî€›cation of popularity bias. Many other research works are conducted to address diî€erent types of confounders, including but not limited to item popularity [2,7,13,35,41â€“43], item exposure [1,9,27,33, 34,38], user selection [16,19,28,30,31], and ranking positions [3, 4, 10, 18, 21, 36]. However, due to the large number of confounders and the existence of unobserved latent confounders, it is unrealistic to design each speciî€›c model to tackle each speciî€›c confounder. Some recent works took advantage of a subset of unbiased data as supervision to remove confounding eî€ects [6,39]. However, unbiased data may not always exist and collecting unbiased data can be diî€œcult since randomized recommendations may hurt the user experience. As a result, a broad-spectrum deconfounded recommendation model to mitigate the confounding eî€ects based on observed data is urgently needed. As we will show later, we incorporate the unobserved confounders into the causal graph and leverage front-door adjustments to mitigate the eî€ect of confounders, which is able to deconfound recommender systems based on observed data without the need to enumerate confounders or collect unbiased datasets. In this section, we introduce the notations used in this paper, as well as some concepts and theorems in causal inference so as to prepare readers with the basics. In this paper, we use uppercase letters to represent random variables. In particular, we useğ‘ˆ ,ğ‘‰ , ğ‘€, ğ‘Œ,ğ¶to represent user, item, mediator, preference, and confounders. We use lowercase letters to indicate the speciî€›c value of a random variable. In particular, we useğ‘¢, ğ‘£, ğ‘š,ğ‘¦ to indicate a speciî€›c user, item, mediator, and preference value. We use uppercase calligraphy to represent set. For exampleU = {ğ‘¢, ğ‘¢, Â· Â· Â· , ğ‘¢}is user set andV = {ğ‘£, ğ‘£, Â· Â· Â· , ğ‘£}is item set. Moreover, we use bold font lowercase to represent the latent vector embedding of users, items and mediators, such asu, v âˆˆ R, m âˆˆ R, whereğ·andğ·are the dimensions of the embedding vectors and they are not necessarily equal. Figure 2: ğ‘‹ represents treatment variable, ğ‘Œ represents outcome variable, ğ‘€ represents mediator variable, ğ¶ represents confounder variable. Figure (a) shows variable ğ¶ as observed and measurable, while in Figure (b), variableğ¶ is unobserved or unmeasurable. In this section, we will introduce back-door adjustment and frontdoor adjustment in causal inference. We will mathematically illustrate why back-door adjustment is not applicable in our setting and why we use front-door adjustment instead. Definition 1. (Back-door Criterion) [20, p.61] Given an ordered pair of variables(ğ‘‹, ğ‘Œ )in a causal graphG, a set of variablesğ‘ satisî€›es the back-door criterion with respect to(ğ‘‹, ğ‘Œ )ifğ‘satisî€›es the following conditions: â€“ No node in ğ‘ is a descendant of ğ‘‹ ; â€“ ğ‘ blocks every path between ğ‘‹ and ğ‘Œ that contains an arrow into ğ‘‹ . With the help of a set of variables that satisfy the back-door criterion, we can adjust for the eî€ect of measured confounders. We take the causal graph in Figure 2(a) as an example. Considering the treatment variableğ‘‹and the outcome variableğ‘Œ, we want to estimate the eî€ect ofğ‘‹onğ‘Œ, which is denoted asğ‘ƒ (ğ‘Œ = ğ‘¦|ğ‘‘ğ‘œ (ğ‘‹ = ğ‘¥)). Due to the existence of confounderğ¶, we cannot conclude that ğ‘ƒ (ğ‘Œ = ğ‘¦ |ğ‘‘ğ‘œ(ğ‘‹ = ğ‘¥)) = ğ‘ƒ (ğ‘Œ = ğ‘¦|ğ‘‹ = ğ‘¥). However, since variableğ¶ satisî€›es the back-door criterion, we use it to adjust the eî€ect, in other words, we are accounting for and measuring all confounders [24]. Therefore, we compute ğ‘ƒ (ğ‘Œ = ğ‘¦|ğ‘‘ğ‘œ(ğ‘‹ = ğ‘¥)) as follows:îƒ• ğ‘ƒ (ğ‘Œ = ğ‘¦ |ğ‘‘ğ‘œ(ğ‘‹ = ğ‘¥)) =ğ‘ƒ (ğ‘Œ = ğ‘¦ |ğ‘‹ = ğ‘¥, ğ¶ = ğ‘)ğ‘ƒ (ğ¶ = ğ‘) (1) The above equation is based on the assumption that the confounder variable, which also satisî€›es the backdoor criterion, is measurable. However, in recommender systems, there may exist various unobserved or unmeasurable confounding variables. To address this setting, we introduce the front-door criterion. Definition 2. (Front-door Criterion) [20, p.69] Given an ordered pair of variables(ğ‘‹, ğ‘Œ )in a causal graphG, a set of variablesğ‘ satisî€›es the front-door criterion with respect to(ğ‘‹, ğ‘Œ )ifğ‘satisî€›es the following conditions: â€“ ğ‘ intercepts all directed paths from ğ‘‹ to ğ‘Œ . â€“ There is no unblocked path from ğ‘‹ to ğ‘. â€“ ğ‘‹ blocks all back-door paths from ğ‘ to ğ‘Œ . Given a set of variables that satisî€›es the front-door criterion, we can identify the causal eî€ect with unobserved confounders. Definition 3. (Front-door Adjustment) [20, p.69] If a set of variablesğ‘satisfy the front-door criterion related to an ordered pair of variables(ğ‘‹, ğ‘Œ ), and ifğ‘ƒ (ğ‘¥, ğ‘§) >0, then the causal eî€ect ofğ‘‹onğ‘Œ is identiî€›able and is given by We take Figure 2(b) as an example. Although variableğ¶satisî€›es the back-door criterion, it is not measurable, so the back-door adjustment (Eq.(1)) cannot be applied in this example. Although the back-door adjustment is not applicable here, given that variableğ‘€satisî€›es the front-door criterion, we can use the front-door adjustment to handle unmeasurable or unobserved confounders. Intuitively, the desired eî€ect can be expressed as follows Since the only parent node of variableğ‘€isğ‘‹, and variableğ‘€ satisî€›es the back-door criterion with respect to(ğ‘€, ğ‘Œ )so that we can apply back-door adjustment forğ‘ƒ (ğ‘¦|ğ‘‘ğ‘œ(ğ‘š)), therefore, Eq.(3) can be further derived asîƒ•îƒ• We can see Eq.(4)is exactly the front-door adjustment as Eq.(2). In this section, we î€›rst introduce our designed causal graph depicting user behaviors with unobserved confounders. We then elaborate on our deconfounded causal collaborative î€›ltering model based on the front-door adjustment. We î€›rst formulate the process of user-system interaction as a causal graph. First, the user will determine which recommended item(s) to interact with. Then, according to the corresponding item features (not aî€ected by other variables), user will reveal his or her preference feedback on the item. The whole process can be aî€ected by confounders. Combining global confounders and personal confounders as introduced in Figure 1, we design the causal graph as shown in Figure 3. In this causal graph, we are actually taking item features as mediators between item nodeğ‘‰and preference nodeğ‘Œ, i.e.,ğ‘€is not directly inî€uenced by user nodeğ‘ˆand confoundersğ¶. This is intuitive and reasonable because item features such as the color or brand of products and the genre or director of movies are inherent and î€›xed properties of an item, which are not inî€uenced by users or external confounders. It is worth clarifying that the causal graph is used for describing how data is generated. We ultimately build a recommendation model that can leverage this causal graph to produce better estimations of user preferences. In this section, we estimate user preference from a causal view. In particular, we estimate a userâ€™s preference if a certain item is recommended to the user, which can be represented asğ‘ƒ (ğ‘¦|ğ‘¢, ğ‘‘ğ‘œ(ğ‘£)). The estimation of the preference scoreğ‘ƒ (ğ‘¦|ğ‘¢, ğ‘‘ğ‘œ(ğ‘£))is based on the designed causal graph in Figure 3. Although there exist a set of variables{ğ¶,ğ‘ˆ }that satisfy the back-door criterion in Figure Figure 3: The meaning of variables are: ğ‘ˆ represents user, ğ‘‰ represents item, ğ‘€ represents mediator (e.g. item feature), ğ‘Œ represents userâ€™s preference, and ğ¶ represents unobserved confounders. Dashed nodes represent unobserved variables and dashed arrows represent causal relations pointing from unobserved variables. 3, the back-door adjustment (as Eq.(1)) is not applicable because variableğ¶is unobserved or unmeasurable. Therefore, we apply front-door adjustment to estimate userâ€™s preference towards items with unobserved confounders. We estimate preference score of a (ğ‘¢, ğ‘£) pair as follow: ğ‘ƒ (ğ‘¦|ğ‘¢, ğ‘‘ğ‘œ(ğ‘£)) =ğ‘ƒ (ğ‘š|ğ‘£)ğ‘ƒ (ğ‘£|ğ‘¢)ğ‘ƒ (ğ‘¦|ğ‘¢, ğ‘£ whereğ‘¦represents preference score andğ‘šrepresents item features. For simplicity, we treat item features as values retrieved from the dataset. We deî€›ne ğ‘ƒ (ğ‘š|ğ‘£) as follows whereğ¹:V â†’ Mis a database retrieval function which returns item feature from the dataset. It is worth mentioning that the item features can be extracted from many sources, such as image or text information. Combining Eq.(5)and Eq.(6), we can rewrite the estimation of ğ‘ƒ (ğ‘¦|ğ‘¢, ğ‘‘ğ‘œ(ğ‘£)) as follow: whereğ‘š= ğ¹ (ğ‘£)is the feature representation of itemğ‘£.ğ‘ƒ (ğ‘¦|ğ‘¢, ğ‘‘ğ‘œ(ğ‘£)) is calculated by a weighted average over all items as denoted in Eq.(7). However, real-world systems may include a large scale of items, therefore, it is unrealistic to involve all items to estimate the preference of a user-item pair. To tackle this issue, we modify the original front-door adjustment to a sample-based one that is more suitable and realistic for the recommendation scenario. Speciî€›cally, we randomly sample a set of items while calculatingğ‘ƒ (ğ‘¦|ğ‘¢, ğ‘‘ğ‘œ(ğ‘£)). The item set for a user-item pair(ğ‘¢, ğ‘£)is represented asğ‘…(ğ‘¢, ğ‘£) (including sampled items and itemğ‘£), and the number of sampled items isğ‘›, which is a hyper-parameter to be selected. Therefore, we can rewrite Eq.(7) into a sample-based format. For each itemğ‘£âˆˆ ğ‘…(ğ‘¢, ğ‘£)in Eq.(8), its exposure probability (i.e. ğ‘ƒ (ğ‘£|ğ‘¢)) and conditional preference (i.e.ğ‘ƒ (ğ‘¦|ğ‘¢, ğ‘£,ğ‘š)) are two required values. We will introduce how to calculate them respectively. 4.2.1Calculate the Exposure Probability. The exposure probabilityğ‘ƒ (ğ‘£ |ğ‘¢)represents the probability of an itemğ‘£being exposed to a certain userğ‘¢, which plays an important role in our model. The implicit feedback in the dataset contains binary interactions, which indicates which user interacted with which item. If we take the interacted items as exposed (positive) samples and non-interacted items as unexposed (negative) samples (we will relax this assumption in the following), then we can train an exposure model based on pair-wise learning to rank as followsîƒ•îƒ•îƒ• whereğœ (Â·)is the sigmoid function:ğœ (ğ‘¥) =,ğ‘£andğ‘£are positive and negative items for userğ‘¢respectively,ğ‘ƒis the predicted exposure probability for user-item pair(ğ‘¢, ğ‘£), which represents ğ‘ƒ (ğ‘£ |ğ‘¢)in Eq.(8). More speciî€›cally, we can apply Matrix Factorization (MF) [12] to calculate ğ‘ƒ: wherepandqare embedding representations for userğ‘¢and item ğ‘£,ğ‘is the user preference oî€set term,ğ‘is item preference oî€set term, and ğ‘is global oî€set term. Although we can obtain exposure probabilities based on Eq.(10), it ignores the bias in the observational data, that the non-interacted items may not always represent negative samples. To address this issue and get more accurate and unbiased exposure probabilities, some works are available, such as doubly robust model [32] and predictive model [15]. For simplicity, we apply the simple IPS-based debiasing technique [27]. Concretely, we use propensity scores to correct the predicted probability. whereğ‘is the propensity score for user-item pair(ğ‘¢, ğ‘£). We still apply the pair-wise ranking framework as Eq.(9)to train the exposure probability Eq.(11). Theoretically, Eq.(11)will return more accurate and unbiased exposure probabilities [38]. We will discuss the empirical inî€uence of diî€erent exposure models in the experiments section. 4.2.2Calculate the Conditional Preference. To estimate the desired value ofğ‘ƒ (ğ‘¦|ğ‘¢, ğ‘‘ğ‘œ(ğ‘£)), the conditional preferenceğ‘ƒ (ğ‘¦|ğ‘¢, ğ‘£,ğ‘š) is an essential component. Recall thatğ‘¢represents a certain user, ğ‘£represents a speciî€›c item, andğ‘šrepresents the item feature of the treatment itemğ‘£. We design a functionğ‘“:ğ‘ˆ ,ğ‘‰ , ğ‘€ â†’ ğ‘Œwhich takes users, items and item features as input and returns preference scores such thatğ‘ƒ (ğ‘¦|ğ‘¢, ğ‘£,ğ‘š)is proportional to the corresponding conditional preference score. For a triple(ğ‘¢, ğ‘£,ğ‘š), we î€›rst use a Multilayer Perceptron (MLP) to encode the item and item feature into a vector, and then use the dot product between the obtained vector and the user representation to get the preference score. ğ‘“ (ğ‘¢, ğ‘£,ğ‘š) = u Â· ğœ™ (Wğœ™ (Wğœ™ (. . . ğœ™ (Wvm) . . . )))(13) whereu, vâˆˆ Rare the user and item latent embedding vectors inğ·-dimensional space (and it is not same aspandqin Eq.(11)); (a) Retrieve feature representation(c) Conditional preference for each item Figure 4: The process of estimating preferenceË†ğ‘¦. mis the feature representation for item ğ‘£; ğ‘£ ğ‘“is the conditional preference ğ‘“ (ğ‘¢, ğ‘£,ğ‘š) of user ğ‘¢ on item ğ‘£(Eq.(13)); ğ‘ƒ the ğ‘ƒvalue according to Eq.(11));Ë†ğ‘¦is the î€›nal preference score between user ğ‘¢ and item ğ‘£ (Eq.(14)). Algorithm 1Deconfounded Causal Collaborative Filtering (DCCF) Input: Training Dataset, including observed interactions as user-item pair (ğ‘¢, ğ‘£) and the item feature representation m for all items in ğ·-dimensional space; L2-norm regularization weight: ğœ†; number of sampled items for each user-item pair: ğ‘› Output: user representations U, item representations V, MLP network W mâˆˆ Ris the item feature representation inğ·-dimensional space (ğ·andğ·are not necessarily equal), which is retrieved from data;â„“is the number of layers in MLP;W, ğ‘– =1, . . . , â„“are weight matrices to be learned; andğœ™ (Â·)is the rectiî€›ed linear unit (ReLU) activation function: ğœ™ (ğ‘¥) = max(0, ğ‘¥). 4.2.3Calculate the Expectation. According to Eq.(8), the estimationğ‘ƒ (ğ‘¦|ğ‘¢, ğ‘‘ğ‘œ(ğ‘£))is the conditional expectation ofğ‘ƒ (ğ‘¦|ğ‘¢, ğ‘£,ğ‘š). Combined with Eq.(12), we have our estimation as follows: ğ‘ƒ (ğ‘¦|ğ‘¢, ğ‘‘ğ‘œ(ğ‘£)) âˆË†ğ‘¦î€‘ğ‘ƒ (ğ‘£|ğ‘¢)ğ‘“ (ğ‘¢, ğ‘£,ğ‘š whereğ‘ƒ (ğ‘£|ğ‘¢)is obtained by Eq.(11)andğ‘“ (ğ‘¢, ğ‘£,ğ‘š)is calculated by Eq.(13). The calculation ofË†ğ‘¦is shown in Figure 4. is the exposure probability of item ğ‘£on user ğ‘¢ (i.e., In this section, we will introduce details about model learning, i.e., how to learn the estimation as Eq.(14). In this work, we use the pairwise learning to ranking algorithm [23] for training. Suppose we observe userğ‘¢interacted with itemğ‘£in the dataset, The estimated preferenceË†ğ‘¦is obtained from Eq.(14). We sample another item ğ‘£âˆˆ Vthat userğ‘¢did not interact with as a negative sample. The estimated preference for negative sampleğ‘£is represented asË†ğ‘¦. The diî€erence between two estimated preferences is noted asË†ğ‘¦. Given the observed interactions, we randomly sample a negative item for each user-item pair in implementation. Speciî€›cally, we use Vto represent the observed items set for userğ‘¢(ğ‘£âˆˆ V) and Vto represent the sampled negative item set for userğ‘¢(ğ‘£âˆˆ V). The recommendation loss function can be written as:îƒ•îƒ•îƒ• whereÎ˜represents all parameters of the model;ğœ†is the L2-norm regularization weight;ğœ (Â·)is the sigmoid function:ğœ (ğ‘¥) =. It is worth mentioning that the representation of item featuremand exposure probabilityğ‘ƒ (ğ‘£|ğ‘¢)are î€›xed during training. The overall algorithm is provided in Algorithm 1. In this section, we conduct experiments to show how our deconfounded recommender works on real datasets. We examine its recommendation performance and compare it to the traditional association-based recommendation models and existing deconfounding methods. We will î€›rst describe datasets, baselines and implementation details and then provide our results and analysis. Our experiments are conducted on the Amazon Review Datasets [17] which include user, item, rating and product metadata spanning from May 1996 to October 2018. More speciî€›cally, we experiment with two datasets, (1) Electronics and (2) CDs and Vinyl. For each dataset, we sample 70% of user purchase as training data, 10% as validation data and the remaining 20% as testing data. The statistics about the datasets are shown in Table 1. For each dataset, we apply two splitting strategies. The î€›rst one is the traditional random splitting strategy (denoted as RAND), which considers each data sample with equal probability to be chosen into the testing set. Another is skewed splitting strategy (denoted as SKEW) following [5], which exposes as uniformly as possible each user to each item in testing set. We î€›rst calculate the popularity of each item and î€›nd the least popular item. For all other items, We use its popularity ratio compared with the least popular item to calculate the probability of being divided into the test set. For example, a 100 times more popular item than the least popular item will have a probability of being sampled in the test set as 1%. To avoid from the least popular item being not available in training, similar to [5], we cap the maximum probability for a user-item interaction record to be put into the test set as 0.9. The SKEW dataset is used to test if our model can perform well on an unbiased testing set. All data and source code will be released when paper is published. The baselines include both classical association-based recommendation models and state-of-the-art deconfounded recommendation models, as well as a variant of our own model. We introduce some details about the baselines used in our experiments. â€¢ BPR-MF[23]: The Bayesian Personalized Ranking model for recommendation. Speciî€›cally, We use Matrix Factorization (MF) as the prediction function under the BPR framework, which considers user, item and global oî€set terms for MF. â€¢ DMF[37]: Deep Matrix Factorization is a deep learning model for recommendation, which î€›lters the user-item interaction matrix through a neural network architecture for prediction. â€¢ IPW-MF[28]: Inverse Propensity Weighting Matrix Factorization for recommendation, which adapted causal inference (inverse propensity weighting, speciî€›cally) on the matrix factorization model to handle the selection bias in observational data. â€¢ DCF[34]: The deconfounded recommendation model, which uses an exposure model to construct a substitute confounder and then conditions on the substitute confounder for modeling. â€¢ DCCF_ND: This is a no-deconfounding (ND) variant of our model. Speciî€›cally, for a user-item pair(ğ‘¢, ğ‘£), this variant has no sampled item setğ‘…(ğ‘¢, ğ‘£)and only usesğ‘“ (ğ‘¢, ğ‘£,ğ‘š)in Eq.(13)as the estimated preference. It can be considered as our model without the front-door adjustment, which loses the deconfounding ability. Finally, we useDCCFto denote the complete version of our model. We use the same train, validation and test set for all models, including our models and baseline models. We evaluate models on top-ğ¾ recommendation task. More speciî€›cally, the models are evaluated based on nDCG@5, Recall@5, and Precision@5 Metrics. For evaluation, we apply real-plus-N [25] to calculate the values of each metric. Concretely, for each user in the validation and testing set, we randomly sample 1000 negative items for ranking evaluation. All recommendation models adopt the Bayesian Personalized Ranking (BPR) [23] framework for pair-wise learning. During the training, we sample one negative item, that the user did not interact with, for each interacted user-item pair. We optimize the models using mini-batch Adam with a batch size of 128. To get the feature representationğ‘€of the items, we apply a pre-trained sentence embedding modelto represent the textual information of an item into a dense vector embedding with dimension 768. The textual information comes from the title, feature, and literal description of each item, which are included in the meta-data of the amazon review dataset. We use the above pre-trained sentence transformer to convert them into separate embeddings and further take the average as the feature representation of the item. As for the parameters, we consider the embedding dimension from {64,128}, the structure of neural network is two-layer MLP with dimension 64 for deep models. For all recommendation models, we consider the learning rate from {0.0005,0.001,0.003,0.005}, the â„“-regularization weight is chosen from {1e-3, 1e-4, 1e-5}. For fair comparison, we tune the parameters to the best performance for each model on the validation data based on nDCG@5. For our model, we sample 20 items for each user-item pair for calculating the expectation (i.e., the number of sampled itemsğ‘›in Section 4.2). To get the exposure probability calculated based on Eq.(11), we estimate the user independent propensity scores as [27]: Hereğ‘¦is an indicator:ğ‘¦=1 if the user-item pair(ğ‘¢, ğ‘£)is observed in the dataset,ğ‘¦=0 otherwise. We setğœ‚ =0.5 in the experiment. The running time of our model is about 40 seconds/epoch for Electronics and 15 seconds/epoch for CDs and Vinyl. The recommendation performance on baselines and our model are shown in Table 2. We evaluate both Electronics and CDs and Vinyl datasets with RAND and SKEW splitting, respectively. For RAND and SKEW splitting, we strictly follow the 7:1:2 ratio to split train, validation and test data for each user, which makes the testing data the same size for each user on both splitting strategies. The SKEW strategy simulates a test set with unbiased user feedback, and the test distribution is diî€erent from the training distribution. Comparing the RAND and SKEW strategies, we can see that the recommendation performance with RAND strategy is consistently better than the performance with SKEW strategy on both of Electronics and CDs and Vinyl datasets. This shows that learning recommendation models when the training and testing Table 2: Recommendation performance for Electronics and CDs and Vinyl on RAND and SKEW splitting datasets. We evaluate on ranking task with metrics nDCG@5, Recall@5 and Precision@5. The best results are highlighted in bold. distributions are diî€erent (SKEW) is a more challenging task than under the same train-test distribution (RAND). The following observations are consistent no matter what the splitting strategy is. First, the recommendation models shown in Table 2 can be categorized into classic association-based models and deconfounded models, where the diî€erence between the two is whether the eî€ects of confounders are mitigated or not. From the results, we can see that the deconfounded recommendation models (IPW-MF, DCF and DCCF) achieve better recommendation performance than classic recommendation models (BPR-MF and DMF) on both datasets. When averaging across all deconfounded recommendation models on all datasets and splitting strategies, the deconfounded models get 36.3% relative improvement on nDCG@5 than classic recommendation models, 38.0% on Recall@5, and 33.6% on Precision@5. According to this comparison, we can know that the existence of confounders will lead to inaccuate recommendations and deconfounded recommendation models will improve the recommendation performance by eliminating the eî€ect of confounders. Among three deconfounded recommendation models, we can see that our DCCF model achieves the highest recommendation performance. Compared with the strongest deconfounded model in baseline, when averaging across all datasets and splitting strategies, our model gets 10.1% improvement on nDCG@5, 11.8% improvement on Recall@5, and 8.4% improvement on Precision@5. These observations imply that by applying the front-door adjustment into the estimation of userâ€™s preference, our model is capable of reducing the eî€ect of unobserved confounders and further improving the recommendation performance. Moreover, based on the results, applying the front-door adjustment is more eî€ective than applying inverse propensity weighting or substituting the unobserved confounders. Although the front-door adjustment is eî€ective on reducing the eî€ect of unobserved confounders, it requires a mediator in the causal graph, i.e., the variableğ‘€in Figure 3, which represents item feature. We want to conî€›rm that the improved performance is indeed brought by the deconfounding eî€ect instead of the use of item features. As a result, we consider a variant of our model DCCF_ND, which also involves item feature representation into estimation but without the front-door adjustment as deconfounding component. More speciî€›cally, unlike DCCF that applies the frontdoor adjustment with weighted sum over sampled items to get the estimation of a user-item pair, DCCF_ND only considers the user-item pair itself when calculating the estimation. From Table 2, we can see that DCCF_ND is even worse than classic models in most cases. Therefore, the improvement of our model is brought by deconfounding with the front-door adjustment instead of involving item feature representation into calculation. In this section, we will discuss the inî€uence of the exposure models. As we mentioned before, the exposure probability, which is required by the front-door adjustment but not available in the feedback data, is an essential component of our model. To empirically show the inî€uence of it, we design three versions of our model with diî€erent exposure probabilities. The only diî€erence among them is how to get the exposure probability. â€¢ DCCF_Random: In this model, the exposure probabilities are not learned from the data, instead, we randomly generate a matrix to represent the exposure probability. â€¢ DCCF_Bias: In this model, we estimate the exposure probability as Eq.(10), and use the pair-wise learning method to train the model based on implicit feedback. â€¢ DCCF_Unbias: This model is the same asDCCFin Table 2. Concretely, we consider the bias in the implicit feedback data, and apply Eq.(11)to get unbiased estimation of exposure probabilities. We report the recommendation performance of above three version in Table 3. Following the main experiment, we evaluate two datasets on two splitting strategies. The performance is also based on ranking metrics. For each of the version, we use the same item feature representation and sample 10 items for each pair to calculate the estimated preference. From the results, we can see that DCCF_Unbias gets the best performance and DCCF_Random gets the worse performance. This observation is consistent on both RAND and SKEW splitting strategies. Comparing the three versions with diî€erent exposure models shows that accurate exposure probability will lead to accurate estimation under the front-door adjustment. The exposure probability is not observed in the feedback data, therefore, we need to learn a model to estimate it from observational feedback data. DCCF_Unbias uses the unbiased estimation and gets the most accurate exposure probability, while DCCF_Random randomly generate exposure probabilities, which is irrelevant with the feedback data, and thus will get the least accurate probability. We can see that the ranking of the exposure probability accuracy matches the ranking of recommendation performance. Table 3: The recommendation performance of DCCF under diî€erent exposure models. We report the evaluatation on ranking task with metrics nDCG@5, Recall@5 and Precision@5. The best results are highlighted in bold. The exposure model aî€ects our model in many ways, not only the best recommendation performance, but also the trend of the recommendation performance as the number of sampled item increases. As we mentioned in Section 4 and Eq.(14), we apply the front-door adjustment over a set of sampled items to make it suitable for the recommendation scenario. Ideally, if there exist the ground truth values of exposure probability and we apply them into the calculation, then increasing the number of sampled items may reduce the eî€œciency but will at least not hurt the performance signiî€›cantly. In order to investigate how our model changes with increasing the number of sampled items under diî€erent exposure models, we plot nDCG@5 for three versions of the model with diî€erent numbers of sampled items, as shown in Figure 5. As we can see from the î€›gure, the performance of DCCF_Unbias increases with the increasing of sample number, the performance of DCCF_Bias increases î€›rst and then drops after 5 samples, and the performance of DCCF_Random is monotonically decreasing. Meanwhile, for a given number of sampled items, the performance among the three models follows the conclusion as Table 3 in most cases, i.e., DCCF_Unbias>DCCF_Bias>DCCF_Random. For DCCF_Unbias, since it has the most accurate exposure probability, it will get better performance with more sampled items. For DCCF_Bias, the probability is learned from data but not accurate enough. Therefore, when the number of sampled items is small, the model can get slightly better performance with the help of sampled items, but when more sampled items are involved into the estimation, inaccurate probabilities may mislead front-door adjustment and hurt the performance, thus resulting in performance drops. For DCCF_Random, the sampled items do not provide useful information but instead introduce noises that completely mislead the front-door adjustment, and thus hurt the performance. In summary, accurate exposure probability will improve the performance while inaccurate probability hurts the performance. Therefore, it is important to adopt an accurate exposure model. In this paper, we notice that the unobserved confounders may result in inaccurate recommendations. To solve this problem, we propose a deconfounded causal collaborative î€›ltering model. Speciî€›cally, we î€›rst design a causal graph to depict user behaviors with unobserved confounders. We then apply the front-door adjustment to design the model for eliminating the inî€uence of unobserved confounders. Considering the large scale of items in real-world system, we use the sample-based front-door adjustment to calculate the deconfounded estimation of usersâ€™ preference. Experiments on real-world datasets with both random splitting and skewed splitting show that our deconfounded model can outperform both classical association-based models and deconfounded recommendation models. Furthermore, the experiments on the inî€uence of exposure models show that the performance of our deconfounded causal collaborative î€›ltering model highly depends on the accuracy of the learned exposure probabilities. Therefore, a proper exposure model helps improve the recommendation performance of our deconfounded recommendation model. There are still spaces for future improvements. First, our current model depends on the quality of exposure models, in the future, we can design a deconfounded recommendation model that is less aî€ected by the exposure model. Second, our model treats all the confounders as bias terms and removes all of their inî€uence from the recommender system. However, the confounders may not always be harmful from the provider side. In practice, certain confounders can be useful and their aî€ects should be remained in the recommendation. This requires a mixed recommendation strategy that considers partially associative rules and partially causal rules. Finally, the causal model used in DCCF could also be adapted to increase the interpretability of the recommender systems, which is another important aspect to be considered for recommendation. This work was supported in part by NSF IIS-1910154, IIS-2007907 and IIS-2046457. Any opinions, î€›ndings, conclusions or recommendations expressed in this material are those of the authors and do not necessarily reî€ect those of the sponsors.
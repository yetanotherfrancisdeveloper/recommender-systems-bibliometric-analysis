J.P.Morgan CTO Applied ResearchJ.P.Morgan CTO Applied Research fran.silavong@jpmchase.comsean.j.moran@jpmchase.com Machine learning on source code (MLOnCode) is a popular research î€›eld that has been driven by the availability of large-scale code repositories and the development of powerful probabilistic and deep learning models for mining source code. Code-to-code recommendation is a task in MLOnCode that aims to recommend relevant, diverse and concise code snippets that usefully extend the code currently being written by a developer in their development environment (IDE). Code-to-code recommendation engines hold the promise of increasing developer productivity by reducing context switching from the IDE and increasing code-reuse. Existing code-to-code recommendation engines do not scale gracefully to large codebases, exhibiting a linear growth in query time as the code repository increases in size. In addition, existing code-to-code recommendation engines fail to account for the global statistics of code repositories in the ranking function, such as the distribution of code snippet lengths, leading to sub-optimal retrieval results. We address both of these weaknesses with Senatus, a new code-to-code recommendation engine. At the core of Senatus is De-Skew LSH a new locality sensitive hashing (LSH) algorithm that indexes the data for fast (sub-linear time) retrieval while also counteracting the skewness in the snippet length distribution using novel abstract syntax tree-based feature scoring and selection algorithms. We evaluate Senatus via automatic evaluation and with an expert developer user study and î€›nd the recommendations to be of higher quality than competing baselines, while achieving faster search. For example, on the CodeSearchNet dataset we show that Senatus improves performance by 6.7% F1 and query time 16x is faster compared to Facebook Aroma on the task of code-to-code recommendation. Locality sensitive hashing, MinHash LSH, machine learning on sourcecode, Code-to-code recommendation ACM Reference Format: Fran Silavong, Sean Moran, Antonios Georgiadis, Rohan Saphal, and Robert Otter. 2021. DeSkew-LSH based Code-to-Code Recommendation Engine. In Proceedings of ACM Conference (Conferenceâ€™17). ACM, New York, NY, USA, 12 pages. https://doi.org/10.1145/1122445.1122456 High quality and reliable software is a must for the smooth running of a multitude of systems that drive the modern world, from the î€›nancial system, online commerce to landing the latest exploratory rover on Mars. Machine learning for mining code repositories (MLOnCode) has gained traction in the research community with the emergence of large-scale repositories of opensource code (e.g . Github, CodeNet [40]), with associated metadata (e.g. comments, documentation, commit history, resource usage) and the parallel advancements in the development of probabilistic and deep learning models for pattern recognition in sourcecode [1]. There is scope for MLOnCode to facilitate the familiar software development experience by augmenting common tasks with machine learning to enhance developer productivity, eî€œciency and improve code reliability and consistency. For example, in the build stage of the Software Development Lifecyle (SDLC), code-to-code recommendation engines [5,8,30,35] suggest contextually relevant code directly within the developerâ€™s IDE, reducing the need to context switch and leave the IDE to search the web. The promise of code-to-code recommendation engines is built on the î€›nding that most code is similar to code that is already written, for example in one study up to 40% of the code repositories were found to have noticeable overlap [35]. In another example, the testing stage of the SDLC is aided by automatic unit test generation tools [37,45] that are able to automatically generate a bank of unit tests and program repair and bug testing detection innovations [25, 26, 39, 50]. In this paper we focus on the build and test phase of the SDLC lifecycle, and the speciî€›c task of code-to-code recommendation. We follow the deî€›nition given in [35] in which the input to the search engine is a code snippet and the output is a ranked list of concise, diverse and relevant code snippets that usefully extend the query code snippet with additional functionality. This deî€›nition is a twist on the familiar task of code search which typically does not require the snippets in the ranked list to extend the query snippet or to be concise and diverse. Code search is a well researched î€›eld with a multitude of prior work in the area, roughly broken down into code clone detectors and code-search tools [4,5,8,11,14,20,22â€“ 24,30,33,35,43,48]. Code-to-code recommendation can be approached using existing systems for code search and clone detection although both types of systems have their disadvantages for codeto-code recommendation as highlighted by [35]. For example, code clone detectors [11,20,22,43] retrieve mostly near duplicate or duplicate snippets which are not useful in code-to-code recommendation and code search tools [4,23,24] make no attempt at ensuring that the ranked snippets usefully extend the query. In evaluating the aforementioned solutions for code-to-code recommendation, search and clone detection we generally î€›nd that there is a gap in scaling these systems to massive codebases while simultaneously maintaining or even improving the retrieval quality of the system. In addition to scalability concerns, we also î€›nd limitations in existing code search tools in terms of retrieval eî€ectiveness. Codeto-code recommendation is a challenging task for contemporary Information Retrieval (IR) methods; code is designed to be understood by both humans and by machine and this requirement leads to the similarities between code and natural language [1] that can be exploited by traditional text-based search engines. Nevertheless there are many key diî€erences between natural language and code which the search engine should ideally take into consideration when ranking. For example code has well-deî€›ned structure, a formal syntax and semantics and is designed from the start to be executed [1]. Treating code as a bag-of-words and applying traditional search techniques such as BM25 and TF-IDF lead to sub-optimal performance compared to search that encapsulates the logical structure of the code in the featurisation [35]. In addition to code properties such as the logical structure, in this paper we also argue that is important for a retrieval engine to consider the global statistics of the data in a code repository. More speciî€›cally, we provide evidence of a power-law distribution in code snippet lengths in typical code repositories, in which there is a large number of short code snippets with a long tail of larger code snippets. Existing code search tools do not take this phenomenon into consideration when ranking, leading to a degradation in retrieval eî€ectiveness. In this work we propose Senatus, a new code-to-code recommendation engine that addresses both of these issues. Senatus exhibits a sub-linear growth in query-time with respect to the code repository size while addressing retrieval quality degradation by novel feature scoring and selection techniques that counteracts the data skewness inherent in typical code repositories with respect to snippet length. Senatus works by indexing the code repository using Minhash-LSH. Minwise Hashing (Minhash) [6,7,31,44] is a wellknown method for maintaining the Jaccard similiarity between sets by re-representing those sets as typically much lower-dimensional similarity preserving feature vectors. Locality sensitive hashing (LSH) [2,18] as applied to those Minhash feature vectors can provide an eî€ective technique for indexing the data so that, at query time, only buckets to which the query hashes need to be checked for similar items. Intuitively, items colliding in the same buckets should be highly likely to have a high Jaccard similarity thereby circumventing a search across all items in the databasse. Minhash-LSH has been applied to a large range of applications from web search [51], earthquake detection [41], graph sampling [12] to scalable online collaborative î€›ltering for news personalisation [13] and eî€œcient clustering of massive collections of genomic sequences [36]. Different to these existing approaches, we explore the application of Minhash-LSH to the task of code-to-code recommendation over large-scale code repositories. We î€›nd that Minhash-LSH has poor retrieval quality out-of-the-box when applied to the code-to-code recommendation task and we identify the aforementioned skewness in code snippet lengths to be the primary issue. Senatus counteracts the data skewness by applying novel feature scoring and selection methods that operate directly on the abstract syntax tree (AST) structural representation of code, leading to both faster query time and superior retrieval eî€ectiveness versus competitive baseline search systems. In summary, our contributions to the î€›eld of code-to-code recommendation in this paper are four-fold: â€¢ Scalable Code-to-Code Recommendation:We design and study the scalability of a Minhash-based retrieval algorithm , known as DeSkew LSH, for accelerating the lookup time for code-to-code-recommendation. Rather than anO(|ğ‘ |) comparison of a query against all snippets in the repository ofğ‘code snippets, we achieve anO(ğ‘™ğ‘œğ‘”|ğ‘ |)retrieval time by only examining colliding snippets in the same hashtable buckets. This hashing approach achieves a 16.6ğ‘¥improvement in query time without the requirement for any specialized hardware, and+6% improvement in retrieval eî€ectiveness versus Facebookâ€™s state-of-the-art Aroma code recommendation engine. We intend to open-source Senatus to the community. â€¢ Data Skewness in Code Repositories:We study the distribution of code snipp et lengths in two public sourcecode repositories, CodeSearchNet [17] and the Neural Code Search evaluation dataset [28] and î€›nd that the snippet lengths are heavily skewed, following a power-law distribution, with the vast majority of the snippets being short in length, and a long tail of longer snippets. We argue that code-to-code recommendation engines, to return concise and useful snippets, should implement techniques to counteract the bias caused by this skewness. â€¢ Feature Scoring and Selection:We propose two novel feature scoring methods, Normalized Sub-Path Frequency (NSPF) and Inverse Leaves Frequency (ILF) that score parse tree features based on the tree structure in an Abstract Syntax Tree (AST) parsing of a code snippet. We argue that these tree structure sensitive feature scoring methods are more suitable for tackling skewness for the purposes of codeto-code recommendation. Based on the scores produced by these functions we propose two feature selection techniques: Top-K and Mid-N percentile for selecting a compact, discriminative set of code features based on the scores. â€¢ User Study and Annotate d Dataset:We conduct a user study with expert developers to validate our approach versus competitive baseline systems. The user study shows that the recommendations from Senatus are signiî€›cantly more useful to developers in completing their programming tasks. We intend to release our manual annotations to the community. The rest of this paper is organized as follows: in Section 2 we describe the closest related work in the code-to-code recommendation literature. In Section 3 we describe our contribution, a scalable and accurate method for sourcecode recommendation. In Section 4 we experimentally evaluate Senatus on two public sourcecode repositories and a user study. Finally in Section 5 we draw conclusions and provide pointers for future work. In this section we review relevant developments in the î€›elds of Machine Learning on Sourcecode (MLOnCode) and minwise hashing (minhash). In MLOnCode, methods for code search and code-tocode recommendation are the closest to the work in this paper, with the comprehensive MLOnCode survey article [1] detailing other tasks and associated methods in the vibrant î€›eld. Code search can be conducted with keyword queries, natural language queries or through query-by-example and submitting an example code snippet [34]. Keyword-based Code Search:Many code search tools tend to be text-based search engines, including OpenGrok, Github search, searchcode.com and Codase. These sourcecode search engines support full-text search, with options for searching for the presence of syntactic elements such as identiî€›ers (class names, method names, attribute names) and function or variable deî€›nitions. While useful, full-text search over sourcecode is not able to take into consideration the syntactical structure of the code; without the structural context the retrieval may bring back many irrelevant results for the developer to shift through e.g. searching for how exception handling is performed for a î€›le-opening command is likely to return many false positives without including surrounding structural context in the query. Commercial options for sourcecode search include Sourcegraph, a code search and navigation engine deployed at a wide variety of organisations such as Amazon, CERN and Uber. Sourcegraph appears more feature rich - in addition to full-text search and regex-based search, Sourcegraph oî€ers a structural search via Comby syntax, which is a lightweight mechanism for matching the structures of a programâ€™s parse tree enabling more precise search in sourcecode. Extensions have sought to improve keyword-based code search e.g. by leveraging test cases [27] and using associated code documentation to improve retrieval of concise code snippets in the SNIFF search engine [10]. Natural Language-based Code Search:Recently there has been signiî€›cant interest in learning the mapping between natural language and sourcecode [8, 15], enabling a user to search sourcecode repositories with natural language (e.g. â€œHow to write data to a CSV î€›leâ€). An example is Neural Code Search (NCS) [8] that utilises neural networks to learn a shared latent space for sourcecode and natural language. Natural language code search can be useful for certain use-cases, for example, to facilitate browsing of a repository. However, for contextually relevant code suggestions that are useful to a developer as they code e.g. î€›xing bugs, refactoring, natural language code search techniques somewhat fall short in convenience in comparison to query-by-example code search. Query-by-example code search:In this paper we contribute new ideas to the î€›eld of query-by-example code search, and specifically in the sub-task of code-to-code recommendation. In code-tocode recommendation, a search engine returns a list of concise, diverse and relevant code snippets given an example query code snippet as input. Code-to-code recommendation engines are based on the premise that developers typically write code that is similar to code written by other developers [35]. Evidence of this usage has been provided by e.g. Bajracharya et al. who have analysed the log î€›les of Koders, a web-based code search engine, and report that 90% of the queries are related to developers searching for code to reuse in their project [3]. Given this, an eî€ective method for automatically surfacing contextually relevant code snippets, portions of which could be reused, is potentially very useful in a developerâ€™s workî€ow. The potential beneî€›ts of an eî€ective code-to-code recommendation engine are numerous. For example, it could save developer time by presenting contextually relevant code suggestions directly in the developerâ€™s integrated development environment (IDE), or given a partially written code snippet, a developer can view suggestions that demonstrate how the snippet could be completed or extended with related functionality written by other developers. This avoids the context switching typically associated with searching for relevant code snippets via web search engines or on Stackoverî€ow. Secondly, code-to-code recommendation improves code consistency, by showing a developer how other developers in their organisation have implemented similar functionality, encouraging eî€ective code re-use. Next, a code search engine can enable better management of large-scale change, for example, by surfacing to a developer how other developers in the organisation are using their API, allowing more informed choices as to how new functionality can be added to the API. Lastly, code-to-code recommendation can improve the quality of code in a sourcecode repository, by encouraging developers to program in a similar manner to a curated repository of high quality code e.g. code that has been veriî€›ed by cybersecurity experts to have no known security vulnerabilities. Prior research in the î€›eld of code search is substantial [4,5,8, 11,14,20,22â€“24,30,33,35,43,48], with the recent review article summarising the breadth of research alongside opportunities and challenges in the î€›eld [34]. Early work in this î€›eld includes clone detection which are systems that aim to î€›nd highly similar code snippets known as Type 1-3 code clones (i.e. syntactically similar code). Relevant prior work in this area includes CCFinder and SourcererCC [22,43]. Recent work in clone detection has Type 4 clones (semantically similar code) [42, 47] and gapped clones [46]. As argued in [35], clone detectors are not suitable for the task of code-to-code recommendation, where the desire is for the retrieved code snippets to contain both the query and additional useful code that could be re-purposed by the developer for their task. Other related work includes code-to-code search tools such as FaCoY [23] and Krugle [24], however, again these type of tools are not useful for code-to-code recommendation as they may produce redundant results in the ranked list with extraneous additional code in the result snippets that are not a concise extension of the query. Figure 1: Overview of Senatus. Method bodies are featurized by traversing their abstract syntax tree (AST). Our proposed feature selection techniques are applied to the resulting features, which are then minhashed to produce signatures. LSH is used to bucket the signatures, with colliding signatures returned as approximately similar snippets that are passed onto the downstream tasks to generate recommendations for the end-user. The orange box indicates the De-Skew LSH stage of Senatus Facebook Aroma:Facebookâ€™s Aroma code-to-code recommendation engine [35] is designed to provide diverse and concise retrieval results that are a useful extension of the query snippet. Senatus is most related to and signiî€›cantly improves upon the retrieval quality and query time of Aroma. Aroma is a structured code-tocode recommendation engine and at its core is a featurisation and similarity computation algorithm based on a Simpliî€›ed Abstract Parse Tree (SPT) representation that facilitates recommendation by tolerating a degree of non-similarity in very similar snippets. The Aroma Abstract Syntax Tree (AST) is simpliî€›ed into a SPT by replacing local variable names with a common tag (e.g. #VAR) unless they are global variables or method names, as they can be important in diî€erentiating code snippets. In order to capture structural relationships, Aroma further creates features using three types of relationships between variable-based tokens on the AST: a) parent, b) sibling and c) variable re-use. The individual tokens as well as the structural relationship features parsed from the code corpus constitute the vocabulary for the task, and are given individual indices which are then used to convert the AST into a vector. Aroma accepts a partial query snippet and searches for method bodies which contain that snippet. In order to achieve this quickly, Aroma î€›rst performs a fast light-weight search on the whole sourcecode corpus, followed by a slower high-quality pruning and re-ranking process on the selected (e.g. 1000) results. The light-weight search uses sparse matrix multiplication between the vectorized query and the matrix containing all the methods, and the pruning is based on a custom greedy algorithm which computes the maximal subtree containing the query [35]. Aroma implements two retrieval post-processing steps: clustering and intersection. For the clustering phase, Aroma uses a customized algorithm, which creates clusters such that: a) intersecting the snippets within a cluster will still contain more code than the query and b) the pruned snippets within each cluster are similar. The clusters are not mutually exclusive and because this operation is slow, it only happens on a selected number of results ( e.g. top 100) which are most similar to the query after the pruning and re-ranking step. Finally, in the intersection step, Figure 2: Distribution of Code Snippet Lengths (Log-Log Plot). We observe the characteristic linear relationship evident on a log-log plot of variables related by a power-law. Aroma generates the recommendations to the users, by applying the aforementioned pruning process within each cluster. Minwise Hashing:advancements in minwise hashing (MinHash) are relevant to Senatus data indexing and query processing. MinHash was introduced in the seminal papers by Broder et al. [6,7] and converts sets to signatures that preserve the Jaccard similarity of the sets. Locality sensitive hashing (LSH) [2,18] can be applied to these signatures so that similar signatures collide in the same hashtable buckets with high probability. MinHash has subsequently been extended in several directions to improve its performance and eî€œciency: for example the method of [44,51] counteracts bias towards smaller sets, Ioî€e et al. [19] extend MinHash to weighted Jaccard similarity on multisets and b-bit MinHash [32] targets storage space savings by retaining only the lowest b-bits of each hash value. Similarity search is a fundamental building block for a sourcecode retrieval system. Ever expanding codebases, such as Github, serve over 100 million sourcecode repositories, and this sheer scale Figure 3: The core of Senatus, employing approximate similarity search via Minhash LSH to cluster similar code snippets. Left to right: simpliî€›e d parse tree of a code snippet that is featurized. Feature selection (Equations 3-4) removes noisy features, leaving those more eî€ective for code-to-code recommendation. Minhash signature is generated from the features and these signatures are hashed into buckets enabling sub-linear time retrieval. poses challenges for eî€œcient code search. We are in the era of â€œBig Codeâ€ a term recently coined by Allamanis et al. [1], to describe the widespread existence of large code corpora and associated metadata (e.g. commit history, comments, ratings etc.). It is expensive to compute the exact similarity between a query and every snippet in the codebase given the linear scaling of the query-time with respect to the database size for brute force search. Approximate similarity search, such as Minwise Hashing (MinHash) [7], has proven to be an eî€ective method for reducing the number of comparisons required. Minhash converts large sets of tokens into short signatures where the signatures approximately maintain the Jaccard similarity between the sets. These much more compact similarity preserving signatures can be used in locality sensitive hashing (LSH) to cluster together similar sets in sub-linear time via bucketing in hashtables. We î€›nd that, in the source code domain, application of MinHash leads to sub-optimal retrieval eî€ectiveness due to the heavily skewed distribution of code snippet length (Figure 2). Set similarity measures either favour code snippets that are shorter or signiî€›cantly longer than the query snippet, e.g. over 100 lines, and neither aid downstream code search and recommendation tasks. For a code-to-code recommendation to be useful, the ranked code snippets from the search engine should include the query snippet and a small number of additional lines demonstrating how that query snippet could be augmented by the developer [35]. In this section we describe a new method, dubbed De-Skew LSH, that adapts Minhash-LSH so that it can be successfully be used in the sourcecode retrieval domain. De-Skew LSH, shown in Figure 3, encompasses novel feature selection and pruning techniques to counteract the data skewness for MinHash-LSH. We incorporate De-Skew LSH in our code-to-code recommendation engine Senatus (Figure 1) and show that the engine is quantitatively better than existing approaches in our experimental evaluation in Section 4. For the purposes of this paper, a code snippet is deî€›ned as either a complete method or function of arbitrary length when referring to the corpus, or a piece of complete or semi-complete code of arbitrary length when referring to the query. The Aroma code search engine [35] transforms each code snippet into a simpliî€›ed parse tree (SPT) for the purposes of code similarity computation. The SPT is a representation of the code snippet that summarizes the salient structural information relating to the snippet. The SPT is designed to remove irrelevant lower level syntactical information from the snippet as well as language-speciî€›c tokens and thus better captures the program structure rather than program syntax, as recommended by Aroma. In our work, structural features, namely token, parent, sibling, variable usage features, extracted from a traversal of the SPT are used to represent the code snippets for the purposes of similarity computation. We observe that the length of code features follows a characteristic power-law distribution in sourcecode repositories, for which a vast majority of code snippets are shorter with a heavy-tail of much longer length snippets. Figure 2 demonstrates this phenomena empirically in the CodeSearchNet and Neural Code Search Evaluation datasets. Additionally, user queries tend to be shorter than the desired retrieved results, especially for code-to-code recommendation tools as developers are usually seeking ideas and suggestions for useful additional code to augment their current function. In our experimental results (Section 4) we present empirical evidence for the importance of appropriately handling the mismatch in snippet length in a modern code-to-code recommendation engine. Aroma [35] deî€›nes a functionğ¹ (.)that featurizes a code snippet into a binary vector resulting from the traversal of the snippetâ€™s SPT. To compare feature vectors, Aroma computes the containment score (Equation 1) between the feature set of query,q âˆˆ Z, and the feature set of each method in anğ‘method corpus,{m} to retrieve relevant code snippets, providing that the similarity is higher than a predeî€›ned threshold. Code snippets with a longer length have a higher probability to overlap with the query, but are not necessarily relevant to the query. Given the heavy-tail of long code snippets, the use of the containment score will create a bias towards code snippets that are longer in feature length. In addition to poor retrieval performance, users will have a sub-optimal experience as they will spend more time digesting and attempting to distil relevant information from the much longer code snippets. Both issues are contrary to the core modus operandi of code-to-code recommendation tools. Jaccard similarity(2)or set resemblance is an alternative set similarity measure to retrieve relevant code snippets. Smaller code snippets or snippets that are similar to the query length tend to have a higher Jaccard similarity, which is due to the denominator,|ğ¹ (ğ‘) âˆª ğ¹ (ğ‘š)|. This bias towards shorter snippets does not bring additional value to the users, especially in the code-to-code recommendation task where we desire retrieval results that non-trivially extend the query snippet (i.e. so that the developer can copy and paste the additional code into their function). Since the computation of containment score can be treated as a sparse matrix multiplication, the query time is signiî€›cantly lower than using other similarity metrics, but it still remains a fundamentallyO(|ğ‘ |)operation. In comparison, MinHash LSH oî€ers O(ğ‘™ğ‘œğ‘”|ğ‘ |)retrieval time by converting binary features into compact signatures using the minwise hash function family that preserves Jaccard similarity and hashing those signatures into buckets. In more detail, the minwise hash family applies a random permutation ğœ‹on the feature set (ğ¹ (ğ‘)) and stores the minimum value, where ğ¹ (.)is a featurisation function giving a binary set for input vector ğ‘: â„(ğ¹ (ğ‘)) = ğ‘šğ‘–ğ‘›(ğœ‹ (ğ¹ (ğ‘))). It is a well known result that the probability ofğ‘ƒğ‘Ÿ (â„(ğ¹ (ğ‘)) = â„(ğ¹ (ğ‘))) is equal to the Jaccard similarity between the underlying sets [7]. The Minhash signatures can be much more compact than the underlying sets, saving memory. LSH is applied to these sets to enable a faster and more scalable approach for similarity search as evidenced in our experimental results. Asymmetric transformation [44] proposes a variant of Minhash for containment score instead of the Jaccard similarity. In this approach, padding is performed to obtain vectors of the same î€›xed length prior to applying the hash functions. The query snippet is not padded. However this approach is suboptimal for code-to-code recommendation: if we pad every snippet to the maximum length in the corpus, this will create a large MinHash signature as suggested by the heavy-tail in Figure 2 and therefore will result in very high computational and memory cost. We adapt traditional feature scoring techniques used in IR, such as the Term Frequency-Inverse Document Frequency (TF-IDF), to the source code domain. Speciî€›cally, we use a scoring function to rank the features based on relevance and only retain those within the predeî€›ned range for Minhashing. We then leverage Locality Sensitive Hashing (LSH) on these MinHash signatures, such that the probability of collision only depends on relevant features, thus counteracting the data skewness and improving retrieval performance. The approximately similar snippets are retrieved inO(ğ‘™ğ‘œğ‘”|ğ‘ |)time and limit the subsequent exact similarity search to only a small subset of the corpora. It is important to note that this approach is agnostic to the chosen feature selection techniques. The next section describes our feature selection methods and the application of Minhash. In this Section we present a methodology to score, rank and select a discriminative subset of structural sub-tree features for MinHash based on the AST representation of code. We î€›rst describe our chosen AST representation that deî€›nes the structural terms in the vector space. We instantiate the AST representation by following the featurisation techniques proposed by Aroma [35]. In Algorithm 1,ğ¸ğ‘¥ğ‘¡ğ‘Ÿğ‘ğ‘ğ‘¡ğ¹ğ‘’ğ‘ğ‘¡ğ‘¢ğ‘Ÿğ‘’converts code snippets (e.g. queries, methods or classes) to their corresponding Simpliî€›ed Parse Tree (SPT) and traverses through the tree to extract four types of features: (1) Token Features, (2) Parent Features (3) Sibling Features, and (4) Variable Usage Features. More speciî€›cally, the sourcecode î€›rst gets converted to an AST using ANTLR with the appropriate Lexer and Parser grammars for the language of choice. We implemented our solution in Java, Python but also Jupyter Notebooks, by treating each cell as if they were individual methods. The ASTs are then simpliî€›ed to SPTs by replacing local variables with the #VAR token, unless they are method names or global variables. In addition: â€¢SPTs are represented as a list (or array) of subtrees and leaf nodes. â€¢ Subtrees are represented by one or more "#". â€¢Parent relationships are represented using ">", and are not limited only to direct parent. â€¢ Sibling relationships are represented using ">>". â€¢ Variable re-use is represented using "> > >". â€¢Numerical indices are used to diî€erentiate relationships of the same type ( e.g. parent from parent, sibling from sibling). The SPT representation deî€›nes the structural terms in our vector space vocabulary, with relationships between children and ancestors captured as independent dimensions in the space. To mitigate the eî€ect of data skewness on the performance of minhash we describe a feature scoring and selection scheme. Our term scoring function is deî€›ned in Equation 3. ğ‘ ğ‘ğ‘œğ‘Ÿğ‘’(ğ‘, ğ‘¡,ğ‘) =1, if ğ‘™â‰¤ ğ‘“ (ğ‘, ğ‘¡,ğ‘) â‰¤ ğ‘™0, otherwise(3) Only features with a score of 1 are retained for the subsequent Minhash signature generation. Hereğ‘âˆˆ ğµis the set of tree contexts (paths),ğ‘‰is the set of structural terms in our vocabulary, and we deî€›ne score(q,t,ğ‘) as the score of termğ‘¡with respect to the query ğ‘and context (tree path)ğ‘and similarity for the database snippet ğ‘‘term weighting, weight(d,t,ğ‘). The two data-driven thresholds, ğ‘™andğ‘™, select a subset of the terms to be used in the generation of the Minhash signatures. We propose two diî€erent variants of the feature scoring functionğ‘“ (.)that individually seek to emphasise diî€erent aspects of the code, for example API usage or method structures. Figure 4 illustrates this with an example. Our Algorithm 1Senatus (DeSkew LSH): the anatomy of a scalable code search engine. LSH familyğ¹with the width parameterğ‘˜and the number of hash tables ğ» Figure 4: Comparison of structural feature scoring (Equations 4): we propose to emphasise structural features associated with API usage (green box) with NSPF, and/or distinctive features on a method-level (blue dotted box) with ILF, instead of ordinary tree structures, such as#=#1#ğ‘‰ ğ´ğ‘… (grey) and ##1 > #ğ‘‰ ğ´ğ‘… (orange). proposed tree-based feature scoring functions listed in Equation(4) rank the structural sub-tree features in the SPT representation based on their importance. ğ‘“(ğ‘, ğ‘¡, ğ‘) =|ğ‘¡|Ã(ğ‘, ğ‘¡, ğ‘) =1|leaf t|(4) Hereğ‘¡refers to a particular term in the vocabulary e.g. #VAR, and leafğ‘¡is a leaf node feature. Normalized Sub-Path Frequency (NSPF) is a global operator divides the frequency of tree-based terms in the query,ğ‘, by the total number of occurrences of that term in the entire codebase (ofğ‘methods), such that common features rank lower. In comparison, Inverse Leaves Frequency (ILF) is a local operator, restricted to the query or database code snippet terms only. ILF computes the inverse of the leaf node frequency within the simpliî€›ed parse tree only, which removes the dependency on the background corpora and penalizes the common features on a level that is local to the given code snippet. We empirically test both variants in our experimental evaluation in Section 4. We propose two diî€erent feature selection functions to compute the thresholds ğ‘™and ğ‘™in Equation 3: â€¢ ğ‘‡ğ‘œğ‘âˆ’ğ¾: features where only the topğ¾highest ranking features are kept. ğ‘‡ğ‘œğ‘âˆ’ğ¾ focuses mostly on API usage terms. â€¢ ğ‘€ğ‘–ğ‘‘âˆ’ğ‘ Percentile: features where we rank the normalized NSPF or ILF and remove the top and bottom(100âˆ’ ğ‘ )/2 percentile. In addition to API usage terms, it focuses on method structures that typically not captured byğ‘¡ğ‘œğ‘âˆ’ğ¾approach. If the frequencies of the î€›ltered features exceedsğ¾, we then cap the size to ğ¾ by removing the bottom percentile. Figure 5 demonstrates the selected terms from an example code snippet. This is theğ‘†ğ‘’ğ‘™ğ‘’ğ‘ğ‘¡ ğ¹ğ‘’ğ‘ğ‘¡ğ‘¢ğ‘Ÿğ‘’step in Algorithm 1. We shown that ILF and NSPF score representative terms, such as API usage variables, higher, whereas standard techniques that rank purely on the count of the structural features does not, as indicated by the Full ASTs column. Our methodology enables a similarity search to be conducted on a compact and discriminative term set. The î€›nal step of our proposed lightweight search process is the application of Locality Sensitive Hashing (LSH) to the MinHash signatures generated from relevant terms î€›ltered by Top-K or MidN percentile. With the smaller set of colliding code fragments, we apply exact similarity search by computing the dot product between the query and the candidates to further reî€›ne the results. We evaluate retrieval eî€ectiveness on two publicly available code search corpora: CodeSearchNet [16] (CSN) and the Neural Code Search Evaluation Dataset [29] (NCS). The statistics of both datasets are shown in Table 1. Automatic evaluation:CodeSearchNet [16] consists of 99 natural language queries with their respective relevant code snippets. Figure 5: Comparison in the structural features retained by the Top-K and Mid-N Percentile feature selection techniques. The example code snippet is at the top and the features retained in the table below. The Neural Code Search (NCS) Evaluation Dataset [29] contains 287 Stack Overî€ow questions and code answer pairs on topics related to Android programming. As we are interested in code-to-code recommendation we use the paired natural language-code snippet pairs in these datasets to generate groundtruth code-code snippet pairs. To generate our groundtruth dataset we consider as relevant snippets with the same natural language question. This permits us to measure both precision and recall of retrieval, which was not possible with the micro-benchmarking methodology employed by the Aroma authors [35]. With related code snippet clusters formed in this way, we randomly choose one snippet from the cluster as the query and consider the remaining snippets as part of our database over which retrieval for that query is performed. We remove duplicate snippets by computing the SHA1 hash of the snippetâ€™s feature vector instead of a hash of the entire code snippet, where, for example, the same snippets but with diî€erent local variable naming or docstrings will be î€›ltered out. User Study:In addition to the automated evaluation, we also conducted a user study to evaluate retrieval eî€ectiveness. The results are presented in Table 5. We followed a pooling technique [21] to manually annotate a subset of the NCS dataset. More speciî€›cally, we randomly sampled a subset of 73 queries from NCS dataset and pooled results from three retrieval systems, one based on natural language (matching the question associated with the snippet in the NCS dataset with questions associated with the database snippets) and two based on source code structure (Aroma, Senatus). 10 queries were the same for each annotator, to facilitate computation of the inter-annotator agreement. We then asked four expert developers to answer the question Imagine you are programming the query code snippet, would you î€›nd the retrieved result useful for completing your programming task?. The annotators were allowed to select a score on a scale of 1-5, with 1 indicating not useful and 5 indicating very useful. The grades were then normalized into binary label with min-max scaling and thresholding: a result is deemed useful if the normalized rating is higher than 0.5 and not useful if lower than 0.5. In total 1510 query-result snippet pairs were manually annotated, providing a rich dataset for evaluation The inter-annotator agreement (Kappa statistic [9]) was 0.53, indicating a moderate agreement between the annotators, which is encouraging given the subjective nature and diî€œculty of the task. Table 2: Minhash LSH Parameter Settings: we studied the changes to retrieval performance when number of bands (ğµ) and numb er of rows (ğ‘…) varies with a validation set from the Neural Code Search (NCS) dataset. We then select the optimal parameters with the highest F1 score. Table 3: Feature Selection Parameter Study: we investigated how diî€erent values of ğ¾ and ğ‘ impacts the performance and retrieval time. The parameters that oî€ers the highest F1 Score were selected i.e. ğ¾ = 100 and ğ‘ = 95 Minhash LSH requires the setting of the number of bands (ğµ) and number of rows (ğ‘…). We evaluated the performance and speed with varyingğµandğ‘…on 20 randomly selected queries and 200,000 code snippets from Neural Code Search (NCS) with the NSPF approach, and summarized the î€›ndings in Table 2. We err on the side of recall and selected the range ofğµandğ‘…that gives us an approximate threshold less than 0.2. The optimal parameters areğ‘ =50, ğ‘Ÿ =2 for NCS, which equate to a likely Jaccard similarity between candidate similar snippets of at leastğ‘¡ =0.14 for NCS. Following a similar Table 4: Comparison of Retrieval Performance. P, R, Time refer to the precision, recall and average query time in seconds respectively. â€œ*" indicates that the improvement is statistically signiî€›cant as compared to the baseline, Aroma, using a paired t-test (ğ‘ < 0.05) and bold numbers indicate the best performance in that column. Senatus - DeSkew LSH (this paper) approach, we setğ‘ =100, ğ‘Ÿ =2 for CodeSearchNet (CSN), which also equates to a similar approximate Jaccard similarity ofğ‘¡ =0.10. We have also investigated the eî€ect ofğ¾andğ‘on the performance. These values determine the number of features used for MinHash, where the largerğ¾orğ‘the more features are selected and vice versa. Using the same experimental settings as the LSH parameter study, we set the values empirically via grid search:ğ¾ =100 andğ‘ =2.5 that have the highest F1 Score. Table 3 highlighted the most notable î€›ndings from the grid search, where 100â©½ ğ¾ â©½500 and 95â©½ ğ‘ â©½99. The search range fromğ‘is straight forward and the range forğ¾stems from Figure 2. It indicates that the majority of the code snippets are distributed between 100 and 1000 for both datasets, and we err on the side of retrieval time, we studied the range between 100 and 500 (query time increases as the features size results increases). Therefore, we argue that the î€›ltered number of features should also fall within the same range, as less than 100 results in signiî€›cant information loss and more than 500 results in bias from the skewness stated in Section 3.2. Both datasets share the sameğ¾andğ‘values due to the close similarity in their distributions of code snippet lengths. Our quantitative evaluation examines the performance of the lightweight search stage in Aroma versus De-Skew LSH of Senatus and the end-to-end performance with the additional downstream stages of re-ranking, clustering and intersection. For Aroma lightweight search versus De-Skew LSH, Table 4 summarizes the quantitative results in terms of Precision@100, Recall@100 and F1@100 and average retrieval time (in seconds). Also compared are MinHash [7] and Asymmetric MinHash [44]. Figure 7 summarizes the end-to-end system performance. Improvement in retrieval time and quality:For search over corpora with millions of methods, we î€›nd that Senatus De-Skew LSH empirically outperforms the light-weight search stage from Aroma. In particular, on the CodeSearchNet corpus Senatus DeSkew LSH outperforms Aroma by +7% F1@100 and is 16.6x faster. Figure 6: Comparison of Scalability in terms of the number of operations O, retrieval time (seconds) and the impact of query length. We empirically show that Senatus (red) has a O(ğ‘™ğ‘œğ‘”ğ‘ ) retrieval time regardless of query length. ğ‘„ğ‘– represents the ğ‘–-th quartile, ğ‘– âˆˆ {1,2,3,4}, in the distribution of feature lengths. On the Neural Code Search dataset, Senatus De-Skew LSH outperforms Aroma by 1.77x F1@100 and is 13.1x faster. Comparing Table 5: Comparison of Retrieval Performance with Manual Annotations (Kappa=0.53). The improvement to Senatus is statistically signiî€›cant as compared to Aroma Lightweight Search using a paired t-test (ğ‘ < 0.05). Senatus De-Skew LSH to the traditional MinHash approach that uses Jaccard similarity and Asymmetric MinHash we î€›nd significant increases in F1@100, showing the promise of our proposed feature scoring and feature selection methodologies (ILF, NSPF). More speciî€›cally, we found that Top-K + NSPF oî€ers a better quality and speed trade-oî€s as suggested by the performance breakdown in Table 4. We further evaluated the retrieval quality of similarity against Aroma and natural language based system, where it retrieves snippets that have semantically similar questions in the NCS dataset. The semantic meaning is derived from the cosine similarity between the bag of words (BoW) representation of the natural language questions. We see a 15% improvement in retrieval quality when compared to Aroma and 51% increase compared to question matching as indicated by the F1@10 score in Table 5. Search at Scale:Figure 6 demonstrates the scalability of DeSkew LSH stage from Senatus when compared to light-weight search from Aroma using the NCS dataset. We measure the average number of operations and retrieval time against the number of methods in the corpus together with the impact of query length. Unlike Aroma, the retrieval time for Senatus only grows logarithmically with the corpus size and the query length has minimal impact onOand time. More speciî€›cally, the queries with the length within the î€›rst and last quartile result in slightly shorter retrieval time as there are less colliding snippets evidenced by the power-law distributions in Figure 2. Conciseness and Diversity:Finally, we evaluate the end-toend performance of Aroma and Senatus with re-ranking and pruning, clustering and intersection all following the De-Skew LSH stage (see Figure 1). For eî€ective code-to-code recommendation we desire that the returned snippets are both diverse and a concise extension of the query snippet. The ratio between the length of the query snippets and the ground-truth snippets is an indicator of the conciseness of the recommended snippets. Much longer (and conversely, much shorter) retrieval snippets are arguably less useful as they will likely contain functionality that is very diî€erent (and therefore not useful) to the much smaller query snippet or they will lack any additional information compared to the query snippet (if shorter than the query). In Figure 7, the candidate lengths retrieved by Aroma are severely skewed with a heavy-tail when compared to the generated ground-truth pairs from the NCS dataset, whereas Senatus retrieves snippets closer to the groundtruth distribution. In Table 7, we also observe a similar behaviour with the average pairwise similarity between the recommended snippets. This measures the diversity of the recommendations, whereby a relatively lower similarity score i.e. more distinct, leads to more diverse set of recommendations. Senatus has a lower containment score i.e. more Figure 7: Comparison of the ratio of query-to-candidate snippets length and average pairwise similarity between recommended snippets. Senatus (middle) recommends more concise and diverse code snippets, whereas Aroma can recommend much longer snippets with respect to the query size, which are arguably less useful. diverse. The bias explained explained in Section 3 led to Senatus having a higher Jaccard similarity than Aroma as evidenced by the containment score and length ratio. The similarity between recommendations from Senatus is signiî€›cantly closer to the groundtruth. These results combined provide evidence that Senatus provides more concise and diverse code recommendations. We present Senatus, a code-to-code recommendation engine. Senatus incorporates several innovations to enable high scalability and best-in-class accuracy. We present De-Skew LSH which adapts Minhash LSH to the sourcecode retrieval domain to reduce the number of similarity computation operations. We provide an analysis of two public code datasets and show how they both present a characteristic power-law distribution on code snippet length. We demonstrate that the skewness is a detriment to retrieval eî€ectiveness and we propose two novel feature scoring methods inspired by TF-IDF term scoring: 1) Normalized Sub-Path Frequency (NSPF) and 2) Inverse Leaves Frequency (ILF) feature scoring mechanisms to address the bias. Incorporating De-Skew LSH into our code recommendation engine Senatus leads to fast search time and improved recommendation quality. Future work in this area is many and varied. We will explore relevance feedback so that the user is able to provide feedback on the search quality, which can then be used to further improve the rankings. Investigating learning-to-rank in this î€›eld is particularly attractive, in particular how weakly supervised labels [49] could be used in a learning-to-rank context for code search. Furthermore, more sophisticated approaches in capturing logical blocks of code in Jupyter Notebooks could enable higher quality recommendations, especially in the domains of data science and machine learning.
<title>How to Eî€˜ectively Identify and Communicate Person-Targeting Media Bias in Daily News Consumption?</title> <title>1. Introduction</title> <title>arXiv:2110.09151v1  [cs.CY]  18 Oct 2021</title> <title>2. Related Work</title> Media bias has been long studied in the social sciences, resulting in a comprehensive set of models to describe it, such as political framing [ ] and the news production process deî€›ning causes, forms, and eî€˜ects of bias [ ], and eî€˜ective methods to analyze it [ ]. Established methods, such as content analysis and frame analysis [ ], typically include systematic reading and labeling of texts. Despite their high eî€˜ectiveness and reliability, they are largely conducted manually and do not scale with the vast amount of news. In contrast, many methods in computer science concerned with media bias employ automated and thus more eî€cient approaches but yield non-optimal results [ ], e.g., because they treat bias as only vaguely deî€›ned â€œtopic diversityâ€ ] or â€œdiî€˜erences in [news] coverageâ€ [ ]. Though, methods for the identiî€›cation of biased words exist for other domains, such as Wikipedia articles [9]. Helping news consumers to become aware of media bias is an eî€˜ective means to mitigate the negative eî€˜ects of slanted news coverage, such as polarization [ 10 ]. Moreover, most studies î€›nd that automated approaches concerned with the communication of biases in the news can successfully increase bias-awareness in news consumers [ 11 12 13 14 ]. However, previous approaches suî€˜er from at least one of the following shortcomings. First, researchers cannot quantitatively pinpoint which individual components facilitate bias-awareness [11, 12, 13, 14]. Instead, studies measure overall eî€˜ectiveness of analysis or visualizations. Second, approaches are concerned with the identiî€›cation or communication of biases only in titles [ 11 ], on the article-level [ 14 ], or outlet-level [ 15 ]. Considering only the overall article or even properties of its publisher, may lead to incorrect classiî€›cation or missing instances of bias, e.g., that aî€˜ect readersâ€™ perception on the sentence-level. In sum, many approaches eî€˜ectively communicate biases to users and most studies indicate how society beneî€›ts from doing so. However, many approaches identify only vaguely deî€›ned or superî€›cial biases, e.g., because they do not use the established, eî€˜ective models and analyses. Further, none of the reviewed approaches narrows down eî€˜ectiveness regarding change in bias-awareness to individual analysis and visualization components. Lastly, to our knowledge, no approach identiî€›es biases on the sentence level in news articles. <title>3. System</title> Given a set of news articles reporting on the same political event, our systemâ€™s analysis aims to î€›nd groups of articles that frame the event similarly using four analysis tasks. These groups are later visualized (Section 4) to enable non-expert news consumers to quickly get a bias-sensitive synopsis of a given news event. For (1) article gathering, we extract news articles reporting on one event [ 16 ], currently for a set of user-deî€›ned URLs, or by providing texts to the system. We then perform state-of-the-art NLP (2) preprocessing using Stanford CoreNLP. (3) Target concept analysis î€›nds and resolves person mentions across the topicâ€™s articles, including also broadly deî€›ned and event-speciî€›c coreferences that are otherwise non-coreferential or even opposing, such as â€œfreedom î€›ghtersâ€ and â€œterroristsâ€ [3]. (4) Frame identiî€›cation determines how articles portray persons and then groups those articles that similarly portray (or frame) the persons. This task centers around political framing [ ], where a frame represents a speciî€›c perspective on an issue, e.g., which aspects are highlighted when reporting on the issue. While identifying frames would approximate content analyses as conducted in social science research on media bias more closely, it would yield lower classiî€›cation performance [ 17 18 ] or require infeasible eî€˜ort since frames are typically created for a speciî€›c research-question [ ]. Our system, however, is meant to analyze media bias caused by framing on any coverage reporting on policy issues. Thus, we seek to determine a fundamental eî€˜ect resulting from framing: polarity of individual persons, which we identify on sentenceand aggregate to article-level. To achieve state of-the-art performance in target-dependent sentiment classiî€›cation (TSC) on news articles, we use a î€›ne-tuned RoBERTa-based neural model (ğ¹ 1 = 83.1) [19]. The last step of frame identiî€›cation is to determine groups of articles that similarly frame the event, i.e., the persons involved in the event. We currently use a simple, polarity-based method that î€›rst determines the person that occurs most frequently across all articles, named most frequent actor (MFA). Then, the method assigns each article to one of three groups, depending on whether the articleâ€™s MFA mentions are mostly positive, ambivalent, or negative. We also calculate each articleâ€™s relevance to the (1) event and the (2) articleâ€™s group using simple word-embedding scoring. <title>4. Visualizations</title> The overall workî€œow follows typical online news consumption, i.e., users see î€›rst an overview of news events and then view individual news articles. To measure eî€˜ectiveness not only of our visualizations but also their constituents, we design them so that their components can be altered. To more precisely measure the change in bias-awareness concerning only the textual content, the visualizations show texts of articles (and information about biases in the texts) but no other content, e.g., photos and outlet name. The overview aims to enable users to quickly get a synopsis of a news event. We devise three visualizations. (1) Plain represents popular news aggregators. Using a bias-agnostic design similar to Google News, this baseline shows article headlines and excerpts in a list sorted by their relevance to the event (Section 3). (2) PolSides, which represents a bias-aware news aggregator [ 15 ], and (3) MFAP share a bias-aware, comparative layout but use diî€˜erent methods to determine which frames or biases are present in event coverage. The layout of PolSides and MFAP is vertically divided in three parts, two of which are shown in Figure 1. The eventâ€™s main article (part A) shows the eventâ€™s most representative article. The comparative bias-groups part (C) shows up to three frames present in event coverage, by showcasing each frameâ€™s most representative article. PolSides yields these frames by grouping articles depending on their political orientation (left, center, and right) [ 15 ]. For MFAP, we use our polarity-based grouping (Section 3) so that the resulting groups represent frames that are primarily in favor, against, or ambivalent regarding the eventâ€™s MFA. Conceptually, PolSides employs the left-right dichotomy, which is a simple yet often eî€˜ective means to partition the media into distinctive slants. However, this dichotomy is determined only on the outlet-level and thus may incorrectly classify event-speciî€›c framing, e.g., articles with diî€˜erent perspectives having supposedly identical perspectives (and vice versa). Finally, a list shows the headlines of further articles reporting on the event (bottom, not shown in Figure 1). In each overview, further components can be enabled depending on the conjoint proî€›le (cf. Section 5). PolSides tags (shown close to D in Figure 1) and/or MFAP tags are shown next to each article headline, and indicate the political orientation of the articleâ€™s outlet and the articleâ€™s overall polarity regarding the MFA, respectively. The article view shows an articleâ€™s text and optionally the following visual clues to communicate bias information: (1) in-text polarity highlights, (2) polarity context bar, (3) PolSides tags, and (4) MFAP tags (with identical function to those in the overview). These clues are enabled, disabled, or altered depending on the conjoint proî€›le. In-text polarity highlights aim to enable users to identify person-targeting sentiment on the sentence-level. We test the eî€˜ectiveness of the following modes: single-color (visually marking a person mention using a neutral color, i.e., gray, if the respective sentence mentions the person positively or negatively), two-color (using green and red colors for positive and negative mentions, respectively), three-color (same as two-color and additionally showing neutral polarity as gray), and disabled (no highlights are shown). The polarity context bar aims to enable users to quickly contrast how the current article and others portray the MFA. The 1D scatter plot depicted in Figure 2 places articles as circles depending on their overall polarity regarding the MFA. <title>5. Experiments</title> To evaluate the eî€˜ectiveness of our system in supporting non-expert users to become aware of biases in news coverage, we conducted a user study consisting of two conjoint experiments. The study seeks to answers two research questions. What are eî€˜ective means to communicate biases to non-expert news consumers when viewing an overview of a news topic (RQ1) and when reading a single news article (RQ2)? The î€›rst experiment (E1) focuses on improving the general design of the overview (RQ1), while the second experiment (E2) focuses on answering both RQ1 with improved visualizations and RQ2. All survey data including questionnaires and anonymized respondentsâ€™ information is available freely (Section 1). In both experiments, we used a conjoint design to â€œseparately identify [. . .] component-speciî€›c causal eî€˜ects by randomly manipulating multiple attributes of alternatives simultaneouslyâ€ 20 ]. Respondents are asked to rate so-called â€œproî€›les,â€ which consist of multiple â€œattributes,â€ which are for example the overview, which topic it shows (or which article is shown in the article view), and if or which tags or in-text color highlights are shown. In conjoint design, these attributes are chosen randomly and independently of another for each respondent, which allows an estimation of the relative inî€œuence of each component on the bias-awareness (called Average Marginal Component Eî€˜ects (AMCE)) [20]. We selected three news topics to ensure varying degrees of expected polarization as an indicator for biased coverage: gun control (high polarization), debt ceiling (high-mid), and Australian bushî€›res (low). We selected a single event for each topic. To ensure heterogeneity in content and writing styles, we manually retrieved a balanced selection of ten articles from left-, center, and right-wing US online outlets as self-identiî€›ed by them. We conducted both experiments on Amazon Mechanical Turk. Respondents had to be located in the US, have a history of successfully completed, high quality work, and were compensated 1-2$ depending on the study duration. In E1, we used data of 260 (of 308) respondents, which satisî€›ed our quality measures, i.e., we discarded 48 respondents that, e.g., were unrealistically fast or answered test questions incorrectly. To keep cognitive load low, respondents were shown only a single topic in the overview, which was randomly drawn from the aforementioned selection. In E2, we used data of 98 (of 110) respondents. To increase cost eî€ciency, we only showed a selection of overview variants that exhibited positive trends in E1 (instead of fully randomly varying all attributes as in E1). Further, we showed respondents three tasks (resulting in 294 tasks in total), where each task consisted of a single overview and article view. Our study consists of seven steps. A (1) pre-study questionnaire asks demographic data [ 21 ]. (2) Overview (as described in Section 4.1). A (3) post-overview questionnaire operationalizes the biasawareness in respondents by asking about their perception of the diversity and disagreement in viewpoints, whether the visualization encourages contrasting the individual headlines, and how many perspectives of the public discourse were shown. While it is â€œintrinsically diî€cult to objectively deî€›ne what bias isâ€ [ 12 ], on a high level we expect bias to be perceived in the form of diî€˜erences in and opposition of the slant of articles; hence, we operationalize bias-awareness as the motivation and skill of a person to compare and contrast perspectives and information presented in the news using a set of 10-point Likert scaled questions, such as â€œWhen shown the overview, did this encourage you to compare and contrast the diî€˜erent articles?â€ (4) Article view (as described in Section 4.2). A (5) post-article questionnaire operationalizes bias-awareness in respondents [ 21 ]. In a (6) post-study questionnaire, users give feedback on the study, i.e., what they (dis)liked. E1 consisted of steps (1â€“3, 6). E2 consisted of all steps, where (2, 3) may be skipped depending on the conjoint proî€›le and (2â€“5) were repeated three times since three topics were shown. We found positive, signiî€›cant eî€˜ects on the change in bias-awareness when using the overview variants PolSides or MFAP (RQ1) in E2. Tags also increased bias-awareness signiî€›cantly. Regarding the article view (RQ2), E2 yielded insigniî€›cant results. Prior to E2, we focused our evaluation of E1 on qualitatively identifying î€œaws in the design of visualizations and the study, due to the lack of signiî€›cant trends in E1. For example, 35% users experienced a lack of clarity and transparency, e.g., how the visualized information was derived. This weakness was exaggerated if respondents felt the shown information was incorrect (6% PolSides, 11% MFAP), e.g., an article that seemed negative from its headlines was labeled as ambivalent. Prior to E2, we addressed all the major lines of criticism, e.g., by adding brief explanations about all visual clues and in particular about the bias grouping (see B in Figure 1). The goal of E2 was to test the set of overviews that had positive trends in E1 (to answer RQ1) and to test components in the article view (RQ2). E2 showed positive, signiî€›cant eî€˜ects of both bias-sensitive overviews, where the best overviews were PolSides (with PolSides tags) and MFAP (without tags). The AMCEs in Table 1 show that both overviews have very high and strongly signiî€›cant eî€˜ectiveness (PolSides ğ¸ğ‘ ğ‘¡ = 7.83 and MFAP ğ¸ğ‘ ğ‘¡ = 6.13 , which are not signiî€›cantly diî€˜erent to another albeit one being slightly higher [ 22 ]). Quantitative (by analyzing the eî€˜ects on the individual questions composing the overall post-overview score) and qualitative analysis of both overviews suggests that MFAP reveals biases that are actually present in the news articles, whereas PolSides only facilitates the visibility of biasesâ€”a typical issue of prior approaches for automated bias detection [ 14 ]. By imitating the content analysis, our system yielded substantial frames as shown in Figure 1 whereas PolSides showed, e.g., the following headlines of rather â€œartiî€›cialâ€ frames: â€œTrump Announces Deal On Debt Limit, Spending Capsâ€ and â€œTrump, Congress Clinch Debt-Limit Deal After Tense Negotiations.â€ MFAP (random), an overview where articles were randomly assigned to one bias-group, yielded ğ¸ğ‘ ğ‘¡ = 5.76 , indicating that only pointing out possible biases already increased bias-awareness. In MFAP, showing no tags yielded the highest eî€˜ectiveness ( 6.13 compared to 5.87 when both tags were shown). This indicates that the MFAP design reveals â€œenoughâ€ bias information and further visual clues may yield too complex visualizations. None of the tags alone have signiî€›cant eî€˜ects when combined with the Plain version, indicating that a bias-group layout is necessary for bias-awareness. In the article view, only showing the PolSides tags had a signiî€›cant positive eî€˜ect on bias awareness ( 2.45 ). There were no signiî€›cant eî€˜ects for the MFAP tags and polarity context bar. Analyzing respondentsâ€™ criticism in the post-study questions, we attribute this to two shortcomings. First, too few in-text highlights to have a consistent eî€˜ect (21% of the article views had â‰¤ 5 highlights, 7% had none). When controlling for the number of highlights, they had a signiî€›cant, positive eî€˜ect on bias-awareness. Second, there was a strong inî€œuence of individual topics on the eî€˜ectiveness, e.g., respondents reported the debt ceiling topic was â€œtoo complicatedâ€ or â€œboringâ€ to follow. We plan to address this by conducting a study with more respondents and a wider range of topics, to ensure a better representation of the public discourses. Doing so will also strengthen the generalizability of the results and allow to investigate the eî€˜ects of usersâ€™ demographic data on their bias-awareness and change thereof [ 23 ]. Due to the small sample size in E2, our current analysis was inconclusive regarding demographic eî€˜ects. Although we did not î€›lter for a representative sample of the US population, the distributions of our samples are approximately similar to the distributions of the US population in key dimensions such as age and political education. However, we propose to verify the generalizability of the studyâ€™s î€›ndings to the entire US population or other countries using a larger respondent sample. Further, in E1 and E2 we assumed that MTurk workers are mostly non-expert news consumers. To verify this, we propose to explicitly ask for participantsâ€™ degree of media literacy. <title>6. Conclusion</title> We present the î€›rst system to automatically identify and then communicate person-targeting forms of bias in news articles reporting on policy events. Earlier, these biases could only be identiî€›ed using content analyses, whichâ€“despite their eî€˜ectiveness in capturing also subtle yet powerful biasesâ€“could only be conducted for few topics in the past due to their high cost, manual eî€˜ort, and required expertise. In a large-scale user study, we employ a conjoint design to measure the eî€˜ectiveness of visualizations and individual components. We î€›nd that our overviews signiî€›cantly increase bias-awareness in respondents. In particular and in contrast to prior work, our bias-identiî€›cation method seems to reveal biases that emerge from the content of news coverage and individual articles. In practical terms, our results suggest that the biases found and communicated by our method are actually present in the news articles, whereas the reviewed prior work only facilitates detection of biases, e.g., by distinguishing between left- and right-wing outlets. In sum, our exploratory work indicates the eî€˜ectiveness of bias-sensitive news recommendation as a promising line of research for future work. <title>Acknowledgments</title> This work is funded by the WIN program of the Heidelberg Academy of Sciences and Humanities, î€›nanced by the Ministry of Science, Research and the Arts of the State of Baden-WÃ¼rttemberg, Germany. The authors thank the anonymous reviewers for their valuable comments that helped to improve this paper. <title>References</title> [1] S. DellaVigna, E. Kaplan, The Fox News Eî€˜ect: Media Bias and Voting, Technical Report 3, National Bureau of Economic Research, Cambridge, MA, 2006. URL: http://www.nber.org/ papers/w12169.pdf. doi:10.3386/w12169. [2] C. Budak, What happened? The Spread of Fake News Publisher Content During the 2016 U.S. Presidential Election, in: The World Wide Web Conference on - WWW â€™19, ACM Press, New York, New York, USA, 2019, pp. 139â€“150. URL: http://dl.acm.org/citation.cfm? doid=3308558.3313721. doi:10.1145/3308558.3313721. [3] F. Hamborg, K. Donnay, B. Gipp, Automated identiî€›cation of media bias in news articles: an interdisciplinary literature review, International Journal on Digital Libraries 20 (2019) 391â€“415. URL: https://doi.org/10.1007/s00799-018-0261-y. doi: [4] F. Hamborg, Media Bias, the Social Sciences, and NLP: Automating Frame Analyses to Identify Bias by Word Choice and Labeling, in: Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop, Association for Computational Linguistics, Stroudsburg, PA, USA, 2020, pp. 79â€“87. URL: https://www. aclweb.org/anthology/2020.acl-srw.12. doi:10.18653/v1/2020.acl-srw.12. [5] R. M. Entman, Framing Bias: Media in the Distribution of Power, Journal of Communication 57 (2007) 163â€“173. URL: https://academic.oup.com/joc/article/57/1/163-173/4102665. doi:10.1111/j.1460-2466.2006.00336.x. [6] M. S. Davis, E. Goî€˜man, Frame Analysis: An Essay on the Organization of Experience., Contemporary Sociology 4 (1975) 599. URL: http://www.jstor.org/stable/2064021?origin= crossref. doi:10.2307/2064021. [7] S. Park, M. Ko, J. Kim, Y. Liu, J. Song, The politics of comments, in: Proceedings of the ACM 2011 conference on Computer supported cooperative work - CSCW â€™11, ACM, ACM Press, New York, New York, USA, 2011, p. 113. URL: http://portal.acm.org/citation.cfm? doid=1958824.1958842. doi:10.1145/1958824.1958842. [8] S. A. Munson, D. X. Zhou, P. Resnick, Sidelines: An Algorithm for Increasing Diversity in News and Opinion Aggregators., in: ICWSM, 2009. [9] M. Recasens, C. Danescu-Niculescu-Mizil, D. Jurafsky, Linguistic Models for Analyzing and Detecting Biased Language, in: Proceedings of the 51st Annual Meeting on Association for Computational Linguistics, Association for Computational Linguistics, Soî€›a, BG, 2013, pp. 1650â€“1659. URL: https://www.aclweb.org/anthology/P13-1162.pdf. [10] S. Mullainathan, A. Shleifer, The market for news, American Economic Review (2005) 1031â€“1053. [11] H.-K. Kong, Z. Liu, K. Karahalios, Frames and Slants in Titles of Visualizations on Controversial Topics, in: Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems, ACM, New York, NY, USA, 2018, pp. 1â€“12. URL: https: //dl.acm.org/doi/10.1145/3173574.3174012. doi:10.1145/3173574.3174012. [12] S. Park, S. Kang, S. Chung, J. Song, NewsCube: Delivering multiple aspects of news to mitigate media bias, in: Proceedings of the 27th international conference on Human factors in computing systems - CHI 09, ACM Press, New York, New York, USA, 2009, p. 443. URL: http://dl.acm.org/citation.cfm?doid=1518701.1518772. doi: [13] S. Park, M. Ko, J. Kim, H. Choi, J. Song, NewsCube 2.0: An Exploratory Design of a Social News Website for Media Bias Mitigation, in: Workshop on Social Recommender Systems, 2011. [14] F. Hamborg, N. Meuschke, B. Gipp, Bias-aware news analysis using matrix-based news aggregation, International Journal on Digital Libraries 21 (2020) 129â€“147. URL: http: //link.springer.com/10.1007/s00799-018-0239-9. doi:10.1007/s00799-018-0239-9. [15] AllSides.com, AllSides - balanced news, 2021. [16] F. Hamborg, N. Meuschke, C. Breitinger, B. Gipp, news-please: A Generic News Crawler and Extractor, in: Proceedings of the 15th International Symposium of Information Science, Verlag Werner HÃ¼lsbusch, 2017, pp. 218â€“223. [17] D. Card, A. E. Boydstun, J. H. Gross, P. Resnik, N. A. Smith, The Media Frames Corpus: Annotations of Frames Across Issues, in: Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 2: Short Papers), Association for Computational Linguistics, Stroudsburg, PA, USA, 2015, pp. 438â€“444. URL: http://aclweb.org/anthology/ P15-2072. doi:10.3115/v1/P15-2072. [18] D. Card, J. Gross, A. Boydstun, N. A. Smith, Analyzing Framing through the Casts of Characters in the News, in: Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics, Stroudsburg, PA, USA, 2016, pp. 1410â€“1420. URL: http://aclweb.org/anthology/D16-1148. doi: [19] F. Hamborg, K. Donnay, Newsmtsc: (multi-)target-dependent sentiment classiî€›cation in news articles, in: Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics (EACL 2021), 2021, pp. 1663â€“1675. [20] J. Hainmueller, D. J. Hopkins, T. Yamamoto, Causal Inference in Conjoint Analysis: Understanding Multidimensional Choices via Stated Preference Experiments, Political Analysis 22 (2014) 1â€“30. URL: https://www.cambridge.org/core/product/identiî€›er/S1047198700013589/ type/journal_article. doi:10.1093/pan/mpt024. [21] T. Spinde, F. Hamborg, K. Donnay, A. Becerra, B. Gipp, Enabling News Consumers to View and Understand Biased News Coverage: A Study on the Perception and Visualization of Media Bias, in: Proceedings of the ACM/IEEE Joint Conference on Digital Libraries in 2020, ACM, New York, NY, USA, 2020, pp. 389â€“392. URL: https://dl.acm.org/doi/10.1145/ 3383583.3398619. doi:10.1145/3383583.3398619. [22] A. Gelman, H. Stern, The Diî€˜erence Between â€œSigniî€›cantâ€ and â€œNot Signiî€›cantâ€ is not Itself Statistically Signiî€›cant, The American Statistician 60 (2006) 328â€“331. URL: http://www. tandfonline.com/doi/abs/10.1198/000313006X152649. doi: [23] K. Coe, D. Tewksbury, B. J. Bond, K. L. Drogos, R. W. Porter, A. Yahn, Y. Zhang, Hostile News: Partisan Use and Perceptions of Cable News Programming, Journal of Communication 58 (2008) 201â€“219. URL: https://academic.oup.com/joc/article/58/2/201-219/4098517. doi: